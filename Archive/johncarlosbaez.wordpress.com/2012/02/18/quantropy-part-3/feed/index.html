<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Quantropy (Part 3)	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/</link>
	<description></description>
	<lastBuildDate>Mon, 11 Nov 2013 23:03:05 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: Quantropy (Part 4) &#124; Azimuth		</title>
		<link>https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-33952</link>

		<dc:creator><![CDATA[Quantropy (Part 4) &#124; Azimuth]]></dc:creator>
		<pubDate>Mon, 11 Nov 2013 23:03:05 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=8079#comment-33952</guid>

					<description><![CDATA[If you have carefully read all my previous posts on quantropy (Part 1, Part 2 and Part 3), there&#8217;s only a little new stuff here. But still, it&#8217;s better organized [&#8230;]]]></description>
			<content:encoded><![CDATA[<p>If you have carefully read all my previous posts on quantropy (Part 1, Part 2 and Part 3), there&#8217;s only a little new stuff here. But still, it&#8217;s better organized [&#8230;]</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-16762</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sat, 14 Jul 2012 03:08:11 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=8079#comment-16762</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-16759&quot;&gt;Robin Oswald&lt;/a&gt;.

Glad you liked the posts!  Actually Planck&#039;s constant is analogous to &lt;i&gt;inverse&lt;/i&gt; temperature, not temperature.  To see this in an intuitive way, note that increasing Planck&#039;s constant increases quantum fluctuations, while increasing temperature increases thermal fluctuations.  Also: we get classical dynamics obeying the principle of least action when Planck&#039;s constant goes to zero, while we get classical statics obeying the principle of least energy when the temperature goes to zero.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-16759">Robin Oswald</a>.</p>
<p>Glad you liked the posts!  Actually Planck&#8217;s constant is analogous to <i>inverse</i> temperature, not temperature.  To see this in an intuitive way, note that increasing Planck&#8217;s constant increases quantum fluctuations, while increasing temperature increases thermal fluctuations.  Also: we get classical dynamics obeying the principle of least action when Planck&#8217;s constant goes to zero, while we get classical statics obeying the principle of least energy when the temperature goes to zero.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Robin Oswald		</title>
		<link>https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-16759</link>

		<dc:creator><![CDATA[Robin Oswald]]></dc:creator>
		<pubDate>Sat, 14 Jul 2012 01:11:18 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=8079#comment-16759</guid>

					<description><![CDATA[Interesting series of posts! Just a small typo at the end:

&lt;blockquote&gt;In statistical mechanics we have

$latex \beta = \frac{1}{kT}$

while in quantum mechanics we have

$latex \beta = i\hbar$
&lt;/blockquote&gt;

The last equation should obviously be 

$latex \beta = \frac{1}{i \hbar}$]]></description>
			<content:encoded><![CDATA[<p>Interesting series of posts! Just a small typo at the end:</p>
<blockquote><p>In statistical mechanics we have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3D+%5Cfrac%7B1%7D%7BkT%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta = &#92;frac{1}{kT}" class="latex" /></p>
<p>while in quantum mechanics we have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3D+i%5Chbar&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta = i&#92;hbar" class="latex" />
</p></blockquote>
<p>The last equation should obviously be </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3D+%5Cfrac%7B1%7D%7Bi+%5Chbar%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta = &#92;frac{1}{i &#92;hbar}" class="latex" /></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Nathaniel Virgo		</title>
		<link>https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14973</link>

		<dc:creator><![CDATA[Nathaniel Virgo]]></dc:creator>
		<pubDate>Sat, 21 Apr 2012 14:07:57 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=8079#comment-14973</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14967&quot;&gt;John Baez&lt;/a&gt;.

I agree, the math is exactly the same - it&#039;s the interpretation I&#039;m trying to get at.  It&#039;s kind of a subtle point, and I was afraid I wouldn&#039;t be able to get it across clearly.

The point is that, when doing classical MaxEnt (which I do a lot), sometimes you know $latex \langle E \rangle$ and want to work out $latex \beta$, and sometimes you know $latex \beta$ and want to work out $latex \langle E \rangle$.  I was just pointing out that for quantropy it&#039;s always the latter case. $\lambda$ isn&#039;t a variable whose value depends on the system&#039;s state like $\beta$ is, but rather it is (or appears to be) a universal constant. Beyond that, my point isn&#039;t really anything more than &quot;hey, that&#039;s interesting, I wonder what it means?&quot;

To put it another way, if we lived in an isothermal universe (i.e. one where everything everywhere was connected to a heat bath at a constant temperature) then $\beta$ would have the same value for all systems, and so we&#039;d think of it as a universal constant. That isn&#039;t the universe we live in, though, and $\beta$ has different values for different systems. But for the quantropy case, $\lambda$ does seem to always have the same value, for every system, unless I&#039;ve misunderstood something.  That&#039;s what I meant when I said it looks, naively, like the universe is in contact with a sort of Wick-rotated heat bath (or rather an action bath) with a constant imaginary temperature. I&#039;m not saying that&#039;s a plausible physical picture, just that it&#039;s interesting that that&#039;s what the maths seems to look like.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14967">John Baez</a>.</p>
<p>I agree, the math is exactly the same &#8211; it&#8217;s the interpretation I&#8217;m trying to get at.  It&#8217;s kind of a subtle point, and I was afraid I wouldn&#8217;t be able to get it across clearly.</p>
<p>The point is that, when doing classical MaxEnt (which I do a lot), sometimes you know <img src="https://s0.wp.com/latex.php?latex=%5Clangle+E+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle E &#92;rangle" class="latex" /> and want to work out <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" />, and sometimes you know <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> and want to work out <img src="https://s0.wp.com/latex.php?latex=%5Clangle+E+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle E &#92;rangle" class="latex" />.  I was just pointing out that for quantropy it&#8217;s always the latter case. $\lambda$ isn&#8217;t a variable whose value depends on the system&#8217;s state like $\beta$ is, but rather it is (or appears to be) a universal constant. Beyond that, my point isn&#8217;t really anything more than &#8220;hey, that&#8217;s interesting, I wonder what it means?&#8221;</p>
<p>To put it another way, if we lived in an isothermal universe (i.e. one where everything everywhere was connected to a heat bath at a constant temperature) then $\beta$ would have the same value for all systems, and so we&#8217;d think of it as a universal constant. That isn&#8217;t the universe we live in, though, and $\beta$ has different values for different systems. But for the quantropy case, $\lambda$ does seem to always have the same value, for every system, unless I&#8217;ve misunderstood something.  That&#8217;s what I meant when I said it looks, naively, like the universe is in contact with a sort of Wick-rotated heat bath (or rather an action bath) with a constant imaginary temperature. I&#8217;m not saying that&#8217;s a plausible physical picture, just that it&#8217;s interesting that that&#8217;s what the maths seems to look like.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14967</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sat, 21 Apr 2012 11:29:54 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=8079#comment-14967</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14966&quot;&gt;Nathaniel Virgo&lt;/a&gt;.

I&#039;m glad you liked these posts, Nathaniel!  You wrote:

&lt;blockquote&gt;
That is, you&#039;re not finding a stationary point of the quantropy subject to a constraint $latex \langle A_x \rangle = iA$ for some particular known value of $latex A$ and then choosing $latex \lambda$ such that the constraint is satisfied. Instead it looks like you&#039;re using the Lagrange multiplier technique to find a functional relationship between $latex A$ and $latex \lambda$ and then plugging in a known value of $latex \lambda$ (equal to $latex 1/i\hbar$) to find $latex A$.
&lt;/blockquote&gt;

I don&#039;t think of these as significantly different things.  The way it always works when you&#039;re looking for a stationary point of a function $f$ subject to a constraint on some other function $g$ is that you set 

$latex \nabla (f - \lambda g) = 0 $

and solve the resulting equations.  In this process, it&#039;s pretty much always easier to pick a value of $latex \lambda$ and find out what value the constraint $latex g$ than takes, rather than the other way around---though in terms of the original problem, you usually &lt;i&gt;want&lt;/i&gt; to think of things the other way around.  

In particular, I don&#039;t see anything about the math of quantropy that differs from the math of entropy in this respect.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14966">Nathaniel Virgo</a>.</p>
<p>I&#8217;m glad you liked these posts, Nathaniel!  You wrote:</p>
<blockquote><p>
That is, you&#8217;re not finding a stationary point of the quantropy subject to a constraint <img src="https://s0.wp.com/latex.php?latex=%5Clangle+A_x+%5Crangle+%3D+iA&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle A_x &#92;rangle = iA" class="latex" /> for some particular known value of <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> and then choosing <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;lambda" class="latex" /> such that the constraint is satisfied. Instead it looks like you&#8217;re using the Lagrange multiplier technique to find a functional relationship between <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;lambda" class="latex" /> and then plugging in a known value of <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;lambda" class="latex" /> (equal to <img src="https://s0.wp.com/latex.php?latex=1%2Fi%5Chbar&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/i&#92;hbar" class="latex" />) to find <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" />.
</p></blockquote>
<p>I don&#8217;t think of these as significantly different things.  The way it always works when you&#8217;re looking for a stationary point of a function $f$ subject to a constraint on some other function $g$ is that you set </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cnabla+%28f+-+%5Clambda+g%29+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;nabla (f - &#92;lambda g) = 0 " class="latex" /></p>
<p>and solve the resulting equations.  In this process, it&#8217;s pretty much always easier to pick a value of <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;lambda" class="latex" /> and find out what value the constraint <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="g" class="latex" /> than takes, rather than the other way around&#8212;though in terms of the original problem, you usually <i>want</i> to think of things the other way around.  </p>
<p>In particular, I don&#8217;t see anything about the math of quantropy that differs from the math of entropy in this respect.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Nathaniel Virgo		</title>
		<link>https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14966</link>

		<dc:creator><![CDATA[Nathaniel Virgo]]></dc:creator>
		<pubDate>Sat, 21 Apr 2012 10:45:43 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=8079#comment-14966</guid>

					<description><![CDATA[Hi there

I&#039;ve recently come across this series of posts and found them quite intriguing. I&#039;ve often wondered if there might be a way to get to quantum theory by modifying classical (Bayesian) probability theory in some principled way, and this looks like it might be the beginning of a path that could lead in that direction. 

It&#039;s very interesting stuff, but there&#039;s a slight conceptual issue that&#039;s been bothering me, and I wonder whether thinking about it more might shed some more light on what this analogy really means. I hope I can express it clearly enough.

In the thermal case, when you derive the Boltzmann distribution by maximising the entropy, it&#039;s done subject to to a constraint on the expected energy, i.e. you set $latex \langle E_x \rangle = E$, for some prescribed value $latex E$. Once you&#039;ve done the whole Lagrange multiplier thing you then have to choose the particular value for $latex \beta$ such that the constraint $latex \langle E_x \rangle = E$ is satisfied. $latex \beta$ thus becomes a function of $latex E$.

But then it turns out that in practice you often know $latex \beta$ and not $latex E$, because the system is in contact with a heat bath that fixes the temperature. In this case you still get $latex \beta$ as a function of $latex E$, but you plug in the value of $latex \beta$ to find $latex E$ and not the other way around.

Now, in your quantropy analogy you&#039;re doing the latter thing. That is, you&#039;re not finding a stationary point of the quantropy subject to a constraint $latex \langle A_x \rangle = iA$ for some particular known value of $latex A$ and then choosing $latex \lambda$ such that the constraint is satisfied. Instead it looks like you&#039;re using the Lagrange multiplier technique to find a functional relationship between $latex A$ and $latex \lambda$ and then plugging in a known value of $latex \lambda$ (equal to $latex 1/i\hbar$) to find $latex A$.

So I&#039;m wondering what that really means. I realise you probably don&#039;t have an answer to that yourself, but it seems to me that thinking about it might (or might not) be a useful next step to take. Naively, it looks like it&#039;s saying the universe is in contact with a sort of Wick-rotated heat bath with an imaginary temperature of $latex 1/i\hbar$. But I wonder if there&#039;s some other, more sensible interpretation of this step.]]></description>
			<content:encoded><![CDATA[<p>Hi there</p>
<p>I&#8217;ve recently come across this series of posts and found them quite intriguing. I&#8217;ve often wondered if there might be a way to get to quantum theory by modifying classical (Bayesian) probability theory in some principled way, and this looks like it might be the beginning of a path that could lead in that direction. </p>
<p>It&#8217;s very interesting stuff, but there&#8217;s a slight conceptual issue that&#8217;s been bothering me, and I wonder whether thinking about it more might shed some more light on what this analogy really means. I hope I can express it clearly enough.</p>
<p>In the thermal case, when you derive the Boltzmann distribution by maximising the entropy, it&#8217;s done subject to to a constraint on the expected energy, i.e. you set <img src="https://s0.wp.com/latex.php?latex=%5Clangle+E_x+%5Crangle+%3D+E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle E_x &#92;rangle = E" class="latex" />, for some prescribed value <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E" class="latex" />. Once you&#8217;ve done the whole Lagrange multiplier thing you then have to choose the particular value for <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> such that the constraint <img src="https://s0.wp.com/latex.php?latex=%5Clangle+E_x+%5Crangle+%3D+E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle E_x &#92;rangle = E" class="latex" /> is satisfied. <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> thus becomes a function of <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E" class="latex" />.</p>
<p>But then it turns out that in practice you often know <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> and not <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E" class="latex" />, because the system is in contact with a heat bath that fixes the temperature. In this case you still get <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> as a function of <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E" class="latex" />, but you plug in the value of <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> to find <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E" class="latex" /> and not the other way around.</p>
<p>Now, in your quantropy analogy you&#8217;re doing the latter thing. That is, you&#8217;re not finding a stationary point of the quantropy subject to a constraint <img src="https://s0.wp.com/latex.php?latex=%5Clangle+A_x+%5Crangle+%3D+iA&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle A_x &#92;rangle = iA" class="latex" /> for some particular known value of <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> and then choosing <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;lambda" class="latex" /> such that the constraint is satisfied. Instead it looks like you&#8217;re using the Lagrange multiplier technique to find a functional relationship between <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;lambda" class="latex" /> and then plugging in a known value of <img src="https://s0.wp.com/latex.php?latex=%5Clambda&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;lambda" class="latex" /> (equal to <img src="https://s0.wp.com/latex.php?latex=1%2Fi%5Chbar&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/i&#92;hbar" class="latex" />) to find <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" />.</p>
<p>So I&#8217;m wondering what that really means. I realise you probably don&#8217;t have an answer to that yourself, but it seems to me that thinking about it might (or might not) be a useful next step to take. Naively, it looks like it&#8217;s saying the universe is in contact with a sort of Wick-rotated heat bath with an imaginary temperature of <img src="https://s0.wp.com/latex.php?latex=1%2Fi%5Chbar&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/i&#92;hbar" class="latex" />. But I wonder if there&#8217;s some other, more sensible interpretation of this step.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Garett Leskowitz		</title>
		<link>https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14210</link>

		<dc:creator><![CDATA[Garett Leskowitz]]></dc:creator>
		<pubDate>Thu, 08 Mar 2012 17:19:38 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=8079#comment-14210</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-13907&quot;&gt;John Baez&lt;/a&gt;.

In my mind, the n gates or signposts that are erected in the specification of the particle&#039;s positions are strongly reminiscent of &quot;collapse events.&quot;  By increasing n, we increase the finesse with which we specify what the particle can do on its way from point A to point B, and we make our description of the particle&#039;s time evolution &quot;more classical&quot; - more like a trajectory and less like wavefunction evolution.

This increase in information content seems to require an increase in the action, relative to a fundamental unit, i hbar.

The connection to heat capacity is very interesting.  Heat capacity is a key quantity in thermal physics, and I would hope to see it make it into the table of analogues!

To a physical chemist, the heat capacity measures how many joules of energy are required to cause a kelvin of temperature change.  It is an extensive quantity, and, in my mind anyway, is a measure of &quot;thermally accessible degrees of freedom.&quot;  Is this usefully related to the finesse with which we can (or have to) specify microscopic details of a macroscopically defined, thermal system?

The definition of (constant volume) heat capacity involves a derivative of internal energy with respect to temperature.  The analogue on the quantum side would seem to involve a derivative of action with respect to i hbar.

This analogue might raise and answer (admittedly vague) questions like &quot;quantitatively, how much more quantum would this system behave if i hbar were bigger?&quot;

One final comment regarding the n &quot;gates&quot;:  A study of the harmonic oscillator might be illuminating.  In quantum optics it is possible to produce &quot;squeezed states&quot; of a cavity mode by coupling it resonantly to a detector at multiples of a resonance frequency.  I wonder if judicious selection of the time schedule of selected gate points changes quantities like expected action, etc., in an understandable way.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-13907">John Baez</a>.</p>
<p>In my mind, the n gates or signposts that are erected in the specification of the particle&#8217;s positions are strongly reminiscent of &#8220;collapse events.&#8221;  By increasing n, we increase the finesse with which we specify what the particle can do on its way from point A to point B, and we make our description of the particle&#8217;s time evolution &#8220;more classical&#8221; &#8211; more like a trajectory and less like wavefunction evolution.</p>
<p>This increase in information content seems to require an increase in the action, relative to a fundamental unit, i hbar.</p>
<p>The connection to heat capacity is very interesting.  Heat capacity is a key quantity in thermal physics, and I would hope to see it make it into the table of analogues!</p>
<p>To a physical chemist, the heat capacity measures how many joules of energy are required to cause a kelvin of temperature change.  It is an extensive quantity, and, in my mind anyway, is a measure of &#8220;thermally accessible degrees of freedom.&#8221;  Is this usefully related to the finesse with which we can (or have to) specify microscopic details of a macroscopically defined, thermal system?</p>
<p>The definition of (constant volume) heat capacity involves a derivative of internal energy with respect to temperature.  The analogue on the quantum side would seem to involve a derivative of action with respect to i hbar.</p>
<p>This analogue might raise and answer (admittedly vague) questions like &#8220;quantitatively, how much more quantum would this system behave if i hbar were bigger?&#8221;</p>
<p>One final comment regarding the n &#8220;gates&#8221;:  A study of the harmonic oscillator might be illuminating.  In quantum optics it is possible to produce &#8220;squeezed states&#8221; of a cavity mode by coupling it resonantly to a detector at multiples of a resonance frequency.  I wonder if judicious selection of the time schedule of selected gate points changes quantities like expected action, etc., in an understandable way.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14159</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Wed, 07 Mar 2012 03:36:44 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=8079#comment-14159</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14148&quot;&gt;Uwe Stroinski&lt;/a&gt;.

Uwe wrote:

&lt;blockquote&gt;
A sole analogy possibly won’t convince people. There is just not enough innovation and probably not a lot of physics and certainly no relevant mathematics contained. Such or similar might be a first opinion when dealing with this. Things change, at least for me, with the introduction of quantropy.
&lt;/blockquote&gt;

What are you talking about, exactly, when you say &#039;a sole analogy&#039;?  

At first I thought you meant the analogy between entropy and quantropy, but the last sentence suggest otherwise.  The analogy between quantum mechanics and statistical mechanics?  This analogy is already very famous, and there&#039;s a &lt;i&gt;huge&lt;/i&gt; amount of physics and mathematics in it.  Many books have been written based on this analogy: for example, Glimm and Jaffe&#039;s &lt;i&gt;Quantum Physics: A Functional Integral Point of View&lt;/i&gt; constructs quantum field theories using Wick rotation to transform path integrals into statistical mechanics problems, and Barry Simon&#039;s &lt;i&gt;Functional Integration and Quantum Physics&lt;/i&gt; covers different aspects of the same territory.  The subject of conformal field theory is another example: thanks to this analogy it leads a double life, on the one hand allowing people to understand critical points in 2d statistical mechanics problems, and on the quantum side playing a fundamental role in string theory.  

So the first interesting thing about quantropy is that it&#039;s an obvious yet apparently largely unexplored aspect of this already famous analogy.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14148">Uwe Stroinski</a>.</p>
<p>Uwe wrote:</p>
<blockquote><p>
A sole analogy possibly won’t convince people. There is just not enough innovation and probably not a lot of physics and certainly no relevant mathematics contained. Such or similar might be a first opinion when dealing with this. Things change, at least for me, with the introduction of quantropy.
</p></blockquote>
<p>What are you talking about, exactly, when you say &#8216;a sole analogy&#8217;?  </p>
<p>At first I thought you meant the analogy between entropy and quantropy, but the last sentence suggest otherwise.  The analogy between quantum mechanics and statistical mechanics?  This analogy is already very famous, and there&#8217;s a <i>huge</i> amount of physics and mathematics in it.  Many books have been written based on this analogy: for example, Glimm and Jaffe&#8217;s <i>Quantum Physics: A Functional Integral Point of View</i> constructs quantum field theories using Wick rotation to transform path integrals into statistical mechanics problems, and Barry Simon&#8217;s <i>Functional Integration and Quantum Physics</i> covers different aspects of the same territory.  The subject of conformal field theory is another example: thanks to this analogy it leads a double life, on the one hand allowing people to understand critical points in 2d statistical mechanics problems, and on the quantum side playing a fundamental role in string theory.  </p>
<p>So the first interesting thing about quantropy is that it&#8217;s an obvious yet apparently largely unexplored aspect of this already famous analogy.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Uwe Stroinski		</title>
		<link>https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14148</link>

		<dc:creator><![CDATA[Uwe Stroinski]]></dc:creator>
		<pubDate>Tue, 06 Mar 2012 15:41:30 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=8079#comment-14148</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14038&quot;&gt;John Baez&lt;/a&gt;.

&lt;blockquote&gt;
I figure that as long as most people think quantropy is a weird, stupid or useless idea, it’s safe for me to talk about it publicly. But I don’t want to recruit a lot of people into working on it before I’ve put something on the arXiv.
&lt;/blockquote&gt;

These are some substantial objections against quantropy and once you elevate this from blog to arXiv you maybe want to deal with them. Thus it might be helpful for you to know why I do not think that this is useless (thereby giving some possible uses). 

A sole analogy possibly won&#039;t convince people. There is just not enough innovation and probably not a lot of physics and certainly no relevant mathematics contained. Such or similar might be a first opinion when dealing with this. Things change, at least for me, with the introduction of quantropy. Why is this the case? Now one can break the symmetry and introduce something new by making the integrals converge. For example, if you consider particles travelling along the paths with the speed of light you will eventually get a cutoff in the integrals. You have mentioned a cutoff in one of your articles as a way to define things. In this case the purely mathematical $latex n$ will be replaced by a physically hopefully more tractable velocity $latex c$. Is such a computation new? Most likely not. Feynman an his follow ups could certainly do these computations. However, there is a slim chance that they simply were not interested in it for two reasons: Their integrals converged anyway and the resulting Schrödinger equation would contain an unwanted velocity parameter. The situation in the quantropy business is different. Here, a choice _has_ to be made since otherwise nothing converges. If it is the above choice of a &quot;speed limit&quot; reevaluating your motivating example for quantropy might lead to what you have called a &quot;Feynman&#039;s sum over histories formulation of quantum mechanics&quot; augmented with a velocity parameter. My knowledge of physics is slim enough to consider this to be interesting.

With this thoughts I certainly do not want to diminish other choices to make the integrals converge or even robust approaches that do not consider convergence at all. Anything goes. These are just my (naive?) thoughts why one should not immediately discard this idea.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14038">John Baez</a>.</p>
<blockquote><p>
I figure that as long as most people think quantropy is a weird, stupid or useless idea, it’s safe for me to talk about it publicly. But I don’t want to recruit a lot of people into working on it before I’ve put something on the arXiv.
</p></blockquote>
<p>These are some substantial objections against quantropy and once you elevate this from blog to arXiv you maybe want to deal with them. Thus it might be helpful for you to know why I do not think that this is useless (thereby giving some possible uses). </p>
<p>A sole analogy possibly won&#8217;t convince people. There is just not enough innovation and probably not a lot of physics and certainly no relevant mathematics contained. Such or similar might be a first opinion when dealing with this. Things change, at least for me, with the introduction of quantropy. Why is this the case? Now one can break the symmetry and introduce something new by making the integrals converge. For example, if you consider particles travelling along the paths with the speed of light you will eventually get a cutoff in the integrals. You have mentioned a cutoff in one of your articles as a way to define things. In this case the purely mathematical <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> will be replaced by a physically hopefully more tractable velocity <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c" class="latex" />. Is such a computation new? Most likely not. Feynman an his follow ups could certainly do these computations. However, there is a slim chance that they simply were not interested in it for two reasons: Their integrals converged anyway and the resulting Schrödinger equation would contain an unwanted velocity parameter. The situation in the quantropy business is different. Here, a choice _has_ to be made since otherwise nothing converges. If it is the above choice of a &#8220;speed limit&#8221; reevaluating your motivating example for quantropy might lead to what you have called a &#8220;Feynman&#8217;s sum over histories formulation of quantum mechanics&#8221; augmented with a velocity parameter. My knowledge of physics is slim enough to consider this to be interesting.</p>
<p>With this thoughts I certainly do not want to diminish other choices to make the integrals converge or even robust approaches that do not consider convergence at all. Anything goes. These are just my (naive?) thoughts why one should not immediately discard this idea.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14144</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Tue, 06 Mar 2012 07:53:45 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=8079#comment-14144</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14138&quot;&gt;Steven S.&lt;/a&gt;.

Hmm!  I&#039;ve been thinking about strange things like this myself recently: the analogies between classical mechanics, thermodynamics, statistical mechanics and quantum mechanics lead to some strange possibilities like quantizing thermodynamics, quantizing quantum mechanics, etc.  Of course &#039;second quantization&#039; is a known thing, and known to be useful... but there could be other things, not yet explored, which are logically consistent and (who knows?) perhaps even useful somehow.

You&#039;re right: the formula 

$latex \hbar \nu/2$ 

for the ground state energy of the quantum harmonic oscillator looks suspiciously similar to the formula 

$latex \hbar / 2i$

for the &#039;expected action per decision&#039; of a free quantum particle.  But I don&#039;t see a mathematical relationship underlying this similarity, so I&#039;m reluctant to plunge in and try stuff!  

On the other hand, there&#039;s a clear mathematical relationship between 

$latex \hbar / 2i$ 

as the &#039;expected action per decision&#039; for a free quantum particle and 

$latex k T / 2$ 

as the &#039;expected energy per degree of freedom&#039; for a classical harmonic oscillator.
That&#039;s what I worked out in this post.

So, you (or someone) could try to find a precise mathematical relation between the 

$latex \hbar \nu /2 $ 

ground state energy of the quantum harmonic oscillator and the 

$latex k T / 2$ 

expected action per degree of freedom of the classical harmonic oscillator.   But the first number shows up as an eigenvalue of a differential operator, while the second shows up as the value of an integral (as in this post).  Also, the first depends on the frequency of the oscillator, while the second does not!  So I don&#039;t see a connection.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2012/02/18/quantropy-part-3/#comment-14138">Steven S.</a>.</p>
<p>Hmm!  I&#8217;ve been thinking about strange things like this myself recently: the analogies between classical mechanics, thermodynamics, statistical mechanics and quantum mechanics lead to some strange possibilities like quantizing thermodynamics, quantizing quantum mechanics, etc.  Of course &#8216;second quantization&#8217; is a known thing, and known to be useful&#8230; but there could be other things, not yet explored, which are logically consistent and (who knows?) perhaps even useful somehow.</p>
<p>You&#8217;re right: the formula </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Chbar+%5Cnu%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar &#92;nu/2" class="latex" /> </p>
<p>for the ground state energy of the quantum harmonic oscillator looks suspiciously similar to the formula </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Chbar+%2F+2i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar / 2i" class="latex" /></p>
<p>for the &#8216;expected action per decision&#8217; of a free quantum particle.  But I don&#8217;t see a mathematical relationship underlying this similarity, so I&#8217;m reluctant to plunge in and try stuff!  </p>
<p>On the other hand, there&#8217;s a clear mathematical relationship between </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Chbar+%2F+2i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar / 2i" class="latex" /> </p>
<p>as the &#8216;expected action per decision&#8217; for a free quantum particle and </p>
<p><img src="https://s0.wp.com/latex.php?latex=k+T+%2F+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k T / 2" class="latex" /> </p>
<p>as the &#8216;expected energy per degree of freedom&#8217; for a classical harmonic oscillator.<br />
That&#8217;s what I worked out in this post.</p>
<p>So, you (or someone) could try to find a precise mathematical relation between the </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Chbar+%5Cnu+%2F2+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar &#92;nu /2 " class="latex" /> </p>
<p>ground state energy of the quantum harmonic oscillator and the </p>
<p><img src="https://s0.wp.com/latex.php?latex=k+T+%2F+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k T / 2" class="latex" /> </p>
<p>expected action per degree of freedom of the classical harmonic oscillator.   But the first number shows up as an eigenvalue of a differential operator, while the second shows up as the value of an integral (as in this post).  Also, the first depends on the frequency of the oscillator, while the second does not!  So I don&#8217;t see a connection.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

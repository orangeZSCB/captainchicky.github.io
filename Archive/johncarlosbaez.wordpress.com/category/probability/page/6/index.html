<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>probability | Azimuth | Page 6</title>
<link rel="profile" href="http://gmpg.org/xfn/11" />
<link rel="pingback" href="https://johncarlosbaez.wordpress.com/xmlrpc.php" />
<meta name='robots' content='max-image-preview:large' />
<link rel='dns-prefetch' href='//s1.wp.com' />
<link rel='dns-prefetch' href='//s2.wp.com' />
<link rel='dns-prefetch' href='//s0.wp.com' />
<link rel='dns-prefetch' href='//s.wordpress.com' />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Feed" href="https://johncarlosbaez.wordpress.com/feed/" />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Comments Feed" href="https://johncarlosbaez.wordpress.com/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; probability Category Feed" href="https://johncarlosbaez.wordpress.com/category/probability/feed/" />
	<script type="text/javascript">
		/* <![CDATA[ */
		function addLoadEvent(func) {
			var oldonload = window.onload;
			if (typeof window.onload != 'function') {
				window.onload = func;
			} else {
				window.onload = function () {
					oldonload();
					func();
				}
			}
		}
		/* ]]> */
	</script>
			<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/72x72\/","ext":".png","svgUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/s1.wp.com\/wp-includes\/js\/wp-emoji-release.min.js?m=1625065786h&ver=5.8.1"}};
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([10084,65039,8205,55357,56613],[10084,65039,8203,55357,56613])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='all-css-0-1' href='https://s2.wp.com/_static/??-eJyNkttSAyEMhl9IlqVOdbxwfBYOEVOBZSBYeXuz1e6sVrveMDl9yU9AHrOwUyJIJGMTOTSPqUpMz5iQ+mIMttYbuVFMLxChytyMPJXFTBfcGfKNXQPFc6aAfFNq2A9KmobBSRMm+yoCmqJLl5V6gKURJhua4zGHKiM41BB46qxo5eSgOxQRwGvbh4hpG+fc2v8G/S3+pJSbAWU9S9Z9aiR8QfdD9r9bFE2YfN3A7fSF7QY18t4cVlqC4nd29WTzzjkes768+BXsiM4DMV7PtiB4v45kHiOMyQVqFXxGbFF8/pSZe4qP6u5W3T/sx3F3+ACgX/YH?cssminify=yes' type='text/css' media='all' />
<style id='wp-block-library-inline-css'>
.has-text-align-justify {
	text-align:justify;
}
</style>
<style id='global-styles-inline-css'>
body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--normal: 16px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--huge: 42px;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-normal-font-size{font-size: var(--wp--preset--font-size--normal) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-huge-font-size{font-size: var(--wp--preset--font-size--huge) !important;}
</style>
<link rel='stylesheet' id='all-css-2-1' href='https://s0.wp.com/_static/??-eJx9i0EKgCAQAD+ULYJRHaK3qJhY666o0fezW126zcAMGNR09LaUDq4kLFN1VCGeIuHpAxXwjgWy1TUwfURsqEP+W7MzyL6hh1a99JnWuEg1zEpNo1T7DZLtMYQ=?cssminify=yes' type='text/css' media='all' />
<link rel='stylesheet' id='print-css-3-1' href='https://s2.wp.com/wp-content/mu-plugins/global-print/global-print.css?m=1465851035h&cssminify=yes' type='text/css' media='print' />
<style id='jetpack-global-styles-frontend-style-inline-css'>
:root { --font-headings: unset; --font-base: unset; --font-headings-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif; --font-base-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif;}
</style>
<link rel='stylesheet' id='all-css-6-1' href='https://s0.wp.com/wp-content/themes/h4/global.css?m=1420737423h&cssminify=yes' type='text/css' media='all' />
<script id='wpcom-actionbar-placeholder-js-extra'>
var actionbardata = {"siteID":"12777403","siteName":"Azimuth","siteURL":"http:\/\/johncarlosbaez.wordpress.com","siteHost":"johncarlosbaez.wordpress.com","icon":"<img alt='' src='https:\/\/s2.wp.com\/i\/logo\/wpcom-gray-white.png' class='avatar avatar-50' height='50' width='50' \/>","canManageOptions":"","canCustomizeSite":"","isFollowing":"","themeSlug":"pub\/contempt","signupURL":"https:\/\/wordpress.com\/start\/","loginURL":"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2013%2F02%2F05%2Fgame-theory-part-9%2F&signup_flow=account","themeURL":"","xhrURL":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/admin-ajax.php","nonce":"e6f6fdfb46","isSingular":"","isFolded":"","isLoggedIn":"","isMobile":"","subscribeNonce":"<input type=\"hidden\" id=\"_wpnonce\" name=\"_wpnonce\" value=\"ffcb185558\" \/>","referer":"https:\/\/johncarlosbaez.wordpress.com\/category\/probability\/page\/6\/","canFollow":"1","feedID":"62242","statusMessage":"","subsEmailDefault":"instantly","customizeLink":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/customize.php?url=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2Fcategory%2Fprobability%2Fpage%2F6%2F","i18n":{"view":"View site","follow":"Follow","following":"Following","edit":"Edit","login":"Log in","signup":"Sign up","customize":"Customize","report":"Report this content","themeInfo":"Get theme: Contempt","shortlink":"Copy shortlink","copied":"Copied","followedText":"New posts from this site will now appear in your <a href=\"https:\/\/wordpress.com\/read\">Reader<\/a>","foldBar":"Collapse this bar","unfoldBar":"Expand this bar","editSubs":"Manage subscriptions","viewReader":"View site in Reader","viewReadPost":"View post in Reader","subscribe":"Sign me up","enterEmail":"Enter your email address","followers":"Join 5,228 other followers","alreadyUser":"Already have a WordPress.com account? <a href=\"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2013%2F02%2F05%2Fgame-theory-part-9%2F&signup_flow=account\">Log in now.<\/a>","stats":"Stats","notifyNewPosts":"Notify me of new posts","notifyNewPostsDetails":"Receive web and mobile notifications for new posts from this site.","emailNewPosts":"Email me new posts","emailNewPostsDetails":"You can customize your notification settings further <a href=\"https:\/\/wordpress.com\/following\/manage?s=johncarlosbaez.wordpress.com\">here<\/a>.","emailNewComments":"Email me new comments","instantly":"Instantly","daily":"Daily","weekly":"Weekly"}};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s2.wp.com/_static/??-eJyFykEKwkAMQNELmQ4qtboQz1LbWDJMknGSQXt7K9SFILj6i//CI8Og4igeooWs5oxm/YRNtE34vqxXSgjVsCxAHEhu+sOV5JCLPufPIxlSHdHeM94rlnlNwyR/ETBNpXdc8YXP28OuOx3brt3HF3swRvU='></script>
<script type='text/javascript'>
	window.addEventListener( 'DOMContentLoaded', function() {
		rltInitialize( {"token":null,"iframeOrigins":["https:\/\/widgets.wp.com"]} );
	} );
</script>
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://johncarlosbaez.wordpress.com/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://s1.wp.com/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress.com" />

<!-- Jetpack Open Graph Tags -->
<meta property="og:type" content="website" />
<meta property="og:title" content="probability &#8211; Page 6 &#8211; Azimuth" />
<meta property="og:url" content="https://johncarlosbaez.wordpress.com/category/probability/" />
<meta property="og:site_name" content="Azimuth" />
<meta property="og:image" content="https://s0.wp.com/i/blank.jpg" />
<meta property="og:locale" content="en_US" />
<meta name="twitter:site" content="@wordpressdotcom" />
<meta property="fb:app_id" content="249643311490" />

<!-- End Jetpack Open Graph Tags -->
<link rel="shortcut icon" type="image/x-icon" href="https://s1.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48" />
<link rel="icon" type="image/x-icon" href="https://s1.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48" />
<link rel="apple-touch-icon" href="https://s2.wp.com/i/webclip.png" />
<link rel='openid.server' href='https://johncarlosbaez.wordpress.com/?openidserver=1' />
<link rel='openid.delegate' href='https://johncarlosbaez.wordpress.com/' />
<link rel="search" type="application/opensearchdescription+xml" href="https://johncarlosbaez.wordpress.com/osd.xml" title="Azimuth" />
<link rel="search" type="application/opensearchdescription+xml" href="https://s1.wp.com/opensearch.xml" title="WordPress.com" />
<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>		<style type="text/css">
			.recentcomments a {
				display: inline !important;
				padding: 0 !important;
				margin: 0 !important;
			}

			table.recentcommentsavatartop img.avatar, table.recentcommentsavatarend img.avatar {
				border: 0px;
				margin: 0;
			}

			table.recentcommentsavatartop a, table.recentcommentsavatarend a {
				border: 0px !important;
				background-color: transparent !important;
			}

			td.recentcommentsavatarend, td.recentcommentsavatartop {
				padding: 0px 0px 1px 0px;
				margin: 0px;
			}

			td.recentcommentstextend {
				border: none !important;
				padding: 0px 0px 2px 10px;
			}

			.rtl td.recentcommentstextend {
				padding: 0px 10px 2px 0px;
			}

			td.recentcommentstexttop {
				border: none;
				padding: 0px 0px 0px 10px;
			}

			.rtl td.recentcommentstexttop {
				padding: 0px 10px 0px 0px;
			}
		</style>
		<meta name="application-name" content="Azimuth" /><meta name="msapplication-window" content="width=device-width;height=device-height" /><meta name="msapplication-task" content="name=Subscribe;action-uri=https://johncarlosbaez.wordpress.com/feed/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=Sign up for a free blog;action-uri=http://wordpress.com/signup/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=WordPress.com Support;action-uri=http://support.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=WordPress.com Forums;action-uri=http://forums.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="description" content="Posts about probability written by John Baez" />
<style type="text/css">
#headerimg{
	background: url(https://johncarlosbaez.files.wordpress.com/2010/08/azimuth_header.jpg) no-repeat;
}
#header h1 a, .description {
	color:#E5F2E9;
}
</style>
<!-- There is no amphtml version available for this URL. -->		<link rel="stylesheet" id="custom-css-css" type="text/css" href="https://s0.wp.com/?custom-css=1&#038;csblog=RBZ9&#038;cscache=6&#038;csrev=7" />
		</head>
<body class="archive paged category category-probability category-10451 paged-6 category-paged-6 customizer-styles-applied highlander-enabled highlander-light">

<div id="page">

<div id="header">
	<div id="headerimg" onclick="location.href='https://johncarlosbaez.wordpress.com';" style="cursor: pointer;">
		<h1><a href="https://johncarlosbaez.wordpress.com/">Azimuth</a></h1>
		<div class="description"></div>
	</div>
</div>

<ul id="pagebar" class="menu pagebar"><li ><a href="https://johncarlosbaez.wordpress.com/">Home</a></li><li class="page_item page-item-2"><a href="https://johncarlosbaez.wordpress.com/about/">About</a></li>
</ul>

<div id="grad" style="height: 65px; width: 100%; background: url(https://s2.wp.com/wp-content/themes/pub/contempt/images/blue_flower/topgrad.jpg);">&nbsp;</div>

	<div id="content">

	
		
			<div class="post-14497 post type-post status-publish format-standard hentry category-game-theory category-mathematics category-probability" id="post-14497">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/02/05/game-theory-part-9/" rel="bookmark">Game Theory (Part&nbsp;9)</a></h2>
				<small>5 February, 2013</small><br />


				<div class="entry">
					<p><a href="https://johncarlosbaez.wordpress.com/2013/01/28/game-theory-part-8/">Last time</a> we talked about independence of a <i>pair</i> of events, but we can easily go on and talk about independence of a longer sequence of events.  For example, suppose we have three coins.   Suppose:</p>
<p>&bull; the 1st coin has probability <img src="https://s0.wp.com/latex.php?latex=p_H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_H" class="latex" /> of landing heads up and <img src="https://s0.wp.com/latex.php?latex=p_T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_T" class="latex" /> of landing tails up;<br />
&bull; the 2nd coin has probability <img src="https://s0.wp.com/latex.php?latex=q_H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q_H" class="latex" /> of landing heads up and <img src="https://s0.wp.com/latex.php?latex=q_T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q_T" class="latex" /> of landing tails up;<br />
&bull; the 3rd coin has probability <img src="https://s0.wp.com/latex.php?latex=r_H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r_H" class="latex" /> of landing heads up and <img src="https://s0.wp.com/latex.php?latex=r_T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r_T" class="latex" /> of landing tails up. </p>
<p>Suppose we flip all of these coins: the 1st, then the 2nd, then the 3rd.  What&#8217;s the probability that we get this sequence of results:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%28H%2C+T%2C+T%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(H, T, T)" class="latex" />
</div>
<p>If the coin flips are <i>independent</i>, the probability is just this product:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=p_H+%5C%2C+q_T+%5C%2C+r_T+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_H &#92;, q_T &#92;, r_T " class="latex" />
</div>
<p>See the pattern?  We just multiply the probabilities.  And there&#8217;s nothing special about <i>coins</i> here, or the number <i>three</i>. We could flip a coin, roll a die, pick a card, and see if it&#8217;s raining outside.  </p>
<p>For example, what&#8217;s the probability that we get heads with our coin, the number 6 on our die, an ace of spades with our cards, and it&#8217;s raining?  <i>If these events are independent</i>, we just calculate:</p>
<p>the probability that we get heads, times<br />
the probability that we roll a 6, times<br />
the probability that we get an ace of spades, times<br />
the probability that it&#8217;s raining outside.</p>
<p>Let&#8217;s solve some puzzles using this idea!</p>
<div align="center"><a href="http://blog.boyet.com/blog/blog/unbiased-tosses-from-a-biased-coin/"><img src="https://i1.wp.com/s3.amazonaws.com/boyetblog/Blog%20images/CoinToss.jpg" /></a></div>
<h3> Three flips of a fair coin </h3>
<p><b>Example 1.</b>   Suppose you have a <b>fair</b> coin: this means it has a 50% chance of landing heads up and a 50% chance of landing tails up.  Suppose you flip it three times and these flips are independent.  What is the probability that it lands heads up, then tails up, then heads up?</p>
<p>We&#8217;re asking about the probability of this event:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%28H%2C+T%2C+H%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(H, T, H)" class="latex" />
</div>
<p>Since the flips are independent this is</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=p_%7B%28H%2CT%2CH%29%7D+%3D+p_H+%5C%2C+p_T+%5C%2C+p_H+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_{(H,T,H)} = p_H &#92;, p_T &#92;, p_H " class="latex" />
</div>
<p>Since the coin is fair we have</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_H+%3D+p_T+%3D+%5Cfrac%7B1%7D%7B2%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_H = p_T = &#92;frac{1}{2} } " class="latex" />
</div>
<p>so </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_H+p_T+p_H+%3D+%5Cfrac%7B1%7D%7B2%7D+%5Ctimes+%5Cfrac%7B1%7D%7B2%7D+%5Ctimes+%5Cfrac%7B1%7D%7B2%7D+%3D+%5Cfrac%7B1%7D%7B8%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_H p_T p_H = &#92;frac{1}{2} &#92;times &#92;frac{1}{2} &#92;times &#92;frac{1}{2} = &#92;frac{1}{8} } " class="latex" />
</div>
<p>So the answer is 1/8, or 12.5%.</p>
<p><b>Example 2.</b>  In the same situation, what&#8217;s the probability that the coin lands heads up exactly twice?</p>
<p>There are 2 &times; 2 &times; 2 = 8 events that can happen:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%28H%2CH%2CH%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(H,H,H) " class="latex" /><br />
<img src="https://s0.wp.com/latex.php?latex=%28H%2CH%2CT%29%2C+%5C%3B+%28H%2CT%2CH%29%2C+%5C%3B+%28T%2CH%2CH%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(H,H,T), &#92;; (H,T,H), &#92;; (T,H,H) " class="latex" /><br />
<img src="https://s0.wp.com/latex.php?latex=%28H%2CT%2CT%29%2C+%5C%3B+%28T%2CH%2CT%29%2C+%5C%3B+%28T%2CT%2CH%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(H,T,T), &#92;; (T,H,T), &#92;; (T,T,H) " class="latex" /><br />
<img src="https://s0.wp.com/latex.php?latex=%28T%2CT%2CT%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(T,T,T) " class="latex" />
</div>
<p>We can work out the probability of each of these events.  For example, we&#8217;ve already seen that <img src="https://s0.wp.com/latex.php?latex=%28H%2CT%2CH%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(H,T,H)" class="latex" /> is</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_%7B%28H%2CT%2CH%29%7D+%3D+p_H+p_T+p_H+%3D+%5Cfrac%7B1%7D%7B8%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_{(H,T,H)} = p_H p_T p_H = &#92;frac{1}{8} }" class="latex" />
</div>
<p>since the coin is fair and the flips are independent.  In fact, all 8 probabilities work out the same way.  We always get 1/8.  In other words, each of the 8 events is equally likely!  </p>
<p>But we&#8217;re interested in the probability that we get exactly two heads.  That&#8217;s the probability of this subset:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=S+%3D+%5C%7B+%28T%2CH%2CH%29%2C+%28H%2CT%2CH%29%2C+%28H%2CH%2CT%29+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = &#92;{ (T,H,H), (H,T,H), (H,H,T) &#92;} " class="latex" />
</div>
<p>Using the rule we saw in <a href="https://johncarlosbaez.wordpress.com/2013/01/26/game-theory-part-7/">Part 7</a>, this probability is</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p%28S%29+%3D+p_%7B%28T%2CH%2CH%29%7D+%2B+p_%7B%28H%2CT%2CH%29%7D+%2B+p_%7B%28H%2CH%2CT%29%7D+%3D+3+%5Ctimes+%5Cfrac%7B1%7D%7B8%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p(S) = p_{(T,H,H)} + p_{(H,T,H)} + p_{(H,H,T)} = 3 &#92;times &#92;frac{1}{8} }" class="latex" />
</div>
<p>So the answer is 3/8, or 37.5%.  </p>
<p>I could have done this a lot faster.  I could say &#8220;there are 8 events that can happen, each equally likely, and three that give us two heads, so the probability is 3/8.&#8221;   But I wanted to show you how we&#8217;re just following rules we&#8217;ve already seen! </p>
<h3> Three flips of a very unfair coin </h3>
<p><b>Example 3.</b>  Now suppose we have an unfair coin with a 90% chance of landing heads up and 10% chance of landing tails up!  What&#8217;s the probability that if we flip it three times, it lands heads up exactly twice?  Again let&#8217;s assume the coin flips are independent.</p>
<p>Most of the calculation works exactly the same way, but now our coin has</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_H+%3D+0.9%2C+%5Cquad+p_T+%3D+0.1+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_H = 0.9, &#92;quad p_T = 0.1 } " class="latex" />
</div>
<p>We&#8217;re interested in the events where the coin comes up heads twice, so we look at this subset:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=S+%3D+%5C%7B+%28T%2CH%2CH%29%2C+%28H%2CT%2CH%29%2C+%28H%2CH%2CT%29+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = &#92;{ (T,H,H), (H,T,H), (H,H,T) &#92;} " class="latex" />
</div>
<p>The probability of this subset is</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+p%28S%29+%26%3D%26+p_%7B%28T%2CH%2CH%29%7D+%2B+p_%7B%28H%2CT%2CH%29%7D+%2B+p_%7B%28H%2CH%2CT%29%7D+%5C%5C++%26%3D%26+p_T+%5C%2C+p_H++%5C%2C+p_H+%2B+p_H+%5C%2C+p_T+%5C%2C+p_H+%2B+p_H+%5C%2C+p_H+%5C%2C+p_T+%5C%5C+%26%3D%26+3+p_T+p_H%5E2+%5C%5C+%26%3D%26+3+%5Ctimes+0.1+%5Ctimes+0.9%5E2+%5C%5C+%26%3D%26+0.3+%5Ctimes+0.81+%5C%5C+%26%3D%26+0.243+%5Cend%7Barray%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} p(S) &amp;=&amp; p_{(T,H,H)} + p_{(H,T,H)} + p_{(H,H,T)} &#92;&#92;  &amp;=&amp; p_T &#92;, p_H  &#92;, p_H + p_H &#92;, p_T &#92;, p_H + p_H &#92;, p_H &#92;, p_T &#92;&#92; &amp;=&amp; 3 p_T p_H^2 &#92;&#92; &amp;=&amp; 3 &#92;times 0.1 &#92;times 0.9^2 &#92;&#92; &amp;=&amp; 0.3 &#92;times 0.81 &#92;&#92; &amp;=&amp; 0.243 &#92;end{array}" class="latex" />
</div>
<p>So now the probability is just 24.3%.  </p>
<h3> Six flips of a fair coin </h3>
<p><b>Example 4.</b>  Suppose you have a fair coin.  Suppose you flip it six times and these flips are independent.  What is the probability that it lands heads up exactly twice?</p>
<p>We did a similar problem already, where we flipped the coin three times.  Go back and look at that if you forget!  The answer to <i>that</i> problem was </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+3+%5Ctimes+%5Cfrac%7B1%7D%7B8%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ 3 &#92;times &#92;frac{1}{8} }" class="latex" />
</div>
<p>Why?  Here&#8217;s why: there were 3 ways to get two heads when you flipped 3 coins, and each of these events had probability</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cleft%28%5Cfrac%7B1%7D%7B2%7D%5Cright%29%5E3+%3D+%5Cfrac%7B1%7D%7B8%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;left(&#92;frac{1}{2}&#92;right)^3 = &#92;frac{1}{8} }" class="latex" />
</div>
<p>We can do our new problem the same way.  Count the number of ways to get two heads when we flip six coins.  Then multiply this by</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cleft%28%5Cfrac%7B1%7D%7B2%7D%5Cright%29%5E6+%3D+%5Cfrac%7B1%7D%7B64%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;left(&#92;frac{1}{2}&#92;right)^6 = &#92;frac{1}{64} }" class="latex" />
</div>
<p>The hard part is to count how many ways we can get two heads when we flip six coins.  To get good at probabilities, we have to get good at counting.  It&#8217;s boring to list all the events we&#8217;re trying to count:</p>
<div align="center">
(H,H,T,T,T,T), (H,T,H,T,T,T), (H,T,T,H,T,T), &#8230;
</div>
<p>So let&#8217;s try to come up with a better idea.  </p>
<p>We have to pick 2 out of our 6 flips to be H&#8217;s.  How many ways are there to do this?   </p>
<p>There are 6 ways to pick <i>one</i> of the flips and draw a <font color="red">red H</font> on it, and then 5 ways left over to pick <i>another</i> and draw a <font color="blue">blue H</font> on it&#8230; letting the rest be T&#8217;s.  For example:</p>
<div align="center">
(T, <font color="blue">H</font>, T, T, <font color="red">H</font>, T)
</div>
<p>So, we&#8217;ve got 6 &times; 5 = 30 choices.  But we don&#8217;t really care which H is red and which H is blue&mdash;that&#8217;s just a trick to help us solve the problem.  For example, we don&#8217;t want to count </p>
<div align="center">
(T, <font color="blue">H</font>, T, T, <font color="red">H</font>, T)
</div>
<p>as different from </p>
<div align="center">
(T, <font color="red">H</font>, T, T, <font color="blue">H</font>, T)
</div>
<p>So, there aren&#8217;t really 30 ways to get two heads.  There are only half as many!  There are 15 ways.</p>
<p>So, the probability of getting two heads when we flip the coin six times is </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+15+%5Ctimes+%5Cfrac%7B1%7D%7B64%7D+%3D+%5Cfrac%7B15%7D%7B64%7D+%5Capprox+.234+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ 15 &#92;times &#92;frac{1}{64} = &#92;frac{15}{64} &#92;approx .234 } " class="latex" />
</div>
<p>where the squiggle means &#8216;approximately&#8217;.  So: about 23.4%.</p>
<h3> Binomial coefficients </h3>
<p>Now for some jargon, which will help when we do harder problems like this.  We say there are <b>6 choose 2</b> ways to choose 2 out of 6 things, and we write this as</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cbinom%7B6%7D%7B2%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;binom{6}{2} } " class="latex" />
</div>
<p>This sort of number is called a <b><a href="http://en.wikipedia.org/wiki/Binomial_coefficient">binomial coefficient</a></b>.  </p>
<p>We&#8217;ve just shown that</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cbinom%7B6%7D%7B2%7D++%3D+%5Cfrac%7B6+%5Ctimes+5%7D%7B2+%5Ctimes+1%7D+%3D+15+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;binom{6}{2}  = &#92;frac{6 &#92;times 5}{2 &#92;times 1} = 15 }" class="latex" />
</div>
<p>Why write it like this funky fraction: <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B6+%5Ctimes+5%7D%7B2+%5Ctimes+1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;frac{6 &#92;times 5}{2 &#92;times 1}" class="latex" />?  Because it&#8217;ll help us see the pattern for doing harder problems like this!</p>
<h3> Nine flips of a fair coin </h3>
<p>If we flip a fair coin 9 times, and the flips are independent, what&#8217;s the probability that we get heads exactly 6 times?</p>
<p>This works just like the last problem, only the numbers are bigger.  So, I&#8217;ll do it faster!  </p>
<p>When we flip the coin 9 times there are <img src="https://s0.wp.com/latex.php?latex=2%5E9&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="2^9" class="latex" /> possible events that can happen.   Each of these is equally likely if it&#8217;s a fair coin and the flips are independent.  So each has probability </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%5Cfrac%7B1%7D%7B2%5E9%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  &#92;frac{1}{2^9} } " class="latex" />
</div>
<p>To get the answer, we need to multiply this by the number of ways we can get heads exactly 6 times.  This number is called &#8216;9 choose 6&#8217; or</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cbinom%7B9%7D%7B6%7D++%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;binom{9}{6}  }" class="latex" />
</div>
<p>for short.  It&#8217;s the number of ways we can choose 6 things out of a collection of 9.  </p>
<p>So we just need to know: what&#8217;s 9 choose 6?  We can work this out as before.  There are 9 ways to pick <i>one</i> of the flips and draw a <font color="red">red H</font> on it, then 8 ways left to pick <i>another</i> and draw a <font color="blue">blue H</font> on it, and 7 ways left to pick <i>a third</i> and draw a <font color="orange">orange H</font> on it.  That sounds like 9 &times; 8 &times; 7.  </p>
<p>But we&#8217;ve overcounted!   After all, we don&#8217;t care about the colors.  We don&#8217;t care about the difference between this:</p>
<div align="center">
(T, <font color="red">H</font>, T, T, <font color="orange">H</font>, T, T, <font color="blue">H</font>, T)
</div>
<p>and this:</p>
<div align="center">
(T, <font color="orange">H</font>, T, T, <font color="blue">H</font>, T, T, <font color="red">H</font>, T)
</div>
<p>In fact we&#8217;ve counted each possibility 6 times!  Why six?   The first H could be red, green or blue&#8212;that&#8217;s 3 choices.  But then the second H could be either of the two remaining 2 colors&#8230; and for the third, we just have 1 choice.  So there are 3 &times; 2 &times; 1 = 6 ways to permute the colors.</p>
<p>So, the <i>actual</i> number of ways to get 6 heads out of 9 coin flips is </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7B9+%5Ctimes+8+%5Ctimes+7%7D%7B3+%5Ctimes+2+%5Ctimes+1%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{9 &#92;times 8 &#92;times 7}{3 &#92;times 2 &#92;times 1} } " class="latex" />
</div>
<p>In other words:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cbinom%7B9%7D%7B6%7D+%3D+%5Cfrac%7B9+%5Ctimes+8+%5Ctimes+7%7D%7B3+%5Ctimes+2+%5Ctimes+1%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;binom{9}{6} = &#92;frac{9 &#92;times 8 &#92;times 7}{3 &#92;times 2 &#92;times 1} } " class="latex" />
</div>
<p>To get the answer to our actual problem, remember we need to multiply <img src="https://s0.wp.com/latex.php?latex=1%2F2%5E9&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/2^9" class="latex" /> by this.  So the answer is</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7B1%7D%7B2%5E9%7D+%5Ctimes+%5Cbinom%7B9%7D%7B6%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{1}{2^9} &#92;times &#92;binom{9}{6} }" class="latex" />
</div>
<p>If you&#8217;re a pure mathematician, you can say you&#8217;re done now.  But normal people won&#8217;t understand this answer, so let&#8217;s calculate it out.  I hope you know the first ten powers of two: 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024.  So:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+2%5E9+%3D+512+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ 2^9 = 512 }" class="latex" />
</div>
<p>I hope you can also do basic arithmetic like this:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cbinom%7B9%7D%7B6%7D+%3D+%5Cfrac%7B9+%5Ctimes+8+%5Ctimes+7%7D%7B3+%5Ctimes+2+%5Ctimes+1%7D+%3D+84%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;binom{9}{6} = &#92;frac{9 &#92;times 8 &#92;times 7}{3 &#92;times 2 &#92;times 1} = 84} " class="latex" />
</div>
<p>So, the probability of getting 6 heads when you do 9 independent flips of a fair coin is</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7B1%7D%7B2%5E9%7D+%5Ctimes+%5Cbinom%7B9%7D%7B6%7D++%3D+%5Cfrac%7B84%7D%7B512%7D+%3D+0.164025+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{1}{2^9} &#92;times &#92;binom{9}{6}  = &#92;frac{84}{512} = 0.164025 } " class="latex" />
</div>
<p>or 16.4025%. I broke down and used a calculator at the last step.   We&#8217;re becoming serious nerds here.</p>
<p>Okay, that&#8217;s enough for now.  We&#8217;ve been counting how many ways we can get a certain number of heads from a certain number of coin flips.  What we&#8217;re realy doing is taking a set of coin flips, say <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> of them, and choosing a subset of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k" class="latex" /> of them to be heads.  So, we say</p>
<p><b>Definition.</b>  The <b><a href="http://en.wikipedia.org/wiki/Binomial_coefficient">binomial coefficient</a></b> </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cbinom%7Bn%7D%7Bk%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;binom{n}{k} } " class="latex" />
</div>
<p>called <b><img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> choose <img src="https://s0.wp.com/latex.php?latex=k%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k," class="latex" /></b> is the number of ways of choosing a subset of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k" class="latex" /> things from a set of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> things.  </p>
<p>We have seen in some examples that</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cbinom%7Bn%7D%7Bk%7D+%3D+%5Cfrac%7Bn%28n-1%29%28n-2%29+%5Ccdots+%28n-k%2B1%29%7D%7Bk%28k-1%29%28k-2%29+%5Ccdots+1%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;binom{n}{k} = &#92;frac{n(n-1)(n-2) &#92;cdots (n-k+1)}{k(k-1)(k-2) &#92;cdots 1} } " class="latex" />
</div>
<p>Here there&#8217;s a product of <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k" class="latex" /> consecutive numbers on top, and <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k" class="latex" /> on bottom too.  We didn&#8217;t prove this is true in general, but it&#8217;s not hard to see, using the tricks we&#8217;ve used already.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/02/05/game-theory-part-9/#comments">9 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/mathematics/game-theory/" rel="category tag">game theory</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/02/05/game-theory-part-9/" rel="bookmark" title="Permanent Link to Game Theory (Part&nbsp;9)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-14471 post type-post status-publish format-standard hentry category-game-theory category-mathematics category-probability" id="post-14471">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/01/28/game-theory-part-8/" rel="bookmark">Game Theory (Part&nbsp;8)</a></h2>
				<small>28 January, 2013</small><br />


				<div class="entry">
					<p><a href="https://johncarlosbaez.wordpress.com/2013/01/26/game-theory-part-7/">Last time</a> we learned some rules for calculating probabilities.  But we need a few more rules to get very far.  </p>
<p>For example:</p>
<p>We say a coin is <b>fair</b> if it has probability 1/2 of landing heads up and probability 1/2 of landing tails up.  What is the probability that if we flip two fair coins, <i>both</i> will land heads up?</p>
<p>Since each coin could land heads up or tails up, there are 4 events to consider here: </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%28H%2CH%29%2C+%28H%2CT%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(H,H), (H,T)," class="latex" /><br />
<img src="https://s0.wp.com/latex.php?latex=%28T%2CH%29%2C+%28T%2CT%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(T,H), (T,T) " class="latex" />
</div>
<p>It seems plausible that each should be equally likely.  If so, each has probability 1/4.  So then the answer to our question would be 1/4.</p>
<p>But this is plausible only because we&#8217;re assuming that what one coin does doesn&#8217;t affect that the other one does!  In other words, we&#8217;re assuming the two coin flips are &#8216;independent&#8217;.</p>
<p>If the coins were connected in some sneaky way, maybe each time one landed heads up, the other would land tails up.  Then the answer to our question would be zero.  Of course this seems silly.  But it&#8217;s good to be very clear about this issue&#8230; because sometimes one event <i>does</i> affect another!  </p>
<p>For example, suppose there&#8217;s a 5% probability of rain each day in the winter in Riverside.  What&#8217;s the probability that it rains two days in a row?  Remember that 5% is 0.05.  So, you might guess the answer is</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=0.05+%5Ctimes+0.05+%3D+0.0025&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0.05 &#92;times 0.05 = 0.0025" class="latex" />
</div>
<p>But this is wrong, because <i>if it rains one day, that increases the probability that it will rain the next day</i>.  In other words, these events aren&#8217;t independent.</p>
<p>But if two events <i>are</i> independent, there&#8217;s an easy way to figure out the probability that they both happen: just multiply their probabilities!   For example, if the chance that it will rain today in Riverside is 5% and the chance that it will rain tomorrow in Singapore is 60%, the chance that <i>both</i> these things will happen is</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=0.05+%5Ctimes+0.6+%3D+0.03&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0.05 &#92;times 0.6 = 0.03" class="latex" />
</div>
<p>or 3%, <i>if</i> these events are independent.   I could try to persuade that this is a good rule, and maybe I will&#8230; but for now let&#8217;s just state it in a general way.</p>
<h3> Independence </h3>
<p>So, let&#8217;s make a precise definition out of all this!  Suppose we have two sets of events, <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y." class="latex" />  Remember that <img src="https://s0.wp.com/latex.php?latex=X+%5Ctimes+Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X &#92;times Y" class="latex" />, the <b>Cartesian product</b> of the sets <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" />, is the set of all ordered pairs <img src="https://s0.wp.com/latex.php?latex=%28i%2Cj%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(i,j)" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i &#92;in X" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=j+%5Cin+Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j &#92;in Y" class="latex" />:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=X+%5Ctimes+Y+%3D+%5C%7B+%28i%2Cj%29+%3A+%5C%3B+i+%5Cin+X%2C+j+%5Cin+Y+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X &#92;times Y = &#92;{ (i,j) : &#92;; i &#92;in X, j &#92;in Y &#92;} " class="latex" />
</div>
<p>So, an event in <img src="https://s0.wp.com/latex.php?latex=X+%5Ctimes+Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X &#92;times Y" class="latex" /> consists of an event in <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> and an event in <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" />.   For example, if </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=X+%3D+%5C%7B+%5Ctextrm%7Brain+today%7D%2C+%5Ctextrm%7Bno+rain+today%7D+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X = &#92;{ &#92;textrm{rain today}, &#92;textrm{no rain today} &#92;} " class="latex" />
</div>
<p>and </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=Y+%3D+%5C%7B+%5Ctextrm%7Brain+tomorrow%7D%2C+%5Ctextrm%7Bno+rain+tomorrow%7D+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y = &#92;{ &#92;textrm{rain tomorrow}, &#92;textrm{no rain tomorrow} &#92;} " class="latex" />
</div>
<p>then</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=X+%5Ctimes+Y+%3D+%5Cbegin%7Barray%7D%7Bl%7D+%5C%7B+%5Ctextrm%7B%28rain+today%2C+rain+tomorrow%29%7D%2C+%5C%5C+%5Ctextrm%7B%28no+rain+today%2C+rain+tomorrow%29%7D%2C+%5C%5C+++%5Ctextrm%7B%28rain+today%2C+no+rain+tomorrow%7D%2C+%5C%5C+%5Ctextrm%7B%28no+rain+today%2C+no+rain+tomorrow%29%7D+%5C%7D+%5Cend%7Barray%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X &#92;times Y = &#92;begin{array}{l} &#92;{ &#92;textrm{(rain today, rain tomorrow)}, &#92;&#92; &#92;textrm{(no rain today, rain tomorrow)}, &#92;&#92;   &#92;textrm{(rain today, no rain tomorrow}, &#92;&#92; &#92;textrm{(no rain today, no rain tomorrow)} &#92;} &#92;end{array} " class="latex" />
</div>
<p>Now we can define &#8216;independence&#8217;.  It&#8217;s a rule for getting a probability distribution on <img src="https://s0.wp.com/latex.php?latex=X+%5Ctimes+Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X &#92;times Y" class="latex" /> from probability distributions on <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" />:</p>
<p><b>Definition.</b>  Suppose <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> is a probability distribution on a set of events <img src="https://s0.wp.com/latex.php?latex=X%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X," class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> is a probability distribution on a set of events <img src="https://s0.wp.com/latex.php?latex=Y.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y." class="latex" />  If these events are <b>independent</b>, we use the probability distribution <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=X+%5Ctimes+Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X &#92;times Y" class="latex" /> given by</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=r_%7B%28i%2Cj%29%7D+%3D+p_i+q_j+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r_{(i,j)} = p_i q_j " class="latex" />
</div>
<p>People often call this probability distribution <img src="https://s0.wp.com/latex.php?latex=p+%5Ctimes+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p &#92;times q" class="latex" /> instead of <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" />.</p>
<h3> Examples </h3>
<p><b>Example 1.</b> Suppose we have a fair coin.  This means we have a set of events </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=X+%3D+%5C%7BH%2C+T+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X = &#92;{H, T &#92;} " class="latex" />
</div>
<p>and a probability distribution <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> with </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_H+%3D+p_T+%3D+%5Cfrac%7B1%7D%7B2%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_H = p_T = &#92;frac{1}{2} } " class="latex" />
</div>
<p>Now suppose we flip it twice.  We get a set of four events:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=X+%5Ctimes+X+%3D+%5C%7B%28H%2CH%29%2C+%28H%2CT%29%2C+%28T%2CH%29%2C+%28T%2CT%29%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X &#92;times X = &#92;{(H,H), (H,T), (T,H), (T,T)&#92;} " class="latex" />
</div>
<p>Suppose the two coin flips are independent.  Then we describe the pair of coin flips using the probability measure <img src="https://s0.wp.com/latex.php?latex=r+%3D+p+%5Ctimes+p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r = p &#92;times p" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=X+%5Ctimes+X%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X &#92;times X," class="latex" /> with</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+r_%7B%28H%2CH%29%7D+%3D+p_H+p_H+%3D+%5Cfrac%7B1%7D%7B4%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ r_{(H,H)} = p_H p_H = &#92;frac{1}{4} }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+r_%7B%28H%2CT%29%7D+%3D+p_H+p_T+%3D+%5Cfrac%7B1%7D%7B4%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ r_{(H,T)} = p_H p_T = &#92;frac{1}{4} }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+r_%7B%28T%2CH%29%7D+%3D+p_T+p_H+%3D+%5Cfrac%7B1%7D%7B4%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ r_{(T,H)} = p_T p_H = &#92;frac{1}{4} }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+r_%7B%28T%2CT%29%7D+%3D+p_T+p_T+%3D+%5Cfrac%7B1%7D%7B4%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ r_{(T,T)} = p_T p_T = &#92;frac{1}{4} }" class="latex" />
</div>
<p>So, each of the four events&#8212;&#8220;heads, heads&#8221; and so on&#8212;has probability 1/4.  This is fairly boring: you should have known this already!  </p>
<p>But now we can do a harder example:</p>
<p><b>Example 2.</b>  Suppose we have an unfair coin that has a 60% chance of landing heads up and a 40% chance of landing tails up.  Now we have a new probability distribution on <img src="https://s0.wp.com/latex.php?latex=X%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X," class="latex" /> say <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" />:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+q_H+%3D+.6%2C+%5Cquad+q_T+%3D+.4+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ q_H = .6, &#92;quad q_T = .4 } " class="latex" />
</div>
<p>Now say we flip this coin twice.  What are the probabilities of the four different events that can happen?  Let&#8217;s assume the two coin flips are independent.  This means we should describe the pair of coin flips with a probability measure <img src="https://s0.wp.com/latex.php?latex=s+%3D+q+%5Ctimes+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s = q &#92;times q" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=X+%5Ctimes+X.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X &#92;times X." class="latex" />   This tells us the answer to our question.  We can work it out:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+s_%7B%28H%2CH%29%7D+%3D+q_H+q_H+%3D+0.6+%5Ctimes+0.6+%3D+0.36+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ s_{(H,H)} = q_H q_H = 0.6 &#92;times 0.6 = 0.36 }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+s_%7B%28H%2CT%29%7D+%3D+q_H+q_T+%3D+0.6+%5Ctimes+0.4+%3D+0.24+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ s_{(H,T)} = q_H q_T = 0.6 &#92;times 0.4 = 0.24 }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+s_%7B%28T%2CH%29%7D+%3D+q_T+q_H+%3D+0.4+%5Ctimes+0.6+%3D+0.24+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ s_{(T,H)} = q_T q_H = 0.4 &#92;times 0.6 = 0.24 }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+s_%7B%28T%2CT%29%7D+%3D+q_T+q_T+%3D+0.4+%5Ctimes+0.4+%3D+0.16+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ s_{(T,T)} = q_T q_T = 0.4 &#92;times 0.4 = 0.16 }" class="latex" />
</div>
<p><b>Puzzle 1.</b>  In this situation what is the probability that when we flip the coin twice it comes up heads <i>exactly once?</i></p>
<p><b>Puzzle 2.</b>  In this situation what is the probability that when we flip the coin twice it comes up heads <i>at least once?</i></p>
<p>For these puzzles you need to use what I told you in the section on &#8216;Probabilities of subsets&#8217; near the end of <a href="https://johncarlosbaez.wordpress.com/2013/01/26/game-theory-part-7/">Part 7</a>.</p>
<p><b>Puzzle 3.</b> Now suppose we have one fair coin and one coin that has a 60% chance of landing heads up.   The first one is described by the probability distribution <img src="https://s0.wp.com/latex.php?latex=p%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p," class="latex" /> while the second is described by <img src="https://s0.wp.com/latex.php?latex=q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q." class="latex" />   How likely is it that the first lands heads up and the second lands tails up?  We can answer questions like this if the coin flips are independent.  We do this by multiplying <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> to get a probability measure <img src="https://s0.wp.com/latex.php?latex=t+%3D+p+%5Ctimes+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t = p &#92;times q" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=X+%5Ctimes+X.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X &#92;times X." class="latex" />  Remember the rule for how to do this:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=t_%7B%28i%2Cj%29%7D+%3D+p_i+q_j+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t_{(i,j)} = p_i q_j " class="latex" />
</div>
<p>where each of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j" class="latex" /> can be either <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=T.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T." class="latex" /></p>
<p>What are these probabilities:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+t_%7B%28H%2CH%29%7D+%3D+%3F+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ t_{(H,H)} = ? }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+t_%7B%28H%2CT%29%7D+%3D+%3F+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ t_{(H,T)} = ? }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+t_%7B%28T%2CH%29%7D+%3D+%3F+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ t_{(T,H)} = ? }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+t_%7B%28T%2CT%29%7D+%3D+%3F+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ t_{(T,T)} = ? }" class="latex" />
</div>
<p><b>Puzzle 4.</b>  In this situation what is the probability that <i>exactly one</i> coin lands heads up?</p>
<p><b>Puzzle 5.</b>  In this situation what is the probability that <i>at least one</i> coin lands heads up?</p>
<p>Next time we&#8217;ll go a lot further&#8230;</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/01/28/game-theory-part-8/#comments">8 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/mathematics/game-theory/" rel="category tag">game theory</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/01/28/game-theory-part-8/" rel="bookmark" title="Permanent Link to Game Theory (Part&nbsp;8)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-14407 post type-post status-publish format-standard hentry category-game-theory category-mathematics category-probability" id="post-14407">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/01/26/game-theory-part-7/" rel="bookmark">Game Theory (Part&nbsp;7)</a></h2>
				<small>26 January, 2013</small><br />


				<div class="entry">
					<p>We need to learn a little probability theory to go further in our work on game theory.</p>
<p>We&#8217;ll start with some finite set <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> of &#8216;events&#8217;.  The idea is that these are things that can happen&#8212;for example, choices you could make while playing a game.   We assume that if one of these outcomes happens, the others don&#8217;t.   A &#8216;probability distribution&#8217; on this set assigns to each event a number called a &#8216;probability&#8217;&#8212;which says, roughly speaking, how likely that event is.  If we&#8217;ve got some event <img src="https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i," class="latex" /> we&#8217;ll call its probability <img src="https://s0.wp.com/latex.php?latex=p_i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i." class="latex" /></p>
<p>For example, suppose we&#8217;re interested in whether it will rain today or not.  Then we might look at a set of two events:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=X+%3D+%5C%7B%5Ctextrm%7Brain%7D%2C+%5Ctextrm%7Bno+rain%7D+%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X = &#92;{&#92;textrm{rain}, &#92;textrm{no rain} &#92;}" class="latex" />
</div>
<p>If the weatherman says the chance of rain is 20%, then</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=p_%7B%5Ctextrm%7Brain%7D+%7D+%3D+0.2+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_{&#92;textrm{rain} } = 0.2 " class="latex" />
</div>
<p>since 20% is just a fancy way of saying 0.2.  The chance of no rain will then be 80%, or 0.8, since the probabilities should add up to 1:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=p_%7B%5Ctextrm%7Bno+rain%7D%7D+%3D+0.8+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_{&#92;textrm{no rain}} = 0.8 " class="latex" />
</div>
<p>Let&#8217;s make this precise with an official definition:</p>
<p><b>Definition.</b> Given a finite set <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> of <b>events</b>, a <b>probability distribution</b> <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> assigns a real number <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> called a <b>probability</b> to each event <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+X%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i &#92;in X," class="latex" /> such that:</p>
<p>1) <img src="https://s0.wp.com/latex.php?latex=0+%5Cle+p_i+%5Cle+1+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0 &#92;le p_i &#92;le 1 " class="latex" /></p>
<p>and</p>
<p>2) <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Csum_%7Bi+%5Cin+X%7D+p_i+%3D+1%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;sum_{i &#92;in X} p_i = 1} " class="latex" /></p>
<p>Note that this official definition doesn&#8217;t say what an event <i>really is</i>, and it doesn&#8217;t say what probabilities <i>really mean</i>.  But that&#8217;s how it should be!  As usual with math definitions, the words in boldface could be replaced by <i>any other words</i> and the definition would still do its main job, which is to let us prove theorems involving these words.  If we wanted, we could call an event a <b>doohickey</b>, and call a probability a <b>schnoofus</b>.  All our theorems would still be true.</p>
<p>Of course we hope our theorems will be useful in real world applications.  And in these applications, the probabilities <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> will be some way of measuring &#8216;how likely&#8217; events are.  But it&#8217;s actually quite hard to say precisely what probabilities really mean!   People have been arguing about this for centuries.  So it&#8217;s good that we separate this hard task from our definition above, which is quite simple and 100% precise.</p>
<p>Why is it hard to say what probabilities really are?  Well, what does it mean to say &#8220;the probability of rain is 20%&#8221;?  Suppose you see a weather report and read this.  What does it mean?</p>
<p>A student suggests: &#8220;it means that if you looked at a lot of similar days, it would rain on 20% of them.&#8221;</p>
<p>Yes, that&#8217;s pretty good.  But what counts as a &#8220;similar day&#8221;?  How similar does it have to be?  Does everyone have to wear the same clothes?  No, that probably doesn&#8217;t matter, because presumably doesn&#8217;t affect the weather.   But what <i>does</i> affect the weather?  A lot of things!  Do <i>all</i> those things have to be exactly the same for it count as similar day.</p>
<p>And what counts as a &#8220;lot&#8221; of days?  How many do we need?</p>
<p>And it won&#8217;t rain on <i>exactly</i> 20% of those days.  How close do we need to get?</p>
<p>Imagine I have a coin and I claim it lands heads up 50% of the time.  Say I flip it 10 times and it lands heads up every time.  Does that mean I was wrong?  Not necessarily.  It&#8217;s <i>possible</i> that the coin will do this.  It&#8217;s just not very <i>probable</i>.</p>
<p>But look: now we&#8217;re using the word &#8216;probable&#8217;, which is the word we&#8217;re trying to understand!  It&#8217;s getting sort of circular: we&#8217;re saying a coin has a 50% probability of landing heads up if when you flip it a lot of times, it <i>probably</i> lands head up close to 50% of the time.  That&#8217;s not very helpful if you don&#8217;t already have some idea what &#8216;probability&#8217; means.</p>
<p>For all these reasons, and many more, it&#8217;s tricky to say exactly what probabilities really mean.  People have made a lot of progress on this question, but we will sidestep it and focus on learning to calculate with probabilities.</p>
<p>If you want to dig in a bit deeper, try this:</p>
<p>&bull; <a href="http://en.wikipedia.org/wiki/Probability_interpretations">Probability interpretations</a>, Wikipedia.</p>
<h3> Equally likely events </h3>
<p>As I&#8217;ve tried to convince you, it can be hard to figure out the probabilities of events.  But it&#8217;s easy if we assume all the events are equally likely.</p>
<p>Suppose we have a set <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> consisting of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> events.  And suppose that all the probabilities <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> are equal: say for some constant <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c" class="latex" /> we have</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=p_i+%3D+c+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i = c " class="latex" />
</div>
<p>for all <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+X.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i &#92;in X." class="latex" />  Then by rule 1) above,</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+1+%3D+%5Csum_%7Bi+%5Cin+X%7D+p_i+%3D+%5Csum_%7Bi+%5Cin+X%7D+c+%3D+n+c+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ 1 = &#92;sum_{i &#92;in X} p_i = &#92;sum_{i &#92;in X} c = n c } " class="latex" />
</div>
<p>since we&#8217;re just adding the number <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c" class="latex" /> to itself <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> times.  So,</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++c+%3D+%5Cfrac%7B1%7D%7Bn%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  c = &#92;frac{1}{n} } " class="latex" />
</div>
<p>and thus</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_i+%3D+%5Cfrac%7B1%7D%7Bn%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_i = &#92;frac{1}{n} } " class="latex" />
</div>
<p>for all <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i &#92;in X" class="latex" />.</p>
<p>I made this look harder than it really is. I was just trying to show you that it follows from the definitions, not any intuition.  But it&#8217;s obvious: if you have <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> events that are equally likely, each one has probability <img src="https://s0.wp.com/latex.php?latex=1%2Fn.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/n." class="latex" /></p>
<p><b>Example 1.</b>  Suppose we have a coin that can land either heads up or tails up&#8212;let&#8217;s ignore the possibility that it lands on its edge!  Then</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=X+%3D+%5C%7B+H%2C+T%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X = &#92;{ H, T&#92;}" class="latex" />
</div>
<p>If we assume these two events are equally probable, we must have</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_H+%3D+p_T+%3D++%5Cfrac%7B1%7D%7B2%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_H = p_T =  &#92;frac{1}{2} } " class="latex" />
</div>
<p>Note I said <i>&#8220;if we assume&#8221;</i> these two events are equally probable.  I didn&#8217;t say they actually are!  Are they?  Suppose we take a penny and flip it a zillion times.  Will it land heads up almost exactly half a zillion times?</p>
<p>Probably not!  The treasury isn&#8217;t interested in making pennies that do this.  They&#8217;re interested in making the head look like Lincoln, and the tail look like the Lincoln national monument:</p>
<div align="center"><a href="http://en.wikipedia.org/wiki/Penny_%28United_States_coin%29"><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/2010_cent_obverse.png/250px-2010_cent_obverse.png" /></a></div>
<div align="center"><a href="http://en.wikipedia.org/wiki/Penny_%28United_States_coin%29"><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/2005_Penny_Rev_Unc_D.png/250px-2005_Penny_Rev_Unc_D.png" /></a></div>
<p>Or at least they used to.  Since the two sides are different, there&#8217;s no reason they should have the exact same probability of landing on top.</p>
<p>In fact nobody seems to have measured the difference between heads and tails in probabilities for <i>flipping</i> pennies.  For hand-flipped pennies, it seems whatever side that starts on top has a roughly 51% chance of landing on top!  But if you <i>spin</i> a penny, it&#8217;s much more likely to land tails up:</p>
<p>&bull; <a href="http://www.codingthewheel.com/archives/the-coin-flip-a-fundamentally-unfair-proposition">The coin flip: a fundamentally unfair proposition?</a>, <i>Coding the Wheel</i>.</p>
<p><b>Example 2.</b>  Suppose we have a standard deck of cards, well-shuffled, and assume that when I draw a card from this deck, each card is equally likely to be chosen. What is the probability that I draw the ace of spades?</p>
<p>If there&#8217;s no joker in the deck, there are 52 cards, so the answer is 1/52.</p>
<p>Let me remind you how a deck of cards works: I wouldn&#8217;t want someone to fail the course because they didn&#8217;t ever play cards!   Here are the 52 cards in a standard deck.  Here&#8217;s what they all look like (click to enlarge):</p>
<div align="center"><a href="http://math.ucr.edu/home/baez/mathematical/cards.png"><img width="450" src="https://i1.wp.com/math.ucr.edu/home/baez/mathematical/cards.png" /></a></div>
<p>As you can see, they come in 4 kinds, called <b><a href="http://en.wikipedia.org/wiki/Suit_%28cards%29">suits</a></b>.  The suits are:</p>
<p>&bull; clubs: ♣</p>
<p>&bull; spades: ♠</p>
<p>&bull; <font color="red">diamonds: ♦</font></p>
<p>&bull; <font color="red">hearts: ♥</font></p>
<p>Two suits are black and two are red.  Each suit has 13 cards in it, for a total of 4 &times; 13 = 52. The cards in each suit are numbered from 1 to 13, except for four exceptions.  They go like this:</p>
<div align="center">
A, 2, 3, 4, 5, 6, 7, 8, 9, 10, J, Q, K
</div>
<p>A stands for &#8216;ace&#8217;, J for &#8216;jack&#8217;, Q for &#8216;queen&#8217; and K for &#8216;king&#8217;.</p>
<h3> Probabilities of subsets </h3>
<p>If we know a probability distribution on a finite set <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" />, we can define the probability that an event in some subset <img src="https://s0.wp.com/latex.php?latex=S+%5Csubseteq+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S &#92;subseteq X" class="latex" /> will occur.  We define this to be</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7Bp%28S%29+%3D+%5Csum_%7Bi+%5Cin+S%7D+p_i+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{p(S) = &#92;sum_{i &#92;in S} p_i } " class="latex" />
</div>
<p>For example, suppose I always have one of three things for breakfast:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=X+%3D+%5C%7B+%5Ctextrm%7Boatmeal%7D%2C+%5Ctextrm%7Bwaffles%7D%2C+%5Ctextrm%7Beggs%7D+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X = &#92;{ &#92;textrm{oatmeal}, &#92;textrm{waffles}, &#92;textrm{eggs} &#92;} " class="latex" />
</div>
<p>This is my set of outcomes.  If I eat one of these things, I don&#8217;t eat the others, so the probabilities of these different outcomes should add up to 1.</p>
<p>Suppose I have an 86% chance of eating oatmeal for breakfast, a 10% chance of eating waffles, and a 4% chance of eating eggs and toast.  What&#8217;s the probability that I will eat oatmeal <i>or</i> waffles?  These choices form the subset</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=S+%3D+%5C%7B+%5Ctextrm%7Boatmeal%7D%2C+%5Ctextrm%7Bwaffles%7D+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = &#92;{ &#92;textrm{oatmeal}, &#92;textrm{waffles} &#92;} " class="latex" />
</div>
<p>and the probability for this subset is</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=p%28S%29+%3D+p_%7B%5Ctextrm%7Boatmeal%7D%7D+%2B+p_%7B%5Ctextrm%7Bwaffles%7D%7D+%3D+0.86+%2B+0.1+%3D+0.96+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(S) = p_{&#92;textrm{oatmeal}} + p_{&#92;textrm{waffles}} = 0.86 + 0.1 = 0.96 " class="latex" />
</div>
<p>Here&#8217;s an example from cards:</p>
<p><b>Example 2.</b>  Suppose we have a standard deck of cards, well-shuffled, and assume that when I draw a card from this deck, each card is equally likely to be chosen. What is the probability that I draw a card in the suit of hearts?</p>
<p>Since there are 13 cards in the suit of hearts, each with probability 1/52, we add up their probabilities and get</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+13+%5Ctimes+%5Cfrac%7B1%7D%7B52%7D+%3D+%5Cfrac%7B1%7D%7B4%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ 13 &#92;times &#92;frac{1}{52} = &#92;frac{1}{4} }" class="latex" />
</div>
<p>This should make sense, since there are 4 suits, and as many cards in each suit.</p>
<h3> Card tricks </h3>
<p>This is just a fun digression.  The deck of cards involves some weird numerology.  For starters, it has 52 cards.  That&#8217;s a strange number!  Where else have you seen this number?</p>
<p>A student says: &#8220;It&#8217;s the number of weeks in a year.&#8221;</p>
<p>Right!  And these 52 cards are grouped in 4 suits.  What does the year have 4 of?</p>
<p>A student says: &#8220;Seasons!&#8221;</p>
<p>Right!  And we have 52 = 4 &times; 13.  So what are there 13 of?</p>
<p>A student says: &#8220;Weeks in a season!&#8221;</p>
<p>Right!  I have no idea if this is a coincidence or not.  And have you ever added up the values of all the cards in a suit, where we count the ace as 1, and so on?  We get</p>
<div align="center">
1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 + 11 + 12 + 13
</div>
<p>And what&#8217;s that equal to?</p>
<p>After a long pause, a student says &#8220;91.&#8221;</p>
<p>Yes, that&#8217;s a <i>really</i> strange number.  But let&#8217;s say we total up the values of all the cards in the deck, not just one suit.  What do we get?</p>
<p>A student says &#8220;We get 4 &times; 91&#8230; or 364.&#8221;</p>
<p>Right.  Three-hundred and sixty-<i>four</i>.  <i>Almost</i> the number of days in year.</p>
<p>&#8220;So add one more: the joker!  Then you get 365!&#8221;</p>
<p>Right, maybe that&#8217;s why they put an extra card called the <a href="http://en.wikipedia.org/wiki/Joker_%28playing_card%29"><b>joker</b></a> in the deck:</p>
<div align="center"><a href="http://en.wikipedia.org/wiki/Joker_%28playing_card%29"><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Joker_black_02.svg/200px-Joker_black_02.svg.png" /></a></div>
<p>One extra card for one extra day, joker-day&#8230; April Fool&#8217;s Day!  That brings the total up to 365.</p>
<p>Again, I have no idea if this is a coincidence or not. But the people who invented the Tarot deck were pretty weird&mdash;they packed it with symbolism&mdash;so maybe the ordinary cards were designed this way on purpose too.</p>
<p><b>Puzzle.</b>  What are the prime factors of the number 91?  You should know by now&#8230; and you should know what they have to do with the calendar!</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/01/26/game-theory-part-7/#comments">13 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/mathematics/game-theory/" rel="category tag">game theory</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/01/26/game-theory-part-7/" rel="bookmark" title="Permanent Link to Game Theory (Part&nbsp;7)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-13577 post type-post status-publish format-standard hentry category-chemistry category-networks category-oceans category-probability category-software" id="post-13577">
				<h2><a href="https://johncarlosbaez.wordpress.com/2012/12/20/petri-net-programming-part-2/" rel="bookmark">Petri Net Programming (Part&nbsp;2)</a></h2>
				<small>20 December, 2012</small><br />


				<div class="entry">
					<p><i>guest post by <b><a href="http://www.azimuthproject.org/azimuth/show/David+Tanzer">David A. Tanzer</a></b></i></p>
<h3>An introduction to stochastic Petri nets</h3>
<p>In the <a href="https://johncarlosbaez.wordpress.com/2012/10/01/petri-net-programming/">previous article</a>, I explored a simple computational model called Petri nets.  They are used to model reaction networks, and have applications in a wide variety of fields, including population ecology, gene regulatory networks, and chemical reaction networks.  I presented a simulator program for Petri nets, but it had an important limitation:  the model and the simulator contain no notion of the <i>rates</i> of the reactions.  But these rates critically determine the character of the dynamics of network.</p>
<p>Here I will introduce the topic of &#8216;stochastic Petri nets,&#8217; which extends the basic model to include reaction dynamics.  Stochastic means random, and it is presumed that there is an underlying <i>random process</i> that drives the reaction events.   This topic is rich in both its mathematical foundations and its practical applications.  A direct application of the theory yields the rate equation for chemical reactions, which is a cornerstone of chemical reaction theory.  The theory also gives algorithms for analyzing and simulating Petri nets.</p>
<p>We are now entering the &#8216;business&#8217; of software development for applications to science.  The business logic here is nothing but math and science itself.  Our study of this logic is not an academic exercise that is tangential to the implementation effort.  Rather, it is the first phase of a <i>complete</i> software development process for scientific programming applications.</p>
<p>The end goals of this series are to develop working code to analyze and simulate Petri nets, and to apply these tools to informative case studies.  But we have some work to do <i>en route</i>, because we need to truly understand the models in order to properly interpret the algorithms.   The key questions here are when, why, and to what extent the algorithms give results that are empirically predictive.  We will therefore be embarking on some exploratory adventures into the relevant theoretical foundations.  </p>
<p>The overarching subject area to which stochastic Petri nets belong has been described as <i>stochastic mechanics</i> in the <a href="http://math.ucr.edu/home/baez/networks/">network theory</a> series here on Azimuth.  The theme development here will partly parallel that of the network theory series, but with a different focus, since I am addressing a computationally oriented reader.  For an excellent text on the foundations and applications of stochastic mechanics, see:</p>
<p>&bull; Darren Wilkinson, <i>Stochastic Modelling for Systems Biology</i>, Chapman and Hall/CRC Press, Boca Raton, Florida, 2011.</p>
<h3>Review of basic Petri nets</h3>
<p>A Petri net is a graph with two kinds of nodes: species and transitions.  The net is populated with a collection of &#8216;tokens&#8217; that represent individual entities.   Each token is attached to one of the species nodes, and this attachment indicates the type of the token.   We may therefore view a species node as a container that holds all of the tokens of a given type.   </p>
<p>The transitions represent conversion reactions between the tokens.  Each transition is &#8216;wired&#8217; to a collection of input species-containers, and to a collection of output containers.   When it &#8216;fires&#8217;, it removes one token from each input container, and deposits one token to each output container. </p>
<p>Here is the example we gave, for a simplistic model of the formation and dissociation of H<sub>2</sub>O molecules:</p>
<div align="center">
<img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/networks/pictures/H2O-example.png" /></div>
<p>The circles are for species, and the boxes are for transitions.</p>
<p>The transition <b>combine</b> takes in two H tokens and one O token, and outputs one H<sub>2</sub>O token.  The reverse transition is <b>split</b>, which takes in one H<sub>2</sub>O, and outputs two H&#8217;s and one O.</p>
<p>An important application of Petri nets is to the modeling of <i>biochemical</i> reaction networks, which include the gene regulatory networks.  Since genes and enzymes are molecules, and their binding interactions are chemical reactions, the Petri net model is directly applicable.  For example, consider a transition that inputs one gene G, one enzyme E, and outputs the molecular form G &bull; E in which E is bound to a particular site on G.</p>
<p>Applications of Petri nets may differ widely in terms of the population sizes involved in the model.  In general chemistry reactions, the populations are measured in units of moles (where a mole is &#8216;Avogadro&#8217;s number&#8217; 6.022 &middot; 10<sup>23</sup> entities).  In gene regulatory networks, on the other hand, there may only be a handful of genes and enzymes involved in a reaction.  </p>
<p>This difference in scale leads to a qualitative difference in the modelling.  With small population sizes, the stochastic effects will predominate, but with large populations, a continuous, deterministic, average-based approximation can be used.</p>
<h3>Representing Petri nets by reaction formulas</h3>
<p>Petri nets can also be represented by formulas used for chemical reaction networks.  Here is the formula for the Petri net shown above:</p>
<p>H<sub>2</sub>O &harr; H + H + O</p>
<p>or the more compact:</p>
<p>H<sub>2</sub>O &harr; 2 H + O</p>
<p>The double arrow is a compact designation for <i>two</i> separate reactions, which happen to be opposites of each other.</p>
<p>By the way, this reaction is not physically realistic, because one doesn&#8217;t find isolated H and O atoms traveling around and meeting up to form water molecules.  This is the actual reaction pair that predominates in water:</p>
<p>2 H<sub>2</sub>O &harr; OH<sup>&#8211;</sup> + H<sub>3</sub>O<sup>+</sup></p>
<p>Here, a hydrogen nucleus H<sup>+</sup>, with one unit of positive charge, gets removed from one of the H<sub>2</sub>O molecules, leaving behind the <a href="http://en.wikipedia.org/wiki/Hydroxide"><b>hydroxide</b></a> ion OH<sup>&#8211;</sup>.  In the same stroke, this H<sup>+</sup> gets re-attached to the other H<sub>2</sub>O molecule, which thereby becomes a <a href="http://en.wikipedia.org/wiki/Hydronium"><b>hydronium</b></a> ion, H<sub>3</sub>O<sup>+</sup>.</p>
<p>For a more detailed example, consider this reaction chain, which is of concern to the ocean environment:</p>
<p>CO<sub>2</sub> + H<sub>2</sub>O &harr; H<sub>2</sub>CO<sub>3</sub> &harr; H<sup>+</sup> + HCO<sub>3</sub><sup>&#8211;</sup></p>
<p>This shows the formation of <a href="http://en.wikipedia.org/wiki/Carbonic_acid"><b>carbonic acid</b></a>, namely H<sub>2</sub>CO<sub>3</sub>, from water and carbon dioxide.  The next reaction represents the splitting of carbonic acid into a hydrogen ion and a negatively charged <a href="http://en.wikipedia.org/wiki/Bicarbonate"><b>bicarbonate ion</b></a>, HCO<sub>3</sub><sup>&#8211;</sup>.  There is a further reaction, in which a bicarbonate ion further ionizes into an H<sup>+</sup> and a doubly negative <a href="http://en.wikipedia.org/wiki/Carbonate"><b>carbonate ion</b></a> CO<sub>3</sub><sup>2-</sup>.   As the diagram indicates, for each of these reactions, a reverse reaction is also present.   For a more detailed description of this reaction network, see:</p>
<p>&bull; Stephen E. Bialkowski, <a href="http://ion.chem.usu.edu/~sbialkow/Classes/3650/Carbonate/Carbonic%20Acid.html">Carbon dioxide and carbonic acid</a>.</p>
<p>Increased levels of CO<sub>2</sub> in the atmosphere will change the balance of these reactions, leading to a higher concentration of hydrogen ions in the water, i.e., a more acidic ocean.  This is of concern because the metabolic processes of aquatic organisms is sensitive to the pH level of the water.   The ultimate concern is that entire food chains could be disrupted, if some of the organisms cannot survive in a higher pH environment.  See the Wikipedia page on <a href="http://en.wikipedia.org/wiki/Ocean_acidification">ocean acidification</a> for more information.</p>
<p><b>Exercise.</b> Draw Petri net diagrams for these reaction networks.</p>
<h3>Motivation for the study of Petri net dynamics</h3>
<p>The relative rates of the various reactions in a network critically determine the qualitative dynamics of the network as a whole.  This is because the reactions are &#8216;competing&#8217; with each other, and so their relative rates determine the direction in which the state of the system is changing.  For instance, if molecules are breaking down faster then they are being formed, then the system is moving towards full dissociation.  When the rates are equal, the processes balance out, and the system is in an equilibrium state.  Then, there are only temporary fluctuations around the equilibrium conditions.   </p>
<p>The rate of the reactions will depend on the number of tokens present in the system.  For example, if any of the input tokens are zero, then the transition can&#8217;t fire, and so its rate must be zero.  More generally, when there are few input tokens available, there will be fewer reaction events, and so the firing rates will be lower.</p>
<p>Given a specification for the rates in a reaction network, we can then pose the following kinds of questions about its dynamics:</p>
<p>&bull; Does the network have an equilibrium state? </p>
<p>&bull; If so, what are the concentrations of the species at equilibrium?  </p>
<p>&bull; How quickly does it approach the equilibrium? </p>
<p>&bull; At the equilibrium state, there will still be temporary fluctuations around the equilibrium concentrations.  What are the variances of these fluctuations? </p>
<p>&bull; Are there modes in which the network will oscillate between states? </p>
<p>This is the grail we seek.  </p>
<p>Aside from actually performing empirical experiments, such questions can be addressed either analytically or through simulation methods.  In either case, our first step is to define a theoretical model for the dynamics of a Petri net.</p>
<h3>Stochastic Petri nets</h3>
<p>A <b>stochastic Petri net</b> (with kinetics) is a Petri net that is augmented with a specification for the reaction dynamics.  It is defined by the following:  </p>
<p>&bull; An <b>underlying Petri net</b>, which consists of species, transitions, an input map, and an output map.  These maps assign to each transition a multiset of species.  (Multiset means that duplicates are allowed.)  Recall that the state of the net is defined by a <i>marking</i> function, that maps each species to its population count.</p>
<p>&bull; A <b>rate constant</b> that is associated with each transition.</p>
<p>&bull; A <b>kinetic model</b>, that gives the expected firing rate for each transition as a function of the current marking.  Normally, this kinetic function will include the rate constant as a multiplicative factor.</p>
<p>A further &#8216;sanity constraint&#8217; can be put on the kinetic function for a transition:  it should give a positive value if and only if all of its inputs are positive.</p>
<p>&bull; A <b>stochastic model</b>, which defines the probability distribution of the time intervals between firing events.  This specific distribution of the firing intervals for a transition will be a function of the expected firing rate in the current marking.</p>
<p>This definition is based on the standard treatments found, for example in:</p>
<p>&bull; M. Ajmone Marsan, <a href="http://www.fd.cvut.cz/department/k611/pedagog/tho_a/a_soubory/spn_introduction.pdf">Stochastic Petri nets: an elementary introduction</a>, in <i>Advances in Petri Nets</i>, Springer, Berlin, 1989, 1&#8211;23.</p>
<p>or Wilkinson&#8217;s book mentioned above.  I have also added an explicit mention of the kinetic model, based on the &#8216;kinetics&#8217; described in here:</p>
<p>&bull; Martin Feinberg, <a href="http://www.chbmeng.ohio-state.edu/~feinberg/LecturesOnReactionNetworks">Lectures on chemical reaction networks</a>.</p>
<p>There is an implied <i>random process</i> that drives the reaction events.  A classical random process is given by a container with &#8216;particles&#8217; that are randomly traveling around, bouncing off the walls, and colliding with each other.  This is the general idea behind  Brownian motion.  It is called a random process because the outcome results from an &#8216;experiment&#8217; that is not fully determined by the input specification.   In this experiment, you pour in the ingredients (particles of different types), set the temperature (the distributions of the velocities), give it a stir, and then see what happens.  The outcome consists of the paths taken by each of the particles.   </p>
<p>In an important limiting case, the stochastic behavior becomes deterministic, and the population sizes become continuous.  To see this, consider a graph of population sizes over time.  With larger population sizes, the relative jumps caused by the firing of individual transitions become smaller, and graphs look more like continuous curves.  In the limit, we obtain an approximation for high population counts, in which the graphs are continuous curves, and the concentrations are treated as continuous magnitudes.  In a similar way, a pitcher of sugar can be approximately viewed as a continuous fluid.  </p>
<p>This simplification permits the application of continuous mathematics to study of reaction network processes.  It leads to the basic <i>rate equation</i> for reaction networks, which specifies the direction of change of the system as a function of the current state of the system.  </p>
<p>In this article we will be exploring this continuous deterministic formulation of Petri nets, under what is known as the mass action kinetics.  This kinetics is one implementation of the general specification of a kinetic model, as defined above.  This means that it will define the <i>expected</i> firing rate of each transition, in a given marking of the net.  The probabilistic variations in the spacing of the reactions&#8212;around the mean given by the expected firing rate&#8212;is part of the stochastic dynamics, and will be addressed in a subsequent article. </p>
<h3>The mass-action kinetics</h3>
<p>Under the <b>mass action kinetics</b>, the expected firing rate of a transition is proportional to the product of the concentrations of its input species.   For instance, if the reaction were A + C &rarr; D, then the firing rate would be proportional to the concentration of A times the concentration of C, and if the reaction were A + A &rarr; D, it would be proportional to the square of the concentration of A.   </p>
<p>This principle is explained by Feinberg as follows:  </p>
<blockquote><p>For the reaction A+C &rarr; D, an occurrence requires that a molecule of A meet a molecule of C in the reaction, and we take the probability of such an encounter to be proportional to the product [of the concentrations of A and C].   Although we do not presume that every such encounter yields a molecule of D, we nevertheless take the occurrence rate of A+C &rarr; D to be governed by [the product of the concentrations].
</p></blockquote>
<p>For an in-depth proof of the mass action law, see this article:</p>
<p>&bull; Daniel Gillespie, <a href="http://citeseerx.ist.psu.edu/viewdoc/summary/?doi=10.1.1.159.5220">A rigorous definition of the chemical master equation</a>, 1992.</p>
<p>Note that we can easily pass back and forth between speaking of the population counts for the species, and the concentrations of the species, which is just the population count divided by the total volume V of the system.  The mass action law applies to both cases, the only difference being that the constant factors of (1/V) used for concentrations will get absorbed into the rate constants.</p>
<p>The mass action kinetics is a basic law of empirical chemistry.  But there are limits to its validity.  First, as indicated in the proof in the Gillespie, the mass action law rests on the assumptions that the system is well-stirred and in thermal equilibrium.  Further limits are discussed here:</p>
<p>&bull; Georg Job and Regina Ruffler, <a href="http://job-stiftung.de/pdf/buch/physical_chemistry_five_chapters.pdf"><i>Physical Chemistry</i></a> (first five chapters), Section 5.2, 2010.</p>
<p>They write:</p>
<blockquote><p> &#8230;precise measurements show that the relation above is not strictly adhered to. At higher concentrations, values depart quite noticeably from this relation. If we gradually move to lower concentrations, the differences become smaller. The equation here expresses a so-called “limiting law“ which strictly applies only when c &rarr; 0.
</p></blockquote>
<blockquote><p> In practice, this relation serves as a useful approximation up to rather high concentrations. In the case of electrically neutral substances, deviations are only noticeable above 100 mol m<sup>−3</sup>.  For ions, deviations become observable above 1 mol m<sup>−3</sup>, but they are so small that they are easily neglected if accuracy is not of prime concern.
</p></blockquote>
<p>Why would the mass action kinetics break down at high concentrations?  According to the book quoted, it is due to &#8220;molecular and ionic interactions.&#8221;  I haven&#8217;t yet found a more detailed explanation, but here is my supposition about what is meant by molecular interactions in this context.  Doubling the number of A molecules doubles the number of expected collisions between A and C molecules, but it also reduces the probability that any given A and C molecules that are within reacting distance will actually react.  The reaction probability is reduced because the A molecules are &#8216;competing&#8217; for reactions with the C molecules.  With more A molecules, it becomes more likely that a C molecule will simultaneously be within reacting distance of several A molecules; each of these A molecules reduces the probability that the other A molecules will react with the C molecule.   This is most pronounced when the concentrations in a gas get high enough that the molecules start to pack together to form a liquid.  </p>
<h3>The equilibrium relation for a pair of opposite reactions</h3>
<p>Suppose we have two opposite reactions:</p>
<p><img src="https://s0.wp.com/latex.php?latex=T%3A+A+%2B+B+%5Cstackrel%7Bu%7D%7B%5Clongrightarrow%7D+C+%2B+D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T: A + B &#92;stackrel{u}{&#92;longrightarrow} C + D " class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=T%27%3A+C+%2B+D+%5Cstackrel%7Bv%7D%7B%5Clongrightarrow%7D+A+%2B+B+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T&#039;: C + D &#92;stackrel{v}{&#92;longrightarrow} A + B " class="latex" /></p>
<p>Since the reactions have exactly opposite effects on the population sizes, in order for the population sizes to be in a stable equilibrium, the expected firing rates of <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=T%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T&#039;" class="latex" /> must be equal: </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Brate%7D%28T%27%29+%3D+%5Cmathrm%7Brate%7D%28T%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{rate}(T&#039;) = &#92;mathrm{rate}(T) " class="latex" /></p>
<p>By mass action kinetics: </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Brate%7D%28T%29+%3D+u+%5BA%5D+%5BB%5D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{rate}(T) = u [A] [B] " class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Brate%7D%28T%27%29+%3D+v+%5BC%5D+%5BD%5D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{rate}(T&#039;) = v [C] [D] " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5BX%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="[X]" class="latex" /> means the concentration of <img src="https://s0.wp.com/latex.php?latex=X.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X." class="latex" /></p>
<p>Hence at equilibrium:</p>
<p><img src="https://s0.wp.com/latex.php?latex=u+%5BA%5D+%5BB%5D+%3D+v+%5BC%5D+%5BD%5D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="u [A] [B] = v [C] [D] " class="latex" /></p>
<p>So:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7B%5BA%5D%5BB%5D%7D%7B%5BC%5D%5BD%5D%7D+%3D+%5Cfrac%7Bv%7D%7Bu%7D+%3D+K+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{[A][B]}{[C][D]} = &#92;frac{v}{u} = K }" class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="K" class="latex" /> is the equilibrium constant for the reaction pair.  </p>
<h3>Equilibrium solution for the formation and dissociation of a diatomic molecule</h3>
<p>Let A be some type of atom, and let D = A<sub>2</sub> be the diatomic form of A.  Then consider the opposite reactions:</p>
<p><img src="https://s0.wp.com/latex.php?latex=A+%2B+A+%5Cstackrel%7Bu%7D%7B%5Clongrightarrow%7D+D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A + A &#92;stackrel{u}{&#92;longrightarrow} D " class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=D+%5Cstackrel%7Bv%7D%7B%5Clongrightarrow%7D+A+%2B+A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D &#92;stackrel{v}{&#92;longrightarrow} A + A " class="latex" /></p>
<p>From the preceding analysis, at equilibrium the following relation holds:</p>
<p><img src="https://s0.wp.com/latex.php?latex=u+%5BA%5D%5E2+%3D+v+%5BD%5D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="u [A]^2 = v [D] " class="latex" /></p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=N%28A%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N(A)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=N%28B%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N(B)" class="latex" /> be the population counts for A and B, and let</p>
<p><img src="https://s0.wp.com/latex.php?latex=N+%3D+N%28A%29+%2B+2+N%28D%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N = N(A) + 2 N(D) " class="latex" /></p>
<p>be the total number of units of A in the system, whether they be in the form of atoms or diatoms.</p>
<p>The value of <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> is an invariant property of the system.  The reactions cannot change it, because they are just shuffling the units of A from one arrangement to the other.  By way of contrast, <img src="https://s0.wp.com/latex.php?latex=N%28A%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N(A)" class="latex" /> is not an invariant quantity.</p>
<p>Dividing this equation by the total volume <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V" class="latex" />, we get:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5BN%5D+%3D+%5BA%5D+%2B+2+%5BD%5D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="[N] = [A] + 2 [D] " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5BN%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="[N]" class="latex" /> is the concentration of the units of A.</p>
<p>Given a fixed value for <img src="https://s0.wp.com/latex.php?latex=%5BN%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="[N]" class="latex" /> and the rate constants <img src="https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="u" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="v" class="latex" />, we can then solve for the concentrations at equilibrium:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7Bu+%5BA%5D%5E2+%3D+v+%5BD%5D+%3D+v+%28%5BN%5D+-+%5BA%5D%29+%2F+2+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{u [A]^2 = v [D] = v ([N] - [A]) / 2 }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B2+u+%5BA%5D%5E2+%2B+v+%5BA%5D+-+v+%5BN%5D+%3D+0+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{2 u [A]^2 + v [A] - v [N] = 0 }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5BA%5D+%3D+%28-v+%5Cpm+%5Csqrt%7Bv%5E2+%2B+8+u+v+%5BN%5D%7D%29+%2F+4+u+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{[A] = (-v &#92;pm &#92;sqrt{v^2 + 8 u v [N]}) / 4 u }" class="latex" /></p>
<p>Since <img src="https://s0.wp.com/latex.php?latex=%5BA%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="[A]" class="latex" /> can&#8217;t be negative, only the positive square root is valid.</p>
<p>Here is the solution for the case where <img src="https://s0.wp.com/latex.php?latex=u+%3D+v+%3D+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="u = v = 1" class="latex" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5BA%5D+%3D+%28%5Csqrt%7B8+%5BN%5D+%2B+1%7D+-+1%29+%2F+4+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{[A] = (&#92;sqrt{8 [N] + 1} - 1) / 4 }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5BD%5D+%3D+%28%5BN%5D+-+%5BA%5D%29+%2F+2+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{[D] = ([N] - [A]) / 2 }" class="latex" /></p>
<h3>Conclusion</h3>
<p>We&#8217;ve covered a lot of ground, starting with the introduction of the stochastic Petri net model, followed by a general discussion of reaction network dynamics, the mass action laws, and calculating equilibrium solutions for simple reaction networks. </p>
<p>We still have a number of topics to cover on our journey into the foundations, before being able to write <i>informed</i> programs to solve problems with stochastic Petri nets.   Upcoming topics are (1) the deterministic rate equation for general reaction networks and its application to finding equilibrium solutions, and (2) an exploration of the <i>stochastic</i> dynamics of a Petri net.  These are the themes that will support our upcoming software development.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/12/20/petri-net-programming-part-2/#comments">15 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/chemistry/" rel="category tag">chemistry</a>, <a href="https://johncarlosbaez.wordpress.com/category/networks/" rel="category tag">networks</a>, <a href="https://johncarlosbaez.wordpress.com/category/oceans/" rel="category tag">oceans</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>, <a href="https://johncarlosbaez.wordpress.com/category/software/" rel="category tag">software</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/12/20/petri-net-programming-part-2/" rel="bookmark" title="Permanent Link to Petri Net Programming (Part&nbsp;2)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-13488 post type-post status-publish format-standard hentry category-mathematics category-probability" id="post-13488">
				<h2><a href="https://johncarlosbaez.wordpress.com/2012/12/14/game-theory-for-undergraduates/" rel="bookmark">Game Theory for&nbsp;Undergraduates</a></h2>
				<small>14 December, 2012</small><br />


				<div class="entry">
					<p>Starting in January I&#8217;m teaching an introduction to game theory to students who have taken a year of calculus, a quarter of multivariable calculus, but in general nothing else.   The syllabus says this course:</p>
<blockquote><p>
Covers two-person <a href="http://en.wikipedia.org/wiki/Zero%E2%80%93sum_game">zero-sum games</a>, <a href="http://en.wikipedia.org/wiki/Minimax">minimax theorem</a>, and relation to <a href="http://en.wikipedia.org/wiki/Linear_programming">linear programming</a>. Includes <a href="http://en.wikipedia.org/wiki/Non-zero-sum_game#Non-zero.E2.80.93sum">nonzero-sum games</a>, <a href="http://en.wikipedia.org/wiki/Nash_equilibrium">Nash equilibrium theorem</a>, bargaining, the <a href="http://en.wikipedia.org/wiki/Core_%28game_theory%29">core</a>, and the <a href="http://en.wikipedia.org/wiki/Shapley_value">Shapley value</a>. Addresses economic market games.
</p></blockquote>
<p>However, I can do what I want, and I&#8217;d like to include some evolutionary game theory.  Right now I&#8217;m rounding up resources to help me teach this course.  </p>
<p>Here are three books that are not really suitable as texts for a course of this sort, but useful nonetheless:</p>
<p>&bull; Andrew M. Colman, <i>Game Theory and its Applications in the Social and Biological Sciences</i>, Routledge, London, 1995.</p>
<p>This describes 2-person and multi-person zero-sum and nonzero-sum games, concepts like &#8216;Nash equilibrium&#8217;, &#8216;core&#8217; and &#8216;Shapley value&#8217;, their applications, and&#8212;especially refreshing&#8212;<i>empirical evidence</i> comparing the theory of ideal rational players to what actual organisms (including people) do in the real world.</p>
<p>&bull; J. D. Williams, <i>The Compleat Strategyst</i>, McGraw&#8211;Hill, New York, 1966.</p>
<p>This old-fashioned book is chatty and personable.  It features tons of zero-sum games described by 2&times;2, 3&times;3 and 4&times;4 matrices, analyzed in loving detail.  It&#8217;s very limited in scope, but a good supply of examples.</p>
<p>&bull; Lynne Pepall, Dan Richards and George Norman, <i>Industrial Organization: Contemporary Theory and Empirical Applications</i>, Blackwell, Oxford, 2008.</p>
<p>This is a book about industrial organizations, antitrust law, monopolies and oligopolies.   But it uses a hefty portion of game theory, especially in the chapters on &#8216;Static games and Cournot competition&#8217;, &#8216;Price competition&#8217;, and &#8216;Dynamic games and first and second movers&#8217;.  So, I think I can squeeze some nice examples and ideas out of this book to use in my course.</p>
<h3> Over on Google+ </h3>
<p><a href="http://www.qwantz.com/index.php"><img width="440" src="https://lh3.googleusercontent.com/-pUFx-IfYUyI/UMkdfmf7OJI/AAAAAAAATv8/oHy7fnLNq4w/w497-h373/comic2-1387.png" /></a></p>
<p>I also got a lot of help from a discussion <a href="https://plus.google.com/u/0/117663015413546257905/posts/SJXuUWHa3dX">on Google+</a>.  (If ever it seems a bit too quiet here, <a>visit me over there!</a>)</p>
<p>I want the students to play games in class, and Lee Worden had some great advice on how to do that effectively:</p>
<blockquote><p>
For actually playing in class, I like the black-card, red-card system: </p>
<p>&bull; Charles A. Holt and Monica Capra, <a href="http://people.virginia.edu/~cah2k/pdtr.pdf">Classroom games: a prisoner&#8217;s dilemma</a>.</p>
<p>Students can keep their cards at their seats and use them for a whole series of 2-person or n-person games.﻿
</p></blockquote>
<p>I like the double entendre in the title of Holt and Capra&#8217;s paper!  I also like their suggestion of letting students play for small amounts of money: this would grab their attention and also make it easier to explain what their <i>objective</i> should be. </p>
<p>I&#8217;m also considering letting them play for points that improve their <i>grade</i>.  But this might be controversial!  Maybe if it only has a small effect on their grade?  </p>
<p>(Students often ask, when they do badly in a course, what they can do to improve their grade.  Usually I just say &#8220;learn the material and get good at solving problems!&#8221;  But now I could say &#8220;let&#8217;s play a game.  If you win, I&#8217;ll add 5 points to your class score.  If you lose&#8230;.&#8221;)</p>
<p>Vincent Knight gave a nice long reply:</p>
<blockquote><p>
I teach game theory in our MSc program and can suggest two &#8220;games&#8221; that can be played in class:</p>
<p>&bull; Your comic suggests it already, the 2/3rds of the average game. I use that in class and play it twice, once before rationalising it and once after. In the meantime I get TAs to put the results in to a google spreadsheet and show the distribution of guesses to the students. The immediate question is: &#8220;what would happen if we played again and again&#8221;. This brings up ideas of convergence to equilibria.</p>
<p>&bull; The second game I play with students is an Iterated Prisoner&#8217;s dilemma. I separate the whole class (40 students) in to 4 teams and play a round robin tournament of 5 rounds. Specifying that the goal is to minimise total &#8220;years in prison&#8221; (and not the number of duels won). This often throws up a coalition or two at the end which is quite cool.</p>
<p>I don&#8217;t only use the above on our MSc students but also at outreach events and I&#8217;ve written a series of blog posts about it:</p>
<p>&bull; School kids: <a href="http://goo.gl/5u6Ic" rel="nofollow">http://goo.gl/5u6Ic</a></p>
<p>&bull; PhD students: <a href="http://goo.gl/6rkOt" rel="nofollow">http://goo.gl/6rkOt</a></p>
<p>&bull; Conference delegates: <a href="http://goo.gl/JGWM7" rel="nofollow">http://goo.gl/JGWM7</a></p>
<p>&bull; MSc students: <a href="http://goo.gl/oHoz0" rel="nofollow">http://goo.gl/oHoz0</a></p>
<p>The slides I use for the outreach event are available here: <a href="http://goo.gl/vJVWV" rel="nofollow">http://goo.gl/vJVWV</a>.  They include some cool videos (that have certainly made the rounds). I use some of that in the class itself.</p>
<p>I&#8217;m also in the middle of a teaching certification process called pcutl and my first module portfolio is available here: <a href="http://goo.gl/NhJYg" rel="nofollow">http://goo.gl/NhJYg</a>. There&#8217;s a lot more stuff then you might care about in there but towards the end is a lesson plan as well as a reflection about how the session went with the students. There are some pics of the session (with the students up and playing the game) here: <a href="http://goo.gl/wBZwC" rel="nofollow">http://goo.gl/wBZwC</a>.</p>
<p>The notes that I use are in the above portfolio but here is my page on game theory which contains the notes I use on the MSc course (which only has the time to go in to normal form games) and also some videos and Sage Mathematical Software System code: <a href="http://goo.gl/RXr1k" rel="nofollow">http://goo.gl/RXr1k</a>.</p>
<p>Here are 3 videos I put together that I get my students to watch:</p>
<p>&bull; Normal form games and mixed equilibria: <a href="http://goo.gl/dBtDK" rel="nofollow">http://goo.gl/dBtDK</a></p>
<p>&bull; Routing games (Pigou&#8217;s example): <a href="http://goo.gl/807G4" rel="nofollow">http://goo.gl/807G4</a></p>
<p>&bull; Cooperative games (Shapley Value): <a href="http://goo.gl/Pzf1F" rel="nofollow">http://goo.gl/Pzf1F</a></p>
<p>Finally (I really do apologise for the length of this comment), here are some books I recommend:</p>
<p>&bull; Webb&#8217;s <i>Game Theory</i> (in my opinion written for mathematicians): <a href="http://goo.gl/2M83l" rel="nofollow">http://goo.gl/2M83l</a></p>
<p>&bull; Osborne&#8217;s <i>Introduction to Game Theory</i> (a very nice and easy to read text): <a href="http://goo.gl/FXbcd" rel="nofollow">http://goo.gl/FXbcd</a></p>
<p>&bull; Rosenthal&#8217;s <i>A Complete Idiot&#8217;s Guide to Game Theory</i> (this is more of a bedside read, that could serve as an introduction to game theory for a non mathematician): <a href="http://goo.gl/PCs76" rel="nofollow">http://goo.gl/PCs76</a></p>
<p>I&#8217;m actually going to be writing a new game theory course for final year undergraduates next year and will be sharing any resources I put together for that if it&#8217;s of interest to anybody :)
</p></blockquote>
<p>And here are some other suggestions I got:</p>
<p>&bull; Peter Morris, <i>Introduction to Game Theory</i>, Springer, Berlin, 1994.</p>
<p>Over on Google+, Joerg Fliege said this &#8220;is an excellent book for undergraduate students to start with.  I used it myself a couple of years ago for a course in game theory.  It is a bit outdated, though, and does not cover repeat games to any depth.&#8221;</p>
<p>&bull; K. G. Binmore, <i>Playing for Real: a Text on Game Theory</i>, Oxford U. Press, Oxford, 2007.</p>
<p>Benjamin McKay said: &#8220;It has almost no prerequisites, but gets into some serious stuff. I taught game theory once from my own lecture notes, but then I found Binmore&#8217;s book and I wish I had used it instead.&#8221;﻿  A summary says:</p>
<blockquote><p>
This new book is a replacement for Binmore&#8217;s previous game theory textbook, <i>Fun and Games</i>. It is a lighthearted introduction to game theory suitable for advanced undergraduate students or beginning graduate students. It aims to answer three questions: What is game theory? How is game theory applied? Why is game theory right? It is the only book that tackles all three questions seriously without getting heavily mathematical.
</p></blockquote>
<p>&bull; Herbert Gintis, <i>Game Theory Evolving: a Problem-Centered Introduction to Modeling Strategic Behavior</i>, Princeton U. Press, Princeton, 2000.</p>
<p>A summary says this book</p>
<blockquote><p>
exposes students to the techniques and applications of game theory through a problems involving human (and even animal) behaviour. This book shows students how to apply game theory to model how people behave in ways that reflect the nature of human sociality and individuality.
</p></blockquote>
<p>Finally, this one is mostly too advanced for my course, but it&#8217;s 750 pages and it&#8217;s <i>free</i>. </p>
<p>&bull; Noam Nisan, Tim Roughgarde, Eva Tardos and Vijay V. Vazirani, editors, <a href="http://www.cambridge.org/journals/nisan/downloads/Nisan_Non-printable.pdf"><i>Algorithmic Game Theory</i></a>, Cambridge U. Press, Cambridge, 2007.</p>
<p>It&#8217;s about:</p>
<p>&bull; algorithms for computing equilibria in games and markets, </p>
<p>&bull; <a href="http://en.wikipedia.org/wiki/Auction_algorithm">auction algorithms</a>, </p>
<p>&bull; <a href="http://en.wikipedia.org/wiki/Mechanism_design">mechanism design</a> (also known<br />
as &#8216;reverse game theory&#8217;, this is the art of designing a game that coaxes the players into becoming good at doing something you want),</p>
<p>&bull; <a href="http://en.wikipedia.org/wiki/Price_of_anarchy">the price of anarchy</a>: how the efficiency of a system degrades due to selfish behavior of its agents.</p>
<p>Over on Google+, Adam Smith said:</p>
<blockquote><p>
One suggestion is to get some mechanism design into the course (auctions, VCG, &#8230;) and from there into matching. Reasons to do this:</p>
<p>1) Teaching the stable marriage theorem is very fun. </p>
<p>2) This year&#8217;s Nobel prize in economics went to two game theorists for their work on matchings and markets.</p>
<p>3) Interesting auctions are everywhere&#8212;on Ebay, Google&#8217;s ad auctioning system, spectrum distribution, &#8230;
</p></blockquote>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/12/14/game-theory-for-undergraduates/#comments">14 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/12/14/game-theory-for-undergraduates/" rel="bookmark" title="Permanent Link to Game Theory for&nbsp;Undergraduates">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-13135 post type-post status-publish format-standard hentry category-climate category-physics category-probability" id="post-13135">
				<h2><a href="https://johncarlosbaez.wordpress.com/2012/11/13/mathematics-of-the-environment-part-7/" rel="bookmark">Mathematics of the Environment (Part&nbsp;7)</a></h2>
				<small>13 November, 2012</small><br />


				<div class="entry">
					<p><a href="https://johncarlosbaez.wordpress.com/2012/11/10/mathematics-and-the-environment-part-6/">Last time</a> we saw how the ice albedo effect could, in theory, make the Earth&#8217;s climate have two stable states.  In a very simple model, we saw that a hot Earth might stay hot since it&#8217;s dark and absorbs lots of sunlight, while a cold Earth might stay cold&#8212;since it&#8217;s icy and white and reflects most of the sunlight.  </p>
<p>If you haven&#8217;t tried it yet, make sure to play around with this program pioneered by Lesley de Cruz and then implemented in Java by Allan Erskine:</p>
<p>&bull; <a href="http://math.ucr.edu/home/baez/coalbedo/temperature.html">Temperature dynamics</a>.</p>
<p>The explanations were all given in <a href="https://johncarlosbaez.wordpress.com/2012/11/10/mathematics-and-the-environment-part-6/">Part 6</a> so I won&#8217;t repeat them here!   </p>
<p>This week, we&#8217;ll see how <i>noise</i> affects this simple climate model.   We&#8217;ll borrow lots of material from here:</p>
<p>&bull; <a href="http://www.azimuthproject.org/azimuth/show/Glyn+Adgie">Glyn Adgie</a> and <a href="http://www.azimuthproject.org/azimuth/show/Tim+van+Beek">Tim van Beek</a>, <a href="https://johncarlosbaez.wordpress.com/2012/07/30/increasing-the-signal-to-noise-ratio-with-more-noise/">Increasing the signal-to-noise ratio with more noise</a>.   </p>
<p>And we&#8217;ll use software written by these guys together with Allan Erskine.  The power of the Azimuth Project knows no bounds!</p>
<h3> Stochastic differential equations</h3>
<p>The <a href="http://www.azimuthproject.org/azimuth/show/Milankovitch+cycle#Idea">Milankovich cycles</a> are periodic changes in how the Earth orbits the Sun.  One question is: can these changes can be responsible for the ice ages?  On the first sight it seems impossible, because the changes are simply too small. But it turns out that we can find a dynamical system where a small periodic external force is actually strengthened by random &#8216;noise&#8217; in the system. This phenomenon has been dubbed &#8216;stochastic resonance&#8217; and has been proposed as an explanation for the ice ages.  It also shows up in many other phenomena:</p>
<p>&bull; Roberto Benzi, <a href="http://arxiv.org/abs/nlin/0702008">Stochastic resonance: from climate to biology</a>.</p>
<p>But to understand it, we need to think a little about stochastic differential equations.</p>
<p>A lot of systems can be described by ordinary differential equations:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+x%7D%7Bd+t%7D+%3D+f%28x%2C+t%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d x}{d t} = f(x, t)} " class="latex" /> </p>
<p>If <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f" class="latex" /> is nice, the time evolution of the system will be a nice smooth function <img src="https://s0.wp.com/latex.php?latex=x%28t%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x(t)," class="latex" /> like the trajectory of a thrown stone. But there are situations where we have some kind of noise, a chaotic, fluctuating influence, that we would like to take into account. This could be, for example, turbulence in the air flow around a rocket. Or, in our case, short term fluctuations of the weather of the earth. If we take this into account, we get an equation of the form</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+x%7D%7Bd+t%7D+%3D+f%28x%2C+t%29+%2B+w%28t%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d x}{d t} = f(x, t) + w(t) } " class="latex" /></p>
<p>where the <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="w" class="latex" /> is a &#8216;random function&#8217; which models the noise.  Typically this noise is just a simplified way to take into account rapidly changing fine-grained aspects of the system at hand. This way we do not have to explicitly model these aspects, which is often impossible.   </p>
<h3> White noise </h3>
<p>We&#8217;ll look at a model of this sort:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+x%7D%7Bd+t%7D+%3D+f%28x%2C+t%29+%2B+w%28t%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d x}{d t} = f(x, t) + w(t) } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=w%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="w(t)" class="latex" /> is <a href="http://en.wikipedia.org/wiki/White_noise">&#8216;white noise&#8217;</a>.  But what&#8217;s that?  </p>
<p>Very naively speaking, white noise is a random function that typically looks very wild, like this:</p>
<div align="center"><a href="http://en.wikipedia.org/wiki/White_noise"><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/White-noise.png/450px-White-noise.png" /></a></div>
<p>White noise actually has a sound, too: it sounds like <a href="http://upload.wikimedia.org/wikipedia/commons/6/66/Whitenoisesound.ogg">this</a>! The idea is that you can take a random function like the one graphed above, and use it to drive the speakers of your computer, to produce sound waves of an equally wild sort.  And it sounds like static.</p>
<p>However, all this is naive.  Why?   The concept of a &#8216;random function&#8217; is not terribly hard to define, at least if you&#8217;ve taken the usual year-long course on real analysis that we force on our grad students at U.C. Riverside: it&#8217;s a <a href="http://en.wikipedia.org/wiki/Probability_measure">probability measure</a> on some space of functions.   But white noise is a bit too spiky and singular too be a random function: it&#8217;s a random <a href="http://en.wikipedia.org/wiki/Distribution_%28mathematics%29">distribution</a>.  </p>
<p>Distributions were envisioned by Dirac but formalized later by Laurent Schwarz and others.  A distribution <img src="https://s0.wp.com/latex.php?latex=D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D(t)" class="latex" /> is a bit like a function, but often distributions are too nasty to have well-defined values at points!   Instead, all that makes sense are expressions like this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cint_%5Cinfty%5E%5Cinfty+D%28t%29+f%28t%29+%5C%2C+d+t%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;int_&#92;infty^&#92;infty D(t) f(t) &#92;, d t} " class="latex" /></p>
<p>where we multiply the distribution by any <a href="http://en.wikipedia.org/wiki/Compact_support#Compact_support">compactly supported</a> <a href="http://en.wikipedia.org/wiki/Smooth_function">smooth function</a> <img src="https://s0.wp.com/latex.php?latex=f%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(t)" class="latex" /> and then integrate it.  Indeed, we specify a distribution just by saying what all these integrals equal.  For example, the <a href="http://en.wikipedia.org/wiki/Dirac_delta_function">Dirac delta</a> <img src="https://s0.wp.com/latex.php?latex=%5Cdelta%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;delta(t)" class="latex" /> is a distribution defined by</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cint_%5Cinfty%5E%5Cinfty+%5Cdelta%28t%29+f%28t%29+%5C%2C+d+t+%3D+f%280%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;int_&#92;infty^&#92;infty &#92;delta(t) f(t) &#92;, d t = f(0) }" class="latex" /></p>
<p>If you try to imagine the Dirac delta as a function, you run into a paradox: it should be zero everywhere except at <img src="https://s0.wp.com/latex.php?latex=t+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t = 0" class="latex" />, but its integral should equal 1.  So, if you try to graph it, the region under the graph should be an infinitely skinny infinitely tall spike whose area is 1:</p>
<div align="center"><a href="http://en.wikipedia.org/wiki/Dirac_delta_function"><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Dirac_distribution_PDF.svg/300px-Dirac_distribution_PDF.svg.png" /></a></div>
<p>But that&#8217;s impossible, at least in the standard framework of mathematics&#8212;so such a function does not really exist!  </p>
<p>Similarly, white noise <img src="https://s0.wp.com/latex.php?latex=w%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="w(t)" class="latex" /> is too spiky to be an honest random function, but if we multiply it by any compactly supported smooth function <img src="https://s0.wp.com/latex.php?latex=f%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(t)" class="latex" /> and integrate, we get a random variable</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cint_%5Cinfty%5E%5Cinfty+w%28t%29+f%28t%29+%5C%2C+d+t+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;int_&#92;infty^&#92;infty w(t) f(t) &#92;, d t }" class="latex" /></p>
<p>whose probability distribution is a Gaussian with mean zero and standard deviation equal to</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Csqrt%7B+%5Cint_%5Cinfty%5E%5Cinfty+f%28t%29%5E2+%5C%2C+d+t%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;sqrt{ &#92;int_&#92;infty^&#92;infty f(t)^2 &#92;, d t} } " class="latex" /></p>
<p>(Note: the word &#8216;distribution&#8217; has a completely different meaning when it shows up in the phrase <a href="http://en.wikipedia.org/wiki/Probability_density_function">probability distribution</a>!  I&#8217;m assuming you&#8217;re comfortable with <i>that</i> meaning already.)</p>
<p>Indeed, the above formulas make sense and are true, not just when <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f" class="latex" /> is compactly supported and smooth, but whenever </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Csqrt%7B+%5Cint_%5Cinfty%5E%5Cinfty+f%28t%29%5E2+%5C%2C+d+t%7D+%7D+%3C+%5Cinfty+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;sqrt{ &#92;int_&#92;infty^&#92;infty f(t)^2 &#92;, d t} } &lt; &#92;infty " class="latex" /></p>
<p>If you know about Gaussians and you know about this sort of integral, which shows up all over math and physics, you&#8217;ll realize that white noise is an extremely natural concept!</p>
<h3> Brownian motion </h3>
<p>While white noise is not a random function, its integral</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+W%28s%29+%3D+%5Cint_0%5Es+w%28s%29+%5C%2C+ds+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ W(s) = &#92;int_0^s w(s) &#92;, ds } " class="latex" /></p>
<p>turns out to be a well-defined random function.  It has a lot of names, including: the <a href="http://en.wikipedia.org/wiki/Wiener_process">Wiener process</a>, <a href="http://en.wikipedia.org/wiki/Brownian_motion">Brownian motion</a>, <a href="http://en.wikipedia.org/wiki/Brownian_noise">red noise</a> and&#8212;as a kind of off-color joke&#8212;<a href="http://en.wikipedia.org/wiki/Colors_of_noise#Brown.28ian.29_noise">brown noise</a>.  </p>
<p>The capital W here stands for Wiener: that is, <a href="http://en.wikipedia.org/wiki/Norbert_Wiener">Norbert Wiener</a>, the <a href="http://www.technologyreview.com/article/424363/the-original-absent-minded-professor/">famously absent-minded</a> MIT professor who studied this random function&#8230; and also invented <a href="http://en.wikipedia.org/wiki/Cybernetics">cybernetics</a>:</p>
<div align="center"><a href="http://cyberneticzoo.com/?tag=norbert-wiener"><img src="https://i2.wp.com/cyberneticzoo.com/wp-content/uploads/Wiener_May1949.jpg" /></a></div>
<p>Brownian noise sounds like <a href="http://upload.wikimedia.org/wikipedia/commons/4/48/Brown_noise.ogg">this</a>. </p>
<p><b>Puzzle:</b>  How does it sound different from white noise, and why?</p>
<p>It looks like this:</p>
<div align="center"><a href="http://en.wikipedia.org/wiki/Wiener_process#Brownian_scaling"><img src="http://upload.wikimedia.org/wikipedia/commons/2/2a/Wiener_process_animated.gif" /></a>
</div>
<p>Here we are zooming in on closer and closer, while rescaling the vertical axis as well.  We see that Brownian noise is self-similar: if <img src="https://s0.wp.com/latex.php?latex=W%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="W(t)" class="latex" /> is Brownian noise, so is <img src="https://s0.wp.com/latex.php?latex=W%28c+t%29%2F%5Csqrt%7Bc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="W(c t)/&#92;sqrt{c}" class="latex" /> for all <img src="https://s0.wp.com/latex.php?latex=c+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c &gt; 0" class="latex" />.</p>
<p>More importantly for us, Brownian noise is the solution of this differential equation:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+W%7D%7Bd+t%7D+%3D+w%28t%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d W}{d t} = w(t) } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=w%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="w(t)" class="latex" /> is white noise.  This is essentially true by definition, but making it rigorous takes some work.  More fancy stochastic differential equations </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+x%7D%7Bd+t%7D+%3D+f%28x%2C+t%29+%2B+w%28t%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d x}{d t} = f(x, t) + w(t) } " class="latex" /></p>
<p>take even more work to rigorously formulate and solve.  You can read about them here:</p>
<p>&bull; <a href="http://www.azimuthproject.org/azimuth/show/Stochastic+differential+equation">Stochastic differential equation</a>, Azimuth Library.</p>
<p>It&#8217;s actually much easier to explain the <i>difference equations</i> we use to <i>approximately</i> solve these stochastic differential equation on the computer.  Suppose we discretize time into steps like this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=t_i+%3D+i+%5CDelta+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t_i = i &#92;Delta t" class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5CDelta+t+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta t &gt; 0" class="latex" /> is some fixed number, our &#8216;time step&#8217;.  Then we can define</p>
<p><img src="https://s0.wp.com/latex.php?latex=x%28t_%7Bi%2B1%7D%29+%3D+x%28t_i%29+%2B+f%28x%28t_i%29%2C+t_i%29+%5C%3B+%5CDelta+t+%2B+w_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x(t_{i+1}) = x(t_i) + f(x(t_i), t_i) &#92;; &#92;Delta t + w_i " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=w_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="w_i" class="latex" /> are independent Gaussian random variables with mean zero and standard deviation </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7B+%5CDelta+t%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sqrt{ &#92;Delta t}" class="latex" /></p>
<p>The square root in this formula comes from the definition I gave of white noise.</p>
<p>If we use a random number generator to crank out random numbers <img src="https://s0.wp.com/latex.php?latex=w_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="w_i" class="latex" /> distributed in this way, we can write a program to work out the numbers <img src="https://s0.wp.com/latex.php?latex=x%28t_i%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x(t_i)" class="latex" /> if we are given some initial value <img src="https://s0.wp.com/latex.php?latex=x%280%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x(0)" class="latex" />.  And if the time step <img src="https://s0.wp.com/latex.php?latex=%5CDelta+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta t" class="latex" /> is small enough, we can hope to get a &#8216;good approximation to the true solution&#8217;.  Of course defining what we mean by a &#8216;good approximation&#8217; is tricky here&#8230; but I think it&#8217;s more important to just plunge in and see what happens, to get a feel for what&#8217;s going on here.</p>
<h3> Stochastic resonance </h3>
<p>Let&#8217;s do an example of this equation:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+x%7D%7Bd+t%7D+%3D+f%28x%2C+t%29+%2B+w%28t%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d x}{d t} = f(x, t) + w(t) } " class="latex" /></p>
<p>which exhibits &#8216;stochastic resonance&#8217;.  Namely:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+x%7D%7Bd+t%7D+%3D+x%28t%29+-+x%28t%29%5E3+%2B+A+%5C%3B++%5Csin%28t%29++%2B+%5Csqrt%7B2D%7D+w%28t%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d x}{d t} = x(t) - x(t)^3 + A &#92;;  &#92;sin(t)  + &#92;sqrt{2D} w(t) } " class="latex" /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D" class="latex" /> are constants we get to choose.  If we set them both to zero we get:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+x%7D%7Bd+t%7D+%3D+x%28t%29+-+x%28t%29%5E3+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d x}{d t} = x(t) - x(t)^3 } " class="latex" /></p>
<p>This has stable equilibrium solutions at <img src="https://s0.wp.com/latex.php?latex=x+%3D+%5Cpm+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x = &#92;pm 1" class="latex" /> and an unstable equilibrium in between at <img src="https://s0.wp.com/latex.php?latex=x+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x = 0" class="latex" />.  So, this is a bistable model similar to the one we&#8217;ve been studying, but mathematically simpler!  </p>
<p>Then we can add an oscillating time-dependent term:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+x%7D%7Bd+t%7D+%3D+x%28t%29+-+x%28t%29%5E3+%2B+A+%5C%3B++%5Csin%28t%29+%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d x}{d t} = x(t) - x(t)^3 + A &#92;;  &#92;sin(t) }  " class="latex" /></p>
<p>which wiggles the system back and forth.  This can make it jump from one equilibrium to another.  </p>
<p>And then we can add on noise:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+x%7D%7Bd+t%7D+%3D+x%28t%29+-+x%28t%29%5E3+%2B+A+%5C%3B++%5Csin%28t%29++%2B+%5Csqrt%7B2D%7D+w%28t%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d x}{d t} = x(t) - x(t)^3 + A &#92;;  &#92;sin(t)  + &#92;sqrt{2D} w(t) } " class="latex" /></p>
<p>Let&#8217;s see what the solutions look like!</p>
<p>In the following graphs, the green curve is <img src="https://s0.wp.com/latex.php?latex=A+%5Csin%28t%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A &#92;sin(t)," class="latex" />, while the red curve is <img src="https://s0.wp.com/latex.php?latex=x%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x(t)" class="latex" />.  Here is a simulation with a low level of noise:</p>
<div align="center">
<img width="450" src="https://i2.wp.com/www.azimuthproject.org/azimuth/files/stochres_weaknoise.jpg" alt="low noise level" />
</div>
<p>As you can see, within the time of the simulation there is no transition from the stable state at 1 to the one at -1. If we were doing a climate model, this would be like the Earth staying in the warm state.</p>
<p>Here is a simulation with a high noise level:</p>
<div align="center">
<img width="450" src="https://i1.wp.com/math.ucr.edu/home/baez/Stochastic_Resonance_High_Noise_Level.JPG" alt="high noise level" />
</div>
<p>The solution <img src="https://s0.wp.com/latex.php?latex=x%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x(t)" class="latex" /> jumps around wildly. By inspecting the graph with your eyes only, you don&#8217;t see any pattern in it, do you?</p>
<p>But finally, here is a simulation where the noise level is not too small, and not too big:</p>
<div align="center">
<img width="450" src="https://i0.wp.com/www.azimuthproject.org/azimuth/files/stochres_intermednoise.jpg" alt="high noise level" />
</div>
<p>Here we see the noise helping the solution <img src="https://s0.wp.com/latex.php?latex=x%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x(t)" class="latex" /> hops from around <img src="https://s0.wp.com/latex.php?latex=x+%3D+-1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x = -1" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=x+%3D+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x = 1" class="latex" />, or vice versa.  The solution <img src="https://s0.wp.com/latex.php?latex=x%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x(t)" class="latex" /> is not at all &#8216;periodic&#8217;&#8212;it&#8217;s quite random.  But still, it tends to hop back and forth thanks to the combination of the sinusoidal term <img src="https://s0.wp.com/latex.php?latex=A+%5Csin%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A &#92;sin(t)" class="latex" /> and the noise.</p>
<p>Glyn Adgie, Allan Erskine, Jim Stuttard and Tim van Beek have created an online model that lets you solve this stochastic differential equation for different values of <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D" class="latex" />.  You can try it here:</p>
<p>&bull; <a href="http://www.adgie.f9.co.uk/azimuth/stochastic-resonance/Javascript/StochasticResonanceEuler.html">Stochastic resonance example</a>.</p>
<p>You can change the values using the sliders under the graphic and see what happens. You can also choose different &#8216;random seeds&#8217;, which means that the random numbers used in the simulation will be different.</p>
<p>To read more about stochastic resonance, go here:</p>
<p>&bull; <a href="http://www.azimuthproject.org/azimuth/show/Stochastic+resonance">Stochastic resonance</a>, Azimuth Library.</p>
<p>In future weeks I hope to say more about the actual <i>evidence</i> that stochastic resonance plays a role in our glacial cycles!  It would also be great to go back to our climate model from <a href="https://johncarlosbaez.wordpress.com/2012/11/10/mathematics-and-the-environment-part-6/">last time</a> and add noise.   We&#8217;re working on that.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/11/13/mathematics-of-the-environment-part-7/#comments">3 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/climate/" rel="category tag">climate</a>, <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/11/13/mathematics-of-the-environment-part-7/" rel="bookmark" title="Permanent Link to Mathematics of the Environment (Part&nbsp;7)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-12363 post type-post status-publish format-standard hentry category-information-and-entropy category-mathematics category-physics category-probability" id="post-12363">
				<h2><a href="https://johncarlosbaez.wordpress.com/2012/10/08/the-mathematical-origin-of-irreversibility/" rel="bookmark">The Mathematical Origin of&nbsp;Irreversibility</a></h2>
				<small>8 October, 2012</small><br />


				<div class="entry">
					<p><i>guest post by <b><a href="http://aei-mpg.academia.edu/MatteoSmerlak/Papers">Matteo Smerlak</a></b></i></p>
<h3> Introduction </h3>
<p>Thermodynamical dissipation and adaptive evolution are two faces of the same Markovian coin!</p>
<p>Consider this. The <a href="http://en.wikipedia.org/wiki/Second_law_of_thermodynamics">Second Law of Thermodynamics</a> states that the entropy of an isolated thermodynamic system can never decrease; <a href="http://en.wikipedia.org/wiki/Landauer%27s_principle">Landauer&#8217;s principle</a> maintains that the erasure of information inevitably causes dissipation; <a href="http://en.wikipedia.org/wiki/Fisher%27s_fundamental_theorem_of_natural_selection">Fisher&#8217;s fundamental theorem of natural selection</a> asserts that any fitness difference within a population leads to adaptation in an evolution process governed by natural selection. Diverse as they are, these statements have two common characteristics: </p>
<p>1. they express the <i>irreversibility</i> of certain natural phenomena, and </p>
<p>2. the dynamical processes underlying these phenomena involve an element of <i>randomness</i>. </p>
<p>Doesn&#8217;t this suggest to you the following question: Could it be that thermal phenomena, forgetful information processing and adaptive evolution are governed by <i>the same stochastic mechanism?</i> </p>
<p>The answer is—yes! The key to this rather profound connection resides in a universal property of <a href="http://en.wikipedia.org/wiki/Markov_process">Markov processes</a> discovered recently in the context of non-equilibrium statistical mechanics, and known as the <a href="http://en.wikipedia.org/wiki/Fluctuation_theorem">&#8216;fluctuation theorem&#8217;</a>. Typically stated in terms of &#8216;dissipated work&#8217; or &#8216;entropy production&#8217;, this result can be seen as an extension of the Second Law of Thermodynamics to <i>small</i> systems, where thermal fluctuations cannot be neglected. But <i>it is actually much more than this</i>: it is the mathematical underpinning of irreversibility itself, be it thermodynamical, evolutionary, or else. To make this point clear, let me start by giving a general formulation of the fluctuation theorem that makes no reference to physics concepts such as &#8216;heat&#8217; or &#8216;work&#8217;.</p>
<h3> The mathematical fact </h3>
<p>Consider a system randomly jumping between states <img src="https://s0.wp.com/latex.php?latex=a%2C+b%2C%5Cdots&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a, b,&#92;dots" class="latex" /> with (possibly time-dependent) transition rates <img src="https://s0.wp.com/latex.php?latex=%5Cgamma_%7Ba+b%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;gamma_{a b}(t)" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a" class="latex" /> is the state prior to the jump, while <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="b" class="latex" /> is the state after the jump. I&#8217;ll assume that this dynamics defines a (continuous-time) Markov process, namely that the numbers <img src="https://s0.wp.com/latex.php?latex=%5Cgamma_%7Ba+b%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;gamma_{a b}" class="latex" /> are the matrix entries of an <a href="http://math.ucr.edu/home/baez/networks/networks_20.html">infinitesimal stochastic</a> matrix, which means that its off-diagonal entries are non-negative and that its columns sum up to zero. </p>
<p>Now, each possible history <img src="https://s0.wp.com/latex.php?latex=%5Comega%3D%28%5Comega_t%29_%7B0%5Cleq+t%5Cleq+T%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;omega=(&#92;omega_t)_{0&#92;leq t&#92;leq T}" class="latex" /> of this process can be characterized by the sequence of occupied states <img src="https://s0.wp.com/latex.php?latex=a_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a_{j}" class="latex" /> and by the times <img src="https://s0.wp.com/latex.php?latex=%5Ctau_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;tau_{j}" class="latex" /> at which the transitions <img src="https://s0.wp.com/latex.php?latex=a_%7Bj-1%7D%5Clongrightarrow+a_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a_{j-1}&#92;longrightarrow a_{j}" class="latex" /> occur <img src="https://s0.wp.com/latex.php?latex=%280%5Cleq+j%5Cleq+N%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(0&#92;leq j&#92;leq N)" class="latex" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Comega%3D%28%5Comega_%7B0%7D%3Da_%7B0%7D%5Coverset%7B%5Ctau_%7B0%7D%7D%7B%5Clongrightarrow%7D+a_%7B1%7D+%5Coverset%7B%5Ctau_%7B1%7D%7D%7B%5Clongrightarrow%7D%5Ccdots+%5Coverset%7B%5Ctau_%7BN%7D%7D%7B%5Clongrightarrow%7D+a_%7BN%7D%3D%5Comega_%7BT%7D%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;omega=(&#92;omega_{0}=a_{0}&#92;overset{&#92;tau_{0}}{&#92;longrightarrow} a_{1} &#92;overset{&#92;tau_{1}}{&#92;longrightarrow}&#92;cdots &#92;overset{&#92;tau_{N}}{&#92;longrightarrow} a_{N}=&#92;omega_{T})." class="latex" /></p>
<p>Define the <b>skewness</b> <img src="https://s0.wp.com/latex.php?latex=%5Csigma_%7Bj%7D%28%5Ctau_%7Bj%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sigma_{j}(&#92;tau_{j})" class="latex" /> of each of these transitions to be the logarithmic ratio of transition rates:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5Csigma_%7Bj%7D%28%5Ctau_%7Bj%7D%29%3A%3D%5Cln%5Cfrac%7B%5Cgamma_%7Ba_%7Bj%7Da_%7Bj-1%7D%7D%28%5Ctau_%7Bj%7D%29%7D%7B%5Cgamma_%7Ba_%7Bj-1%7Da_%7Bj%7D%7D%28%5Ctau_%7Bj%7D%29%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;sigma_{j}(&#92;tau_{j}):=&#92;ln&#92;frac{&#92;gamma_{a_{j}a_{j-1}}(&#92;tau_{j})}{&#92;gamma_{a_{j-1}a_{j}}(&#92;tau_{j})}}" class="latex" /></p>
<p>Also define the <a href="http://en.wikipedia.org/wiki/Self-information"><b>self-information</b></a> of the system in state <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a" class="latex" /> at time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t" class="latex" /> by:</p>
<p><img src="https://s0.wp.com/latex.php?latex=i_a%28t%29%3A%3D+-%5Cln%5Cpi_%7Ba%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i_a(t):= -&#92;ln&#92;pi_{a}(t)" class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Ba%7D%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi_{a}(t)" class="latex" /> is the probability that the system is in state <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a" class="latex" /> at time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t" class="latex" />, given some prescribed initial distribution <img src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Ba%7D%280%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi_{a}(0)" class="latex" />.  This quantity is also sometimes called the <b>surprisal</b>, as it measures the &#8216;surprise&#8217; of finding out that the system is in state <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a" class="latex" /> at time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t" class="latex" />.</p>
<p>Then the following identity&#8212;the <b>detailed fluctuation theorem</b>&#8212;holds:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BProb%7D%5B%5CDelta+i-%5CSigma%3D-A%5D+%3D+e%5E%7B-A%7D%5C%3B%5Cmathrm%7BProb%7D%5B%5CDelta+i-%5CSigma%3DA%5D+%5C%3B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{Prob}[&#92;Delta i-&#92;Sigma=-A] = e^{-A}&#92;;&#92;mathrm{Prob}[&#92;Delta i-&#92;Sigma=A] &#92;;" class="latex" /></p>
<p>where </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5CSigma%3A%3D%5Csum_%7Bj%7D%5Csigma_%7Bj%7D%28%5Ctau_%7Bj%7D%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;Sigma:=&#92;sum_{j}&#92;sigma_{j}(&#92;tau_{j})}" class="latex" /></p>
<p>is the <b>cumulative skewness</b> along a trajectory of the system, and </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CDelta+i%3D+i_%7Ba_N%7D%28T%29-i_%7Ba_0%7D%280%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta i= i_{a_N}(T)-i_{a_0}(0)" class="latex" /> </p>
<p>is the <b>variation of self-information</b> between the end points of this trajectory.  </p>
<p>This identity has an immediate consequence: if <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5C%2C%5Ccdot%5C%2C%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle&#92;,&#92;cdot&#92;,&#92;rangle" class="latex" /> denotes the average over all realizations of the process, then we have the <b>integral fluctuation theorem</b>: </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+e%5E%7B-%5CDelta+i%2B%5CSigma%7D%5Crangle%3D1%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle e^{-&#92;Delta i+&#92;Sigma}&#92;rangle=1," class="latex" /></p>
<p>which, by the convexity of the exponential and <a href="http://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen&#8217;s inequality</a>, implies:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5CDelta+i%5Crangle%3D%5CDelta+S%5Cgeq%5Clangle%5CSigma%5Crangle.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;Delta i&#92;rangle=&#92;Delta S&#92;geq&#92;langle&#92;Sigma&#92;rangle." class="latex" /></p>
<p>In short: <i>the mean variation of self-information, aka the variation of Shannon entropy</i> </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+S%28t%29%3A%3D+%5Csum_%7Ba%7D%5Cpi_%7Ba%7D%28t%29i_a%28t%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ S(t):= &#92;sum_{a}&#92;pi_{a}(t)i_a(t) }" class="latex" /></p>
<p><i>is bounded from below by the mean cumulative skewness of the underlying stochastic trajectory.</i>  </p>
<p>This is the fundamental mathematical fact underlying irreversibility. To unravel its physical and biological consequences, it suffices to consider the origin and interpretation of the &#8216;skewness&#8217; term in different contexts. (By the way, people usually call <img src="https://s0.wp.com/latex.php?latex=%5CSigma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Sigma" class="latex" /> the &#8216;entropy production&#8217; or &#8216;dissipation function&#8217;&#8212;but how tautological is that?)</p>
<h3> The physical and biological consequences </h3>
<p>Consider first the standard stochastic-thermodynamic scenario where a physical system is kept in contact with a thermal reservoir at inverse temperature <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> and undergoes thermally induced transitions between states <img src="https://s0.wp.com/latex.php?latex=a%2C+b%2C%5Cdots&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a, b,&#92;dots" class="latex" />. By virtue of the <a href="http://en.wikipedia.org/wiki/Detailed_balance"><b>detailed balance condition</b></a>:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+e%5E%7B-%5Cbeta+E_%7Ba%7D%28t%29%7D%5Cgamma_%7Ba+b%7D%28t%29%3De%5E%7B-%5Cbeta+E_%7Bb%7D%28t%29%7D%5Cgamma_%7Bb+a%7D%28t%29%2C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ e^{-&#92;beta E_{a}(t)}&#92;gamma_{a b}(t)=e^{-&#92;beta E_{b}(t)}&#92;gamma_{b a}(t),}" class="latex" /></p>
<p>the skewness <img src="https://s0.wp.com/latex.php?latex=%5Csigma_%7Bj%7D%28%5Ctau_%7Bj%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sigma_{j}(&#92;tau_{j})" class="latex" /> of each such transition is <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta " class="latex" /> times the energy difference between the states <img src="https://s0.wp.com/latex.php?latex=a_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a_{j}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=a_%7Bj-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a_{j-1}" class="latex" />, namely the <i>heat</i> received from the reservoir during the transition. Hence, the mean cumulative skewness <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5CSigma%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;Sigma&#92;rangle" class="latex" /> is nothing but <img src="https://s0.wp.com/latex.php?latex=%5Cbeta%5Clangle+Q%5Crangle%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta&#92;langle Q&#92;rangle," class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> the total heat received by the system along the process. It follows from the detailed fluctuation theorem that </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+e%5E%7B-%5CDelta+i%2B%5Cbeta+Q%7D%5Crangle%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle e^{-&#92;Delta i+&#92;beta Q}&#92;rangle=1" class="latex" /></p>
<p>and therefore </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CDelta+S%5Cgeq%5Cbeta%5Clangle+Q%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta S&#92;geq&#92;beta&#92;langle Q&#92;rangle" class="latex" /> </p>
<p>which is of course <a href="http://en.wikipedia.org/wiki/Clausius_theorem">Clausius&#8217; inequality</a>. In a computational context where the control parameter is the entropy variation itself (such as in a bit-erasure protocol, where <img src="https://s0.wp.com/latex.php?latex=%5CDelta+S%3D-%5Cln+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta S=-&#92;ln 2" class="latex" />), this inequality in turn expresses Landauer&#8217;s principle: it impossible to decrease the self-information of the system&#8217;s state without dissipating a minimal amount of heat into the environment (in this case <img src="https://s0.wp.com/latex.php?latex=-Q+%5Cgeq+k+T%5Cln2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="-Q &#92;geq k T&#92;ln2" class="latex" />, the <a href="http://en.wikipedia.org/wiki/Landauer%27s_principle">&#8216;Landauer bound&#8217;</a>). More general situations (several types of reservoirs, <a href="http://en.wikipedia.org/wiki/Maxwell_demon">Maxwell-demon</a>-like feedback controls) can be treated along the same lines, and the various forms of the Second Law derived from the detailed fluctuation theorem. </p>
<p>Now, many would agree that evolutionary dynamics is a wholly different business from thermodynamics; in particular, notions such as &#8216;heat&#8217; or &#8216;temperature&#8217; are clearly irrelevant to Darwinian evolution. However, the stochastic framework of Markov processes <i>is</i> relevant to describe the genetic evolution of a population, and this fact alone has important consequences. As a simple example, consider the time evolution of mutant fixations <img src="https://s0.wp.com/latex.php?latex=x_%7Ba%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_{a}" class="latex" /> in a population, with <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a" class="latex" /> ranging over the possible genotypes. In a &#8216;symmetric mutation scheme&#8217;, which I understand is biological parlance for &#8216;reversible Markov process&#8217;, meaning one that obeys <a href="http://en.wikipedia.org/wiki/Detailed_balance">detailed balance</a>, the ratio between the <img src="https://s0.wp.com/latex.php?latex=a%5Cmapsto+b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a&#92;mapsto b" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b%5Cmapsto+a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="b&#92;mapsto a" class="latex" /> transition rates is completely determined by the <a href="http://en.wikipedia.org/wiki/Fitness_landscape"><b>fitnesses</b></a> <img src="https://s0.wp.com/latex.php?latex=f_%7Ba%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_{a}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=f_b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_b" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="b" class="latex" />, according to </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5Cfrac%7B%5Cgamma_%7Ba+b%7D%7D%7B%5Cgamma_%7Bb+a%7D%7D+%3D%5Cleft%28%5Cfrac%7Bf_%7Bb%7D%7D%7Bf_%7Ba%7D%7D%5Cright%29%5E%7B%5Cnu%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;frac{&#92;gamma_{a b}}{&#92;gamma_{b a}} =&#92;left(&#92;frac{f_{b}}{f_{a}}&#92;right)^{&#92;nu} }" class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Cnu&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;nu" class="latex" /> is a model-dependent function of the effective population size [Sella2005]. Along a given history of mutant fixations, the cumulated skewness <img src="https://s0.wp.com/latex.php?latex=%5CSigma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Sigma" class="latex" /> is therefore given by minus the <b>fitness flux</b>: </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5CPhi%3D%5Cnu%5Csum_%7Bj%7D%28%5Cln+f_%7Ba_j%7D-%5Cln+f_%7Ba_%7Bj-1%7D%7D%29.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;Phi=&#92;nu&#92;sum_{j}(&#92;ln f_{a_j}-&#92;ln f_{a_{j-1}}).}" class="latex" /></p>
<p>The integral fluctuation theorem then becomes the <b>fitness flux theorem</b>: </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clangle+e%5E%7B-%5CDelta+i+-%5CPhi%7D%5Crangle%3D1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;langle e^{-&#92;Delta i -&#92;Phi}&#92;rangle=1}" class="latex" /></p>
<p>discussed recently by Mustonen and L&auml;ssig [Mustonen2010] and implying Fisher&#8217;s fundamental theorem of natural selection as a special case. (Incidentally, the &#8216;fitness flux theorem&#8217; derived in this reference is more general than this; for instance, it does not rely on the &#8216;symmetric mutation scheme&#8217; assumption above.) The ensuing inequality </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5CPhi%5Crangle%5Cgeq-%5CDelta+S+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;Phi&#92;rangle&#92;geq-&#92;Delta S " class="latex" /> </p>
<p>shows that a positive fitness flux is &#8220;an almost universal evolutionary principle of biological systems&#8221; [Mustonen2010], with negative contributions limited to time intervals with a systematic loss of adaptation (<img src="https://s0.wp.com/latex.php?latex=%5CDelta+S+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta S &gt; 0" class="latex" />). This statement may well be the closest thing to a version of the Second Law of Thermodynamics applying to evolutionary dynamics. </p>
<p>It is really quite remarkable that thermodynamical dissipation and Darwinian evolution can be reduced to the same stochastic mechanism, and that notions such as &#8216;fitness flux&#8217; and &#8216;heat&#8217; can arise as two faces of the same mathematical coin, namely the &#8216;skewness&#8217; of Markovian transitions. After all, the phenomenon of life is in itself a direct challenge to thermodynamics, isn&#8217;t it? When thermal phenomena tend to increase the world&#8217;s disorder, life strives to bring about and maintain exquisitely fine spatial and chemical structures&#8212;which is why Schr&ouml;dinger famously proposed to <i>define</i> life as <i>negative entropy</i>. Could there be a more striking confirmation of his intuition&#8212;and a reconciliation of evolution and thermodynamics in the same go&#8212;than the fundamental inequality of adaptive evolution <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5CPhi%5Crangle%5Cgeq-%5CDelta+S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle&#92;Phi&#92;rangle&#92;geq-&#92;Delta S" class="latex" />?</p>
<p>Surely the detailed fluctuation theorem for Markov processes has other applications, pertaining neither to thermodynamics nor adaptive evolution. Can you think of any?</p>
<h3> Proof of the fluctuation theorem </h3>
<p>I am a physicist, but knowing that many readers of John&#8217;s blog are mathematicians, I&#8217;ll do my best to frame&#8212;and prove&#8212;the FT as an actual theorem. </p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%28%5COmega%2C%5Cmathcal%7BT%7D%2Cp%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;Omega,&#92;mathcal{T},p)" class="latex" /> be a probability space and <img src="https://s0.wp.com/latex.php?latex=%28%5C%2C%5Ccdot%5C%2C%29%5E%7B%5Cdagger%7D%3D%5COmega%5Cto+%5COmega&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;,&#92;cdot&#92;,)^{&#92;dagger}=&#92;Omega&#92;to &#92;Omega" class="latex" /> a measurable involution of <img src="https://s0.wp.com/latex.php?latex=%5COmega&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Omega" class="latex" />. Denote <img src="https://s0.wp.com/latex.php?latex=p%5E%7B%5Cdagger%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p^{&#92;dagger}" class="latex" /> the pushforward probability measure through this involution, and </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+R%3D%5Cln+%5Cfrac%7Bd+p%7D%7Bd+p%5E%5Cdagger%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ R=&#92;ln &#92;frac{d p}{d p^&#92;dagger} }" class="latex" /></p>
<p>the logarithm of the corresponding Radon-Nikodym derivative (we assume <img src="https://s0.wp.com/latex.php?latex=p%5E%5Cdagger&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p^&#92;dagger" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> are mutually absolutely continuous). Then the following lemmas are true, with <img src="https://s0.wp.com/latex.php?latex=%281%29%5CRightarrow%282%29%5CRightarrow%283%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(1)&#92;Rightarrow(2)&#92;Rightarrow(3)" class="latex" />:</p>
<p><b>Lemma 1.</b> The detailed fluctuation relation:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cforall+A%5Cin%5Cmathbb%7BR%7D+%5Cquad++p%5Cbig%28R%5E%7B-1%7D%28-A%29+%5Cbig%29%3De%5E%7B-A%7Dp+%5Cbig%28R%5E%7B-1%7D%28A%29+%5Cbig%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;forall A&#92;in&#92;mathbb{R} &#92;quad  p&#92;big(R^{-1}(-A) &#92;big)=e^{-A}p &#92;big(R^{-1}(A) &#92;big)" class="latex" /></p>
<p><b>Lemma 2.</b>  The integral fluctuation relation:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5Cint_%7B%5COmega%7D+d+p%28%5Comega%29%5C%2Ce%5E%7B-R%28%5Comega%29%7D%3D1+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;int_{&#92;Omega} d p(&#92;omega)&#92;,e^{-R(&#92;omega)}=1 }" class="latex" /></p>
<p><b>Lemma 3.</b>  The positivity of the Kullback-Leibler divergence:</p>
<p><img src="https://s0.wp.com/latex.php?latex=D%28p%5C%2C%5CVert%5C%2C+p%5E%7B%5Cdagger%7D%29%3A%3D%5Cint_%7B%5COmega%7D+d+p%28%5Comega%29%5C%2CR%28%5Comega%29%5Cgeq+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D(p&#92;,&#92;Vert&#92;, p^{&#92;dagger}):=&#92;int_{&#92;Omega} d p(&#92;omega)&#92;,R(&#92;omega)&#92;geq 0." class="latex" /></p>
<p>These are basic facts which anyone can show: <img src="https://s0.wp.com/latex.php?latex=%282%29%5CRightarrow%283%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(2)&#92;Rightarrow(3)" class="latex" /> by Jensen&#8217;s inequality, <img src="https://s0.wp.com/latex.php?latex=%281%29%5CRightarrow%282%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(1)&#92;Rightarrow(2)" class="latex" /> trivially, and <img src="https://s0.wp.com/latex.php?latex=%281%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(1)" class="latex" /> follows from <img src="https://s0.wp.com/latex.php?latex=R%28%5Comega%5E%7B%5Cdagger%7D%29%3D-R%28%5Comega%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="R(&#92;omega^{&#92;dagger})=-R(&#92;omega)" class="latex" /> and the change of variables theorem, as follows,</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+%5Cdisplaystyle%7B+%5Cint_%7BR%5E%7B-1%7D%28-A%29%7D+d+p%28%5Comega%29%7D+%26%3D%26+%5Cdisplaystyle%7B+%5Cint_%7BR%5E%7B-1%7D%28A%29%7Dd+p%5E%7B%5Cdagger%7D%28%5Comega%29+%7D+%5C%5C+%5C%5C+%26%3D%26+%5Cdisplaystyle%7B+%5Cint_%7BR%5E%7B-1%7D%28A%29%7D+d+p%28%5Comega%29%5C%2C+e%5E%7B-R%28%5Comega%29%7D+%7D+%5C%5C+%5C%5C+%26%3D%26+%5Cdisplaystyle%7B+e%5E%7B-A%7D+%5Cint_%7BR%5E%7B-1%7D%28A%29%7D+d+p%28%5Comega%29%7D+.%5Cend%7Barray%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} &#92;displaystyle{ &#92;int_{R^{-1}(-A)} d p(&#92;omega)} &amp;=&amp; &#92;displaystyle{ &#92;int_{R^{-1}(A)}d p^{&#92;dagger}(&#92;omega) } &#92;&#92; &#92;&#92; &amp;=&amp; &#92;displaystyle{ &#92;int_{R^{-1}(A)} d p(&#92;omega)&#92;, e^{-R(&#92;omega)} } &#92;&#92; &#92;&#92; &amp;=&amp; &#92;displaystyle{ e^{-A} &#92;int_{R^{-1}(A)} d p(&#92;omega)} .&#92;end{array}" class="latex" /></p>
<p>But here is the beauty: if </p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=%28%5COmega%2C%5Cmathcal%7BT%7D%2Cp%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;Omega,&#92;mathcal{T},p)" class="latex" /> is actually a Markov process defined over some time interval <img src="https://s0.wp.com/latex.php?latex=%5B0%2CT%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="[0,T]" class="latex" /> and valued in some (say discrete) state space <img src="https://s0.wp.com/latex.php?latex=%5CSigma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Sigma" class="latex" />, with the instantaneous probability <img src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Ba%7D%28t%29%3Dp%5Cbig%28%5C%7B%5Comega_%7Bt%7D%3Da%5C%7D+%5Cbig%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi_{a}(t)=p&#92;big(&#92;{&#92;omega_{t}=a&#92;} &#92;big)" class="latex" /> of each state <img src="https://s0.wp.com/latex.php?latex=a%5Cin%5CSigma&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a&#92;in&#92;Sigma" class="latex" /> satisfying the <b>master equation</b> (aka Kolmogorov equation)</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%5Cpi_%7Ba%7D%28t%29%7D%7Bdt%7D%3D%5Csum_%7Bb%5Cneq+a%7D%5CBig%28%5Cgamma_%7Bb+a%7D%28t%29%5Cpi_%7Ba%7D%28t%29-%5Cgamma_%7Ba+b%7D%28t%29%5Cpi_%7Bb%7D%28t%29%5CBig%29%2C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d&#92;pi_{a}(t)}{dt}=&#92;sum_{b&#92;neq a}&#92;Big(&#92;gamma_{b a}(t)&#92;pi_{a}(t)-&#92;gamma_{a b}(t)&#92;pi_{b}(t)&#92;Big),} " class="latex" /></p>
<p>and</p>
<p>&bull;  the dagger involution is time-reversal, that is <img src="https://s0.wp.com/latex.php?latex=%5Comega%5E%7B%5Cdagger%7D_%7Bt%7D%3A%3D%5Comega_%7BT-t%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;omega^{&#92;dagger}_{t}:=&#92;omega_{T-t}," class="latex" /></p>
<p>then for a given path</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5Comega%3D%28%5Comega_%7B0%7D%3Da_%7B0%7D%5Coverset%7B%5Ctau_%7B0%7D%7D%7B%5Clongrightarrow%7D+a_%7B1%7D+%5Coverset%7B%5Ctau_%7B1%7D%7D%7B%5Clongrightarrow%7D%5Ccdots+%5Coverset%7B%5Ctau_%7BN%7D%7D%7B%5Clongrightarrow%7D+a_%7BN%7D%3D%5Comega_%7BT%7D%29%5Cin%5COmega%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;omega=(&#92;omega_{0}=a_{0}&#92;overset{&#92;tau_{0}}{&#92;longrightarrow} a_{1} &#92;overset{&#92;tau_{1}}{&#92;longrightarrow}&#92;cdots &#92;overset{&#92;tau_{N}}{&#92;longrightarrow} a_{N}=&#92;omega_{T})&#92;in&#92;Omega}" class="latex" /></p>
<p>the logarithmic ratio <img src="https://s0.wp.com/latex.php?latex=R%28%5Comega%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="R(&#92;omega)" class="latex" /> decomposes into &#8216;variation of self-information&#8217; and &#8216;cumulative skewness&#8217; along <img src="https://s0.wp.com/latex.php?latex=%5Comega&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;omega" class="latex" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+R%28%5Comega%29%3D%5Cunderbrace%7B%5CBig%28%5Cln%5Cpi_%7Ba_0%7D%280%29-%5Cln%5Cpi_%7Ba_N%7D%28T%29+%5CBig%29%7D_%7B%5CDelta+i%28%5Comega%29%7D-%5Cunderbrace%7B%5Csum_%7Bj%3D1%7D%5E%7BN%7D%5Cln%5Cfrac%7B%5Cgamma_%7Ba_%7Bj%7Da_%7Bj-1%7D%7D%28%5Ctau_%7Bj%7D%29%7D%7B%5Cgamma_%7Ba_%7Bj-1%7Da_%7Bj%7D%7D%28%5Ctau_%7Bj%7D%29%7D%7D_%7B%5CSigma%28%5Comega%29%7D.%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ R(&#92;omega)=&#92;underbrace{&#92;Big(&#92;ln&#92;pi_{a_0}(0)-&#92;ln&#92;pi_{a_N}(T) &#92;Big)}_{&#92;Delta i(&#92;omega)}-&#92;underbrace{&#92;sum_{j=1}^{N}&#92;ln&#92;frac{&#92;gamma_{a_{j}a_{j-1}}(&#92;tau_{j})}{&#92;gamma_{a_{j-1}a_{j}}(&#92;tau_{j})}}_{&#92;Sigma(&#92;omega)}.}" class="latex" /></p>
<p>This is easy to see if one writes the probability of a path explicitly as</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7Bp%28%5Comega%29%3D%5Cpi_%7Ba_%7B0%7D%7D%280%29%5Cleft%5B%5Cprod_%7Bj%3D1%7D%5E%7BN%7D%5Cphi_%7Ba_%7Bj-1%7D%7D%28%5Ctau_%7Bj-1%7D%2C%5Ctau_%7Bj%7D%29%5Cgamma_%7Ba_%7Bj-1%7Da_%7Bj%7D%7D%28%5Ctau_%7Bj%7D%29%5Cright%5D%5Cphi_%7Ba_%7BN%7D%7D%28%5Ctau_%7BN%7D%2CT%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{p(&#92;omega)=&#92;pi_{a_{0}}(0)&#92;left[&#92;prod_{j=1}^{N}&#92;phi_{a_{j-1}}(&#92;tau_{j-1},&#92;tau_{j})&#92;gamma_{a_{j-1}a_{j}}(&#92;tau_{j})&#92;right]&#92;phi_{a_{N}}(&#92;tau_{N},T)}" class="latex" /></p>
<p>where</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cphi_%7Ba%7D%28%5Ctau%2C%5Ctau%27%29%3D%5Cphi_%7Ba%7D%28%5Ctau%27%2C%5Ctau%29%3D%5Cexp%5CBig%28-%5Csum_%7Bb%5Cneq+a%7D%5Cint_%7B%5Ctau%7D%5E%7B%5Ctau%27%7Ddt%5C%2C+%5Cgamma_%7Ba+b%7D%28t%29%5CBig%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;phi_{a}(&#92;tau,&#92;tau&#039;)=&#92;phi_{a}(&#92;tau&#039;,&#92;tau)=&#92;exp&#92;Big(-&#92;sum_{b&#92;neq a}&#92;int_{&#92;tau}^{&#92;tau&#039;}dt&#92;, &#92;gamma_{a b}(t)&#92;Big)}" class="latex" /></p>
<p>is the probability that the process remains in the state <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a" class="latex" /> between the times <img src="https://s0.wp.com/latex.php?latex=%5Ctau&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;tau" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Ctau%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;tau&#039;" class="latex" />. It follows from the above lemma that</p>
<p><b>Theorem.</b> Let <img src="https://s0.wp.com/latex.php?latex=%28%5COmega%2C%5Cmathcal%7BT%7D%2Cp%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;Omega,&#92;mathcal{T},p)" class="latex" /> be a Markov process and let <img src="https://s0.wp.com/latex.php?latex=i%2C%5CSigma%3A%5COmega%5Crightarrow+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i,&#92;Sigma:&#92;Omega&#92;rightarrow &#92;mathbb{R}" class="latex" /> be defined as above. Then we have</p>
<p>1. The detailed fluctuation theorem:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cforall+A%5Cin%5Cmathbb%7BR%7D%2C+p%5Cbig%28%28%5CDelta+i-%5CSigma%29%5E%7B-1%7D%28-A%29+%5Cbig%29%3De%5E%7B-A%7Dp+%5Cbig%28%28%5CDelta+i-%5CSigma%29%5E%7B-1%7D%28A%29+%5Cbig%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;forall A&#92;in&#92;mathbb{R}, p&#92;big((&#92;Delta i-&#92;Sigma)^{-1}(-A) &#92;big)=e^{-A}p &#92;big((&#92;Delta i-&#92;Sigma)^{-1}(A) &#92;big)" class="latex" /></p>
<p>2.  The integral fluctuation theorem:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cint_%7B%5COmega%7D+d+p%28%5Comega%29%5C%2Ce%5E%7B-%5CDelta+i%28%5Comega%29%2B%5CSigma%28%5Comega%29%7D%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;int_{&#92;Omega} d p(&#92;omega)&#92;,e^{-&#92;Delta i(&#92;omega)+&#92;Sigma(&#92;omega)}=1" class="latex" /></p>
<p>3.  The &#8216;Second Law&#8217; inequality:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5CDelta+S%3A%3D%5Cint_%7B%5COmega%7D+d+p%28%5Comega%29%5C%2C%5CDelta+i%28%5Comega%29%5Cgeq+%5Cint_%7B%5COmega%7D+d+p%28%5Comega%29%5C%2C%5CSigma%28%5Comega%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;Delta S:=&#92;int_{&#92;Omega} d p(&#92;omega)&#92;,&#92;Delta i(&#92;omega)&#92;geq &#92;int_{&#92;Omega} d p(&#92;omega)&#92;,&#92;Sigma(&#92;omega)} " class="latex" /></p>
<p>The same theorem can be formulated for other kinds of Markov processes as well, including diffusion processes (in which case it follows from the <a href="http://en.wikipedia.org/wiki/Girsanov_theorem">Girsanov theorem</a>).</p>
<h3> References </h3>
<p>Landauer&#8217;s principle was introduced here:</p>
<p>&bull; [Landauer1961]  R. Landauer, Irreversibility and heat generation in the computing process}, <i>IBM Journal of Research and Development</i> <b>5</b>, (1961) 183&#8211;191.</p>
<p>and is now being verified experimentally by various groups worldwide.</p>
<p>The &#8216;fundamental theorem of natural selection&#8217; was derived by Fisher in his book:</p>
<p>&bull; [Fisher1930]  R. Fisher, <i>The Genetical Theory of Natural Selection</i>, Clarendon Press, Oxford, 1930.</p>
<p>His derivation has long been considered obscure, even perhaps wrong, but apparently the theorem is now well accepted. I believe the first Markovian models of genetic evolution appeared here:</p>
<p>&bull; [Fisher1922]  R. A. Fisher, On the dominance ratio, <i>Proc. Roy. Soc. Edinb.</i> <b>42</b> (1922), 321&#8211;341.</p>
<p>&bull; [Wright1931]  S. Wright, Evolution in Mendelian populations, <i>Genetics</i> <b>16</b> (1931), 97&#8211;159.</p>
<p>Fluctuation theorems are reviewed here:</p>
<p>&bull; [Sevick2008]  E. Sevick, R. Prabhakar, S. R. Williams, and D. J. Searles, <a href="http://arxiv.org/abs/0709.3888">Fluctuation theorems</a>, <i>Ann. Rev. Phys. Chem.</i> <b>59</b> (2008), 603&#8211;633.</p>
<p>Two of the key ideas for the &#8216;detailed fluctuation theorem&#8217; discussed here are due to Crooks: </p>
<p>&bull; [Crooks1999]  Gavin Crooks, <a href="http://arxiv.org/abs/cond-mat/9901352">The entropy production fluctuation theorem and the nonequilibrium work relation for free energy differences</a>, <a href="http://dx.doi.org/10.1103/PhysRevE.60.2721"><i>Phys. Rev. E</i></a> <b>60</b> (1999), 2721&#8211;2726.</p>
<p>who identified <img src="https://s0.wp.com/latex.php?latex=%28E_%7Ba%7D%28%5Ctau_%7Bj%7D%29-E_%7Ba%7D%28%5Ctau_%7Bj-1%7D%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(E_{a}(&#92;tau_{j})-E_{a}(&#92;tau_{j-1}))" class="latex" /> as heat, and Seifert:</p>
<p>&bull; [Seifert2005]  Udo Seifert, <a href="http://arxiv.org/abs/cond-mat/0503686">Entropy production along a stochastic trajectory and an integral fluctuation theorem</a>, <a href="http://dx.doi.org/10.1103/PhysRevLett.95.040602"><i>Phys. Rev. Lett.</i></a> <b>95</b> (2005), 4.</p>
<p>who understood the relevance of the self-information in this context. </p>
<p>The connection between statistical physics and evolutionary biology is discussed here:</p>
<p>&bull; [Sella2005] G. Sella and A.E. Hirsh, <a href="http://www.pnas.org/content/102/27/9541.full.pdf+html">The application of statistical physics to evolutionary biology</a>, <a href="http://www.pnas.org/content/102/27/9541.short"><i>Proc. Nat. Acad. Sci. USA</i></a> <b>102</b> (2005), 9541&#8211;9546.</p>
<p>and the &#8216;fitness flux theorem&#8217; is derived in </p>
<p>&bull; [Mustonen2010]  V. Mustonen and M. L&auml;ssig, <a href="http://www.pnas.org/content/107/9/4248.full.pdf+html">Fitness flux and ubiquity of adaptive evolution</a>, <a href="http://www.pnas.org/content/107/9/4248.short"><i>Proc. Nat. Acad. Sci. USA</i></a> <b>107</b> (2010), 4248&#8211;4253.</p>
<p>Schr&ouml;dinger&#8217;s famous discussion of the physical nature of life was published here:</p>
<p>&bull; [Schr&ouml;dinger1944]  E. Schr&ouml;dinger, <i>What is Life?</i>, Cambridge University Press, Cambridge, 1944.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/10/08/the-mathematical-origin-of-irreversibility/#comments">57 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/" rel="category tag">information and entropy</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/10/08/the-mathematical-origin-of-irreversibility/" rel="bookmark" title="Permanent Link to The Mathematical Origin of&nbsp;Irreversibility">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-11843 post type-post status-publish format-standard hentry category-information-and-entropy category-mathematics category-probability category-puzzles" id="post-11843">
				<h2><a href="https://johncarlosbaez.wordpress.com/2012/08/29/an-entropy-challenge/" rel="bookmark">An Entropy Challenge</a></h2>
				<small>29 August, 2012</small><br />


				<div class="entry">
					<p>If you like computer calculations, here&#8217;s a little challenge for you.  <a href="http://www.quantumlah.org/people/Dahlsten">Oscar Dahlsten</a> may have solved it, but we&#8217;d love for you to check his work.   It&#8217;s pretty important for the foundations of thermodynamics, but you don&#8217;t need to know any physics or even anything beyond a little algebra to tackle it!  First I&#8217;ll explain it in really simple terms, then I&#8217;ll remind you a bit of why it matters.</p>
<p>We&#8217;re looking for two lists of nonnegative numbers, of the same length, listed in decreasing order:</p>
<p><img src="https://s0.wp.com/latex.php?latex=p_1+%5Cge+p_2+%5Cge+%5Ccdots+%5Cge+p_n+%5Cge+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_1 &#92;ge p_2 &#92;ge &#92;cdots &#92;ge p_n &#92;ge 0 " class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=q_1+%5Cge+q_2+%5Cge+%5Ccdots+%5Cge+q_n+%5Cge+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q_1 &#92;ge q_2 &#92;ge &#92;cdots &#92;ge q_n &#92;ge 0 " class="latex" /></p>
<p>that sum to 1:</p>
<p><img src="https://s0.wp.com/latex.php?latex=p_1+%2B+%5Ccdots+%2B+p_n+%3D+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_1 + &#92;cdots + p_n = 1" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=q_1+%2B+%5Ccdots+%2B+q_n+%3D+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q_1 + &#92;cdots + q_n = 1" class="latex" /></p>
<p>and that obey this inequality:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7B1%7D%7B1+-+%5Cbeta%7D+%5Cln+%5Csum_%7Bi%3D1%7D%5En+p_i%5E%5Cbeta++%5Cle++%5Cfrac%7B1%7D%7B1+-+%5Cbeta%7D+%5Cln+%5Csum_%7Bi%3D1%7D%5En+q_i%5E%5Cbeta+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{1}{1 - &#92;beta} &#92;ln &#92;sum_{i=1}^n p_i^&#92;beta  &#92;le  &#92;frac{1}{1 - &#92;beta} &#92;ln &#92;sum_{i=1}^n q_i^&#92;beta } " class="latex" /></p>
<p>for all <img src="https://s0.wp.com/latex.php?latex=0+%3C+%5Cbeta+%3C+%5Cinfty&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0 &lt; &#92;beta &lt; &#92;infty" class="latex" /> (ignoring <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3D+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta = 1" class="latex" />), yet do <i>not</i> obey these inequalities:</p>
<p><img src="https://s0.wp.com/latex.php?latex=p_1+%2B+%5Ccdots+%2B+p_k+%5Cge+q_1+%2B+%5Ccdots+%2B+q_k+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_1 + &#92;cdots + p_k &#92;ge q_1 + &#92;cdots + q_k " class="latex" /></p>
<p>for all <img src="https://s0.wp.com/latex.php?latex=1+%5Cle+k+%5Cle+n.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1 &#92;le k &#92;le n." class="latex" /></p>
<p>Oscar&#8217;s proposed solution is this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=p+%3D+%280.4%2C+0.29%2C+0.29%2C+0.02%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p = (0.4, 0.29, 0.29, 0.02)" class="latex" /> </p>
<p><img src="https://s0.wp.com/latex.php?latex=q+%3D+%280.39%2C+0.31%2C+0.2%2C+0.1%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q = (0.39, 0.31, 0.2, 0.1)" class="latex" /></p>
<p>Can you see if this works?  Is there a simpler example, like one with lists of just 3 numbers?</p>
<p>This question came up near the end of my post <a href="https://johncarlosbaez.wordpress.com/2012/08/24/more-second-laws-of-thermodynamics/">More Second Laws of Thermodynamics</a>.  I phrased the question with a bit more jargon, and said a lot more about its significance.  Suppose we have two probability distributions on a finite set, say <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q." class="latex" />  We say <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> <b>majorizes</b> <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> if</p>
<p><img src="https://s0.wp.com/latex.php?latex=p_1+%2B+%5Ccdots+%2B+p_k+%5Cge+q_1+%2B+%5Ccdots+%2B+q_k+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_1 + &#92;cdots + p_k &#92;ge q_1 + &#92;cdots + q_k " class="latex" /></p>
<p>for all <img src="https://s0.wp.com/latex.php?latex=1+%5Cle+k+%5Cle+n%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1 &#92;le k &#92;le n," class="latex" /> when we write both lists of numbers in decreasing order.  This means <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> is &#8216;less flat&#8217; than <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" />, so it should have less entropy.  And indeed it does: not just for ordinary entropy, but also for R&eacute;nyi entropy!  The <b>R&eacute;nyi entropy</b> of <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> is defined by</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+H_%5Cbeta%28p%29+%3D+%5Cfrac%7B1%7D%7B1+-+%5Cbeta%7D+%5Cln+%5Csum_%7Bi%3D1%7D%5En+p_i%5E%5Cbeta++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ H_&#92;beta(p) = &#92;frac{1}{1 - &#92;beta} &#92;ln &#92;sum_{i=1}^n p_i^&#92;beta  } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=0+%3C+%5Cbeta+%3C+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0 &lt; &#92;beta &lt; 1" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=1+%3C+%5Cbeta+%3C+%5Cinfty&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1 &lt; &#92;beta &lt; &#92;infty" class="latex" />.  We can also define R&eacute;nyi entropy for <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3D+0%2C+1%2C+%5Cinfty&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta = 0, 1, &#92;infty" class="latex" /> by taking a limit, and at <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3D+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta = 1" class="latex" /> we get the ordinary entropy</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+H_1%28p%29+%3D+-+%5Csum_%7Bi+%3D+1%7D%5En+p_i+%5Cln+%28p_i%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ H_1(p) = - &#92;sum_{i = 1}^n p_i &#92;ln (p_i) } " class="latex" /></p>
<p>The question is whether majorization is more powerful than R&eacute;nyi entropy as a tool to to tell when one probability distribution is less flat than another.  I know that if <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> majorizes <img src="https://s0.wp.com/latex.php?latex=q%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q," class="latex" /> its R&eacute;nyi entropy is less than than that of <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> for all <img src="https://s0.wp.com/latex.php?latex=0+%5Cle+%5Cbeta+%5Cle+%5Cinfty.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0 &#92;le &#92;beta &#92;le &#92;infty." class="latex" />  Your mission, should you choose to accept it, is to show the converse is not true.  </p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/08/29/an-entropy-challenge/#comments">30 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/" rel="category tag">information and entropy</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>, <a href="https://johncarlosbaez.wordpress.com/category/puzzles/" rel="category tag">puzzles</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/08/29/an-entropy-challenge/" rel="bookmark" title="Permanent Link to An Entropy Challenge">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-11756 post type-post status-publish format-standard hentry category-information-and-entropy category-physics category-probability" id="post-11756">
				<h2><a href="https://johncarlosbaez.wordpress.com/2012/08/24/more-second-laws-of-thermodynamics/" rel="bookmark">More Second Laws of&nbsp;Thermodynamics</a></h2>
				<small>24 August, 2012</small><br />


				<div class="entry">
					<p><a href="http://www.quantumlah.org/people/Dahlsten">Oscar Dahlsten</a> is visiting the Centre for Quantum Technologies, so we&#8217;re continuing some conversations about entropy that we started last year, back when the <a href="https://johncarlosbaez.wordpress.com/2011/02/10/rnyi-entropy-and-free-energy/">Entropy Club</a> was active.  But now <a href="http://www.cs.ox.ac.uk/people/jamie.vicary/">Jamie Vicary</a> and <a href="http://www.azimuthproject.org/azimuth/show/Brendan+Fong">Brendan Fong</a> are involved in the conversations.</p>
<p>I was surprised when Oscar told me that for a large class of random processes, the usual second law of thermodynamics is just one of infinitely many laws saying that various kinds of disorder increase.  I&#8217;m annoyed that nobody ever told me about this before! It&#8217;s as if they told me about conservation of <i>energy</i> but not conservation of <i>schmenergy</i>, and <i>phlenergy</i>, and <i>zenergy</i>&#8230;</p>
<p>So I need to tell you about this.  You may not understand it, but at least I can say I tried.  I don&#8217;t want you blaming <i>me</i> for concealing all these extra second laws of thermodynamics!</p>
<p>Here&#8217;s the basic idea.   Not all random processes are guaranteed to make entropy increase.  But a bunch of them always make probability distributions flatter in a certain precise sense.  This makes the entropy of the probability distribution increase.  But when you make a probability distribution flatter in this sense, a bunch of other quantities increase too!  For example, besides the usual entropy, there are infinitely many other kinds of entropy, called &#8216;R&eacute;nyi entropies&#8217;, one for each number between 0 and &infin;.  And a doubly stochastic operator makes <i>all</i> the R&eacute;nyi entropies increase!  This fact is a special case of Theorem 10 here:</p>
<p>&bull; Tim van Erven and Peter Harremoës, <a href="http://arxiv.org/abs/1001.4448">Rényi divergence and majorization</a>.  </p>
<p>Let me state this fact precisely, and then say a word about how this is related to quantum theory and &#8216;the collapse of the wavefunction&#8217;.</p>
<p>To keep things simple let&#8217;s talk about probability distributions on a finite set, though Erven and Harremoës generalize it all to a measure space.  </p>
<p>How do we make precise the concept that one probability distribution is flatter than another?  You know it when you see it, at least some of the time.  For example, suppose I have some system in thermal equilibrium at some temperature, and the probabilities of it being in various states look like this:</p>
<div align="center"><img width="250" src="https://i0.wp.com/math.ucr.edu/home/baez/biodiversity/probabilities_T=1.png" alt="" /></div>
<p>Then say I triple the temperature.   The probabilities flatten out:</p>
<div align="center"><img width="250" src="https://i2.wp.com/math.ucr.edu/home/baez/biodiversity/probabilities_T=3.png" alt="" /></div>
<p>But how can we make this concept precise in a completely general way?  We can do it using the concept of &#8216;majorization&#8217;.  If one probability distribution is <i>less</i> flat than another, people say it &#8216;majorizes&#8217; that other one. </p>
<p>Here&#8217;s the definition.  Say we have two probability distributions <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> on the same set.  For each one, list the probabilities in decreasing order:</p>
<p><img src="https://s0.wp.com/latex.php?latex=p_1+%5Cge+p_2+%5Cge+%5Ccdots+%5Cge+p_n+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_1 &#92;ge p_2 &#92;ge &#92;cdots &#92;ge p_n " class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=q_1+%5Cge+q_2+%5Cge+%5Ccdots+%5Cge+q_n+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q_1 &#92;ge q_2 &#92;ge &#92;cdots &#92;ge q_n " class="latex" /></p>
<p>Then we say <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> <b> <a href="http://en.wikipedia.org/wiki/Majorization">majorizes</a></b> <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> if </p>
<p><img src="https://s0.wp.com/latex.php?latex=p_1+%2B+%5Ccdots+%2B+p_k+%5Cge+q_1+%2B+%5Ccdots+%2B+q_k+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_1 + &#92;cdots + p_k &#92;ge q_1 + &#92;cdots + q_k " class="latex" /></p>
<p>for all <img src="https://s0.wp.com/latex.php?latex=1+%5Cle+k+%5Cle+n.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1 &#92;le k &#92;le n." class="latex" />  So, the idea is that the biggest probabilities in the distribution <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> add up to more than the corresponding biggest ones in <img src="https://s0.wp.com/latex.php?latex=q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q." class="latex" /></p>
<p>In 1960, Alfred R&eacute;nyi defined a generalization of the usual Shannon entropy that depends on a parameter <img src="https://s0.wp.com/latex.php?latex=%5Cbeta.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta." class="latex" />  If <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> is a probability distribution on a finite set, its <b><a href="https://johncarlosbaez.wordpress.com/2011/02/10/rnyi-entropy-and-free-energy/">R&eacute;nyi entropy</a></b> of order <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> is defined to be</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+H_%5Cbeta%28p%29+%3D+%5Cfrac%7B1%7D%7B1+-+%5Cbeta%7D+%5Cln+%5Csum_i+p_i%5E%5Cbeta+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ H_&#92;beta(p) = &#92;frac{1}{1 - &#92;beta} &#92;ln &#92;sum_i p_i^&#92;beta } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=0+%5Cle+%5Cbeta+%3C+%5Cinfty.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0 &#92;le &#92;beta &lt; &#92;infty." class="latex" />   Well, to be honest: if <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> is 0, 1, or <img src="https://s0.wp.com/latex.php?latex=%5Cinfty&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;infty" class="latex" /> we have to define this by taking a limit where we let <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> creep up to that value.  But the limit exists, and when <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3D+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta = 1" class="latex" /> we get the usual Shannon entropy</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+H_1%28p%29+%3D+-+%5Csum_i+p_i+%5Cln%28p_i%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ H_1(p) = - &#92;sum_i p_i &#92;ln(p_i) } " class="latex" /></p>
<p>As I explained a while ago, R&eacute;nyi entropies are important ways of measuring <a href="https://johncarlosbaez.wordpress.com/2012/07/02/the-mathematics-of-biodiversity-part-4/">biodiversity</a>.  But here&#8217;s what I learned just now, from the paper by Erven and Harremoës:</p>
<p><b>Theorem 1.</b>  If a probability distribution <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> majorizes a probability distribution <img src="https://s0.wp.com/latex.php?latex=q%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q," class="latex" /> its R&eacute;nyi entropies are smaller:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+H_%5Cbeta%28p%29+%5Cle+H_%5Cbeta%28q%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ H_&#92;beta(p) &#92;le H_&#92;beta(q) } " class="latex" /></p>
<p>for all <img src="https://s0.wp.com/latex.php?latex=0+%5Cle+%5Cbeta+%3C+%5Cinfty.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0 &#92;le &#92;beta &lt; &#92;infty." class="latex" /></p>
<p>And here&#8217;s what makes this fact so nice.  If you do something to a classical system in a way that might involve some randomness, we can describe your action using a stochastic matrix.   An <img src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n &#92;times n" class="latex" /> matrix <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" /> is called <b><a href="http://en.wikipedia.org/wiki/Stochastic_matrix">stochastic</a></b> if whenever <img src="https://s0.wp.com/latex.php?latex=p+%5Cin+%5Cmathbb%7BR%7D%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p &#92;in &#92;mathbb{R}^n" class="latex" /> is a probability distribution, so is <img src="https://s0.wp.com/latex.php?latex=T+p.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T p." class="latex" /> This is equivalent to saying:</p>
<p>&bull;  the matrix entries of <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" /> are all <img src="https://s0.wp.com/latex.php?latex=%5Cge+0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ge 0," class="latex" /> and</p>
<p>&bull;  each column of <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" /> sums to 1.</p>
<p>If <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" /> is stochastic, it&#8217;s not necessarily true that the entropy of <img src="https://s0.wp.com/latex.php?latex=T+p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T p" class="latex" /> is greater than or equal to that of <img src="https://s0.wp.com/latex.php?latex=p%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p," class="latex" /> not even for the Shannon entropy.  </p>
<p><b>Puzzle 1.</b> Find a counterexample.</p>
<p>However, entropy does increase if we use specially nice stochastic matrices called &#8216;doubly stochastic&#8217; matrices.   People say a matrix <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" /> <b><a href="http://en.wikipedia.org/wiki/Doubly_stochastic_matrix">doubly stochastic</a></b> if it&#8217;s stochastic and it maps the probability distribution</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_0+%3D+%28%5Cfrac%7B1%7D%7Bn%7D%2C+%5Cdots%2C+%5Cfrac%7B1%7D%7Bn%7D%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_0 = (&#92;frac{1}{n}, &#92;dots, &#92;frac{1}{n}) } " class="latex" /></p>
<p>to itself.  This is the most spread-out probability distribution of all: every other probability distribution majorizes this one.</p>
<p>Why do they call such matrices &#8216;doubly&#8217; stochastic?  Well, if you&#8217;ve got a stochastic matrix, each <i>column</i> sums to one.  But a stochastic operator is doubly stochastic if and only if each <i>row</i> sums to 1 as well.</p>
<p>Here&#8217;s a really cool fact:</p>
<p><b>Theorem 2.</b>  If <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" /> is doubly stochastic, <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> majorizes <img src="https://s0.wp.com/latex.php?latex=T+p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T p" class="latex" /> for any probability distribution <img src="https://s0.wp.com/latex.php?latex=p+%5Cin+%5Cmathbb%7BR%7D%5En.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p &#92;in &#92;mathbb{R}^n." class="latex" />  Conversely, if a probability distribution <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> majorizes a probability distribution <img src="https://s0.wp.com/latex.php?latex=q%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q," class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=q+%3D+T+p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q = T p" class="latex" /> for some doubly stochastic matrix <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" />.</p>
<p>Taken together, Theorems 1 and 2 say that doubly stochastic transformations increase entropy&#8230; but not just Shannon entropy!  They increase all the different R&eacute;nyi entropies, as well.  So if time evolution is described by a doubly stochastic matrix, we get <i>lots</i> of &#8216;second laws of thermodynamics&#8217;, saying that all these different kinds of entropy increase!</p>
<p>Finally, what does all this have to do with quantum mechanics, and collapsing the wavefunction?  There are different things to say, but this is the simplest:</p>
<p><b>Theorem 3.</b>  Given two probability distributions <img src="https://s0.wp.com/latex.php?latex=p%2C+q+%5Cin+%5Cmathbb%7BR%7D%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p, q &#92;in &#92;mathbb{R}^n" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> majorizes <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> if and only there exists a self-adjoint matrix <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D" class="latex" /> with eigenvalues <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> and diagonal entries <img src="https://s0.wp.com/latex.php?latex=q_i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q_i." class="latex" /></p>
<p>The matrix <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D" class="latex" /> will be a <a href="http://en.wikipedia.org/wiki/Density_matrix"><b>density matrix</b></a>: a self-adjoint matrix with positive eigenvalues and trace equal to 1.  We use such matrices to describe mixed states in quantum mechanics.  </p>
<p>Theorem 3 gives a precise sense in which preparing a quantum system in some state, letting time evolve, and then measuring it &#8216;increases randomness&#8217;.  </p>
<p>How?  Well, suppose we have a quantum system whose Hilbert space is <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BC%7D%5En.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{C}^n." class="latex" />  If we prepare the system in a mixture of the standard basis states with probabilities <img src="https://s0.wp.com/latex.php?latex=p_i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i," class="latex" /> we can describe it with a diagonal density matrix <img src="https://s0.wp.com/latex.php?latex=D_0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D_0." class="latex" />  Then suppose we wait a while and some unitary time evolution occurs.  The system is now described by a new density matrix </p>
<p><img src="https://s0.wp.com/latex.php?latex=D+%3D+U+D_0+%5C%2C+U%5E%7B-1%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D = U D_0 &#92;, U^{-1} " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="U" class="latex" /> is some unitary operator.  If we then do a measurement to see which of the standard basis states our system now lies in, we&#8217;ll get the different possible results with probabilities <img src="https://s0.wp.com/latex.php?latex=q_i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q_i," class="latex" /> the diagonal entries of <img src="https://s0.wp.com/latex.php?latex=D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D." class="latex" />  But the eigenvalues of <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D" class="latex" /> will still be the numbers <img src="https://s0.wp.com/latex.php?latex=p_i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i." class="latex" />  So, by the theorem, <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> majorizes <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" />!</p>
<p>So, not only Shannon entropy but also all the R&eacute;nyi entropies will increase!</p>
<p>Of course, there are some big physics questions lurking here.  Like: <i>what about the real world?</i>   In the real world, do lots of different kinds of entropy tend to increase, or just some?  </p>
<p>Of course, there&#8217;s a huge famous old problem about how reversible time evolution can be compatible with <i>any</i> sort of law saying that entropy must always increase!   Still, there are some arguments, going back to Boltzmann&#8217;s H-theorem, which show entropy increases under some extra conditions.  So then we can ask if other kinds of entropy, like R&eacute;nyi entropy, increase as well.  This will be true whenever we can argue that time evolution is described by doubly stochastic matrices.  Theorem 3 gives a partial answer, but there&#8217;s probably much more to say. </p>
<p>I don&#8217;t have much more to say right now, though. I&#8217;ll just point out that while doubly stochastic matrices map the &#8216;maximally smeared-out&#8217; probability distribution</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_0+%3D+%28%5Cfrac%7B1%7D%7Bn%7D%2C+%5Cdots%2C+%5Cfrac%7B1%7D%7Bn%7D%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_0 = (&#92;frac{1}{n}, &#92;dots, &#92;frac{1}{n}) } " class="latex" /></p>
<p>to itself, a lot of this theory generalizes to stochastic matrices that map exactly one <i>other</i> probability distribution to itself.  We need to work with <a href="http://en.wikipedia.org/wiki/R%C3%A9nyi_entropy#R.C3.A9nyi_divergence">relative R&eacute;nyi entropy</a> instead of R&eacute;nyi entropy, and so on, but I don&#8217;t think these adjustments are really a big deal.  And there are nice theorems that let you know when a stochastic matrix maps exactly one probability distribution to itself, based on the <a href="https://johncarlosbaez.wordpress.com/2012/08/06/network-theory-part-20/">Perron&ndash;Frobenius theorem</a>.</p>
<h3> References </h3>
<p>I already gave you a reference for Theorem 1, namely the paper by Erven and Harremoës, though I don&#8217;t think they were the first to prove this particular result: they generalize it quite a lot.</p>
<p>What about Theorem 2?  It goes back at least to here:</p>
<p>&bull; Barry C. Arnold, <i>Majorization and the Lorenz Order: A Brief Introduction</i>, Springer Lecture Notes in Statistics <b>43</b>, Springer, Berlin, 1987.</p>
<p>The partial order on probability distributions given by majorization is also called the &#8216;Lorenz order&#8217;, but mainly when we consider probability distributions on infinite sets.  This name  presumably comes from the <a href="http://en.wikipedia.org/wiki/Lorenz_curve">Lorenz curve</a>, a measure of income inequality.  This curve shows for the bottom x% of households, what percentage y% of the total income they have:</p>
<div align="center"><a href="http://en.wikipedia.org/wiki/Lorenz_curve"><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Economics_Gini_coefficient2.svg/400px-Economics_Gini_coefficient2.svg.png" /></a></div>
<p><b>Puzzle 2.</b> If you&#8217;ve got two different probability distributions of incomes, and one majorizes the other, how are their Lorenz curves related?</p>
<p>When we generalize majorization by letting some other probability distribution take the place of</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_0+%3D+%28%5Cfrac%7B1%7D%7Bn%7D%2C+%5Cdots%2C+%5Cfrac%7B1%7D%7Bn%7D%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_0 = (&#92;frac{1}{n}, &#92;dots, &#92;frac{1}{n}) } " class="latex" /></p>
<p>it seems people call it the &#8216;Markov order&#8217;.   Here&#8217;s a really fascinating paper on that, which I&#8217;m just barely beginning to understand:</p>
<p>&bull; A. N. Gorban, P. A. Gorban and G. Judge, <a href="http://arxiv.org/abs/1003.1377">Entropy: the Markov ordering approach</a>, <i><a href="http://www.mdpi.com/1099-4300/12/5/1145">Entropy</a></i> <b>12</b> (2010), 1145&#8211;1193. </p>
<p>What about Theorem 3?  Apparently it goes back to here:</p>
<p>&bull; A. Uhlmann, <i>Wiss. Z. Karl-Marx-Univ. Leipzig</i> <b>20</b> (1971), 633.</p>
<p>though I only know this thanks to a more recent paper:</p>
<p>&bull; Michael A. Nielsen, <a href="http://arxiv.org/abs/quant-ph/9811053">Conditions for a class of entanglement transformations</a>, <i>Phys. Rev. Lett.</i> <b>83</b> (1999), 436&#8211;439.</p>
<p>By the way, Nielsen&#8217;s paper contains another very nice result about majorization!  Suppose you have states <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi" class="latex" /> of a 2-part quantum system.  You can trace out one part and get density matrices describing mixed states of the other part, say <img src="https://s0.wp.com/latex.php?latex=D_%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D_&#92;psi" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=D_%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D_&#92;phi" class="latex" />.  Then Nielsen shows you can get from <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi" class="latex" /> using &#8216;local operations and classical communication&#8217; if and only if <img src="https://s0.wp.com/latex.php?latex=D_%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D_&#92;phi" class="latex" /> majorizes <img src="https://s0.wp.com/latex.php?latex=D_%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D_&#92;psi" class="latex" />.  Note that things are going backwards here compared to how they&#8217;ve been going in the rest of this post: if we can get from <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi" class="latex" />, then all forms of entropy go <i>down</i> when we go from <img src="https://s0.wp.com/latex.php?latex=D_%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D_&#92;psi" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=D_%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D_&#92;phi" class="latex" />!  This &#8216;anti-second-law&#8217; behavior is confusing at first, but <a href="https://johncarlosbaez.wordpress.com/2011/06/02/a-characterization-of-entropy/">familiar to me by now</a>.</p>
<p>When I first learned all this stuff, I naturally thought of the following question&#8212;maybe you did too, just now.  If <img src="https://s0.wp.com/latex.php?latex=p%2C+q+%5Cin+%5Cmathbb%7BR%7D%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p, q &#92;in &#92;mathbb{R}^n" class="latex" /> are probability distributions and </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+H_%5Cbeta%28p%29+%5Cle+H_%5Cbeta%28q%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ H_&#92;beta(p) &#92;le H_&#92;beta(q) } " class="latex" /></p>
<p>for all  <img src="https://s0.wp.com/latex.php?latex=0+%5Cle+%5Cbeta+%3C+%5Cinfty&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0 &#92;le &#92;beta &lt; &#92;infty" class="latex" />, is it true that <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> majorizes <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" />?</p>
<p>Apparently the answer must be <i>no</i>, because Klimesh has gone to quite a bit of work to obtain a weaker conclusion: not that <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> majorizes <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" />, but that <img src="https://s0.wp.com/latex.php?latex=p+%5Cotimes+r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p &#92;otimes r" class="latex" /> majorizes <img src="https://s0.wp.com/latex.php?latex=q+%5Cotimes+r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q &#92;otimes r" class="latex" /> for some probability distribution <img src="https://s0.wp.com/latex.php?latex=r+%5Cin+%5Cmathbb%7BR%7D%5Em.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r &#92;in &#92;mathbb{R}^m." class="latex" />  He calls this <b>catalytic majorization</b>, with <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" /> serving as a &#8216;catalyst&#8217;:</p>
<p>&bull; Matthew Klimesh, <a href="http://arxiv.org/abs/0709.3680">Inequalities that collectively completely characterizes the catalytic majorization relation</a>.</p>
<p>I thank <a href="http://www.vlatkovedral.org/">Vlatko Vedral</a> here at the CQT for pointing this out!</p>
<p>Finally, here is a good general introduction to majorization, pointed out by Vasileios Anagnostopoulos:</p>
<p>&bull; T. Ando, Majorization, doubly stochastic matrices, and comparison of eigenvalues, <i><a href="http://www.sciencedirect.com/science/article/pii/0024379589905806#">Linear Algebra and its Applications</a></i> <b>118</b> (1989), 163-–248.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/08/24/more-second-laws-of-thermodynamics/#comments">47 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/" rel="category tag">information and entropy</a>, <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/08/24/more-second-laws-of-thermodynamics/" rel="bookmark" title="Permanent Link to More Second Laws of&nbsp;Thermodynamics">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-11696 post type-post status-publish format-standard hentry category-chemistry category-mathematics category-networks category-probability" id="post-11696">
				<h2><a href="https://johncarlosbaez.wordpress.com/2012/08/23/network-theory-part-24/" rel="bookmark">Network Theory (Part&nbsp;24)</a></h2>
				<small>23 August, 2012</small><br />


				<div class="entry">
					<p>Now we&#8217;ve reached the climax of our story so far: we&#8217;re ready to prove the deficiency zero theorem.  First let&#8217;s talk about it informally a bit.  Then we&#8217;ll review the notation, and then&#8212;hang on to your seat!&#8212;we&#8217;ll give the proof.</p>
<p>The crucial trick is to relate a bunch of chemical reactions, described by a &#8216;reaction network&#8217; like this:</p>
<div align="center"><img width="200" src="https://i1.wp.com/math.ucr.edu/home/baez/networks/chemical_reaction_network_part_20_VII.png" alt="" /></div>
<p>to a simpler problem where a system randomly hops between states arranged in the same pattern:</p>
<div align="center"><img width="200" src="https://i1.wp.com/math.ucr.edu/home/baez/networks/markov_process_vs_reaction_network_4.png" alt="" /></div>
<p>This is sort of amazing, because we&#8217;ve thrown out lots of detail.  It&#8217;s also amazing because this simpler problem is <i>linear</i>.  In the original problem, the chance that a reaction turns a B + E into a D is proportional to the number of B&#8217;s <i>times</i> the number of E&#8217;s.  That&#8217;s nonlinear!  But in the simplified problem, the chance that your system hops from state 4 to state 3 is just proportional to the probability that it&#8217;s in state 4 to begin with.  That&#8217;s linear.  </p>
<p>The wonderful thing is that, at least under some conditions, we can find <i>equilibrium</i> solutions of our original problem starting from equilibrium solutions of the simpler problem. </p>
<p>Let&#8217;s roughly sketch how it works, and where we are so far.  Our simplified problem is described by an equation like this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%7D%7Bd+t%7D+%5Cpsi+%3D+H+%5Cpsi+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d}{d t} &#92;psi = H &#92;psi } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> is a function that the probability of being in each state, and <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> describes the probability per time of hopping from one state to another.   We can easily understand quite a lot about the equilibrium solutions, where <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> doesn&#8217;t change at all:</p>
<p><img src="https://s0.wp.com/latex.php?latex=H+%5Cpsi+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H &#92;psi = 0 " class="latex" /></p>
<p>because this is a linear equation.  We did this in <a href="http://math.ucr.edu/home/baez/networks/networks_23.html">Part 23</a>.  Of course, when I say &#8216;easily&#8217;, that&#8217;s a relative thing: we needed to use the Perron&ndash;Frobenius theorem, which Jacob introduced in <a href="http://math.ucr.edu/home/baez/networks_20.html">Part 20</a>.  But that&#8217;s a well-known theorem in linear algebra, and it&#8217;s easy to apply here.</p>
<p>In <a href="http://math.ucr.edu/home/baez/networks_22.html">Part 22</a>, we saw that the original problem was described by an equation like this, called the &#8216;rate equation&#8217;:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+x%7D%7Bd+t%7D+%3D+Y+H+x%5EY++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d x}{d t} = Y H x^Y  } " class="latex" /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> is a vector whose entries describe the amount of each kind of chemical: the amount of A&#8217;s, the amount of B&#8217;s, and so on.  The matrix <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> is the same as in the simplified problem, but <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" /> is a matrix that says how many times each chemical shows up in each spot in our reaction network:</p>
<div align="center"><img width="200" src="https://i1.wp.com/math.ucr.edu/home/baez/networks/chemical_reaction_network_part_20_VII.png" alt="" /></div>
<p>The key thing to notice is <img src="https://s0.wp.com/latex.php?latex=x%5EY%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x^Y," class="latex" /> where we take a vector and raise it to the power of a matrix.   We explained this operation back in <a href="http://math.ucr.edu/home/baez/networks_22.html">Part 22</a>.  It&#8217;s this operation that says how many B + E pairs we have, for example, given the number of B&#8217;s and the number of E&#8217;s.  It&#8217;s this that makes the rate equation nonlinear.  </p>
<p>Now, we&#8217;re looking for equilibrium solutions of the rate equation, where the rate of change is zero:</p>
<p><img src="https://s0.wp.com/latex.php?latex=Y+H+x%5EY+%3D+0++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y H x^Y = 0  " class="latex" /></p>
<p>But in fact we&#8217;ll do even better!  We&#8217;ll find solutions of this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=H+x%5EY+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H x^Y = 0" class="latex" /></p>
<p>And we&#8217;ll get these by taking our solutions of this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=H+%5Cpsi+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H &#92;psi = 0 " class="latex" /></p>
<p>and adjusting them so that </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi+%3D+x%5EY+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi = x^Y " class="latex" /></p>
<p>while <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> remains a solution of <img src="https://s0.wp.com/latex.php?latex=H+%5Cpsi+%3D+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H &#92;psi = 0." class="latex" />  </p>
<p>But: how do we do this &#8216;adjusting&#8217;?  That&#8217;s the crux of the whole business!  That&#8217;s what we&#8217;ll do today.  </p>
<p>Remember, <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> is a function that gives a probability for each &#8216;state&#8217;, or numbered box here:</p>
<div align="center"><img width="200" src="https://i1.wp.com/math.ucr.edu/home/baez/networks/markov_process_vs_reaction_network_4.png" alt="" /></div>
<p>The picture here consists of two pieces, called &#8216;connected components&#8217;: the piece containing boxes 0 and 1, and the piece containing boxes 2, 3 and 4.  It turns out that we can multiply <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> by a function that&#8217;s constant on each connected component, and if we had <img src="https://s0.wp.com/latex.php?latex=H+%5Cpsi+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H &#92;psi = 0" class="latex" /> to begin with, that will still be true afterward.  The reason is that there&#8217;s no way for <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> to &#8216;leak across&#8217; from one component to another.  It&#8217;s like having water in separate buckets.  You can increase the amount of water in one bucket, and decrease it another, and as long as the water&#8217;s surface remains flat in each bucket, the whole situation remains in equilibrium.</p>
<p>That&#8217;s sort of obvious.  What&#8217;s not obvious is that we can adjust <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> this way so as to ensure</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi+%3D+x%5EY+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi = x^Y " class="latex" /></p>
<p>for some <img src="https://s0.wp.com/latex.php?latex=x.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x." class="latex" />  </p>
<p>And indeed, it&#8217;s not always true!  It&#8217;s only true if our reaction network obeys a special condition.  It needs to have &#8216;deficiency zero&#8217;.  We defined this concept back in <a href="http://math.ucr.edu/home/baez/networks/networks_21.html">Part 21</a>, but now we&#8217;ll finally use it for something.  It turns out to be precisely the right condition to guarantee we can tweak any function on our set of states,  multiplying it by a function that&#8217;s constant on each connected component, and get a new function <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> with</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi+%3D+x%5EY+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi = x^Y " class="latex" /></p>
<p>When all is said and done, that is the key to the deficiency zero theorem.</p>
<h3> Review </h3>
<p>The battle is almost upon us&mdash;we&#8217;ve got one last chance to review our notation.   We start with a <b>stochastic reaction network</b>:</p>
<div align="center">
<img src="https://i2.wp.com/math.ucr.edu/home/baez/networks/reaction_network_diagram_1.png" alt="" />
</div>
<p>This consists of:</p>
<p>&bull; finite sets of <b>transitions</b> <img src="https://s0.wp.com/latex.php?latex=T%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T," class="latex" /> <b>complexes</b> <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="K" class="latex" /> and <b>species</b> <img src="https://s0.wp.com/latex.php?latex=S%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S," class="latex" /></p>
<p>&bull; a map <img src="https://s0.wp.com/latex.php?latex=r%3A+T+%5Cto+%280%2C%5Cinfty%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r: T &#92;to (0,&#92;infty)" class="latex" /> giving a <b>rate constant</b> for each transition,</p>
<p>&bull; <b>source</b> and <b>target</b> maps <img src="https://s0.wp.com/latex.php?latex=s%2Ct+%3A+T+%5Cto+K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s,t : T &#92;to K" class="latex" /> saying where each transition starts and ends,</p>
<p>&bull; a one-to-one map <img src="https://s0.wp.com/latex.php?latex=Y+%3A+K+%5Cto+%5Cmathbb%7BN%7D%5ES&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y : K &#92;to &#92;mathbb{N}^S" class="latex" /> saying how each complex is made of species.</p>
<p>Then we extend <img src="https://s0.wp.com/latex.php?latex=s%2C+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s, t" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" /> to linear maps:</p>
<div align="center">
<img src="https://i0.wp.com/math.ucr.edu/home/baez/networks/reaction_network_diagram_6.png" /></div>
<p>Then we put inner products on these vector spaces as described <a href="http://math.ucr.edu/home/baez/networks/networks_22.html">last time</a>, which lets us &#8216;turn around&#8217; the maps <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t" class="latex" /> by taking their adjoints:</p>
<p><img src="https://s0.wp.com/latex.php?latex=s%5E%5Cdagger%2C+t%5E%5Cdagger+%3A+%5Cmathbb%7BR%7D%5EK+%5Cto+%5Cmathbb%7BR%7D%5ET+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s^&#92;dagger, t^&#92;dagger : &#92;mathbb{R}^K &#92;to &#92;mathbb{R}^T " class="latex" /></p>
<p>More surprisingly, we can &#8216;turn around&#8217; <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" /> and get a <i>nonlinear</i> map using &#8216;matrix exponentiation&#8217;:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccc%7D+%5Cmathbb%7BR%7D%5ES+%26%5Cto%26+%5Cmathbb%7BR%7D%5EK+%5C%5C+++++++++++++++++++++++++++++++x+++++%26%5Cmapsto%26+++x%5EY+%5Cend%7Barray%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccc} &#92;mathbb{R}^S &amp;&#92;to&amp; &#92;mathbb{R}^K &#92;&#92;                               x     &amp;&#92;mapsto&amp;   x^Y &#92;end{array} " class="latex" /></p>
<p>This is most easily understood by thinking of <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> as a row vector and <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" /> as a matrix:</p>
<p><img src="https://i1.wp.com/math.ucr.edu/home/baez/networks/matrix_exponential.png" /></p>
<p>Remember, complexes are made out of species.   The matrix entry <img src="https://s0.wp.com/latex.php?latex=Y_%7Bi+j%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y_{i j}" class="latex" /> says how many things of the <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j" class="latex" />th species there are in a complex of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th kind.   If <img src="https://s0.wp.com/latex.php?latex=%5Cpsi+%5Cin+%5Cmathbb%7BR%7D%5EK&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi &#92;in &#92;mathbb{R}^K" class="latex" /> says how many complexes there are of each kind, <img src="https://s0.wp.com/latex.php?latex=Y+%5Cpsi+%5Cin+%5Cmathbb%7BR%7D%5ES&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y &#92;psi &#92;in &#92;mathbb{R}^S" class="latex" /> says how many things there are of each species.  Conversely, if <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5Cmathbb%7BR%7D%5ES&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &#92;in &#92;mathbb{R}^S" class="latex" /> says how many things there are of each species, <img src="https://s0.wp.com/latex.php?latex=x%5EY+%5Cin+%5Cmathbb%7BR%7D%5EK&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x^Y &#92;in &#92;mathbb{R}^K" class="latex" /> says how many ways we can build each kind of complex from them.</p>
<p>So, we get these maps:</p>
<div align="center">
<img src="https://i0.wp.com/math.ucr.edu/home/baez/networks/reaction_network_diagram_7.png" /></div>
<p>Next, the <b>boundary operator</b> </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpartial+%3A+%5Cmathbb%7BR%7D%5ET+%5Cto+%5Cmathbb%7BR%7D%5EK+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial : &#92;mathbb{R}^T &#92;to &#92;mathbb{R}^K " class="latex" /> </p>
<p>describes how each transition causes a change in complexes:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpartial+%3D+t+-+s+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial = t - s " class="latex" /></p>
<p>As we saw <a href="http://math.ucr.edu/home/baez/networks/networks_24.html">last time</a>, there is a <b>Hamiltonian</b> </p>
<p><img src="https://s0.wp.com/latex.php?latex=H+%3A+%5Cmathbb%7BR%7D%5EK+%5Cto+%5Cmathbb%7BR%7D%5EK+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H : &#92;mathbb{R}^K &#92;to &#92;mathbb{R}^K " class="latex" /></p>
<p>describing a Markov processes on the set of complexes, given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=H+%3D+%5Cpartial+s%5E%5Cdagger+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H = &#92;partial s^&#92;dagger " class="latex" /></p>
<p>But the star of the show is the rate equation.  This describes how the number of things of each species changes with time.  We write these numbers in a list and get a vector <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5Cmathbb%7BR%7D%5ES&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &#92;in &#92;mathbb{R}^S" class="latex" /> with nonnegative components.  The <b>rate equation</b> says:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+x%7D%7Bd+t%7D+%3D+Y+H+x%5EY+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d x}{d t} = Y H x^Y } " class="latex" /></p>
<p>We can read this as follows:</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> says how many things of each species we have now.</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=x%5EY&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x^Y" class="latex" /> says how many complexes of each kind we can build from these species. </p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=s%5E%5Cdagger+x%5EY&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s^&#92;dagger x^Y" class="latex" /> says how many transitions of each kind can originate starting from these complexes, with each transition weighted by its rate.</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=H+x%5EY+%3D+%5Cpartial+s%5E%5Cdagger+x%5EY&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H x^Y = &#92;partial s^&#92;dagger x^Y" class="latex" /> is the rate of change of the number of complexes of each kind, due to these transitions.  </p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=Y+H+x%5EY&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y H x^Y" class="latex" /> is the rate of change of the number of things of each species.</p>
<h3> The zero deficiency theorem </h3>
<p>We are looking for <b>equilibrium solutions</b> of the rate equation, where the number of things of each species doesn&#8217;t change at all:</p>
<p><img src="https://s0.wp.com/latex.php?latex=Y+H+x%5EY+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y H x^Y = 0 " class="latex" /></p>
<p>In fact we will find <b>complex balanced</b> equilibrium solutions, where even the number of complexes of each kind doesn&#8217;t change:</p>
<p><img src="https://s0.wp.com/latex.php?latex=H+x%5EY+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H x^Y = 0 " class="latex" /></p>
<p>More precisely, we have:</p>
<p><b>Deficiency Zero Theorem (Child&#8217;s Version).</b>   Suppose we have a reaction network obeying these two conditions:</p>
<p>1. It is <b>weakly reversible</b>, meaning that whenever there&#8217;s a transition from one complex <img src="https://s0.wp.com/latex.php?latex=%5Ckappa&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;kappa" class="latex" /> to another <img src="https://s0.wp.com/latex.php?latex=%5Ckappa%27%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;kappa&#039;," class="latex" /> there&#8217;s a directed path of transitions going back from <img src="https://s0.wp.com/latex.php?latex=%5Ckappa%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;kappa&#039;" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%5Ckappa.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;kappa." class="latex" /></p>
<p>2.  It has <b>deficiency zero</b>, meaning <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bim%7D+%5Cpartial++%5Ccap+%5Cmathrm%7Bker%7D+Y+%3D+%5C%7B+0+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{im} &#92;partial  &#92;cap &#92;mathrm{ker} Y = &#92;{ 0 &#92;} " class="latex" />.</p>
<p>Then for any choice of rate constants there exists a complex balanced equilibrium solution of the rate equation where all species are present in nonzero amounts.  In other words, there exists <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5Cmathbb%7BR%7D%5ES&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &#92;in &#92;mathbb{R}^S" class="latex" /> with all components positive and such that:</p>
<p><img src="https://s0.wp.com/latex.php?latex=H+x%5EY+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H x^Y = 0 " class="latex" /></p>
<p><b>Proof.</b> Because our reaction network is weakly reversible, the theorems in <a href="http://math.ucr.edu/home/baez/networks/networks_23.html">Part 23</a> show there exists <img src="https://s0.wp.com/latex.php?latex=%5Cpsi+%5Cin+%280%2C%5Cinfty%29%5EK&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi &#92;in (0,&#92;infty)^K" class="latex" /> with </p>
<p><img src="https://s0.wp.com/latex.php?latex=H+%5Cpsi+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H &#92;psi = 0 " class="latex" /></p>
<p>This <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> may not be of the form <img src="https://s0.wp.com/latex.php?latex=x%5EY%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x^Y," class="latex" /> but we shall adjust <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> so that it becomes of this form, while still remaining a solution of <img src="https://s0.wp.com/latex.php?latex=H+%5Cpsi+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H &#92;psi = 0 " class="latex" />latex .   To do this, we need a couple of lemmas:</p>
<p><b>Lemma 1.</b> <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bker%7D+%5Cpartial%5E%5Cdagger+%2B+%5Cmathrm%7Bim%7D+Y%5E%5Cdagger+%3D+%5Cmathbb%7BR%7D%5EK.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{ker} &#92;partial^&#92;dagger + &#92;mathrm{im} Y^&#92;dagger = &#92;mathbb{R}^K." class="latex" /> </p>
<p><b>Proof.</b>  We need to use a few facts from linear algebra.  If <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V" class="latex" /> is a finite-dimensional vector space with inner product, the <b><a href="http://en.wikipedia.org/wiki/Orthogonal_complement">orthogonal complement</a></b> <img src="https://s0.wp.com/latex.php?latex=L%5E%5Cperp&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L^&#92;perp" class="latex" /> of a subspace <img src="https://s0.wp.com/latex.php?latex=L+%5Csubseteq+V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L &#92;subseteq V" class="latex" /> consists of vectors that are orthogonal to everything in <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=L%5E%5Cperp+%3D+%5C%7B+v+%5Cin+V+%3A+%5Cquad+%5Cforall+w+%5Cin+L+%5Cquad+%5Clangle+v%2C+w+%5Crangle+%3D+0+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L^&#92;perp = &#92;{ v &#92;in V : &#92;quad &#92;forall w &#92;in L &#92;quad &#92;langle v, w &#92;rangle = 0 &#92;} " class="latex" /></p>
<p>We have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28L+%5Ccap+M%29%5E%5Cperp+%3D+L%5E%5Cperp+%2B+M%5E%5Cperp++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(L &#92;cap M)^&#92;perp = L^&#92;perp + M^&#92;perp  " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M" class="latex" /> are subspaces of <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%2B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="+" class="latex" /> denotes the sum of two subspaces: that is, the smallest subspace containing both.  Also, if <img src="https://s0.wp.com/latex.php?latex=T%3A+V+%5Cto+W&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T: V &#92;to W" class="latex" /> is a linear map between finite-dimensional vector spaces with inner product, we have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Cmathrm%7Bker%7D+T%29%5E%5Cperp+%3D+%5Cmathrm%7Bim%7D+T%5E%5Cdagger+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;mathrm{ker} T)^&#92;perp = &#92;mathrm{im} T^&#92;dagger " class="latex" /></p>
<p>and</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Cmathrm%7Bim%7D+T%29%5E%5Cperp+%3D+%5Cmathrm%7Bker%7D+T%5E%5Cdagger+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;mathrm{im} T)^&#92;perp = &#92;mathrm{ker} T^&#92;dagger " class="latex" /></p>
<p>Now, because our reaction network has deficiency zero, we know that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bim%7D+%5Cpartial+%5Ccap+%5Cmathrm%7Bker%7D+Y+%3D+%5C%7B+0+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{im} &#92;partial &#92;cap &#92;mathrm{ker} Y = &#92;{ 0 &#92;} " class="latex" /></p>
<p>Taking the orthogonal complement of both sides, we get</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Cmathrm%7Bim%7D+%5Cpartial+%5Ccap+%5Cmathrm%7Bker%7D+Y%29%5E%5Cperp+%3D+%5Cmathbb%7BR%7D%5EK+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;mathrm{im} &#92;partial &#92;cap &#92;mathrm{ker} Y)^&#92;perp = &#92;mathbb{R}^K " class="latex" /></p>
<p>and using the rules we mentioned, we obtain</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bker%7D+%5Cpartial%5E%5Cdagger+%2B+%5Cmathrm%7Bim%7D+Y%5E%5Cdagger+%3D+%5Cmathbb%7BR%7D%5EK+++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{ker} &#92;partial^&#92;dagger + &#92;mathrm{im} Y^&#92;dagger = &#92;mathbb{R}^K   " class="latex" /></p>
<p>as desired.   &nbsp;  &#9608;</p>
<p>Now, given a vector <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5EK&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}^K" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5ES&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}^S" class="latex" /> with all positive components, we can define the <b>logarithm</b> of such a vector, component-wise:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Cln+%5Cphi%29_i+%3D+%5Cln+%28%5Cphi_i%29+++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;ln &#92;phi)_i = &#92;ln (&#92;phi_i)   " class="latex" /></p>
<p>Similarly, for any vector <img src="https://s0.wp.com/latex.php?latex=%5Cphi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi" class="latex" /> in either of these spaces, we can define its <b>exponential</b> in a component-wise way:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Cexp+%5Cphi%29_i+%3D+%5Cexp%28%5Cphi_i%29++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;exp &#92;phi)_i = &#92;exp(&#92;phi_i)  " class="latex" /></p>
<p>These operations are inverse to each other.  Moreover:</p>
<p><b>Lemma 2.</b>  The nonlinear operator </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccc%7D+%5Cmathbb%7BR%7D%5ES+%26%5Cto%26+%5Cmathbb%7BR%7D%5EK+%5C%5C+++++++++++++++++++++++++++++++x+++++%26%5Cmapsto%26+++x%5EY+%5Cend%7Barray%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccc} &#92;mathbb{R}^S &amp;&#92;to&amp; &#92;mathbb{R}^K &#92;&#92;                               x     &amp;&#92;mapsto&amp;   x^Y &#92;end{array} " class="latex" /></p>
<p>is related to the linear operator</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccc%7D+%5Cmathbb%7BR%7D%5ES+%26%5Cto%26+%5Cmathbb%7BR%7D%5EK+%5C%5C+++++++++++++++++++++++++++++++x+++++%26%5Cmapsto%26+++Y%5E%5Cdagger+x+%5Cend%7Barray%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccc} &#92;mathbb{R}^S &amp;&#92;to&amp; &#92;mathbb{R}^K &#92;&#92;                               x     &amp;&#92;mapsto&amp;   Y^&#92;dagger x &#92;end{array} " class="latex" /></p>
<p>by the formula </p>
<p><img src="https://s0.wp.com/latex.php?latex=x%5EY+%3D+%5Cexp%28Y%5E%5Cdagger+%5Cln+x+%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x^Y = &#92;exp(Y^&#92;dagger &#92;ln x ) " class="latex" /></p>
<p>which holds for all <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%280%2C%5Cinfty%29%5ES.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &#92;in (0,&#92;infty)^S." class="latex" />  </p>
<p><b>Proof.</b>  A straightforward calculation.  By the way, this formula would look a bit nicer if we treated <img src="https://s0.wp.com/latex.php?latex=%5Cln+x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ln x" class="latex" /> as a row vector and multiplied it on the right by <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" />: then we would have</p>
<p><img src="https://s0.wp.com/latex.php?latex=x%5EY+%3D+%5Cexp%28%28%5Cln+x%29+Y%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x^Y = &#92;exp((&#92;ln x) Y) " class="latex" /></p>
<p>The problem is that we are following the usual convention of multiplying vectors by matrices on the left, yet writing the matrix on the right in <img src="https://s0.wp.com/latex.php?latex=x%5EY.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x^Y." class="latex" />  Taking the transpose <img src="https://s0.wp.com/latex.php?latex=Y%5E%5Cdagger&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y^&#92;dagger" class="latex" /> of the matrix <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" /> serves to compensate for this.  &nbsp;  &#9608;</p>
<p>Now, given our vector <img src="https://s0.wp.com/latex.php?latex=%5Cpsi+%5Cin+%280%2C%5Cinfty%29%5EK&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi &#92;in (0,&#92;infty)^K" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=H+%5Cpsi+%3D+0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H &#92;psi = 0," class="latex" /> we can take its logarithm and get <img src="https://s0.wp.com/latex.php?latex=%5Cln+%5Cpsi+%5Cin+%5Cmathbb%7BR%7D%5EK.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ln &#92;psi &#92;in &#92;mathbb{R}^K." class="latex" />   Lemma 1 says that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5EK+%3D+%5Cmathrm%7Bker%7D+%5Cpartial%5E%5Cdagger+%2B+%5Cmathrm%7Bim%7D+Y%5E%5Cdagger+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}^K = &#92;mathrm{ker} &#92;partial^&#92;dagger + &#92;mathrm{im} Y^&#92;dagger " class="latex" /></p>
<p>so we can write</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cln+%5Cpsi+%3D++%5Calpha+%2B+Y%5E%5Cdagger+%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ln &#92;psi =  &#92;alpha + Y^&#92;dagger &#92;beta " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cin+%5Cmathrm%7Bker%7D+%5Cpartial%5E%5Cdagger&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;in &#92;mathrm{ker} &#92;partial^&#92;dagger" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%5Cin+%5Cmathbb%7BR%7D%5ES.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta &#92;in &#92;mathbb{R}^S." class="latex" />  Moreover, we can write</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%3D+%5Cln+x+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta = &#92;ln x " class="latex" /></p>
<p>for some <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%280%2C%5Cinfty%29%5ES%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &#92;in (0,&#92;infty)^S," class="latex" /> so that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cln+%5Cpsi+%3D+%5Calpha+%2B+Y%5E%5Cdagger+%28%5Cln+x%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ln &#92;psi = &#92;alpha + Y^&#92;dagger (&#92;ln x) " class="latex" /></p>
<p>Exponentiating both sides component-wise, we get</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi++%3D+++%5Cexp%28%5Calpha%29+%5C%3B+%5Cexp%28Y%5E%5Cdagger+%28%5Cln+x%29%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi  =   &#92;exp(&#92;alpha) &#92;; &#92;exp(Y^&#92;dagger (&#92;ln x)) " class="latex" /></p>
<p>where at right we are taking the component-wise product of vectors.  Thanks to Lemma 2, we conclude that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi+%3D+%5Cexp%28%5Calpha%29+x%5EY+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi = &#92;exp(&#92;alpha) x^Y " class="latex" /></p>
<p>So, we have taken <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> and <i>almost</i> written it in the form <img src="https://s0.wp.com/latex.php?latex=x%5EY&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x^Y" class="latex" />&#8212;but not quite!  We can adjust <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> to make it be of this form:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cexp%28-%5Calpha%29+%5Cpsi+%3D+x%5EY+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;exp(-&#92;alpha) &#92;psi = x^Y " class="latex" /></p>
<p>Clearly all the components of <img src="https://s0.wp.com/latex.php?latex=%5Cexp%28-%5Calpha%29+%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;exp(-&#92;alpha) &#92;psi" class="latex" /> are positive, since the same is true for both <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cexp%28-%5Calpha%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;exp(-&#92;alpha)." class="latex" />  So, the only remaining task is to check that </p>
<p><img src="https://s0.wp.com/latex.php?latex=H%28%5Cexp%28-%5Calpha%29+%5Cpsi%29+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H(&#92;exp(-&#92;alpha) &#92;psi) = 0 " class="latex" /></p>
<p>We do this using two lemmas:</p>
<p><b>Lemma 3.</b>    If <img src="https://s0.wp.com/latex.php?latex=H+%5Cpsi+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H &#92;psi = 0" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cin+%5Cmathrm%7Bker%7D+%5Cpartial%5E%5Cdagger%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;in &#92;mathrm{ker} &#92;partial^&#92;dagger," class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=H%28%5Cexp%28-%5Calpha%29+%5Cpsi%29+%3D+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H(&#92;exp(-&#92;alpha) &#92;psi) = 0." class="latex" /> </p>
<p><b>Proof.</b>  It is enough to check that multiplication by <img src="https://s0.wp.com/latex.php?latex=%5Cexp%28-%5Calpha%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;exp(-&#92;alpha)" class="latex" /> commutes with the Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H," class="latex" /> since then</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%28%5Cexp%28-%5Calpha%29+%5Cpsi%29+%3D+%5Cexp%28-%5Calpha%29+H+%5Cpsi+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H(&#92;exp(-&#92;alpha) &#92;psi) = &#92;exp(-&#92;alpha) H &#92;psi = 0 " class="latex" /></p>
<p>Recall from <a href="http://math.ucr.edu/home/baez/networks/networks_23.html">Part 23</a> that <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> is the Hamiltonian of a Markov process associated to this &#8216;graph with rates&#8217;:</p>
<div align="center"><img src="https://i1.wp.com/math.ucr.edu/home/baez/networks/markov_process_diagram_1.png" /></div>
<p>As noted here:</p>
<p>&bull; John Baez and Brendan Fong, <a href="http://arxiv.org/abs/1203.2035">A Noether theorem for Markov processes</a>.</p>
<p>multiplication by some function on <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="K" class="latex" /> commutes with <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> if and only if that function is constant on each connected component of this graph.   Such functions are called <b>conserved quantities</b>.  </p>
<p>So, it suffices to show that <img src="https://s0.wp.com/latex.php?latex=%5Cexp%28-%5Calpha%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;exp(-&#92;alpha)" class="latex" /> is constant on each connected component.   For this, it is enough to show that <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha" class="latex" /> itself is constant on each connected component.  But this will follow from the next lemma, since <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cin+%5Cmathrm%7Bker%7D+%5Cpartial%5E%5Cdagger.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;in &#92;mathrm{ker} &#92;partial^&#92;dagger." class="latex" />  &nbsp;  &#9608;</p>
<p><b>Lemma 4.</b>  A function <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cin+%5Cmathbb%7BR%7D%5EK&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;in &#92;mathbb{R}^K" class="latex" /> is a conserved quantity iff <img src="https://s0.wp.com/latex.php?latex=%5Cpartial%5E%5Cdagger+%5Calpha+%3D+0+.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial^&#92;dagger &#92;alpha = 0 ." class="latex" />   In other words, <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha" class="latex" /> is constant on each connected component of the graph <img src="https://s0.wp.com/latex.php?latex=s%2C+t%3A+T+%5Cto+K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s, t: T &#92;to K" class="latex" /> iff <img src="https://s0.wp.com/latex.php?latex=%5Cpartial%5E%5Cdagger+%5Calpha+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial^&#92;dagger &#92;alpha = 0 " class="latex" />.</p>
<p><b>Proof.</b>  Suppose <img src="https://s0.wp.com/latex.php?latex=%5Cpartial%5E%5Cdagger+%5Calpha+%3D+0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial^&#92;dagger &#92;alpha = 0," class="latex" /> or in other words, <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cin+%5Cmathrm%7Bker%7D+%5Cpartial%5E%5Cdagger%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;in &#92;mathrm{ker} &#92;partial^&#92;dagger," class="latex" /> or in still other words, <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cin+%28%5Cmathrm%7Bim%7D+%5Cpartial%29%5E%5Cperp.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;in (&#92;mathrm{im} &#92;partial)^&#92;perp." class="latex" />  To show that <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha" class="latex" /> is constant on each connected component, it suffices to show that whenever we have two complexes connected by a transition, like this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Ctau%3A+%5Ckappa+%5Cto+%5Ckappa%27+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;tau: &#92;kappa &#92;to &#92;kappa&#039; " class="latex" /></p>
<p>then <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha" class="latex" /> takes the same value at both these complexes:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Calpha_%5Ckappa+%3D+%5Calpha_%7B%5Ckappa%27%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha_&#92;kappa = &#92;alpha_{&#92;kappa&#039;} " class="latex" /></p>
<p>To see this, note</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpartial+%5Ctau+%3D+t%28%5Ctau%29+-+s%28%5Ctau%29+%3D+%5Ckappa%27+-+%5Ckappa+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial &#92;tau = t(&#92;tau) - s(&#92;tau) = &#92;kappa&#039; - &#92;kappa " class="latex" /></p>
<p>and since <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cin+%28%5Cmathrm%7Bim%7D+%5Cpartial%29%5E%5Cperp%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;in (&#92;mathrm{im} &#92;partial)^&#92;perp," class="latex" /> we conclude</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Calpha%2C+%5Ckappa%27+-+%5Ckappa+%5Crangle+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;alpha, &#92;kappa&#039; - &#92;kappa &#92;rangle = 0 " class="latex" /></p>
<p>But calculating this inner product, we see</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Calpha_%7B%5Ckappa%27%7D+-+%5Calpha_%7B%5Ckappa%7D+%3D+0++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha_{&#92;kappa&#039;} - &#92;alpha_{&#92;kappa} = 0  " class="latex" /></p>
<p>as desired.  </p>
<p>For the converse, we simply turn the argument around: if <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha" class="latex" /> is constant on each connected component, we see <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Calpha%2C+%5Ckappa%27+-+%5Ckappa+%5Crangle+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;alpha, &#92;kappa&#039; - &#92;kappa &#92;rangle = 0" class="latex" /> whenever there is a transition <img src="https://s0.wp.com/latex.php?latex=%5Ctau+%3A+%5Ckappa+%5Cto+%5Ckappa%27.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;tau : &#92;kappa &#92;to &#92;kappa&#039;." class="latex" />  It follows that <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Calpha%2C+%5Cpartial+%5Ctau+%5Crangle+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;alpha, &#92;partial &#92;tau &#92;rangle = 0" class="latex" /> for every transition <img src="https://s0.wp.com/latex.php?latex=%5Ctau%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;tau," class="latex" /> so <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cin+%28%5Cmathrm%7Bim%7D+%5Cpartial%29%5E%5Cperp+.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;in (&#92;mathrm{im} &#92;partial)^&#92;perp ." class="latex" /></p>
<p>And thus concludes the proof of the lemma!   &nbsp;  &#9608;</p>
<p>And thus concludes the proof of the theorem!   &nbsp;  &#9608;</p>
<p>And thus concludes this post!   </p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/08/23/network-theory-part-24/#comments">6 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/chemistry/" rel="category tag">chemistry</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/networks/" rel="category tag">networks</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2012/08/23/network-theory-part-24/" rel="bookmark" title="Permanent Link to Network Theory (Part&nbsp;24)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
		<div class="navigation">
			<div class="alignleft"><a href="https://johncarlosbaez.wordpress.com/category/probability/page/7/" >&laquo; Previous Entries</a></div>
			<div class="alignright"><a href="https://johncarlosbaez.wordpress.com/category/probability/page/5/" >Next Entries &raquo;</a></div>
		</div>

	
	</div>

	<div id="sidebar">
				<ul>

		 <li>

				<p>You are currently browsing the archives for the probability category.</p>

					</li> 
		<li id="recent-posts-3" class="widget widget_recent_entries">
		<h2 class="widgettitle">latest posts:</h2>

		<ul>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/26/classical-mechanics-versus-thermodynamics-part-4/">Classical Mechanics versus Thermodynamics (Part&nbsp;4)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/">Classical Mechanics versus Thermodynamics (Part&nbsp;3)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/22/maxwells-relations-part-3/">Maxwell&#8217;s Relations (Part&nbsp;3)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/18/maxwells-relations-part-two/">Maxwell&#8217;s Relations (Part&nbsp;2)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/17/maxwells-relations-part-1/">Maxwell&#8217;s Relations (Part&nbsp;1)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/13/the-cyclic-identity-for-partial-derivatives/">The Cyclic Identity for Partial&nbsp;Derivatives</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/17/information-geometry-part-21/">Information Geometry (Part&nbsp;21)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/14/information-geometry-part-20/">Information Geometry (Part&nbsp;20)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/08/information-geometry-part-19/">Information Geometry (Part&nbsp;19)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/05/information-geometry-part-18/">Information Geometry (Part&nbsp;18)</a>
									</li>
					</ul>

		</li>
<li id="recent-comments-2" class="widget widget_recent_comments"><h2 class="widgettitle">latest comments:</h2>
				<table class="recentcommentsavatar" cellspacing="0" cellpadding="0" border="0">
					<tr><td title="Toby Bartels" class="recentcommentsavatartop" style="height:32px; width:32px;"><a href="http://tobybartels.name/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/68c7b083965f5073c50bf7c8d2aac358?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstexttop" style=""><a href="http://tobybartels.name/" rel="nofollow">Toby Bartels</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172598">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="David Corfield" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">David Corfield on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172597">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="Toby Bartels" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://tobybartels.name/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/68c7b083965f5073c50bf7c8d2aac358?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://tobybartels.name/" rel="nofollow">Toby Bartels</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/26/classical-mechanics-versus-thermodynamics-part-4/#comment-172596">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="David Corfield" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://lh3.googleusercontent.com/a/AATXAJxXcoKzwm_cY3LJp3qldhAQvZVoBimQd4xe5tDl=s96-c' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">David Corfield on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172590">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="amarashiki" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://gravatar.com/amarashiki" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/62b2df0762257e75433ad6f161488c3a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://gravatar.com/amarashiki" rel="nofollow">amarashiki</a> on <a href="https://johncarlosbaez.wordpress.com/2012/01/23/classical-mechanics-versus-thermodynamics-part-2/#comment-172566">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="John Baez" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://math.ucr.edu/home/baez/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://math.ucr.edu/home/baez/" rel="nofollow">John Baez</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172560">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="domenico" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://2.gravatar.com/avatar/ba06491deb8346d20356ac2ae05893ee?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">domenico on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172559">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="domenico" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://2.gravatar.com/avatar/ba06491deb8346d20356ac2ae05893ee?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">domenico on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172558">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="Maxwell Relations | Equivalent eXchange" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow"></a></td><td class="recentcommentstextend" style=""><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow">Maxwell Relations |&hellip;</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/22/maxwells-relations-part-3/#comment-172557">Maxwell&#8217;s Relations (Par&hellip;</a></td></tr><tr><td title="Maxwell Relations | Equivalent eXchange" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow"></a></td><td class="recentcommentstextend" style=""><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow">Maxwell Relations |&hellip;</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/18/maxwells-relations-part-two/#comment-172556">Maxwell&#8217;s Relations (Par&hellip;</a></td></tr>				</table>
				</li>
<li id="text-3" class="widget widget_text"><h2 class="widgettitle">How To Write Math Here:</h2>
			<div class="textwidget"><p>You can <a href="http://en.wikibooks.org/wiki/LaTeX/Mathematics">include math in your comments using LaTeX</a>,  but you need to do it this way:</p>
<p>&#036;latex  E = mc^2&#036;</p>
<p>You need the word 'latex' right after the first dollar sign, and it needs a space after it.  Double dollar signs don't work, and other limitations apply, some described <a href="http://en.support.wordpress.com/latex/">here</a>.  You can't preview comments here, but I'm happy to fix errors.</p>
</div>
		</li>
<li id="categories-2" class="widget widget_categories"><h2 class="widgettitle">Read Posts On:</h2>

			<ul>
					<li class="cat-item cat-item-177"><a href="https://johncarlosbaez.wordpress.com/category/art/">art</a> (3)
</li>
	<li class="cat-item cat-item-4003"><a href="https://johncarlosbaez.wordpress.com/category/astronomy/">astronomy</a> (29)
</li>
	<li class="cat-item cat-item-8262191"><a href="https://johncarlosbaez.wordpress.com/category/azimuth/">azimuth</a> (60)
</li>
	<li class="cat-item cat-item-86856"><a href="https://johncarlosbaez.wordpress.com/category/biodiversity/">biodiversity</a> (38)
</li>
	<li class="cat-item cat-item-4936"><a href="https://johncarlosbaez.wordpress.com/category/biology/">biology</a> (107)
</li>
	<li class="cat-item cat-item-355244"><a href="https://johncarlosbaez.wordpress.com/category/carbon-emissions/">carbon emissions</a> (78)
</li>
	<li class="cat-item cat-item-5936"><a href="https://johncarlosbaez.wordpress.com/category/chemistry/">chemistry</a> (74)
</li>
	<li class="cat-item cat-item-6108"><a href="https://johncarlosbaez.wordpress.com/category/climate/">climate</a> (155)
</li>
	<li class="cat-item cat-item-5043"><a href="https://johncarlosbaez.wordpress.com/category/computer-science/">computer science</a> (57)
</li>
	<li class="cat-item cat-item-9204"><a href="https://johncarlosbaez.wordpress.com/category/conferences/">conferences</a> (81)
</li>
	<li class="cat-item cat-item-1098"><a href="https://johncarlosbaez.wordpress.com/category/culture/">culture</a> (4)
</li>
	<li class="cat-item cat-item-657"><a href="https://johncarlosbaez.wordpress.com/category/economics/">economics</a> (32)
</li>
	<li class="cat-item cat-item-1212"><a href="https://johncarlosbaez.wordpress.com/category/energy/">energy</a> (50)
</li>
	<li class="cat-item cat-item-25393"><a href="https://johncarlosbaez.wordpress.com/category/engineering/">engineering</a> (11)
</li>
	<li class="cat-item cat-item-14852"><a href="https://johncarlosbaez.wordpress.com/category/mathematics/game-theory/">game theory</a> (29)
</li>
	<li class="cat-item cat-item-1215"><a href="https://johncarlosbaez.wordpress.com/category/geography/">geography</a> (4)
</li>
	<li class="cat-item cat-item-337"><a href="https://johncarlosbaez.wordpress.com/category/health/">health</a> (4)
</li>
	<li class="cat-item cat-item-678"><a href="https://johncarlosbaez.wordpress.com/category/history/">history</a> (2)
</li>
	<li class="cat-item cat-item-23375499"><a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/">information and entropy</a> (92)
</li>
	<li class="cat-item cat-item-3558"><a href="https://johncarlosbaez.wordpress.com/category/jobs/">jobs</a> (11)
</li>
	<li class="cat-item cat-item-5465"><a href="https://johncarlosbaez.wordpress.com/category/journals/">journals</a> (5)
</li>
	<li class="cat-item cat-item-3582"><a href="https://johncarlosbaez.wordpress.com/category/mathematics/">mathematics</a> (479)
</li>
	<li class="cat-item cat-item-18"><a href="https://johncarlosbaez.wordpress.com/category/music/">music</a> (3)
</li>
	<li class="cat-item cat-item-3968"><a href="https://johncarlosbaez.wordpress.com/category/networks/">networks</a> (185)
</li>
	<li class="cat-item cat-item-154934"><a href="https://johncarlosbaez.wordpress.com/category/oceans/">oceans</a> (13)
</li>
	<li class="cat-item cat-item-1211"><a href="https://johncarlosbaez.wordpress.com/category/physics/">physics</a> (205)
</li>
	<li class="cat-item cat-item-10451 current-cat"><a aria-current="page" href="https://johncarlosbaez.wordpress.com/category/probability/">probability</a> (92)
</li>
	<li class="cat-item cat-item-4909"><a href="https://johncarlosbaez.wordpress.com/category/psychology/">psychology</a> (6)
</li>
	<li class="cat-item cat-item-3330"><a href="https://johncarlosbaez.wordpress.com/category/publishing/">publishing</a> (19)
</li>
	<li class="cat-item cat-item-46615"><a href="https://johncarlosbaez.wordpress.com/category/puzzles/">puzzles</a> (14)
</li>
	<li class="cat-item cat-item-4140243"><a href="https://johncarlosbaez.wordpress.com/category/quantum-technologies/">quantum technologies</a> (28)
</li>
	<li class="cat-item cat-item-562"><a href="https://johncarlosbaez.wordpress.com/category/questions/">questions</a> (3)
</li>
	<li class="cat-item cat-item-93974"><a href="https://johncarlosbaez.wordpress.com/category/risks/">risks</a> (48)
</li>
	<li class="cat-item cat-item-37893"><a href="https://johncarlosbaez.wordpress.com/category/seminars/">seminars</a> (21)
</li>
	<li class="cat-item cat-item-581"><a href="https://johncarlosbaez.wordpress.com/category/software/">software</a> (19)
</li>
	<li class="cat-item cat-item-39438"><a href="https://johncarlosbaez.wordpress.com/category/strategies/">strategies</a> (36)
</li>
	<li class="cat-item cat-item-6877"><a href="https://johncarlosbaez.wordpress.com/category/sustainability/">sustainability</a> (71)
</li>
	<li class="cat-item cat-item-66608272"><a href="https://johncarlosbaez.wordpress.com/category/the-practice-of-science/">the practice of science</a> (27)
</li>
	<li class="cat-item cat-item-61590"><a href="https://johncarlosbaez.wordpress.com/category/this-weeks-finds/">this week&#039;s finds</a> (18)
</li>
			</ul>

			</li>
<li id="linkcat-20924250" class="widget widget_links"><h2 class="widgettitle">also visit these:</h2>

	<ul class='xoxo blogroll'>
<li><a href="http://www.azimuthproject.org/azimuth/show/Azimuth+Blog" title="Go here to see what’s on this blog, organized by topic or author!">Azimuth Blog Overview</a></li>
<li><a href="http://www.azimuthproject.org/azimuth/show/HomePage" title="for scientists and engineers who want to save the planet">Azimuth Project</a></li>
<li><a href="http://bittooth.blogspot.com/" title="David Summers on energy: oil, gas and more">Bit Tooth Energy</a></li>
<li><a href="http://bravenewclimate.com/" title="Barry Brooks on climate and energy policy">Brave New Climate</a></li>
<li><a href="http://physics.ucsd.edu/do-the-math/" title="UC San Diego prof uses physics and estimation to assess energy, growth, options">Do the Math</a></li>
<li><a href="http://dotearth.blogs.nytimes.com/" title="Andrew Revkin’s environmental blog on the New York Times">Dot Earth</a></li>
<li><a href="http://e360.yale.edu/" title="News from the Yale School of Forestry &amp; Environmental Studies">Environment 360</a></li>
<li><a href="http://planet3.org/" title="A metablog on sustainability">Planet3.0</a></li>
<li><a href="http://www.realclimate.org/" title="climate science from climate scientists">RealClimate</a></li>
<li><a href="http://www.easterbrook.ca/steve/" title="Steve Easterbrook&#8217;s blog on software engineering and climate modeling">Serendipity</a></li>
<li><a href="http://scienceofdoom.com/" title="climate science in perspective">The Science of Doom</a></li>
<li><a href="http://e360.yale.edu/" title="opinion, analysis, reporting and debate on environmental issues">Yale Environment 360</a></li>

	</ul>
</li>

<li id="rss_links-3" class="widget widget_rss_links"><h2 class="widgettitle">RSS feeds:</h2>
<p class="size-small"><a class="feed-image-link" href="https://johncarlosbaez.wordpress.com/feed/" title="Subscribe to Posts"><img src="https://johncarlosbaez.wordpress.com/i/rss/red-small.png?m=1391188133h" alt="RSS Feed" /></a>&nbsp;<a href="https://johncarlosbaez.wordpress.com/feed/" title="Subscribe to Posts">RSS - Posts</a></p><p class="size-small"><a class="feed-image-link" href="https://johncarlosbaez.wordpress.com/comments/feed/" title="Subscribe to Comments"><img src="https://johncarlosbaez.wordpress.com/i/rss/red-small.png?m=1391188133h" alt="RSS Feed" /></a>&nbsp;<a href="https://johncarlosbaez.wordpress.com/comments/feed/" title="Subscribe to Comments">RSS - Comments</a></p>
</li>
<li id="blog_subscription-3" class="widget widget_blog_subscription jetpack_subscription_widget"><h2 class="widgettitle"><label for="subscribe-field">Email Subscription:</label></h2>

			<form
				action="https://subscribe.wordpress.com"
				method="post"
				accept-charset="utf-8"
				id=""
			>
				<p>Enter your email address to subscribe to this blog and receive notifications of new posts by email.</p>
					<div class="jetpack-subscribe-count">
						<p>
						Join 5,228 other followers						</p>
					</div>
									<p id="subscribe-email">
					<label
						id="subscribe-field-label"
						for="subscribe-field"
						class="screen-reader-text"
					>
						Email Address:					</label>

					<input
							type="email"
							name="email"
							
							style="width: 95%; padding: 1px 10px"
							placeholder="Enter your email address"
							value=""
							id="subscribe-field"
						/>				</p>

				<p id="subscribe-submit"
									>
                    <input type="hidden" name="action" value="subscribe"/>
                    <input type="hidden" name="blog_id" value="12777403"/>
                    <input type="hidden" name="source" value="https://johncarlosbaez.wordpress.com/category/probability/page/6/"/>
                    <input type="hidden" name="sub-type" value="widget"/>
                    <input type="hidden" name="redirect_fragment" value="blog_subscription-3"/>
					<input type="hidden" id="_wpnonce" name="_wpnonce" value="ffcb185558" />                    <button type="submit"
	                    	                        class="wp-block-button__link"
	                    		                	                >
	                    Sign me up!                    </button>
                </p>
            </form>
			
</li>
<li id="search-3" class="widget widget_search"><h2 class="widgettitle">SEARCH:</h2>
<form method="get" id="searchform" action="https://johncarlosbaez.wordpress.com/">
<div><label for="s" class="search-label">Search</label><input type="text" value="" name="s" id="s" />
<input type="submit" id="searchsubmit" value="Search" />
</div>
</form></li>
<li id="blog-stats-2" class="widget widget_blog-stats"><h2 class="widgettitle">Blog Stats:</h2>
		<ul>
			<li>4,177,577 hits</li>
		</ul>
		</li>
		</ul>
	</div>



<div id="footer">
	<p>
	<br />
	<a href="https://wordpress.com/?ref=footer_blog" rel="nofollow">Blog at WordPress.com.</a>
	</p>
</div>

</div>

				<script type="text/javascript">
		//<![CDATA[
		var infiniteScroll = JSON.parse( decodeURIComponent( '%7B%22settings%22%3A%7B%22id%22%3A%22content%22%2C%22ajaxurl%22%3A%22https%3A%5C%2F%5C%2Fjohncarlosbaez.wordpress.com%5C%2F%3Finfinity%3Dscrolling%22%2C%22type%22%3A%22scroll%22%2C%22wrapper%22%3Atrue%2C%22wrapper_class%22%3A%22infinite-wrap%22%2C%22footer%22%3Atrue%2C%22click_handle%22%3A%221%22%2C%22text%22%3A%22Older%20posts%22%2C%22totop%22%3A%22Scroll%20back%20to%20top%22%2C%22currentday%22%3A%2223.08.12%22%2C%22order%22%3A%22DESC%22%2C%22scripts%22%3A%5B%5D%2C%22styles%22%3A%5B%5D%2C%22google_analytics%22%3Afalse%2C%22offset%22%3A6%2C%22history%22%3A%7B%22host%22%3A%22johncarlosbaez.wordpress.com%22%2C%22path%22%3A%22%5C%2Fcategory%5C%2Fprobability%5C%2Fpage%5C%2F%25d%5C%2F%22%2C%22use_trailing_slashes%22%3Atrue%2C%22parameters%22%3A%22%22%7D%2C%22query_args%22%3A%7B%22paged%22%3A6%2C%22category_name%22%3A%22probability%22%2C%22error%22%3A%22%22%2C%22m%22%3A%22%22%2C%22p%22%3A0%2C%22post_parent%22%3A%22%22%2C%22subpost%22%3A%22%22%2C%22subpost_id%22%3A%22%22%2C%22attachment%22%3A%22%22%2C%22attachment_id%22%3A0%2C%22name%22%3A%22%22%2C%22pagename%22%3A%22%22%2C%22page_id%22%3A0%2C%22second%22%3A%22%22%2C%22minute%22%3A%22%22%2C%22hour%22%3A%22%22%2C%22day%22%3A0%2C%22monthnum%22%3A0%2C%22year%22%3A0%2C%22w%22%3A0%2C%22tag%22%3A%22%22%2C%22cat%22%3A10451%2C%22tag_id%22%3A%22%22%2C%22author%22%3A%22%22%2C%22author_name%22%3A%22%22%2C%22feed%22%3A%22%22%2C%22tb%22%3A%22%22%2C%22meta_key%22%3A%22%22%2C%22meta_value%22%3A%22%22%2C%22preview%22%3A%22%22%2C%22s%22%3A%22%22%2C%22sentence%22%3A%22%22%2C%22title%22%3A%22%22%2C%22fields%22%3A%22%22%2C%22menu_order%22%3A%22%22%2C%22embed%22%3A%22%22%2C%22category__in%22%3A%5B%5D%2C%22category__not_in%22%3A%5B%5D%2C%22category__and%22%3A%5B%5D%2C%22post__in%22%3A%5B%5D%2C%22post__not_in%22%3A%5B%5D%2C%22post_name__in%22%3A%5B%5D%2C%22tag__in%22%3A%5B%5D%2C%22tag__not_in%22%3A%5B%5D%2C%22tag__and%22%3A%5B%5D%2C%22tag_slug__in%22%3A%5B%5D%2C%22tag_slug__and%22%3A%5B%5D%2C%22post_parent__in%22%3A%5B%5D%2C%22post_parent__not_in%22%3A%5B%5D%2C%22author__in%22%3A%5B%5D%2C%22author__not_in%22%3A%5B%5D%2C%22lazy_load_term_meta%22%3Afalse%2C%22posts_per_page%22%3A10%2C%22ignore_sticky_posts%22%3Afalse%2C%22suppress_filters%22%3Afalse%2C%22cache_results%22%3Afalse%2C%22update_post_term_cache%22%3Atrue%2C%22update_post_meta_cache%22%3Atrue%2C%22post_type%22%3A%22%22%2C%22nopaging%22%3Afalse%2C%22comments_per_page%22%3A%22100%22%2C%22no_found_rows%22%3Afalse%2C%22order%22%3A%22DESC%22%7D%2C%22query_before%22%3A%222021-09-26%2017%3A22%3A26%22%2C%22last_post_date%22%3A%222012-08-23%2007%3A29%3A40%22%2C%22body_class%22%3A%22infinite-scroll%20neverending%22%2C%22loading_text%22%3A%22Loading%20new%20page%22%2C%22stats%22%3A%22blog%3D12777403%26v%3Dwpcom%26tz%3D0%26user_id%3D0%26subd%3Djohncarlosbaez%26x_pagetype%3Dinfinite%22%7D%7D' ) );
		//]]>
		</script>
		<!--  -->
<script src='//0.gravatar.com/js/gprofiles.js?ver=202138y' id='grofiles-cards-js'></script>
<script id='wpgroho-js-extra'>
var WPGroHo = {"my_hash":""};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s1.wp.com/wp-content/mu-plugins/gravatar-hovercards/wpgroho.js?m=1610363240h'></script>

	<script>
		// Initialize and attach hovercards to all gravatars
		( function() {
			function init() {
				if ( typeof Gravatar === 'undefined' ) {
					return;
				}

				if ( typeof Gravatar.init !== 'function' ) {
					return;
				}

				Gravatar.profile_cb = function ( hash, id ) {
					WPGroHo.syncProfileData( hash, id );
				};

				Gravatar.my_hash = WPGroHo.my_hash;
				Gravatar.init( 'body', '#wp-admin-bar-my-account' );
			}

			if ( document.readyState !== 'loading' ) {
				init();
			} else {
				document.addEventListener( 'DOMContentLoaded', init );
			}
		} )();
	</script>

		<div style="display:none">
	<div class="grofile-hash-map-68c7b083965f5073c50bf7c8d2aac358">
	</div>
	<div class="grofile-hash-map-34784534843022b3541c8ddd693718cb">
	</div>
	<div class="grofile-hash-map-7d52fbe20c8ac05886a296e9ee2159b1">
	</div>
	<div class="grofile-hash-map-62b2df0762257e75433ad6f161488c3a">
	</div>
	<div class="grofile-hash-map-ba06491deb8346d20356ac2ae05893ee">
	</div>
	</div>
		<div id="infinite-footer">
			<div class="container">
				<div class="blog-info">
					<a id="infinity-blog-title" href="https://johncarlosbaez.wordpress.com/" rel="home">
						Azimuth					</a>
				</div>
				<div class="blog-credits">
					<a href="https://wordpress.com/?ref=footer_blog" rel="nofollow">Blog at WordPress.com.</a> 				</div>
			</div>
		</div><!-- #infinite-footer -->
		
<script>
window.addEventListener( "load", function( event ) {
	var link = document.createElement( "link" );
	link.href = "https://s0.wp.com/wp-content/mu-plugins/actionbar/actionbar.css?v=20210915";
	link.type = "text/css";
	link.rel = "stylesheet";
	document.head.appendChild( link );

	var script = document.createElement( "script" );
	script.src = "https://s0.wp.com/wp-content/mu-plugins/actionbar/actionbar.js?v=20210920";
	script.defer = true;
	document.body.appendChild( script );
} );
</script>

			<div id="jp-carousel-loading-overlay">
			<div id="jp-carousel-loading-wrapper">
				<span id="jp-carousel-library-loading">&nbsp;</span>
			</div>
		</div>
		<div class="jp-carousel-overlay" style="display: none;">

		<div class="jp-carousel-container">
			<!-- The Carousel Swiper -->
			<div
				class="jp-carousel-wrap swiper-container jp-carousel-swiper-container jp-carousel-transitions"
				itemscope
				itemtype="https://schema.org/ImageGallery">
				<div class="jp-carousel swiper-wrapper"></div>
				<div class="jp-swiper-button-prev swiper-button-prev">
					<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
						<mask id="maskPrev" mask-type="alpha" maskUnits="userSpaceOnUse" x="8" y="6" width="9" height="12">
							<path d="M16.2072 16.59L11.6496 12L16.2072 7.41L14.8041 6L8.8335 12L14.8041 18L16.2072 16.59Z" fill="white"/>
						</mask>
						<g mask="url(#maskPrev)">
							<rect x="0.579102" width="23.8823" height="24" fill="#FFFFFF"/>
						</g>
					</svg>
				</div>
				<div class="jp-swiper-button-next swiper-button-next">
					<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
						<mask id="maskNext" mask-type="alpha" maskUnits="userSpaceOnUse" x="8" y="6" width="8" height="12">
							<path d="M8.59814 16.59L13.1557 12L8.59814 7.41L10.0012 6L15.9718 12L10.0012 18L8.59814 16.59Z" fill="white"/>
						</mask>
						<g mask="url(#maskNext)">
							<rect x="0.34375" width="23.8822" height="24" fill="#FFFFFF"/>
						</g>
					</svg>
				</div>
			</div>
			<!-- The main close buton -->
			<div class="jp-carousel-close-hint">
				<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
					<mask id="maskClose" mask-type="alpha" maskUnits="userSpaceOnUse" x="5" y="5" width="15" height="14">
						<path d="M19.3166 6.41L17.9135 5L12.3509 10.59L6.78834 5L5.38525 6.41L10.9478 12L5.38525 17.59L6.78834 19L12.3509 13.41L17.9135 19L19.3166 17.59L13.754 12L19.3166 6.41Z" fill="white"/>
					</mask>
					<g mask="url(#maskClose)">
						<rect x="0.409668" width="23.8823" height="24" fill="#FFFFFF"/>
					</g>
				</svg>
			</div>
			<!-- Image info, comments and meta -->
			<div class="jp-carousel-info">
				<div class="jp-carousel-info-footer">
					<div class="jp-carousel-pagination-container">
						<div class="jp-swiper-pagination swiper-pagination"></div>
						<div class="jp-carousel-pagination"></div>
					</div>
					<div class="jp-carousel-photo-title-container">
						<h2 class="jp-carousel-photo-caption"></h2>
					</div>
					<div class="jp-carousel-photo-icons-container">
						<a href="#" class="jp-carousel-icon-btn jp-carousel-icon-info" aria-label="Toggle photo metadata visibility">
							<span class="jp-carousel-icon">
								<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
									<mask id="maskInfo" mask-type="alpha" maskUnits="userSpaceOnUse" x="2" y="2" width="21" height="20">
										<path fill-rule="evenodd" clip-rule="evenodd" d="M12.7537 2C7.26076 2 2.80273 6.48 2.80273 12C2.80273 17.52 7.26076 22 12.7537 22C18.2466 22 22.7046 17.52 22.7046 12C22.7046 6.48 18.2466 2 12.7537 2ZM11.7586 7V9H13.7488V7H11.7586ZM11.7586 11V17H13.7488V11H11.7586ZM4.79292 12C4.79292 16.41 8.36531 20 12.7537 20C17.142 20 20.7144 16.41 20.7144 12C20.7144 7.59 17.142 4 12.7537 4C8.36531 4 4.79292 7.59 4.79292 12Z" fill="white"/>
									</mask>
									<g mask="url(#maskInfo)">
										<rect x="0.8125" width="23.8823" height="24" fill="#FFFFFF"/>
									</g>
								</svg>
							</span>
						</a>
												<a href="#" class="jp-carousel-icon-btn jp-carousel-icon-comments" aria-label="Toggle photo comments visibility">
							<span class="jp-carousel-icon">
								<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
									<mask id="maskComments" mask-type="alpha" maskUnits="userSpaceOnUse" x="2" y="2" width="21" height="20">
										<path fill-rule="evenodd" clip-rule="evenodd" d="M4.3271 2H20.2486C21.3432 2 22.2388 2.9 22.2388 4V16C22.2388 17.1 21.3432 18 20.2486 18H6.31729L2.33691 22V4C2.33691 2.9 3.2325 2 4.3271 2ZM6.31729 16H20.2486V4H4.3271V18L6.31729 16Z" fill="white"/>
									</mask>
									<g mask="url(#maskComments)">
										<rect x="0.34668" width="23.8823" height="24" fill="#FFFFFF"/>
									</g>
								</svg>

								<span class="jp-carousel-has-comments-indicator" aria-label="This image has comments."></span>
							</span>
						</a>
											</div>
				</div>
				<div class="jp-carousel-info-extra">
					<div class="jp-carousel-info-content-wrapper">
						<div class="jp-carousel-photo-title-container">
							<h2 class="jp-carousel-photo-title"></h2>
						</div>
						<div class="jp-carousel-comments-wrapper">
															<div id="jp-carousel-comments-loading">
									<span>Loading Comments...</span>
								</div>
								<div class="jp-carousel-comments"></div>
								<div id="jp-carousel-comment-form-container">
									<span id="jp-carousel-comment-form-spinner">&nbsp;</span>
									<div id="jp-carousel-comment-post-results"></div>
																														<form id="jp-carousel-comment-form">
												<label for="jp-carousel-comment-form-comment-field" class="screen-reader-text">Write a Comment...</label>
												<textarea
													name="comment"
													class="jp-carousel-comment-form-field jp-carousel-comment-form-textarea"
													id="jp-carousel-comment-form-comment-field"
													placeholder="Write a Comment..."
												></textarea>
												<div id="jp-carousel-comment-form-submit-and-info-wrapper">
													<div id="jp-carousel-comment-form-commenting-as">
																													<fieldset>
																<label for="jp-carousel-comment-form-email-field">Email (Required)</label>
																<input type="text" name="email" class="jp-carousel-comment-form-field jp-carousel-comment-form-text-field" id="jp-carousel-comment-form-email-field" />
															</fieldset>
															<fieldset>
																<label for="jp-carousel-comment-form-author-field">Name (Required)</label>
																<input type="text" name="author" class="jp-carousel-comment-form-field jp-carousel-comment-form-text-field" id="jp-carousel-comment-form-author-field" />
															</fieldset>
															<fieldset>
																<label for="jp-carousel-comment-form-url-field">Website</label>
																<input type="text" name="url" class="jp-carousel-comment-form-field jp-carousel-comment-form-text-field" id="jp-carousel-comment-form-url-field" />
															</fieldset>
																											</div>
													<input
														type="submit"
														name="submit"
														class="jp-carousel-comment-form-button"
														id="jp-carousel-comment-form-button-submit"
														value="Post Comment" />
												</div>
											</form>
																											</div>
													</div>
						<div class="jp-carousel-image-meta">
							<div class="jp-carousel-title-and-caption">
								<div class="jp-carousel-photo-info">
									<h3 class="jp-carousel-caption" itemprop="caption description"></h3>
								</div>

								<div class="jp-carousel-photo-description"></div>
							</div>
							<ul class="jp-carousel-image-exif" style="display: none;"></ul>
							<a class="jp-carousel-image-download" target="_blank" style="display: none;">
								<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
									<mask id="mask0" mask-type="alpha" maskUnits="userSpaceOnUse" x="3" y="3" width="19" height="18">
										<path fill-rule="evenodd" clip-rule="evenodd" d="M5.84615 5V19H19.7775V12H21.7677V19C21.7677 20.1 20.8721 21 19.7775 21H5.84615C4.74159 21 3.85596 20.1 3.85596 19V5C3.85596 3.9 4.74159 3 5.84615 3H12.8118V5H5.84615ZM14.802 5V3H21.7677V10H19.7775V6.41L9.99569 16.24L8.59261 14.83L18.3744 5H14.802Z" fill="white"/>
									</mask>
									<g mask="url(#mask0)">
										<rect x="0.870605" width="23.8823" height="24" fill="#FFFFFF"/>
									</g>
								</svg>
								<span class="jp-carousel-download-text"></span>
							</a>
							<div class="jp-carousel-image-map" style="display: none;"></div>
						</div>
					</div>
				</div>
			</div>
		</div>

		</div>
		<link rel='stylesheet' id='all-css-0-2' href='https://s1.wp.com/_static/??-eJyFy00OQDAQQOELGUP8xUKcpWoiZVTTadO4vVhY2LB8L/kwOdCHDWQD7hEcx8VYQa38EYUYJRlHHqZoZ6Zci2T4I1YKTukNnvGFgmGaYVHM5M933Wzch7Ktir5p+rpbL+lvP34=?cssminify=yes' type='text/css' media='all' />
<script id='jetpack-carousel-js-extra'>
var jetpackSwiperLibraryPath = {"url":"\/wp-content\/mu-plugins\/carousel\/swiper-bundle.js"};
var jetpackCarouselStrings = {"widths":[370,700,1000,1200,1400,2000],"is_logged_in":"","lang":"en","ajaxurl":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/admin-ajax.php","nonce":"805b669379","display_exif":"1","display_comments":"1","display_geo":"1","single_image_gallery":"1","single_image_gallery_media_file":"","background_color":"black","comment":"Comment","post_comment":"Post Comment","write_comment":"Write a Comment...","loading_comments":"Loading Comments...","download_original":"View full size <span class=\"photo-size\">{0}<span class=\"photo-size-times\">\u00d7<\/span>{1}<\/span>","no_comment_text":"Please be sure to submit some text with your comment.","no_comment_email":"Please provide an email address to comment.","no_comment_author":"Please provide your name to comment.","comment_post_error":"Sorry, but there was an error posting your comment. Please try again later.","comment_approved":"Your comment was approved.","comment_unapproved":"Your comment is in moderation.","camera":"Camera","aperture":"Aperture","shutter_speed":"Shutter Speed","focal_length":"Focal Length","copyright":"Copyright","comment_registration":"0","require_name_email":"1","login_url":"https:\/\/johncarlosbaez.wordpress.com\/wp-login.php?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2012%2F08%2F23%2Fnetwork-theory-part-24%2F","blog_id":"12777403","meta_data":["camera","aperture","shutter_speed","focal_length","copyright"],"stats_query_args":"blog=12777403&v=wpcom&tz=0&user_id=0&subd=johncarlosbaez","is_public":"1"};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s0.wp.com/_static/??-eJyNkN1uwyAMhV9oDkouKvVi2rMQcCNT/oZN07z9yNRMbTZFu8LH8J2DreYMJkXBKMqxsngjg/neOX5TT1ehQvZ1osiK4oUiyfJTHLzVNlCEURcVNAuWVoEUba68h1q2+6xYlsfRzdmkALmk+wIFW49lYygaXy3yCjWJYUTbtaCDj8xkJxRWXEc2hbJQivyXH8+XNDo0sjfbnG5kMSnNvNq5h84F+ddIT/FGl1QZvXIouY0PW+OAEfJoYdLer1t5Uf9Igu/97WTjPsJ7fxrO534YTr37Ai2cwB8='></script>
<script type="text/javascript">
// <![CDATA[
(function() {
try{
  if ( window.external &&'msIsSiteMode' in window.external) {
    if (window.external.msIsSiteMode()) {
      var jl = document.createElement('script');
      jl.type='text/javascript';
      jl.async=true;
      jl.src='/wp-content/plugins/ie-sitemode/custom-jumplist.php';
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(jl, s);
    }
  }
}catch(e){}
})();
// ]]>
</script><script type="text/javascript">
			(function() {
				var extend = function(out) {
					out = out || {};

					for (var i = 1; i < arguments.length; i++) {
						if (!arguments[i])
						continue;

						for (var key in arguments[i]) {
						if (arguments[i].hasOwnProperty(key))
							out[key] = arguments[i][key];
						}
					}

					return out;
				};
				extend( window.infiniteScroll.settings.scripts, ["postmessage","mobile-useragent-info","rlt-proxy","jquery-core","jquery-migrate","jquery","wpcom-actionbar-placeholder","grofiles-cards","wpgroho","devicepx","the-neverending-homepage","wpcom-masterbar-tracks-js","jquery.wpcom-proxy-request","wp-embed","jetpack-subscriptions-js","swfobject","videopress","jetpack-carousel","tiled-gallery","carousel-wpcom"] );
				extend( window.infiniteScroll.settings.styles, ["the-neverending-homepage","infinity-contempt","wp-block-library","mediaelement","wp-mediaelement","jetpack-layout-grid","jetpack-ratings","coblocks-frontend","wpcom-core-compat-playlist-styles","wpcom-text-widget-styles","wpcom-bbpress2-staff-css","contempt","geo-location-flair","reblogging","a8c-global-print","h4-global","global-styles","jetpack-global-styles-frontend-style","jetpack-carousel-swiper-css","jetpack-carousel","tiled-gallery"] );
			})();
		</script>
				<span id="infinite-aria" aria-live="polite"></span>
		<script src="//stats.wp.com/w.js?62" defer></script> <script type="text/javascript">
_tkq = window._tkq || [];
_stq = window._stq || [];
_tkq.push(['storeContext', {'blog_id':'12777403','blog_tz':'0','user_lang':'en','blog_lang':'en','user_id':'0'}]);
_stq.push(['view', {'blog':'12777403','v':'wpcom','tz':'0','user_id':'0','subd':'johncarlosbaez'}]);
_stq.push(['extra', {'crypt':'UE40eW5QN0p8M2Y/RE1TaVhzUzFMbjdWNHpwZGhTayxPSUFCMGNrd29+Smw0TDhnZmRTK0hlRi9QSGh6bi9GXVhBJWIlZlR5U1JMLU8/MkNtblkvY1d6eVImTEouL2UleTBRZmlNdkp0aWJaNFJhPS0uTVpHa1hIc25EbVJyQmw/SkZ+Q3lLcjU/NDBvQTY5X1Z+aXxdbltsdkNOcHZrfkhlYmp+eFA9V2VndHYudGslaURwVW9bPy9VRiZGfjlKanBMR3FiVUVWXVl5QjVMSmY/Zj9BW00/SmlSPTUsN1dUd193cW1yaE9XZDhLWj13c0o1azNpVkZUdjUmcHJmdnpSS2N0OXpHMXlKeldxK0pmVGFqMUtULjVKNlBYYWl1JlY0WksmaVVCRjhPLHx+OD1SblMyVlo/V1ImMGR3RlUmW1lvLkc3VGJhTWtfdGkrJS5VLw=='}]);
_stq.push([ 'clickTrackerInit', '12777403', '0' ]);
	</script>
<noscript><img src="https://pixel.wp.com/b.gif?v=noscript" style="height:1px;width:1px;overflow:hidden;position:absolute;bottom:1px;" alt="" /></noscript>
<script>
if ( 'object' === typeof wpcom_mobile_user_agent_info ) {

	wpcom_mobile_user_agent_info.init();
	var mobileStatsQueryString = "";
	
	if( false !== wpcom_mobile_user_agent_info.matchedPlatformName )
		mobileStatsQueryString += "&x_" + 'mobile_platforms' + '=' + wpcom_mobile_user_agent_info.matchedPlatformName;
	
	if( false !== wpcom_mobile_user_agent_info.matchedUserAgentName )
		mobileStatsQueryString += "&x_" + 'mobile_devices' + '=' + wpcom_mobile_user_agent_info.matchedUserAgentName;
	
	if( wpcom_mobile_user_agent_info.isIPad() )
		mobileStatsQueryString += "&x_" + 'ipad_views' + '=' + 'views';

	if( "" != mobileStatsQueryString ) {
		new Image().src = document.location.protocol + '//pixel.wp.com/g.gif?v=wpcom-no-pv' + mobileStatsQueryString + '&baba=' + Math.random();
	}
	
}
</script>
</body>
</html>
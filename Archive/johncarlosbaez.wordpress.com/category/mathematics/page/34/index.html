<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>mathematics | Azimuth | Page 34</title>
<link rel="profile" href="http://gmpg.org/xfn/11" />
<link rel="pingback" href="https://johncarlosbaez.wordpress.com/xmlrpc.php" />
<meta name='robots' content='max-image-preview:large' />
<link rel='dns-prefetch' href='//s1.wp.com' />
<link rel='dns-prefetch' href='//s2.wp.com' />
<link rel='dns-prefetch' href='//s0.wp.com' />
<link rel='dns-prefetch' href='//s.wordpress.com' />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Feed" href="https://johncarlosbaez.wordpress.com/feed/" />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Comments Feed" href="https://johncarlosbaez.wordpress.com/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; mathematics Category Feed" href="https://johncarlosbaez.wordpress.com/category/mathematics/feed/" />
	<script type="text/javascript">
		/* <![CDATA[ */
		function addLoadEvent(func) {
			var oldonload = window.onload;
			if (typeof window.onload != 'function') {
				window.onload = func;
			} else {
				window.onload = function () {
					oldonload();
					func();
				}
			}
		}
		/* ]]> */
	</script>
			<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/72x72\/","ext":".png","svgUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/s1.wp.com\/wp-includes\/js\/wp-emoji-release.min.js?m=1625065786h&ver=5.8.1"}};
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([10084,65039,8205,55357,56613],[10084,65039,8203,55357,56613])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='all-css-0-1' href='https://s2.wp.com/_static/??-eJyNkttSAyEMhl9IlqVOdbxwfBYOEVOBZSBYeXuz1e6sVrveMDl9yU9AHrOwUyJIJGMTOTSPqUpMz5iQ+mIMttYbuVFMLxChytyMPJXFTBfcGfKNXQPFc6aAfFNq2A9KmobBSRMm+yoCmqJLl5V6gKURJhua4zGHKiM41BB46qxo5eSgOxQRwGvbh4hpG+fc2v8G/S3+pJSbAWU9S9Z9aiR8QfdD9r9bFE2YfN3A7fSF7QY18t4cVlqC4nd29WTzzjkes768+BXsiM4DMV7PtiB4v45kHiOMyQVqFXxGbFF8/pSZe4qP6u5W3T/sx3F3+ACgX/YH?cssminify=yes' type='text/css' media='all' />
<style id='wp-block-library-inline-css'>
.has-text-align-justify {
	text-align:justify;
}
</style>
<style id='global-styles-inline-css'>
body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--normal: 16px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--huge: 42px;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-normal-font-size{font-size: var(--wp--preset--font-size--normal) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-huge-font-size{font-size: var(--wp--preset--font-size--huge) !important;}
</style>
<link rel='stylesheet' id='all-css-2-1' href='https://s0.wp.com/_static/??-eJx9i0EKgCAQAD+ULYJRHaK3qJhY666o0fezW126zcAMGNR09LaUDq4kLFN1VCGeIuHpAxXwjgWy1TUwfURsqEP+W7MzyL6hh1a99JnWuEg1zEpNo1T7DZLtMYQ=?cssminify=yes' type='text/css' media='all' />
<link rel='stylesheet' id='print-css-3-1' href='https://s2.wp.com/wp-content/mu-plugins/global-print/global-print.css?m=1465851035h&cssminify=yes' type='text/css' media='print' />
<style id='jetpack-global-styles-frontend-style-inline-css'>
:root { --font-headings: unset; --font-base: unset; --font-headings-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif; --font-base-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif;}
</style>
<link rel='stylesheet' id='all-css-6-1' href='https://s0.wp.com/wp-content/themes/h4/global.css?m=1420737423h&cssminify=yes' type='text/css' media='all' />
<script id='wpcom-actionbar-placeholder-js-extra'>
var actionbardata = {"siteID":"12777403","siteName":"Azimuth","siteURL":"http:\/\/johncarlosbaez.wordpress.com","siteHost":"johncarlosbaez.wordpress.com","icon":"<img alt='' src='https:\/\/s2.wp.com\/i\/logo\/wpcom-gray-white.png' class='avatar avatar-50' height='50' width='50' \/>","canManageOptions":"","canCustomizeSite":"","isFollowing":"","themeSlug":"pub\/contempt","signupURL":"https:\/\/wordpress.com\/start\/","loginURL":"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2013%2F11%2F02%2Fentropy-and-information-in-biological-systems%2F&signup_flow=account","themeURL":"","xhrURL":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/admin-ajax.php","nonce":"e6f6fdfb46","isSingular":"","isFolded":"","isLoggedIn":"","isMobile":"","subscribeNonce":"<input type=\"hidden\" id=\"_wpnonce\" name=\"_wpnonce\" value=\"ffcb185558\" \/>","referer":"https:\/\/johncarlosbaez.wordpress.com\/category\/mathematics\/page\/34\/","canFollow":"1","feedID":"62242","statusMessage":"","subsEmailDefault":"instantly","customizeLink":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/customize.php?url=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2Fcategory%2Fmathematics%2Fpage%2F34%2F","i18n":{"view":"View site","follow":"Follow","following":"Following","edit":"Edit","login":"Log in","signup":"Sign up","customize":"Customize","report":"Report this content","themeInfo":"Get theme: Contempt","shortlink":"Copy shortlink","copied":"Copied","followedText":"New posts from this site will now appear in your <a href=\"https:\/\/wordpress.com\/read\">Reader<\/a>","foldBar":"Collapse this bar","unfoldBar":"Expand this bar","editSubs":"Manage subscriptions","viewReader":"View site in Reader","viewReadPost":"View post in Reader","subscribe":"Sign me up","enterEmail":"Enter your email address","followers":"Join 5,211 other followers","alreadyUser":"Already have a WordPress.com account? <a href=\"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2013%2F11%2F02%2Fentropy-and-information-in-biological-systems%2F&signup_flow=account\">Log in now.<\/a>","stats":"Stats","notifyNewPosts":"Notify me of new posts","notifyNewPostsDetails":"Receive web and mobile notifications for new posts from this site.","emailNewPosts":"Email me new posts","emailNewPostsDetails":"You can customize your notification settings further <a href=\"https:\/\/wordpress.com\/following\/manage?s=johncarlosbaez.wordpress.com\">here<\/a>.","emailNewComments":"Email me new comments","instantly":"Instantly","daily":"Daily","weekly":"Weekly"}};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s2.wp.com/_static/??-eJyFykEKwkAMQNELmQ4qtboQz1LbWDJMknGSQXt7K9SFILj6i//CI8Og4igeooWs5oxm/YRNtE34vqxXSgjVsCxAHEhu+sOV5JCLPufPIxlSHdHeM94rlnlNwyR/ETBNpXdc8YXP28OuOx3brt3HF3swRvU='></script>
<script type='text/javascript'>
	window.addEventListener( 'DOMContentLoaded', function() {
		rltInitialize( {"token":null,"iframeOrigins":["https:\/\/widgets.wp.com"]} );
	} );
</script>
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://johncarlosbaez.wordpress.com/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://s1.wp.com/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress.com" />

<!-- Jetpack Open Graph Tags -->
<meta property="og:type" content="website" />
<meta property="og:title" content="mathematics &#8211; Page 34 &#8211; Azimuth" />
<meta property="og:url" content="https://johncarlosbaez.wordpress.com/category/mathematics/" />
<meta property="og:site_name" content="Azimuth" />
<meta property="og:image" content="https://s0.wp.com/i/blank.jpg" />
<meta property="og:locale" content="en_US" />
<meta name="twitter:site" content="@wordpressdotcom" />
<meta property="fb:app_id" content="249643311490" />

<!-- End Jetpack Open Graph Tags -->
<link rel="shortcut icon" type="image/x-icon" href="https://s1.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48" />
<link rel="icon" type="image/x-icon" href="https://s1.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48" />
<link rel="apple-touch-icon" href="https://s2.wp.com/i/webclip.png" />
<link rel='openid.server' href='https://johncarlosbaez.wordpress.com/?openidserver=1' />
<link rel='openid.delegate' href='https://johncarlosbaez.wordpress.com/' />
<link rel="search" type="application/opensearchdescription+xml" href="https://johncarlosbaez.wordpress.com/osd.xml" title="Azimuth" />
<link rel="search" type="application/opensearchdescription+xml" href="https://s1.wp.com/opensearch.xml" title="WordPress.com" />
<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>		<style type="text/css">
			.recentcomments a {
				display: inline !important;
				padding: 0 !important;
				margin: 0 !important;
			}

			table.recentcommentsavatartop img.avatar, table.recentcommentsavatarend img.avatar {
				border: 0px;
				margin: 0;
			}

			table.recentcommentsavatartop a, table.recentcommentsavatarend a {
				border: 0px !important;
				background-color: transparent !important;
			}

			td.recentcommentsavatarend, td.recentcommentsavatartop {
				padding: 0px 0px 1px 0px;
				margin: 0px;
			}

			td.recentcommentstextend {
				border: none !important;
				padding: 0px 0px 2px 10px;
			}

			.rtl td.recentcommentstextend {
				padding: 0px 10px 2px 0px;
			}

			td.recentcommentstexttop {
				border: none;
				padding: 0px 0px 0px 10px;
			}

			.rtl td.recentcommentstexttop {
				padding: 0px 10px 0px 0px;
			}
		</style>
		<meta name="application-name" content="Azimuth" /><meta name="msapplication-window" content="width=device-width;height=device-height" /><meta name="msapplication-task" content="name=Subscribe;action-uri=https://johncarlosbaez.wordpress.com/feed/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=Sign up for a free blog;action-uri=http://wordpress.com/signup/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=WordPress.com Support;action-uri=http://support.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=WordPress.com Forums;action-uri=http://forums.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="description" content="Posts about mathematics written by John Baez" />
<style type="text/css">
#headerimg{
	background: url(https://johncarlosbaez.files.wordpress.com/2010/08/azimuth_header.jpg) no-repeat;
}
#header h1 a, .description {
	color:#E5F2E9;
}
</style>
<!-- There is no amphtml version available for this URL. -->		<link rel="stylesheet" id="custom-css-css" type="text/css" href="https://s0.wp.com/?custom-css=1&#038;csblog=RBZ9&#038;cscache=6&#038;csrev=7" />
		</head>
<body class="archive paged category category-mathematics category-3582 paged-34 category-paged-34 customizer-styles-applied highlander-enabled highlander-light">

<div id="page">

<div id="header">
	<div id="headerimg" onclick="location.href='https://johncarlosbaez.wordpress.com';" style="cursor: pointer;">
		<h1><a href="https://johncarlosbaez.wordpress.com/">Azimuth</a></h1>
		<div class="description"></div>
	</div>
</div>

<ul id="pagebar" class="menu pagebar"><li ><a href="https://johncarlosbaez.wordpress.com/">Home</a></li><li class="page_item page-item-2"><a href="https://johncarlosbaez.wordpress.com/about/">About</a></li>
</ul>

<div id="grad" style="height: 65px; width: 100%; background: url(https://s2.wp.com/wp-content/themes/pub/contempt/images/blue_flower/topgrad.jpg);">&nbsp;</div>

	<div id="content">

	
		
			<div class="post-16829 post type-post status-publish format-standard hentry category-biology category-conferences category-information-and-entropy category-mathematics" id="post-16829">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/11/02/entropy-and-information-in-biological-systems/" rel="bookmark">Entropy and Information in Biological Systems (Part&nbsp;1)</a></h2>
				<small>2 November, 2013</small><br />


				<div class="entry">
					<p><a href="http://socrates.berkeley.edu/~hartelab/">John Harte</a> is an ecologist who uses maximum entropy methods to predict the distribution, abundance and energy usage of species.  <a href="http://people.mbi.ucla.edu/marcharper/">Marc Harper</a> uses information theory in bioinformatics and evolutionary game theory.   Harper, Harte and I are organizing a workshop on entropy and information in biological systems, and I&#8217;m really excited about it!</p>
<p>It&#8217;ll take place at the <a href="http://www.nimbios.org/">National Institute for Mathematical and Biological Synthesis</a> in Knoxville Tennesee.    We are scheduling it for Wednesday-Friday, April 8-10, 2015.  When the date gets confirmed, I&#8217;ll post an advertisement so you can apply to attend.</p>
<p>Writing the proposal was fun, because we got to pull together lots of interesting people who are applying information theory and entropy to biology in quite different ways.   So, here it is!</p>
<div align="center"><a href="http://www.nimbios.org/"><img width="450" src="https://i0.wp.com/www.utk.edu/tntoday/images/nimbios_logo_lg.jpg" /></a></div>
<h3> Proposal </h3>
<p>Ever since Shannon initiated research on information theory in 1948, there have been hopes that the concept of information could serve as a tool to help systematize and unify work in biology.  The link between information and <i>entropy</i> was noted very early on, and it suggested that a full thermodynamic understanding of biology would naturally involve the information processing and storage that are characteristic of living organisms.  However, the subject is full of conceptual pitfalls for the unwary, and progress has been slower than initially expected.  Premature attempts at &#8216;grand syntheses&#8217; have often misfired.  But applications of information theory and entropy to specific highly focused topics in biology have been increasingly successful, such as:</p>
<p>&bull;  the maximum entropy principle in ecology,<br />
&bull;   Shannon and R&eacute;nyi entropies as measures of biodiversity,<br />
&bull;  information theory in evolutionary game theory,<br />
&bull;  information and the thermodynamics of individual cells.</p>
<p>Because they work in diverse fields, researchers in these specific topics have had little opportunity to trade insights and take stock of the progress so far.  The aim of the workshop is to do just this.  </p>
<p>In what follows, participants&#8217; names are in boldface, while the main goals of the workshop are in italics.</p>
<p><b><a href="http://biology.anu.edu.au/roderick_dewar/">Roderick Dewar</a></b> is a key advocate of the principle of Maximum Entropy Production, which says that biological systems&#8212;and indeed all open, non-equilibrium systems&#8212;act to produce entropy at the maximum rate.  Along with others, he has applied this principle to make testable predictions in a wide range of biological systems, from ATP synthesis [DJZ2006] to respiration and photosynthesis of individual plants [D2010] and plant communities.  He has also sought to derive this principle from ideas in statistical mechanics [D2004, D2009], but it remains controversial.  </p>
<p><i>The first goal of this workshop is to study the validity of this principle</i>.</p>
<p>While they may be related, the principle of Maximum Entropy Production should not be confused with the MaxEnt inference procedure, which says that we should choose the probabilistic hypothesis with the highest entropy subject to the constraints provided by our data.  MaxEnt was first explicitly advocated by Jaynes.  He noted that it is already implicit in the procedures of statistical mechanics, but convincingly argued that it can also be applied to situations where entropy is more &#8216;informational&#8217; than &#8216;thermodynamic&#8217; in character.  </p>
<p>Recently <b><a href="http://socrates.berkeley.edu/~hartelab/">John Harte</a></b> has applied MaxEnt in this way to ecology, using it to make specific testable predictions for the distribution, abundance and energy usage of species across spatial scales and across habitats and taxonomic groups [Harte2008, Harte2009, Harte2011].  <b><a href="http://webapps.lsa.umich.edu/eeb/directory/faculty/aostling/">Annette Ostling</a></b> is an expert on other theories that attempt to explain the same data, such as the &#8216;neutral model&#8217; [AOE2008, ODLSG2009, O2005, O2012]. <b><a href="http://biology.anu.edu.au/roderick_dewar/">Dewar</a></b> has also used MaxEnt in ecology [D2008], and he has argued that it underlies the principle of Maximum Entropy Production.    </p>
<p><i>Thus, a second goal of this workshop is to familiarize all the participants with applications of the MaxEnt method to ecology, compare it with competing approaches, and study whether MaxEnt provides a sufficient justification for the principle of Maximum Entropy Production.</i></p>
<p>Entropy is not merely a predictive tool in ecology: it is also widely used as a measure of biodiversity.  Here Shannon&#8217;s original concept of entropy naturally generalizes to &#8216;R&eacute;nyi entropy&#8217;, which depends on a parameter <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;ge 0" class="latex" />.  This equals</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+H_%5Calpha%28p%29+%3D+%5Cfrac%7B1%7D%7B1-%5Calpha%7D+%5Clog+%5Csum_i+p_i%5E%5Calpha++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ H_&#92;alpha(p) = &#92;frac{1}{1-&#92;alpha} &#92;log &#92;sum_i p_i^&#92;alpha  } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> is the fraction of organisms of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th type (which could mean species, some other taxon, etc.).    In the limit <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cto+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;to 1" class="latex" /> this reduces to the Shannon entropy:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++H%28p%29+%3D+-+%5Csum_i+p_i+%5Clog+p_i+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  H(p) = - &#92;sum_i p_i &#92;log p_i } " class="latex" /></p>
<p>As <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha" class="latex" /> increases, we give less weight to rare types of organisms.  <b><a href="http://www.maths.gla.ac.uk/~cc/">Christina Cobbold</a></b> and <b><a href="http://www.maths.ed.ac.uk/~tl/">Tom Leinster</a></b> have described a systematic and highly flexible system of biodiversity measurement, with R&eacute;nyi entropy at its heart [CL2012].    They consider both the case where all we have are the numbers <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" />, and the more subtle case where we take the distance between different types of organisms into account.  </p>
<p><b><a href="http://math.ucr.edu/home/baez/">John Baez</a></b> has explained the role of R&eacute;nyi entropy in thermodynamics [B2011], and together with <b><a href="http://www.maths.ed.ac.uk/~tl/"></a><a>Tom Leinster</a></b> and <b><a href="http://users.icfo.es/Tobias.Fritz/">Tobias Fritz</a></b> he has proved other theorems characterizing entropy which explain its importance for information processing [BFL2011].  However, these ideas have not yet been connected to the widespread use of entropy in biodiversity studies.  More importantly, the use of entropy as a measure of biodiversity has not been clearly connected to MaxEnt methods in ecology.  Does the success of MaxEnt methods imply a tendency for ecosystems to maximize biodiversity subject to the constraints of resource availability?  This seems surprising, but a more nuanced statement along these general lines might be correct.    </p>
<p><i>So, a third goal of this workshop is to clarify relations between known characterizations of entropy, the use of entropy as a measure of biodiversity, and the use of MaxEnt methods in ecology.</i></p>
<p>As the amount of data to analyze in genomics continues to surpass the ability of humans to analyze it, we can expect automated experiment design to become ever more important.   In <b><a href="http://thinking.bioinformatics.ucla.edu/">Chris Lee</a></b> and <b><a href="http://people.mbi.ucla.edu/marcharper/">Marc Harper</a></b>’s RoboMendel program [LH2013], a mathematically precise concept of &#8216;potential information&#8217;&#8212;how much information is left to learn&#8212;plays a crucial role in deciding what experiment to do next, given the data obtained so far.  It will be useful for them to interact with <b><a href="http://www.princeton.edu/~wbialek/wbialek.html">William Bialek</a></b>, who has expertise in estimating entropy from empirical data and using it to constrain properties of models [BBS, BNS2001, BNS2002], and <b><a href="http://www2.hawaii.edu/~sstill/">Susanne Still</a></b>, who applies information theory to automated theory building and biology [CES2010, PS2012].</p>
<p>However, there is another link between biology and potential information.  <b><a href="http://people.mbi.ucla.edu/marcharper/">Harper</a></b> has noted that in an ecosystem where the population of each type of organism grows at a rate proportional to its fitness (which may depend on the fraction of organisms of each type), the quantity </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+I%28q%7C%7Cp%29+%3D+%5Csum_i+q_i+%5Cln%28q_i%2Fp_i%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ I(q||p) = &#92;sum_i q_i &#92;ln(q_i/p_i) } " class="latex" /></p>
<p>always decreases if there is an evolutionarily stable state [Harper2009].  Here <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> is the fraction of organisms of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th genotype at a given time, while <img src="https://s0.wp.com/latex.php?latex=q_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q_i" class="latex" /> is this fraction in the evolutionarily stable state.  This quantity is often called the Shannon information of <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> &#8216;relative to&#8217; <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" />.  But in fact, it is precisely the same as <b><a href="http://thinking.bioinformatics.ucla.edu/">Lee</a></b> and <b><a href="http://people.mbi.ucla.edu/marcharper/">Harper</a></b>’s potential information!  Indeed, there is a precise mathematical analogy between evolutionary games and processes where a probabilistic hypothesis is refined by repeated experiments.  </p>
<p><i>Thus, a fourth goal of this workshop is to develop the concept of evolutionary games as &#8216;learning&#8217; processes in which information is gained over time.</i>  </p>
<p>We shall try to synthesize this with <b><a href="http://octavia.zoology.washington.edu/">Carl Bergstrom</a></b> and <b><a href="http://www.matina.org/">Matina Donaldson-Matasci</a></b>’s work on the &#8216;fitness value of information&#8217;: a measure of how much increase in fitness a population can obtain per bit of extra information [BL2004, DBL2010, DM2013].   Following <b><a href="http://people.mbi.ucla.edu/marcharper/">Harper</a></b>, we shall consider not only relative Shannon entropy, but also relative R&eacute;nyi entropy, as a measure of information gain [Harper2011].</p>
<p><i>A fifth and final goal of this workshop is to study the interplay between information theory and the thermodynamics of individual cells and organelles.</i></p>
<p><b><a href="http://www2.hawaii.edu/~sstill/">Susanne Still</a></b> has studied the thermodynamics of prediction in biological systems [BCSS2012].   And in a celebrated related piece of work, <b><a href="http://web.mit.edu/physics/people/faculty/england_jeremy.html">Jeremy England</a></b> used thermodynamic arguments to a derive a lower bound for the amount of entropy generated during a process of self-replication of a bacterial cell [England2013].  Interestingly, he showed that <i>E. coli</i> comes within a factor of 3 of this lower bound.   </p>
<p>In short, information theory and entropy methods are becoming powerful tools in biology, from the level of individual cells, to whole ecosystems, to experimental design, model-building, and the measurement of biodiversity. The time is ripe for an investigative workshop that brings together experts from different fields and lets them share insights and methods and begin to tackle some of the big remaining questions.</p>
<h3> Bibliography </h3>
<p>[AOE2008] D. Alonso, A. Ostling and R. Etienne, <a href="http://www-personal.umich.edu/~aostling/papers/alonso2008.pdf">The assumption of symmetry and species abundance distributions</a>, <i>Ecology Letters</i> <b>11</b> (2008), 93&#8211;105.</p>
<p>[TMMABB2012} D. Amodei, W. Bialek, M. J. Berry II, O. Marre, T. Mora, and G. Tkacik, <a href="http://arxiv.org/abs/1207.6319">The simplest maximum entropy model for collective behavior in a neural network</a>, arXiv:1207.6319 (2012).</p>
<p>[B2011] J. Baez, <a href="http://arxiv.org/abs/1102.2098">R&eacute;nyi entropy and free energy</a>, arXiv:1102.2098 (2011).</p>
<p>[BFL2011] J. Baez, T. Fritz and T. Leinster, <a href="http://arxiv.org/abs/1106.1791">A characterization of entropy in terms of information loss</a>, <i>Entropy</i> <b>13</b> (2011), 1945&#8211;1957.</p>
<p>[B2011] J. Baez and M. Stay, <a href="http://arxiv.org/abs/1010.2067">Algorithmic thermodynamics</a>, <i>Math. Struct. Comp. Sci.</i> <b>22</b> (2012), 771&#8211;787.</p>
<p>[BCSS2012] A. J. Bell, G. E. Crooks, S. Still and D. A Sivak, <a href="http://arxiv.org/abs/1203.3271">The thermodynamics of prediction</a>, <i>Phys. Rev. Lett.</i> <b>109</b> (2012), 120604.</p>
<p>[BL2004] C. T. Bergstrom and M. Lachmann, <a href="http://octavia.zoology.washington.edu/publications/BergstromAndLachmann04.pdf">Shannon information and biological fitness</a>, in <i>IEEE Information Theory Workshop 2004</i>, IEEE, 2004, pp. 50-54.</p>
<p>[BBS] M. J. Berry II, W. Bialek and E. Schneidman, <a href="http://arxiv.org/abs/physics/0212114">An information theoretic approach to the functional classification of neurons</a>, in <i>Advances in Neural Information Processing Systems 15</i>, MIT Press, 2005.</p>
<p>[BNS2001] W. Bialek, I. Nemenman and N. Tishby, <a href="http://www.princeton.edu/~wbialek/our_papers/bnt_01a.pdf">Predictability, complexity and learning</a>, <i>Neural Computation</i> <b>13</b> (2001), 2409&#8211;2463.</p>
<p>[BNS2002] W. Bialek, I. Nemenman and F. Shafee, <a href="http://books.nips.cc/papers/files/nips14/LT22.pdf">Entropy and inference, revisited</a>, in <i>Advances in Neural Information Processing Systems 14</i>, MIT Press, 2002.</p>
<p>[CL2012] C. Cobbold and T. Leinster, <a href="http://www.maths.ed.ac.uk/~tl/mdiss.pdf">Measuring diversity: the importance of species similarity</a>, <i>Ecology</i> <b>93</b> (2012), 477&#8211;489.</p>
<p>[CES2010] J. P. Crutchfield, S. Still and C. Ellison, <a href="http://arxiv.org/abs/0708.1580">Optimal causal inference: estimating stored information and approximating causal architecture</a>, <i>Chaos</i> <b>20</b> (2010), 037111.</p>
<p>[D2004] R. C. Dewar, Maximum entropy production and non-equilibrium statistical mechanics, in <i>Non-Equilibrium Thermodynamics and Entropy Production: Life, Earth and Beyond</i>, eds. A. Kleidon and R. Lorenz, Springer, New York, 2004, 41&#8211;55.</p>
<p>[DJZ2006] R. C. Dewar, D. Juret&iacute;c,  P. Zupanov&iacute;c, <a href="http://www.pmfst.hr/~juretic/CPLETT23896.pdf">The functional design of the rotary enzyme ATP synthase is consistent with maximum entropy production</a>, <i>Chem. Phys. Lett.</i> <b>430</b> (2006), 177&#8211;182. </p>
<p>[D2008] R. C. Dewar, A. Port&eacute;, <a href="http://arxiv.org/abs/q-bio/0703061">Statistical mechanics unifies different ecological patterns</a>, <i>J. Theor. Bio.</i> <b>251</b> (2008), 389&#8211;403. </p>
<p>[D2009] R. C. Dewar, <a href="http://www.mdpi.com/1099-4300/11/4/931/pdf">Maximum entropy production as an inference algorithm that translates physical assumptions into macroscopic predictions: don&#8217;t shoot the messenger</a>, <i>Entropy</i> <b>11</b> (2009), 931&#8211;944. </p>
<p>[D2010] R. C. Dewar, <a href="http://rstb.royalsocietypublishing.org/content/365/1545/1429.full">Maximum entropy production and plant optimization theories</a>, <i>Phil. Trans. Roy. Soc. B</i> <b>365</b> (2010) 1429&#8211;1435.</p>
<p>[DBL2010} M. C. Donaldson-Matasci, C. T. Bergstrom, and<br />
M. Lachmann, <a href="http://arxiv.org/abs/q-bio/0510007">The fitness value of information</a>, <i>Oikos</i> <b>119</b> (2010), 219-230.</p>
<p>[DM2013] M. C. Donaldson-Matasci, G. DeGrandi-Hoffman, and A. Dornhaus, Bigger is better: honey bee colonies as distributed information-gathering systems, <i>Animal Behaviour</i> <b>85</b> (2013), 585&#8211;592.</p>
<p>[England2013] J. L. England, <a href="http://arxiv.org/abs/1209.1179">Statistical physics of self-replication</a>, <i>J. Chem. Phys.</i> <b>139</b> (2013), 121923.</p>
<p>[ODLSG2009} J. L. Green,  J. K. Lake, J. P. O’Dwyer, A. Ostling and V. M. Savage, <a href="http://www-personal.umich.edu/~aostling/papers/ODwyer2009.pdf">An integrative framework for stochastic, size-structured community assembly</a>, <i>PNAS</i> <b>106</b> (2009), 6170&#8211;6175.</p>
<p>[Harper2009] M. Harper, <a href="http://arxiv.org/abs/0911.1383">Information geometry and evolutionary game theory</a>, arXiv:0911.1383 (2009).</p>
<p>[Harper2011] M. Harper, <a href="http://arxiv.org/abs/0911.1764">Escort evolutionary game theory</a>, <i>Physica D</i> <b>240</b> (2011), 1411&#8211;1415.</p>
<p>[Harte2008] J. Harte, T. Zillio, E. Conlisk and A. Smith, Maximum entropy and the state-variable approach to macroecology, <i>Ecology</i> <b>89</b> (2008), 2700&#8211;2711.</p>
<p>[Harte2009] J. Harte, A. Smith and D. Storch, Biodiversity scales from plots to biomes with a universal species-area curve, <i>Ecology Letters</i> <b>12</b> (2009), 789–797.</p>
<p>[Harte2011] J. Harte, <i>Maximum Entropy and Ecology: A Theory of Abundance, Distribution, and Energetics</i>, Oxford U. Press, Oxford, 2011.</p>
<p>[LH2013] M. Harper and C. Lee, <a href="http://arxiv.org/abs/1210.4808">Basic experiment planning via information metrics: the RoboMendel problem</a>, arXiv:1210.4808 (2012).</p>
<p>[O2005] A. Ostling, <a href="http://www-personal.umich.edu/~aostling/papers/O2005.pdf">Neutral theory tested by birds</a>, <i>Nature</i> <b>436</b> (2005), 635.</p>
<p>[O2012] A. Ostling, <a href="http://www-personal.umich.edu/~aostling/papers/O2012fit.pdf">Do fitness-equalizing tradeoffs lead to neutral communities?</a>, <i>Theoretical Ecology</i> <b>5</b> (2012), 181&#8211;194. </p>
<p>[PS2012] D. Precup and S. Still, <a href="http://www2.hawaii.edu/~sstill/StillPrecup2011.pdf">An information-theoretic approach to curiosity-driven reinforcement learning</a>, <i>Theory in Biosciences</i> <b>131</b> (2012), 139&#8211;148.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/11/02/entropy-and-information-in-biological-systems/#comments">35 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/biology/" rel="category tag">biology</a>, <a href="https://johncarlosbaez.wordpress.com/category/conferences/" rel="category tag">conferences</a>, <a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/" rel="category tag">information and entropy</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/11/02/entropy-and-information-in-biological-systems/" rel="bookmark" title="Permanent Link to Entropy and Information in Biological Systems (Part&nbsp;1)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-16731 post type-post status-publish format-standard hentry category-biology category-chemistry category-mathematics category-networks" id="post-16731">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/10/11/autocatalysis-in-reaction-networks/" rel="bookmark">Autocatalysis in Reaction&nbsp;Networks</a></h2>
				<small>11 October, 2013</small><br />


				<div class="entry">
					<p><i>guest post by <b><a href="http://www.tcs.tifr.res.in/~manoj/">Manoj Gopalkrishnan</a></b></i></p>
<p>Since this is my first time writing a blog post here, let me start with a word of introduction. I am a computer scientist at the <a href="http://www.tifr.res.in/">Tata Institute of Fundamental Research</a>, broadly interested in connections between Biology and Computer Science, with a particular interest in reaction networks. I first started thinking about them during my Ph.D. at the <a href="http://www.usc.edu/dept/molecular-science/">Laboratory for Molecular Science</a>.  My fascination with them has been predominantly mathematical. As a graduate student, I encountered an area with rich connections between combinatorics and dynamics, and surprisingly easy-to-state and compelling unsolved conjectures, and got hooked.</p>
<p>There is a story about Richard Feynman that he used to take bets with mathematicians. If any mathematician could make Feynman understand a mathematical statement, then Feynman would guess whether or not the statement was true. Of course, Feynman was in a habit of winning these bets, which allowed him to make the boast that mathematics, especially in its obsession for proof, was essentially irrelevant, since a relative novice like himself could after a moment&#8217;s thought guess at the truth of these mathematical statements. I have always felt Feynman&#8217;s claim to be unjust, but have often wondered what mathematical statement I would put to him so that his chances of winning were no better than random.</p>
<p>Today I want to tell you of a result about reaction networks that I have recently discovered with Abhishek Deshpande. The statement seems like a fine candidate to throw at Feynman because until we proved it, I would not have bet either way about its truth. Even after we obtained a short and elementary proof, I do not completely &#8216;see&#8217; why it must be true. I am hoping some of you will be able to demystify it for me. So, I&#8217;m just going to introduce enough terms to be able to make the statement of our result, and let you think about how to prove it.</p>
<p>John and his colleagues have been talking about reaction networks as Petri nets in the <a href="http://math.ucr.edu/home/baez/networks/">network theory</a> series on this blog.  As discussed in <a href="https://johncarlosbaez.wordpress.com/2011/03/31/network-theory-part-2/">part 2</a> of that series, a Petri net is a diagram like this:</p>
<div align="center"><img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/networks/wolf-rabbit.png" /></div>
<p>Following John&#8217;s terminology, I will call the aqua squares &#8216;transitions&#8217; and the yellow circles &#8216;species&#8217;.  If we have some number #rabbit of rabbits and some number #wolf of wolves, we draw #rabbit many black dots called &#8216;tokens&#8217; inside the yellow circle for rabbit, and #wolf tokens inside the yellow circle for wolf, like this:</p>
<div align="center"><img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/networks/wolf-rabbit_3_4.png" /></div>
<p>Here #rabbit = 4 and #wolf = 3.  The predation transition consumes one &#8216;rabbit&#8217; token and one &#8216;wolf&#8217; token, and produces two &#8216;wolf&#8217; tokens, taking us here:</p>
<div align="center"><img width="450" src="https://i0.wp.com/math.ucr.edu/home/baez/networks/wolf-rabbit_4_3.png" /></div>
<p>John explained in <a href="http://math.ucr.edu/home/baez/networks/networks_2.html">parts 2</a> and <a href="https://johncarlosbaez.wordpress.com/2011/04/03/network-theory-part-3/">3</a> how one can put rates on different transitions. For today I am only going to be concerned with &#8216;reachability:&#8217; what token states are reachable from what other token states.  John talked about this idea in <a href="http://math.ucr.edu/home/baez/networks/networks_25.html">part 25</a>.</p>
<p>By a <b>complex</b> I will mean a population vector: a snapshot of the number of tokens in each species.  In the example above, (#rabbit, #wolf) is a complex. If <img src="https://s0.wp.com/latex.php?latex=y%2C+y%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y, y&#039;" class="latex" /> are two complexes, then we write </p>
<p><img src="https://s0.wp.com/latex.php?latex=y+%5Cto+y%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y &#92;to y&#039;" class="latex" /> </p>
<p>if we can get from <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=y%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y&#039;" class="latex" /> by a single transition in our Petri net.  For example, we just saw that </p>
<p><img src="https://s0.wp.com/latex.php?latex=%284%2C3%29%5Cto+%283%2C4%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(4,3)&#92;to (3,4)" class="latex" /> </p>
<p>via the predation transition.</p>
<p><b>Reachability</b>, denoted <img src="https://s0.wp.com/latex.php?latex=%5Cto%5E%2A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;to^*" class="latex" />, is the transitive closure of the relation <img src="https://s0.wp.com/latex.php?latex=%5Cto&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;to" class="latex" />.  So <img src="https://s0.wp.com/latex.php?latex=y%5Cto%5E%2A+y%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y&#92;to^* y&#039;" class="latex" /> (read <img src="https://s0.wp.com/latex.php?latex=y%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y&#039;" class="latex" /> <b>is reachable from</b> <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y" class="latex" />) iff there are complexes </p>
<p><img src="https://s0.wp.com/latex.php?latex=y%3Dy_0%2Cy_1%2Cy_2%2C%5Cdots%2Cy_k+%3Dy%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y=y_0,y_1,y_2,&#92;dots,y_k =y&#039;" class="latex" /> </p>
<p>such that </p>
<p><img src="https://s0.wp.com/latex.php?latex=y_0%5Cto+y_1%5Cto%5Ccdots%5Cto+y_%7Bk-1%7D%5Cto+y_k.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y_0&#92;to y_1&#92;to&#92;cdots&#92;to y_{k-1}&#92;to y_k." class="latex" />  </p>
<p>For example, here <img src="https://s0.wp.com/latex.php?latex=%285%2C1%29+%5Cto%5E%2A+%281%2C+5%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(5,1) &#92;to^* (1, 5)" class="latex" /> by repeated predation. </p>
<p>I am very interested in switches. After all, a computer is essentially a box of switches! You can build computers by connecting switches together. In fact, that&#8217;s how early computers like the <a href="http://en.wikipedia.org/wiki/Z3_%28computer%29">Z3</a> were built. The CMOS gates at the heart of modern computers are essentially switches. By analogy, the study of switches in reaction networks may help us understand biochemical circuits.</p>
<p>A <b>siphon</b> is a set of species that is &#8216;switch-offable&#8217;. That is, if there are no tokens in the siphon states, then they will remain absent in future.  Equivalently, the only reactions that can produce tokens in the siphon states are those that require tokens from the siphon states before they can fire. Note that no matter how many rabbits there are, if there are no wolves, there will continue to be no wolves. So {wolf} is a siphon. Similarly, {rabbit} is a siphon, as is the union {rabbit, wolf}. However, when Hydrogen and Oxygen form Water, {Water} is not a siphon.  </p>
<p>For another example, consider this Petri net:</p>
<div align="center"><img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/networks/chemistryNetBasicA.png" /></div>
<p>The set {HCl, NaCl} is a siphon. However, there is a conservation law: whenever an HCl token is destroyed, an NaCl token is created, so that #HCl + #NaCl is invariant. If both HCl and NaCl were present to begin with, the complexes where both are absent are not reachable.  In this sense, this siphon is not &#8216;really&#8217; switch-offable.   As a first pass at capturing this idea, we will introduce the notion of &#8216;critical set&#8217;.  </p>
<p>A <b>conservation law</b> is a linear expression involving numbers of tokens that is invariant under every transition in the Petri net. A conservation law is <b>positive</b> if all the coefficients are non-negative.  A <b>critical set</b> of states is a set that does not contain the support of a positive conservation law.  </p>
<p>For example, the support of the positive conservation law #HCl + #NaCl is {HCl, NaCl}, and hence no set containing this set is critical.  Thus {HCl, NaCl} is a siphon, but not critical.  On the other hand, the set {NaCl} is critical but not a siphon.   {HCl} is a critical siphon.  And in our other example, {Wolf, Rabbit} is a critical siphon. </p>
<p>Of particular interest to us will be <b>minimal critical siphons</b>, the minimal sets among critical siphons.  Consider this example:</p>
<div align="center"><img width="350" src="https://i1.wp.com/math.ucr.edu/home/baez/networks/siphons.png" /></div>
<p>Here we have two transitions: </p>
<p><img src="https://s0.wp.com/latex.php?latex=X+%5Cto+2Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X &#92;to 2Y" class="latex" /> </p>
<p>and </p>
<p><img src="https://s0.wp.com/latex.php?latex=2X+%5Cto+Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="2X &#92;to Y" class="latex" />  </p>
<p>The set <img src="https://s0.wp.com/latex.php?latex=%5C%7BX%2CY%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{X,Y&#92;}" class="latex" /> is a critical siphon.  But so is the smaller set <img src="https://s0.wp.com/latex.php?latex=%5C%7BX%5C%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{X&#92;}." class="latex" />  So, <img src="https://s0.wp.com/latex.php?latex=%5C%7BX%2CY%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{X,Y&#92;}" class="latex" /> is not minimal.</p>
<p>We define a <b>self-replicable</b> set to be a set <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> of species such that there exist complexes <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y&#039;" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=y%5Cto%5E%2A+y%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y&#92;to^* y&#039;" class="latex" /> such that for all <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i &#92;in A" class="latex" /> we have </p>
<p><img src="https://s0.wp.com/latex.php?latex=y%27_i+%3E+y_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y&#039;_i &gt; y_i" class="latex" /> </p>
<p>So, there are transitions that accomplish the job of creating more tokens for all the species in <img src="https://s0.wp.com/latex.php?latex=A.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A." class="latex" />  In other words: these species can &#8216;replicate themselves&#8217;.</p>
<p>We define a <b>drainable</b> set by changing the <img src="https://s0.wp.com/latex.php?latex=%3E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&gt;" class="latex" /> to a <img src="https://s0.wp.com/latex.php?latex=%3C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&lt;" class="latex" />.  So, there are transitions that accomplish the job of <i>reducing</i> the number of tokens for all the species in <img src="https://s0.wp.com/latex.php?latex=A.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A." class="latex" />  These species can &#8216;drain away&#8217;.</p>
<p>Now here comes the statement: </p>
<div align="center">
<i>Every minimal critical siphon is either drainable or self-replicable!</i></div>
<p>We prove it in this paper:</p>
<p>&bull; Abhishek Deshpande and Manoj Gopalkrishnan,  <a href="https://selectedpapers.net/arxiv/1309.3957">Autocatalysis in reaction networks</a>.</p>
<p>But first note that the statement becomes false if the critical siphon is not minimal.  Look at this example again:</p>
<div align="center"><img width="350" src="https://i1.wp.com/math.ucr.edu/home/baez/networks/siphons.png" /></div>
<p>The set <img src="https://s0.wp.com/latex.php?latex=%5C%7BX%2CY%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{X,Y&#92;}" class="latex" /> is a critical siphon.  However <img src="https://s0.wp.com/latex.php?latex=%5C%7BX%2CY%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{X,Y&#92;}" class="latex" /> is neither self-replicable (since every reaction destroys <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" />) nor drainable (since every reaction produces <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" />).   But we&#8217;ve already seen that <img src="https://s0.wp.com/latex.php?latex=%5C%7BX%2CY%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{X,Y&#92;}" class="latex" /> is not minimal.  It has a critical subsiphon, namely <img src="https://s0.wp.com/latex.php?latex=%5C%7BX%5C%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{X&#92;}." class="latex" />   This one <i>is</i> minimal&mdash;and it obeys our theorem, because it is drainable.  </p>
<p>Checking these statements is a good way to make sure you understand the concepts!  I know I&#8217;ve introduced a lot of terminology here, and it takes a while to absorb.</p>
<p>Anyway: our proof that every minimal critical siphon is either drainable or self-replicable makes use of a fun result about matrices. Consider a real square matrix with a sign pattern like this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%28+%5Cbegin%7Barray%7D%7Bcccc%7D+%3C0+%26+%3E0+%26+%5Ccdots+%26+%3E+0+%5C%5C+%3E0+%26+%3C0+%26+%5Ccdots+%26%3E+0+%5C%5C+%5Cvdots+%26+%5Cvdots+%26+%3C0+%26%3E+0+%5C%5C+%3E0+%26+%3E0+%26+%5Ccdots+%26+%3C0+%5Cend%7Barray%7D+%5Cright%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;left( &#92;begin{array}{cccc} &lt;0 &amp; &gt;0 &amp; &#92;cdots &amp; &gt; 0 &#92;&#92; &gt;0 &amp; &lt;0 &amp; &#92;cdots &amp;&gt; 0 &#92;&#92; &#92;vdots &amp; &#92;vdots &amp; &lt;0 &amp;&gt; 0 &#92;&#92; &gt;0 &amp; &gt;0 &amp; &#92;cdots &amp; &lt;0 &#92;end{array} &#92;right)" class="latex" /></p>
<p>If the matrix is full-rank then there is a positive linear combination of the rows of the matrix so that all the entries are nonzero and have the same sign.  In fact, we prove something stronger in Theorem 5.9 of our paper.  At first, we thought this statement about matrices should be equivalent to one of the many well-known alternative statements of <a href="http://en.wikipedia.org/wiki/Farkas%27_lemma">Farkas&#8217; lemma</a>, like Gordan&#8217;s theorem. </p>
<p>However, we could not find a way to make this work, so we ended up proving it by a different technique. Later, my colleague <a href="http://www.tcs.tifr.res.in/%7Ejaikumar/">Jaikumar Radhakrishnan</a> came up with a clever proof that uses Farkas&#8217; lemma twice. However, so far we have not obtained the stronger result in Theorem 5.9 with this proof technique.</p>
<p>My interest in the result that every minimal critical siphon is either drainable or self-replicable is not purely aesthetic (though aesthetics is a big part of it). There is a research community of folks who are thinking of reaction networks as a programming language, and synthesizing molecular systems that exhibit sophisticated dynamical behavior as per specification:</p>
<p>&bull; <a href="http://www.dna-computing.org/">International Conference on DNA Computing and Molecular Programming</a>.</p>
<p>&bull; <a href="http://www.cs.duke.edu/FNANO/">Foundations of Nanoscience: Self-Assembled Architectures and Devices</a>.</p>
<p>&bull; <a href="http://molecular-programming.org/">Molecular Programming Architectures, Abstractions, Algorithms and Applications</a>. </p>
<p>Networks that exhibit some kind of catalytic behavior are a recurring theme among such systems, and even more so in biochemical circuits. </p>
<p>Here is an example of catalytic behavior:</p>
<p><img src="https://s0.wp.com/latex.php?latex=A+%2B+C+%5Cto+B+%2B+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A + C &#92;to B + C" class="latex" /></p>
<p>The &#8216;catalyst&#8217; <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" /> helps transform <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=B.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B." class="latex" /> In the absence of <img src="https://s0.wp.com/latex.php?latex=C%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C," class="latex" /> the reaction is turned off. Hence, catalysts are switches in chemical circuits! From this point of view, it is hardly surprising that they are required for the synthesis of complex behaviors.</p>
<p>In information processing, one needs amplification to make sure that a signal can propagate through a circuit without being overwhelmed by errors. Here is a chemical counterpart to such amplification:</p>
<p><img src="https://s0.wp.com/latex.php?latex=A+%2B+C+%5Cto+2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A + C &#92;to 2C" class="latex" /></p>
<p>Here the catalyst <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" /> catalyzes its own production: it is an &#8216;autocatalyst&#8217;, or a self-replicating species. By analogy, autocatalysis is key for scaling synthetic molecular systems.</p>
<p>Our work deals with these notions on a network level. We generalize the notion of catalysis in two ways. First, we allow a catalyst to be a set of species instead of a single species; second, its absence can turn off a reaction pathway instead of a single reaction. We propose the notion of self-replicable siphons as a generalization of the notion of autocatalysis. In particular, &#8216;weakly reversible&#8217; networks have critical siphons precisely when they exhibit autocatalytic behavior.  I was led to this work when I noticed the manifestation of this last statement in many examples.</p>
<p>Another hope I have is that perhaps one can study the dynamics of each minimal critical siphon of a reaction network separately, and then somehow be able to answer interesting questions about the dynamics of the entire network, by stitching together what we know for each minimal critical siphon. On the synthesis side, perhaps this could lead to a programming language to synthesize a reaction network that will achieve a specified dynamics. If any of this works out, it would be really cool! I think of how abelian group theory (and more broadly, the theory of abelian categories, which includes categories of vector bundles) benefits from a <a href="http://en.wikipedia.org/wiki/Abelian_group#Classification">fundamental theorem</a> that lets you break a finite abelian group into parts that are easy to study&mdash;or how number theory benefits from a special case, the <a href="http://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic">fundamental theorem of arithmetic</a>.  John has also pointed out that reaction networks are really presentations of symmetric monoidal categories, so perhaps this could point the way to a Fundamental Theorem for Symmetric Monoidal Categories. </p>
<p>And then there is the Global Attractor Conjecture, a<br />
long-standing open problem concerning the long-term behavior of solutions to the <a href="https://johncarlosbaez.wordpress.com/2011/04/03/network-theory-part-3/">rate equations</a>. Now that is a whole story by itself, and will have to wait for another day.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/10/11/autocatalysis-in-reaction-networks/#comments">18 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/biology/" rel="category tag">biology</a>, <a href="https://johncarlosbaez.wordpress.com/category/chemistry/" rel="category tag">chemistry</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/networks/" rel="category tag">networks</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/10/11/autocatalysis-in-reaction-networks/" rel="bookmark" title="Permanent Link to Autocatalysis in Reaction&nbsp;Networks">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-16724 post type-post status-publish format-standard hentry category-mathematics category-the-practice-of-science" id="post-16724">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/09/29/levels-of-excellence/" rel="bookmark">Levels of Excellence</a></h2>
				<small>29 September, 2013</small><br />


				<div class="entry">
					<p> </p>
<div align="center"></div>


<figure class="wp-block-image"><img data-attachment-id="26879" data-permalink="https://johncarlosbaez.wordpress.com/hua_shan_steps/" data-orig-file="https://johncarlosbaez.files.wordpress.com/2019/09/hua_shan_steps.jpg" data-orig-size="480,640" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="hua_shan_steps" data-image-description="" data-image-caption="" data-medium-file="https://johncarlosbaez.files.wordpress.com/2019/09/hua_shan_steps.jpg?w=225" data-large-file="https://johncarlosbaez.files.wordpress.com/2019/09/hua_shan_steps.jpg?w=450" src="https://johncarlosbaez.files.wordpress.com/2019/09/hua_shan_steps.jpg?w=400" alt="" class="wp-image-26879" srcset="https://johncarlosbaez.files.wordpress.com/2019/09/hua_shan_steps.jpg?w=400 400w, https://johncarlosbaez.files.wordpress.com/2019/09/hua_shan_steps.jpg?w=113 113w, https://johncarlosbaez.files.wordpress.com/2019/09/hua_shan_steps.jpg?w=225 225w, https://johncarlosbaez.files.wordpress.com/2019/09/hua_shan_steps.jpg 480w" sizes="(max-width: 400px) 100vw, 400px" /></figure>


<p>Over on Google+, a computer scientist at McGill named <a href="https://plus.google.com/u/0/101780559173703781847/posts">Artem Kaznatcheev</a> passed on this great description of what it&#8217;s like to learn math, written by someone who calls himself <a href="http://www.reddit.com/r/math/comments/1mtian/mathematicians_of_reddit_is_there_some_point/cccitg2">&#8216;man after midnight&#8217;</a>:</p>
<blockquote>
<p>The way it was described to me when I was in high school was in terms of &#8216;levels&#8217;.</p>
<p>Sometimes, in your mathematics career, you find that your slow progress, and careful accumulation of tools and ideas, has suddenly allowed you to do a bunch of new things that you couldn&#8217;t possibly do before. Even though you were learning things that were useless by themselves, when they&#8217;ve all become second nature, a whole new world of possibility appears. You have &#8220;leveled up&#8221;, if you will. Something clicks, but now there are new challenges, and now, things you were barely able to think about before suddenly become critically important.</p>
<p>It&#8217;s usually obvious when you&#8217;re talking to somebody a level above you, because they see lots of things instantly when those things take considerable work for you to figure out. These are good people to learn from, because they remember what it&#8217;s like to struggle in the place where you&#8217;re struggling, but the things they do still make sense from your perspective (you just couldn&#8217;t do them yourself).</p>
<p>Talking to somebody two or levels above you is a different story. They&#8217;re barely speaking the same language, and it&#8217;s almost impossible to imagine that you could ever know what they know. You can still learn from them, if you don&#8217;t get discouraged, but the things they want to teach you seem really philosophical, and you don&#8217;t think they&#8217;ll help you—but for some reason, they do.</p>
<p>Somebody three levels above is actually speaking a different language. They probably seem less impressive to you than the person two levels above, because most of what they&#8217;re thinking about is completely invisible to you. From where you are, it is not possible to imagine what they think about, or why. You might think you can, but this is only because they know how to tell entertaining stories. Any one of these stories probably contains enough wisdom to get you halfway to your next level if you put in enough time thinking about it.</p>
<p>What follows is my rough opinion on how this looks in a typical path towards a Ph.D. in math. Obviously this is rather subjective, and makes math look too linear, but I think it&#8217;s a useful thought experiment.</p>
<p>Consider the change that a person undergoes in first mastering elementary algebra. Let&#8217;s say that that&#8217;s one level. This student is now comfortable with algebraic manipulation and the idea of variables.</p>
<p>The next level may come somewhere during a first calculus course. The student now understands the concept of the infinitely small, of slope at a point, and can reason about areas, physical motion, and optimization.</p>
<p>Many stop here, believing that they have finally learned math. Those who do not stop, might proceed through multivariable calculus and perhaps a basic linear algebra course with the tools they currently possess. Their next level comes when they find themselves suffering through an abstract algebra course, and have to once again reshape their whole thought process just to squeak by with a C.</p>
<p>Once this student masters all of that, the rest of the undergraduate curriculum at their university might be a breeze. But not so with graduate school. They gain a level their first year. They gain another their third year. And they are horrified to discover that they are expected to gain a third level before they graduate. This level is the hardest of them all, because it is the first one that consists in mastering material that has been created largely by the student.</p>
<p>I don&#8217;t know how many levels there are after that. At least three.</p>
<p>So, the bad news is, you never do see the whole picture (though you see the old picture shrink down to a tiny point), and you can&#8217;t really explain what you do see. But the good news is that the world of mathematics is so rich and exciting and wonderful that even your wildest dreams about it cannot possibly compare. It is not like seeing the Matrix—it is like seeing the Matrix within the Matrix within the Matrix within the Matrix within the Matrix.</p>
</blockquote>
<p>As he points out, this talk of &#8216;levels&#8217; is too linear. You can be much better at algebraic geometry than your friend, but way behind them in probability theory. Or even within a field like algebraic geometry, you might be able to understand sheaf cohomology better than your friend, yet still way behind in some classical topic like elliptic curves.</p>
<p>To have worthwhile conversations with someone who is not evenly matched with you in some subject, it&#8217;s often good for one of you to play &#8216;student&#8217; while the other plays &#8216;teacher&#8217;. Playing teacher is an ego boost, and it helps organize your thoughts &#8211; but playing student is a great way to amass knowledge and practice humility&#8230; and a good student can help the teacher think about things in new ways.</p>
<p>Taking turns between who is teacher and who is student helps keep things from becoming unbalanced. And it&#8217;s especially fun when some subject can only be understood with the combined knowledge of both players.</p>
<p>I have a feeling good mathematicians spend a lot of time playing these games&#8212;we often hear of famous teams like Atiyah, Bott and Singer, or even bigger ones like the French collective called &#8216;Bourbaki&#8217;. For about a decade, I played teacher/student games with James Dolan, and it was really productive. I should probably find a new partner to learn the new kinds of math I&#8217;m working on now. Trying to learn things by yourself is a huge disadvantage if you want to quickly rise to higher &#8216;levels&#8217;.</p>
<p>If we took things a bit more seriously and talked about them more, maybe a lot of us could get better at things faster.</p>
<p></p>
<div align="center"> <img src="https://anahawnews.com/wp-content/uploads/2016/08/michael-phelps.jpg" width="450" /></div>
<p></p>
<p>Indeed, after I passed on these remarks, T.A. Abinandanan, a professor of materials science in Bangalore, pointed out this study on excellence in <i>swimming</i>:</p>
<p>• Daniel Chambliss, <a href="https://fermatslibrary.com/s/the-mundanity-of-excellence-an-ethnographic-report-on-stratification-and-olympic-swimmers">The mundanity of excellence</a>.</p>
<p>Chambliss emphasizes that in swimming there really are discrete levels of excellence, because there are different kinds of swimming competitions, each with their own different ethos. Here are some of his other main points:</p>
<p>1) Excellence comes from qualitative changes in behavior, not just quantitative ones. More time practicing is not good enough. Nor is simply moving your arms faster! A low-level breaststroke swimmer does very different things than a top-ranked one. The low-level swimmer tends to pull her arms far back beneath her, kick the legs out very wide without bringing them together at the finish, lift herself high out of the water on the turn, and fail to go underwater for a long ways after the turn. The top-ranked one sculls her arms out to the side and sweeps back in, kicks narrowly with the feet finishing together, stays low on the turns, and goes underwater for a long distance after the turn. They&#8217;re completely different!</p>
<p>2) The different levels of excellence in swimming are like different worlds, with different rules. People can move up or down within a level by putting in more or less effort, but going up a level requires something very different&#8212;see point 1).</p>
<p>3) Excellence is not the product of socially deviant personalities. The best swimmers aren&#8217;t &#8220;oddballs,&#8221; nor are they loners&#8212;kids who have given up &#8220;the normal teenage life&#8221;.</p>
<p>4) Excellence does not come from some mystical inner quality of the athlete. Rather, it comes from learning how to do lots of things right.</p>
<p>5) The best swimmers are more disciplined. They&#8217;re more likely to be strict with their training, come to workouts on time, watch what they eat, sleep regular hours, do proper warmups before a meet, and the like.</p>
<p>6) Features of the sport that low-level swimmers find unpleasant, excellent swimmers enjoy. What others see as boring &#8211; swimming back and forth over a black line for two hours, say &#8211; the best swimmers find peaceful, even meditative, or challenging, or therapeutic. They enjoy hard practices, look forward to difficult competitions, and try to set difficult goals.</p>
<p>7) The best swimmers don&#8217;t spend a lot of time dreaming about big goals like winning the Olympics. They concentrate on &#8220;small wins&#8221;: clearly defined minor achievements that can be rather easily done, but produce real effects.</p>
<p>8) The best swimmers don&#8217;t &#8220;choke&#8221;. Faced with what seems to be a tremendous challenge or a strikingly unusual event such as the Olympic Games, they take it as a normal, manageable situation. One way they do this is by sticking to the same routines. Chambliss calls this the &#8220;mundanity of excellence&#8221;.</p>
<p>I&#8217;ve just paraphrased chunks of the paper. The whole thing is worth reading! I can&#8217;t help wondering how much these lessons apply to other areas. He gives an example that could easily apply to mathematics&#8212;a</p>
<blockquote>
<p>more personal example of failing to maintain a sense of mundanity, from the world of academia: the inability to finish the doctoral thesis, the hopeless struggle for the magnum opus. Upon my arrival to graduate school some 12 years ago, I was introduced to an advanced student we will call Michael. Michael was very bright, very well thought of by his professors, and very hard working, claiming (apparently truthfully) to log a minimum of twelve hours a day at his studies. Senior scholars sought out his comments on their manuscripts, and their acknowledgements always mentioned him by name. All the signs pointed to a successful career. Yet seven years later, when I left the university, Michael was still there-still working 12 hours a day, only a bit less well thought of. At last report, there he remains, toiling away: &#8220;finishing up,&#8221; in the common expression.</p>
<p>In our terms, Michael could not maintain his sense of mundanity. He never accepted that a dissertation is a mundane piece of work, nothing more than some words which one person writes and a few other people read. He hasn&#8217;t learned that the real exams, the true tests (such as the dissertation requirement) in graduate school are really designed to discover whether at some point one is willing just to turn the damn thing in.</p>
</blockquote>									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/09/29/levels-of-excellence/#comments">43 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/the-practice-of-science/" rel="category tag">the practice of science</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/09/29/levels-of-excellence/" rel="bookmark" title="Permanent Link to Levels of Excellence">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-16584 post type-post status-publish format-standard hentry category-mathematics category-networks category-physics category-probability" id="post-16584">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/08/13/quantum-network-theory-part-2/" rel="bookmark">Quantum Network Theory (Part&nbsp;2)</a></h2>
				<small>13 August, 2013</small><br />


				<div class="entry">
					<p><i>guest post by <b><a href="http://www.azimuthproject.org/azimuth/show/Tomi+Johnson">Tomi Johnson</a></b></i></p>
<p><a href="https://johncarlosbaez.wordpress.com/2013/08/05/quantum-network-theory-part-1/">Last time</a> I told you how a random walk called the &#8216;uniform escape walk&#8217; could be used to analyze a network. In particular, Google uses it to rank nodes. For the case of an undirected network, the steady state of this random walk tells us the <b>degrees</b> of the nodes&#8212;that is, how many edges come out of each node.</p>
<p>Now I&#8217;m going to prove this to you. I&#8217;ll also exploit the connection between this random walk and a <i>quantum</i> walk, also introduced last time. In particular, I&#8217;ll connect the properties of this quantum walk to the degrees of a network by exploiting its relationship with the random walk. </p>
<p>This is pretty useful, considering how tricky these quantum walks can be.  As the parts of the world that we model using quantum mechanics get bigger and have more complicated structures, like biological network, we need all the help in understanding quantum walks that we can get.  So I&#8217;d better start!</p>
<h3> Flashback </h3>
<p>Starting with any (<a href="http://en.wikipedia.org/wiki/Simple_graph#Simple_graph">simple</a>, <a href="http://en.wikipedia.org/wiki/Simple_graph#Graph_classes_in_terms_of_connectivity">connected</a>) graph, we can get an old-fashioned &#8216;stochastic&#8217; random walk on this graph, but also a quantum walk.   The first is the <b>uniform escape stochastic walk</b>, where the walker has an equal probability per time of walking along any edge leaving the node they are standing at.  The second is the related quantum walk we&#8217;re going to study now.  These two walks are generated by two matrices, which we called <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q." class="latex" />  The good thing is that these matrices are <a href="http://en.wikipedia.org/wiki/Matrix_similarity">similar</a>, in the technical sense.</p>
<p> We studied this <a href="https://johncarlosbaez.wordpress.com/2013/08/05/quantum-network-theory-part-1/">last time</a>, and everything we learned is summarized here:</p>
<div align="center"><a href="http://arxiv.org/abs/1305.6078"><img alt="Diagram outlining the main concepts (again)" src="https://i0.wp.com/www.tomijohnson.co.uk/Images/quantum-stochastic-scheme.png" width="450" /></a></div>
<p>where:</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G" class="latex" /> is a simple graph that specifies</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> the adjacency matrix (the generator of a quantum walk) with elements <img src="https://s0.wp.com/latex.php?latex=A_%7Bi+j%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A_{i j}" class="latex" /> equal to unity if nodes <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j" class="latex" /> are connected, and zero otherwise (<img src="https://s0.wp.com/latex.php?latex=A_%7Bi+i%7D+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A_{i i} = 0" class="latex" />), which subtracted from</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D" class="latex" /> the diagonal matrix of degrees <img src="https://s0.wp.com/latex.php?latex=D_%7Bi+i%7D+%3D+%5Csum_j+A_%7Bi+j%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D_{i i} = &#92;sum_j A_{i j}" class="latex" /> gives</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=L+%3D+D+-+A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L = D - A" class="latex" /> the symmetric Laplacian (generator of stochastic and quantum walks), which when normalized by <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D" class="latex" /> returns both</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=S+%3D+L+D%5E%7B-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = L D^{-1}" class="latex" /> the generator of the uniform escape stochastic walk and</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=Q+%3D+D%5E%7B-1%2F2%7D+L+D%5E%7B-1%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q = D^{-1/2} L D^{-1/2}" class="latex" /> the quantum walk generator to which it is similar!</p>
<p>Now I hope you remember where we are.  Next I’ll talk you through the mathematics of the uniform escape stochastic walk <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> and how it connects to the degrees of the nodes in the large-time limit. Then I’ll show you how this helps us solve aspects of the quantum walk generated by <img src="https://s0.wp.com/latex.php?latex=Q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q." class="latex" /></p>
<h3> Stochastic walk </h3>
<p>The uniform escape stochastic walk generated by <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> is popular because it has a really useful <b>stationary state</b>.</p>
<div style="background:#fff1f1;border:solid black;border-width:2px 1px;padding:0 1em;margin:0 1em;overflow:auto;">
To recap from <a href="http://math.ucr.edu/home/baez/networks/networks_20.html">Part 20</a> of the <a href="http://math.ucr.edu/home/baez/networks/">network theory</a> series, a <b>stationary state</b> of a stochastic walk is one that does not change in time.  By the master equation </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%7D%7Bd+t%7D+%5Cpsi%28t%29+%3D+-S+%5Cpsi%28t%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d}{d t} &#92;psi(t) = -S &#92;psi(t)} " class="latex" /> </p>
<p>the stationary state must be an eigenvector of <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> with eigenvalue <img src="https://s0.wp.com/latex.php?latex=0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0." class="latex" /></p>
<p>A fantastic pair of theorems hold:</p>
<p>&bull; There is always a unique (up to multiplication by a positive number) positive eigenvector <img src="https://s0.wp.com/latex.php?latex=%5Cpi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> with eigenvalue <img src="https://s0.wp.com/latex.php?latex=0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0." class="latex" />  That is, there is a <i>unique stationary state</i> <img src="https://s0.wp.com/latex.php?latex=%5Cpi.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi." class="latex" /></p>
<p>&bull; Regardless of the initial state <img src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(0)," class="latex" /> any solution of the master equation approaches this stationary state <img src="https://s0.wp.com/latex.php?latex=%5Cpi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi" class="latex" /> in the large-time limit:</p>
<p> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clim_%7Bt+%5Crightarrow+%5Cinfty%7D+%5Cpsi%28t%29+%3D+%5Cpi+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;lim_{t &#92;rightarrow &#92;infty} &#92;psi(t) = &#92;pi }" class="latex" />
</div>
<p>To find this unique stationary state, consider the Laplacian <img src="https://s0.wp.com/latex.php?latex=L%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L," class="latex" /> which is both infinitesimal stochastic and symmetric. Among other things, this means the rows of <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" /> sum to zero:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Csum_j+L_%7Bi+j%7D+%3D+0+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;sum_j L_{i j} = 0 } " class="latex" /></p>
<p>Thus, the &#8216;all ones&#8217; vector <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbf{1}" class="latex" /> is an eigenvector of <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" /> with zero eigenvalue:</p>
<p><img src="https://s0.wp.com/latex.php?latex=L+%5Cmathbf%7B1%7D+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L &#92;mathbf{1} = 0 " class="latex" /></p>
<p>Inserting the identity <img src="https://s0.wp.com/latex.php?latex=I+%3D+D%5E%7B-1%7D+D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="I = D^{-1} D" class="latex" /> into this equation we then find <img src="https://s0.wp.com/latex.php?latex=D+%5Cmathbf%7B1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D &#92;mathbf{1}" class="latex" /> is a zero eigenvector of <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=L+%5Cmathbf%7B1%7D+%3D++%28+L+D%5E%7B-1%7D+%29+%28+D+%5Cmathbf%7B1%7D+%29+%3D+S+%28+D+%5Cmathbf%7B1%7D+%29+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L &#92;mathbf{1} =  ( L D^{-1} ) ( D &#92;mathbf{1} ) = S ( D &#92;mathbf{1} ) = 0 " class="latex" /></p>
<p>Therefore we just need to normalize this to get the large-time stationary state of the walk:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cpi+%3D+%5Cfrac%7BD+%5Cmathbf%7B1%7D%7D%7B%5Csum_i+D_%7Bi+i%7D%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;pi = &#92;frac{D &#92;mathbf{1}}{&#92;sum_i D_{i i}} }" class="latex" /></p>
<p>If we write <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> for the basis vector that is zero except at the <i>i</i>th node of our graph, and 1 at that node,  the inner product <img src="https://s0.wp.com/latex.php?latex=%5Clangle+i+%2C+%5Cpi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle i , &#92;pi &#92;rangle" class="latex" /> is large-time probability of finding a walker at that node.  The equation above implies this is proportional to the degree <img src="https://s0.wp.com/latex.php?latex=D_%7Bi+i%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D_{i i}" class="latex" /> of node <img src="https://s0.wp.com/latex.php?latex=i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i." class="latex" /></p>
<p>We can check this for the following graph:</p>
<div align="center">
<img alt="Illustration of a simple graph" src="https://i2.wp.com/www.tomijohnson.co.uk/Images/graph.png" />
</div>
<p>We find that <img src="https://s0.wp.com/latex.php?latex=%5Cpi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi" class="latex" /> is</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cleft%28+%5Cbegin%7Bmatrix%7D+1%2F6+%5C%5C+1%2F6+%5C%5C+1%2F4+%5C%5C+1%2F4+%5C%5C+1%2F6+%5Cend%7Bmatrix%7D+%5Cright%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;left( &#92;begin{matrix} 1/6 &#92;&#92; 1/6 &#92;&#92; 1/4 &#92;&#92; 1/4 &#92;&#92; 1/6 &#92;end{matrix} &#92;right) } " class="latex" /></p>
<p>which implies large-time probability <img src="https://s0.wp.com/latex.php?latex=1%2F6&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/6" class="latex" /> for nodes <img src="https://s0.wp.com/latex.php?latex=1%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1," class="latex" /> <img src="https://s0.wp.com/latex.php?latex=2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="2" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=5%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="5," class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=1%2F4&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/4" class="latex" /> for nodes <img src="https://s0.wp.com/latex.php?latex=3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="3" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=4.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="4." class="latex" /> Comparing this to the original graph, this exactly reflects the arrangement of degrees, as we knew it must. </p>
<p>Math works!</p>
<h3> The quantum walk </h3>
<p>Next up is the quantum walk generated by <img src="https://s0.wp.com/latex.php?latex=Q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q." class="latex" /> Not a lot is known about quantum walks on networks of arbitrary geometry, but below we’ll see some analytical results are obtained by exploiting the similarity of <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q." class="latex" /></p>
<p>Where to start? Well, let&#8217;s start at the bottom, what quantum physicists call the <b>ground state</b>. In contrast to stochastic walks, for a quantum walk every eigenvector <img src="https://s0.wp.com/latex.php?latex=%5Cphi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_k" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> is a stationary state of the quantum walk.  (In Puzzle 5, at the bottom of this page, I ask you to prove this).  The stationary state <img src="https://s0.wp.com/latex.php?latex=%5Cphi_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_0" class="latex" /> is of particular interest physically and mathematically. Physically, since eigenvectors of the <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> correspond to states of well-defined energy equal to the associated eigenvalue, <img src="https://s0.wp.com/latex.php?latex=%5Cphi_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_0" class="latex" /> is the state of lowest energy, energy zero, hence the name &#8216;ground state&#8217;.  (In Puzzle 3, I ask you to prove that all eigenvalues of <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> are non-negative, so zero really does correspond to the ground state.)</p>
<p>Mathematically, the relationship between eigenvectors implied by the similarity of <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> means </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cphi_0+%5Cpropto+D%5E%7B-1%2F2%7D+%5Cpi+%5Cpropto++D%5E%7B1%2F2%7D+%5Cmathbf%7B1%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_0 &#92;propto D^{-1/2} &#92;pi &#92;propto  D^{1/2} &#92;mathbf{1} " class="latex" /> </p>
<p>So in the ground state, the probability of our quantum walker being found at node <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> is </p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C+%5Clangle+i+%2C+%5Cphi_0+%5Crangle+%7C%5E2+%5Cpropto+%7C+%5Clangle+i+%2C+D%5E%7B1%2F2%7D+%5Crangle+%5Cmathbf%7B1%7D+%7C%5E2+%3D+D_%7Bi+i%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;langle i , &#92;phi_0 &#92;rangle |^2 &#92;propto | &#92;langle i , D^{1/2} &#92;rangle &#92;mathbf{1} |^2 = D_{i i}" class="latex" /> </p>
<p>Amazingly, this probability is proportional to the degree and so is exactly the same as <img src="https://s0.wp.com/latex.php?latex=%5Clangle+i+%2C+%5Cpi+%5Crangle%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle i , &#92;pi &#92;rangle," class="latex" /> the probability in the stationary state <img src="https://s0.wp.com/latex.php?latex=%5Cpi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi" class="latex" /> of the stochastic walk!</p>
<p>In short: a zero energy quantum walk <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> leads to exactly the same distribution of the walker over the nodes as in the large-time limit of the uniform escape stochastic walk <img src="https://s0.wp.com/latex.php?latex=S.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S." class="latex" />   The classically important notion of degree distribution also plays a role in quantum walks!</p>
<p>This is already pretty exciting.  What else can we say? If you are someone who feels faint at the sight of quantum mechanics, well done for getting this far, but watch out for what&#8217;s coming next. </p>
<p>What if the walker starts in some other initial state? Is there some quantum walk analogue of the unique large-time state of a stochastic walk?</p>
<p>In fact, the quantum walk in general does not converge to a stationary state. But there is a probability distribution that can be thought to characterize the quantum walk in the same way as the large-time state characterizes the stochastic walk. It&#8217;s the <b>large-time average probability vector</b> <img src="https://s0.wp.com/latex.php?latex=P.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P." class="latex" /></p>
<p>If you didn&#8217;t know the time that had passed since the beginning of a quantum walk, then the best estimate for the probability of your measuring the walker to be at node <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> would be the large-time average probability</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clangle+i+%2C+P+%5Crangle+%3D+%5Clim_%7BT+%5Crightarrow+%5Cinfty%7D+%5Cfrac%7B1%7D%7BT%7D+%5Cint_0%5ET+%7C+%5Cpsi_i+%28t%29+%7C%5E2+d+t+%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;langle i , P &#92;rangle = &#92;lim_{T &#92;rightarrow &#92;infty} &#92;frac{1}{T} &#92;int_0^T | &#92;psi_i (t) |^2 d t }  " class="latex" /></p>
<p>There’s a bit that we can do to simplify this expression. As usual in quantum mechanics, let&#8217;s start with the trick of diagonalizing <img src="https://s0.wp.com/latex.php?latex=Q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q." class="latex" />  This amounts to writing </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++Q%3D+%5Csum_k+%5Cepsilon_k+%5CPhi_k+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  Q= &#92;sum_k &#92;epsilon_k &#92;Phi_k } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5CPhi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Phi_k" class="latex" /> are projectors onto the eigenvectors <img src="https://s0.wp.com/latex.php?latex=%5Cphi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_k" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=Q%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q," class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;epsilon_k" class="latex" /> are the corresponding eigenvalues of <img src="https://s0.wp.com/latex.php?latex=Q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q." class="latex" />  If we insert this equation into</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi%28t%29++%3D+e%5E%7B-Q+t%7D+%5Cpsi%280%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(t)  = e^{-Q t} &#92;psi(0) " class="latex" /> </p>
<p>we get </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%5Cpsi%28t%29++%3D+%5Csum_k+e%5E%7B-%5Cepsilon_k+t%7D+%5CPhi_k+%5Cpsi%280%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  &#92;psi(t)  = &#92;sum_k e^{-&#92;epsilon_k t} &#92;Phi_k &#92;psi(0) }" class="latex" /></p>
<p>and thus</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clangle+i+%2C+P+%5Crangle+%3D+%5Clim_%7BT+%5Crightarrow+%5Cinfty%7D+%5Cfrac%7B1%7D%7BT%7D+%5Cint_0%5ET+%7C+%5Csum_k+e%5E%7B-i+%5Cepsilon_k+t%7D+%5Clangle+i%2C+%5CPhi_k+%5Cpsi+%280%29+%5Crangle+%7C%5E2+d+t+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;langle i , P &#92;rangle = &#92;lim_{T &#92;rightarrow &#92;infty} &#92;frac{1}{T} &#92;int_0^T | &#92;sum_k e^{-i &#92;epsilon_k t} &#92;langle i, &#92;Phi_k &#92;psi (0) &#92;rangle |^2 d t } " class="latex" /></p>
<p>Due to the integral over all time, the interference between terms corresponding to different eigenvalues averages to zero, leaving:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clangle+i+%2C+P+%5Crangle+%3D+%5Csum_k+%7C+%5Clangle+i%2C+%5CPhi_k+%5Cpsi%280%29+%5Crangle+%7C%5E2+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;langle i , P &#92;rangle = &#92;sum_k | &#92;langle i, &#92;Phi_k &#92;psi(0) &#92;rangle |^2 }" class="latex" /></p>
<p>The large-time average probability is then the sum of terms contributed by the projections of the initial state onto each eigenspace.</p>
<p>So we have a distribution that characterizes a quantum walk for a general initial state, but it&#8217;s a complicated beast. What can we say about it?</p>
<p>Our best hope of understanding the large-time average probability is through the term <img src="https://s0.wp.com/latex.php?latex=%7C+%5Clangle+i%2C+%5CPhi_0+%5Cpsi+%280%29+%5Crangle+%7C%5E2+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;langle i, &#92;Phi_0 &#92;psi (0) &#92;rangle |^2 " class="latex" />  associated with the zero energy eigenspace, since we know everything about this space.</p>
<p>For example, we know the zero energy eigenspace is one-dimensional and spanned by the eigenvector <img src="https://s0.wp.com/latex.php?latex=%5Cphi_0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_0." class="latex" /> This means that the projector is just the usual outer product</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CPhi_0+%3D+%7C+%5Cphi_0+%5Crangle+%5Clangle+%5Cphi_0+%7C+%3D+%5Cphi_0+%5Cphi_0%5E%5Cdagger+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Phi_0 = | &#92;phi_0 &#92;rangle &#92;langle &#92;phi_0 | = &#92;phi_0 &#92;phi_0^&#92;dagger " class="latex" /></p>
<p>where we have normalized <img src="https://s0.wp.com/latex.php?latex=%5Cphi_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_0" class="latex" /> according to the inner product <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cphi_0%2C+%5Cphi_0%5Crangle+%3D+1.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;phi_0, &#92;phi_0&#92;rangle = 1." class="latex" /> (If you&#8217;re wondering why I&#8217;m using all these angled brackets, well, they&#8217;re a notation named after <a href="http://en.wikipedia.org/wiki/Bra–ket_notation">Dirac</a> that is adored by quantum physicists.)</p>
<p>The zero eigenspace contribution to the large-time average probability then breaks nicely into two:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+%7C+%5Clangle+i%2C+%5CPhi_0+%5Cpsi+%280%29+%5Crangle+%7C%5E2+%26%3D%26+%7C+%5Clangle+i%2C+%5Cphi_0%5Crangle+%5C%3B+%5Clangle+%5Cphi_0%2C++%5Cpsi+%280%29+%5Crangle+%7C%5E2++%5C%5C++%5C%5C++%26%3D%26+%7C+%5Clangle+i%2C+%5Cphi_0%5Crangle+%7C%5E2+%5C%3B+%7C+%5Clangle+%5Cphi_0+%2C+%5Cpsi+%280%29+%5Crangle+%7C%5E2+%5C%5C+++%5C%5C++%26%3D%26+%5Clangle+i+%2C++%5Cpi+%5Crangle+%5C%3B+%7C+%5Clangle+%5Cphi_0+%2C++%5Cpsi+%280%29+%5Crangle+%7C%5E2+%5Cend%7Barray%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} | &#92;langle i, &#92;Phi_0 &#92;psi (0) &#92;rangle |^2 &amp;=&amp; | &#92;langle i, &#92;phi_0&#92;rangle &#92;; &#92;langle &#92;phi_0,  &#92;psi (0) &#92;rangle |^2  &#92;&#92;  &#92;&#92;  &amp;=&amp; | &#92;langle i, &#92;phi_0&#92;rangle |^2 &#92;; | &#92;langle &#92;phi_0 , &#92;psi (0) &#92;rangle |^2 &#92;&#92;   &#92;&#92;  &amp;=&amp; &#92;langle i ,  &#92;pi &#92;rangle &#92;; | &#92;langle &#92;phi_0 ,  &#92;psi (0) &#92;rangle |^2 &#92;end{array}" class="latex" /></p>
<p>This is just the product of two probabilities:</p>
<p>&bull; first, the probability <img src="https://s0.wp.com/latex.php?latex=%5Clangle+i+%2C+%5Cpi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle i , &#92;pi &#92;rangle" class="latex" /> for a quantum state in the zero energy eigenspace to be at node <img src="https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i," class="latex" /> as we found above, </p>
<p>and</p>
<p>&bull; second, the probability <img src="https://s0.wp.com/latex.php?latex=%7C+%5Clangle+%5Cphi_0%2C+%5Cpsi+%280%29%5Crangle+%7C%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;langle &#92;phi_0, &#92;psi (0)&#92;rangle |^2" class="latex" /> of being in this eigenspace to begin with.   (Remember, in quantum mechanics the probability of measuring the system to have an energy is the modulus squared of the projection of the state onto the associated eigenspace, which for the one-dimensional zero energy eigenspace means just the inner product with the ground state.)</p>
<p>This is all we need to say something interesting about the large-time average probability for all states.  We&#8217;ve basically shown that we can break the large-time probability vector <img src="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P" class="latex" /> into a sum of two normalized probability vectors:</p>
<p><img src="https://s0.wp.com/latex.php?latex=P+%3D+%281-+%5Ceta%29+%5Cpi+%2B+%5Ceta+%5COmega+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P = (1- &#92;eta) &#92;pi + &#92;eta &#92;Omega " class="latex" /></p>
<p>the first <img src="https://s0.wp.com/latex.php?latex=%5Cpi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi" class="latex" /> being the stochastic stationary state associated with the zero energy eigenspace, and the second $\Omega$ associated with the higher energy eigenspaces, with </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clangle+i+%2C+%5COmega+%5Crangle+%3D+%5Cfrac%7B+%5Csum_%7Bk%5Cneq+0%7D+%7C+%5Clangle+i%2C+%5CPhi_k++%5Cpsi+%280%29+%5Crangle+%7C%5E2++%7D%7B+%5Ceta%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;langle i , &#92;Omega &#92;rangle = &#92;frac{ &#92;sum_{k&#92;neq 0} | &#92;langle i, &#92;Phi_k  &#92;psi (0) &#92;rangle |^2  }{ &#92;eta} } " class="latex" /></p>
<p>The weight of each term is governed by the parameter</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Ceta+%3D++1+-+%7C+%5Clangle+%5Cphi_0%2C+%5Cpsi+%280%29%5Crangle+%7C%5E2+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;eta =  1 - | &#92;langle &#92;phi_0, &#92;psi (0)&#92;rangle |^2 " class="latex" /></p>
<p>which you could think of as the <b>quantumness</b> of the result. This is one minus the probability of the walker being in the zero energy eigenspace, or equivalently the probability of the walker being outside the zero energy eigenspace.</p>
<p>So even if we don&#8217;t know <img src="https://s0.wp.com/latex.php?latex=%5COmega%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Omega," class="latex" /> we know its importance is controlled by a parameter <img src="https://s0.wp.com/latex.php?latex=%5Ceta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;eta" class="latex" /> that governs how close the large-time average distribution <img src="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P" class="latex" /> of the quantum walk is to the corresponding stochastic stationary distribution <img src="https://s0.wp.com/latex.php?latex=%5Cpi.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi." class="latex" /> </p>
<p>What do we mean by &#8216;close&#8217;? Find out for yourself:</p>
<p><b>Puzzle 1.</b> Show, using a triangle inequality, that the <a href="http://en.wikipedia.org/wiki/Trace_distance">trace distance</a> between the two characteristic stochastic and quantum distributions <img src="https://s0.wp.com/latex.php?latex=%5C%7B+%5Clangle+i+%2C+P+%5Crangle+%5C%7D_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{ &#92;langle i , P &#92;rangle &#92;}_i" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5C%7B+%5Clangle+i+%2C+%5Cpi+%5Crangle+%5C%7D_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{ &#92;langle i , &#92;pi &#92;rangle &#92;}_i" class="latex" /> is upper-bounded by <img src="https://s0.wp.com/latex.php?latex=2+%5Ceta.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="2 &#92;eta." class="latex" /></p>
<p>Can we say anything physical about when the quantumness <img src="https://s0.wp.com/latex.php?latex=%5Ceta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;eta" class="latex" /> is big or small?</p>
<p>Because the eigenvalues of <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> have a physical interpretation in terms of energy, the answer is yes. The quantumness <img src="https://s0.wp.com/latex.php?latex=%5Ceta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;eta" class="latex" /> is the probability of being outside the zero energy state. Call the next lowest eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5CDelta+%3D+%5Cmin_%7Bk+%5Cneq+0%7D+%5Cepsilon_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta = &#92;min_{k &#92;neq 0} &#92;epsilon_k" class="latex" /> the <b>energy gap</b>. If the quantum walk is not in the zero energy eigenspace then it must be in an eigenspace of energy greater or equal to <img src="https://s0.wp.com/latex.php?latex=%5CDelta.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta." class="latex" /> Therefore the expected energy <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E" class="latex" /> of the quantum walker must bound the quantumness <img src="https://s0.wp.com/latex.php?latex=E+%5Cge+%5Ceta+%5CDelta.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E &#92;ge &#92;eta &#92;Delta." class="latex" /></p>
<p>This tells us that a quantum walk with a low energy is similar to a stochastic walk in the large-time limit.  We already knew this was <i>exactly</i> true in the zero energy limit, but this result goes further.</p>
<p>So little is known about quantum walks on networks of arbitrary geometry that we were very pleased to find this result.  It says there is a special case in which the walk is characterized by the degree distribution of the network, and a clear physical parameter that bounds how far the walk is from this special case.</p>
<p>Also, in finding it we learned that the difficulties of the initial state dependence, enhanced by the lack of convergence to a stationary state, could be overcome for a quantum walk, and that the relationships between quantum and stochastic walks extend beyond those with shared generators.</p>
<h3> What next? </h3>
<p>That’s all for the latest bit of idea sharing at the interface between stochastic and quantum systems.</p>
<p>I hope I’ve piqued your interest about quantum walks. There’s so much still left to work out about this topic, and your help is needed!</p>
<p>Other questions we have include: What holds analytically about the form of the quantum correction? Numerically it is known that the so-called quantum correction <img src="https://s0.wp.com/latex.php?latex=%5COmega&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Omega" class="latex" /> tends to enhance the probability of being found on nodes of low degree compared to <img src="https://s0.wp.com/latex.php?latex=%5Cpi.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi." class="latex" />  Can someone explain why? What happens if a small amount of stochastic noise is added to a quantum walk? Or a lot of noise?</p>
<p>It’s difficult to know who is best placed to answer these questions: experts in quantum physics, graph theory, complex networks or stochastic processes? I suspect it’ll take a bit of help from everyone. </p>
<h3> Background reading </h3>
<p>A couple of textbooks with comprehensive sections on non-negative matrices and continuous-time stochastic processes are:</p>
<p>&bull; Peter Lancaster and Miron Tismenetsky, <a href="http://en.wikipedia.org/wiki/Special:BookSources/9780124355606#Online_text"><i>The Theory of Matrices: with Applications</i></a>, 2nd edition, Academic Press, San Diego, 1985.</p>
<p>&bull; James R. Norris, <a href="http://en.wikipedia.org/wiki/Special:BookSources/9780521633963#Online_text"><i>Markov Chains</i></a>, Cambridge University Press, Cambridge, 1997.</p>
<p>There is, of course, the book that arose from the Azimuth <a href="http://math.ucr.edu/home/baez/networks/">network theory series</a>, which considers several relationships between quantum and stochastic processes on networks: </p>
<p>&bull; John Baez and Jacob Biamonte, <a href="http://math.ucr.edu/home/baez/stoch_stable.pdf"><i>A Course on Quantum Techniques for Stochastic Mechanics</i></a>, 2012.</p>
<p>Another couple of books on complex networks are:</p>
<p>&bull; Mark Newman, <a href="http://en.wikipedia.org/wiki/Special:BookSources/9780199206650#Online_text"><i>Networks: An Introduction</i></a>, Oxford University Press, Oxford, 2010.</p>
<p>&bull; Ernesto Estrada, <a href="http://en.wikipedia.org/wiki/Special:BookSources/9780199591756#Online_text"><i>The Structure of Complex Networks: Theory and Applications</i></a>, Oxford University Press, Oxford, 2011. Note that the <a href="http://fds.oup.com/www.oup.com/pdf/13/9780199591756_chapter1.pdf">first chapter</a> is available free online.</p>
<p>There are plenty more useful references in our article on this topic:</p>
<p>&bull; Mauro Faccin, Tomi Johnson, Jacob Biamonte, Sabre Kais and Piotr Migda&#322;, <a href="http://arxiv.org/abs/1305.6078">Degree distribution in quantum walks on complex networks</a>.</p>
<h3> Puzzles for the enthusiastic </h3>
<p>Sadly I didn&#8217;t have space to show proofs of all the theorems I used. So here are a few puzzles that guide you to doing the proofs for yourself:</p>
<h4> Stochastic walks and stationary states </h4>
<p><b>Puzzle 2.</b> (For the hard core.) Prove there is always a unique positive eigenvector for a stochastic walk generated by <img src="https://s0.wp.com/latex.php?latex=S.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S." class="latex" /> You’ll need the assumption that the graph <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G" class="latex" /> is connected. It&#8217;s not simple, and you’ll probably need help from a book, perhaps one of those above by Lancaster and Tismenetsky, and Norris.</p>
<p><b>Puzzle 3.</b> Show that the eigenvalues of <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> (and therefore <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" />) are non-negative.  A good way to start this proof is to apply the <a href="http://en.wikipedia.org/wiki/Perron–Frobenius_theorem">Perron-Frobenius theorem</a> to the non-negative matrix <img src="https://s0.wp.com/latex.php?latex=M+%3D+-+S+%2B+I+%5Cmax_i+S_%7Bi+i%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M = - S + I &#92;max_i S_{i i}." class="latex" /> This implies that <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M" class="latex" /> has a positive eigenvalue <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" /> equal to its <b>spectral radius</b></p>
<p><img src="https://s0.wp.com/latex.php?latex=r+%3D+%5Cmax_k+%7C+%5Clambda_k+%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r = &#92;max_k | &#92;lambda_k |" class="latex" /> </p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Clambda_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;lambda_k" class="latex" /> are the eigenvalues of <img src="https://s0.wp.com/latex.php?latex=M%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M," class="latex" /> and the associated eigenvector <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="v" class="latex" /> is positive.  Since <img src="https://s0.wp.com/latex.php?latex=S+%3D+-+M+%2B+I+%5Cmax_i+S_%7Bi+i%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = - M + I &#92;max_i S_{i i}," class="latex" /> it follows that <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> shares the eigenvectors of <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M" class="latex" /> and the associated eigenvalues are related by inverted translation:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cepsilon_k+%3D+-+%5Clambda_k+%2B+%5Cmax_i+S_%7Bi+i%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;epsilon_k = - &#92;lambda_k + &#92;max_i S_{i i}" class="latex" /></p>
<p><b>Puzzle 4.</b> Prove that regardless of the initial state <img src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(0)," class="latex" /> the zero eigenvector <img src="https://s0.wp.com/latex.php?latex=%5Cpi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi" class="latex" /> is obtained in the large-time limit <img src="https://s0.wp.com/latex.php?latex=%5Clim_%7Bt+%5Crightarrow+%5Cinfty%7D+%5Cpsi%28t%29+%3D+%5Cpi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;lim_{t &#92;rightarrow &#92;infty} &#92;psi(t) = &#92;pi" class="latex" /> of the walk generated by <img src="https://s0.wp.com/latex.php?latex=S.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S." class="latex" /> This breaks down into two parts:</p>
<p><b>(a)</b> Using the approach from Puzzle 5, to show that <img src="https://s0.wp.com/latex.php?latex=S+v++%3D+%5Cepsilon_v+v%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S v  = &#92;epsilon_v v," class="latex" /> the positivity of <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="v" class="latex" /> and the infinitesimal stochastic property <img src="https://s0.wp.com/latex.php?latex=%5Csum_i+S_%7Bi+j%7D+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sum_i S_{i j} = 0" class="latex" /> imply that <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon_v+%3D+%5Cepsilon_0+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;epsilon_v = &#92;epsilon_0 = 0" class="latex" /> and thus <img src="https://s0.wp.com/latex.php?latex=v+%3D+%5Cpi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="v = &#92;pi" class="latex" /> is actually the unique zero eigenvector and stationary state of <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> (its uniqueness follows from puzzle 4, you don’t need to re-prove it).</p>
<p><b>(b)</b> By inserting the decomposition <img src="https://s0.wp.com/latex.php?latex=S+%3D+%5Csum_k+%5Cepsilon_k+%5CPi_k+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = &#92;sum_k &#92;epsilon_k &#92;Pi_k " class="latex" /> into <img src="https://s0.wp.com/latex.php?latex=e%5E%7B-S+t%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="e^{-S t} " class="latex" /> and using the result of puzzle 5, complete the proof.</p>
<p>(Though I ask you to use the diagonalizability of <img src="https://s0.wp.com/latex.php?latex=S%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S," class="latex" /> the main results still hold if the generator is irreducible but not diagonalizable.)</p>
<h4> Quantum walks </h4>
<p>Here are a couple of extra puzzles for those of you interested in quantum mechanics:</p>
<p><b>Puzzle 5.</b> In quantum mechanics, probabilities are given by the moduli squared of amplitudes, so multiplying a state by a number of modulus unity has no physical effect. By inserting </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+Q%3D+%5Csum_k+%5Cepsilon_k+%5CPhi_k+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ Q= &#92;sum_k &#92;epsilon_k &#92;Phi_k }" class="latex" /> </p>
<p>into the quantum time evolution matrix <img src="https://s0.wp.com/latex.php?latex=e%5E%7B-Q+t%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="e^{-Q t}," class="latex" /> show that if </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29+%3D+%5Cphi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(0) = &#92;phi_k" class="latex" /> </p>
<p>then </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi%28t%29++%3D+e%5E%7B+-+i+%5Cepsilon_k+t%7D+%5Cpsi%280%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(t)  = e^{ - i &#92;epsilon_k t} &#92;psi(0)" class="latex" /> </p>
<p>hence <img src="https://s0.wp.com/latex.php?latex=%5Cphi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_k" class="latex" /> is a stationary state in the quantum sense, as probabilities don&#8217;t change in time.</p>
<p><b>Puzzle 6.</b> By expanding the initial state <img src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(0)" class="latex" /> in terms of the complete orthogonal basis vectors <img src="https://s0.wp.com/latex.php?latex=%5Cphi_k+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_k " class="latex" /> show that for a quantum walk <img src="https://s0.wp.com/latex.php?latex=%5Cpsi%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(t)" class="latex" /> never converges to a stationary state unless it began in one.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/08/13/quantum-network-theory-part-2/#comments">21 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/networks/" rel="category tag">networks</a>, <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/08/13/quantum-network-theory-part-2/" rel="bookmark" title="Permanent Link to Quantum Network Theory (Part&nbsp;2)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-16571 post type-post status-publish format-standard hentry category-mathematics category-networks category-physics" id="post-16571">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/08/05/quantum-network-theory-part-1/" rel="bookmark">Quantum Network Theory (Part&nbsp;1)</a></h2>
				<small>5 August, 2013</small><br />


				<div class="entry">
					<p>guest post by <i><b><a href="http://www.azimuthproject.org/azimuth/show/Tomi+Johnson">Tomi Johnson</a></b></i></p>
<p>If you were to randomly click a hyperlink on this web page and keep doing so on each page that followed, where would you end up?  </p>
<p>As an esteemed user of Azimuth, I’d like to think you browse more intelligently, but the above is the question Google asks when deciding how to rank the world’s web pages. </p>
<p>Recently, together with the team (<a href="http://people.isi.it/faccin">Mauro Faccin</a>, <a href="http://www.azimuthproject.org/azimuth/show/Jacob+Biamonte">Jacob Biamonte</a> and <a href="http://migdal.wikidot.com/">Piotr Migda&#322;</a>) at the ISI Foundation in Turin, we attended a workshop in which several of the attendees were asking a similar question with a twist. &#8220;What if you, the web surfer, behaved quantum mechanically?&#8221;</p>
<p>Now don’t panic! I have no reason to think you might enter a superposition of locations or tunnel through a wall. This merely forms part of a recent drive towards understanding the role that network science can play in quantum physics.</p>
<p>As we&#8217;ll find, playing with quantum networks is fun. It could also become a necessity. The size of natural systems in which quantum effects have been identified has grown steadily over the past few years. For example, attention has recently turned to explaining the remarkable efficiency of <a href="http://en.wikipedia.org/wiki/Light-harvesting_complex">light-harvesting complexes</a>, comprising tens of molecules and thousands of atoms, using quantum mechanics. If this expansion continues, perhaps quantum physicists will have to embrace the concepts of complex networks. </p>
<p>To begin studying quantum complex networks, we found a revealing toy model. Let me tell you about it. Like all good stories, it has a beginning, a middle and an end. In this part, I&#8217;ll tell you the beginning and the middle. I&#8217;ll introduce the stochastic walk describing the randomly clicking web surfer mentioned above and a corresponding quantum walk. In part 2 the story ends with the bounding of the difference between the two walks in terms of the energy of the walker.</p>
<p>But for now I&#8217;ll start by introducing you to a graph, this time representing the internet! </p>
<p>If this taster gets you interested, there are more details available here: </p>
<p>&bull; Mauro Faccin, Tomi Johnson, Jacob Biamonte, Sabre Kais and Piotr Migda&#322;, <a href="http://arxiv.org/abs/1305.6078">Degree distribution in quantum walks on complex networks</a>, arXiv:1305.6078 (2013). </p>
<h3> What does the internet look like from above? </h3>
<p>As we all know, the idea of the internet is to connect computers to each other. What do these connections look like when abstracted as a network, with each computer a node and each connection an edge? </p>
<p>The internet on a local scale, such as in your house or office, might look something like this:</p>
<p>&nbsp;</p>
<div align="center"><a href="http://www.posta.co.tz/net.htm"><img alt="Local network" src="https://i1.wp.com/www.posta.co.tz/images1/net3.jpg" width="400" /></a></div>
<p>with several devices connected to a central hub. Each hub connects to other hubs, and so the internet on a slightly larger scale might look something like this:</p>
<p>&nbsp;</p>
<div align="center"><a href="https://www.coursera.org/course/sna"><img alt="Regional network" src="https://s3.amazonaws.com/coursera/topics/sna/large-icon.png" width="400" /></a></div>
<p>What about the full global, not local, structure of the internet? To answer this question, researchers have developed representations of the whole internet, such as this one:</p>
<p>&nbsp;</p>
<div align="center"><a href="http://research.blogs.lincoln.ac.uk/2011/06/20/tsb-to-explore-internet-of-things/"><img alt="Global network" src="https://i2.wp.com/research.blogs.lincoln.ac.uk/files/2011/02/map-of-internet.png" width="400" /></a></div>
<p>While such representations might be awe inspiring, how can we make any sense of them? Or are they merely excellent desktop wallpapers and new-age artworks?</p>
<p>In terms of complex network theory, there&#8217;s actually a lot that can be said that is not immediately obvious from the above representation.  </p>
<p>For example, we find something very interesting if we plot the number of web pages with different incoming links (called <b>degree</b>) on a log-log axis. What is found for the African web is the following:</p>
<div align="center"><a href="http://www2002.org/CDROM/poster/164/"><img alt="Power law degree distribution" src="https://i1.wp.com/www2002.org/CDROM/poster/164/powerlaw.png" width="400" /></a></div>
<p>This shows that very few pages are linked to by a very large number others, while a very large number of pages receive very few links. More precisely, what this shows is a <b>power law distribution</b>, the signature of which is a straight line on a log-log axis.</p>
<p>In fact, power law distributions arise in a diverse number of real world networks, human-built networks such as the internet and naturally occurring networks. It is often discussed alongside the concept of the <a href="http://en.wikipedia.org/wiki/Preferential_attachment">preferential attachment</a>; highly connected nodes seem to accumulate connections more quickly. We all know of a successful blog whose success had led to an increased presence and more success. That&#8217;s an example of preferential attachment.</p>
<p>It&#8217;s clear then that degree is an important concept in network theory, and its distribution across the nodes a useful characteristic of a network. Degree gives one indication of how important a node is in a network.</p>
<p>And this is where stochastic walks come in. Google, who are in the business of ranking the importance of nodes (web pages) in a network (the web), use (up to a <a href="http://en.wikipedia.org/wiki/Google_matrix">small modification</a>) the idealized model of a stochastic walker (web surfer) who randomly hops to connected nodes (follows one of the links on a page). This is called the <b>uniform escape model</b>, since the total rate of leaving any node is set to be the same for all nodes. Leaving the walker to wander for a long while, Google then takes the probability of the walker being on a node to rank the importance of that node. In the case that the network is undirected (all links are reciprocated) this long-time probability, and therefore the rank of the node, is proportional to the degree of the node. </p>
<p>So node degrees and the uniform escape model play an important role in the fields of complex networks and stochastic walks. But can they tell us anything about the much more poorly understood topics of quantum networks and quantum walks? In fact, yes, and demonstrating that to you is the purpose of this pair of articles.</p>
<p>Before we move on to the interesting bit, the math, it&#8217;s worth just listing a few properties of quantum walks that make them hard to analyze, and explaining why they are poorly understood. These are the difficulties we will show how to overcome below.</p>
<p>&bull; <b>No convergence</b>. In a stochastic walk, if you leave the walker to wander for a long time, eventually the probability of finding a walker at a node converges to a constant value. In a quantum walk, this doesn’t happen, so the walk can’t be characterized so easily by its long-time properties.</p>
<p>&bull; <b>Dependence on initial states</b>. In some stochastic walks the long-time properties of the walk are independent of the initial state. It is possible to characterize the stochastic walk without referring to the initialization of the walker. Such a characterization is not so easy in quantum walks, since their evolution always depends on the initialization of the walker. Is it even possible then to say something useful that applies to all initializations?</p>
<p>&bull; <b>Stochastic and quantum generators differ</b>. Those of you familiar with the <a href="http://math.ucr.edu/home/baez/networks/">network theory series</a> know that some generators produce both stochastic and quantum walks (see <a href="https://johncarlosbaez.wordpress.com/2011/11/04/network-theory-part-16/">part 16</a> for more details). However, most stochastic walk generators, including that for the uniform escape model, do not generate quantum walks and vice versa. How do we then compare stochastic and quantum walks when their generators differ?</p>
<p>With the task outlined, let&#8217;s get started! </p>
<h3> Graphs and walks </h3>
<p>In the next couple of sections I&#8217;m going to explain the diagram below to you. If you’ve been following the <a href="http://math.ucr.edu/home/baez/networks/">network theory series</a>, in particular <a href="http://math.ucr.edu/home/baez/networks/networks_20.html">part 20</a>, you’ll find parts of it familiar. But as it&#8217;s been a while since the last post covering this topic, let&#8217;s start with the basics. </p>
<div align="center"><a href="http://arxiv.org/abs/1305.6078"><img alt="Diagram outlining the main concepts" src="https://i0.wp.com/www.tomijohnson.co.uk/Images/quantum-stochastic-scheme.png" width="450" /></a></div>
<p>A <a href="http://en.wikipedia.org/wiki/Simple_graph#Simple_graph"><b>simple graph</b></a> <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G" class="latex" /> can be used to define both stochastic and quantum walks. A simple graph is something like this:</p>
<div align="center"><img alt="Illustration of a simple graph" src="https://i2.wp.com/www.tomijohnson.co.uk/Images/graph.png" /></div>
<p>where there is at most one edge between any two nodes, there are no edges from a node to itself and all edges are undirected. To avoid complications, let’s stick to simple graphs with a finite number <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> of nodes. Let’s also assume you can get from every node to every other node via some combination of edges i.e. the graph is <b>connected</b>.</p>
<p>In the particular example above the graph represents a network of <img src="https://s0.wp.com/latex.php?latex=n+%3D+5&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n = 5" class="latex" /> nodes, where nodes 3 and 4 have degree (number of edges) 3, and nodes 1, 2 and 5 have degree 2.</p>
<p>Every simple graph defines a matrix <img src="https://s0.wp.com/latex.php?latex=A%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A," class="latex" /> called the <b>adjacency matrix</b>. For a network with <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> nodes, this matrix is of size <img src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n &#92;times n," class="latex" /> and each element <img src="https://s0.wp.com/latex.php?latex=A_%7Bi+j%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A_{i j}" class="latex" /> is unity if there is an edge between nodes <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j" class="latex" />, and zero otherwise (let&#8217;s use this basis for the rest of this post). For the graph drawn above the adjacency matrix is</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%28+%5Cbegin%7Bmatrix%7D+0+%26+1+%26+0+%26+1+%26+0+%5C%5C+1+%26+0+%26+1+%26+0+%26+0+%5C%5C+0+%26+1+%26+0+%26+1+%26+1+%5C%5C+1+%26+0+%26+1+%26+0+%26+1+%5C%5C+0+%26+0+%26+1+%26+1+%26+0+%5Cend%7Bmatrix%7D+%5Cright%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;left( &#92;begin{matrix} 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &#92;&#92; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &#92;&#92; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &#92;&#92; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &#92;&#92; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &#92;end{matrix} &#92;right) " class="latex" /></p>
<p>By construction, every adjacency matrix is <b>symmetric</b>: </p>
<p><img src="https://s0.wp.com/latex.php?latex=A+%3DA%5ET&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A =A^T" class="latex" /> </p>
<p>(the <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" /> means the transposition of the elements in the node basis) and further, because each <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> is real, it is <b>self-adjoint</b>: </p>
<p><img src="https://s0.wp.com/latex.php?latex=A%3DA%5E%5Cdagger&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A=A^&#92;dagger" class="latex" /> </p>
<p>(the <img src="https://s0.wp.com/latex.php?latex=%5Cdagger&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;dagger" class="latex" /> means conjugate transpose).</p>
<p>This is nice, since (as seen in parts <a href="http://math.ucr.edu/home/baez/networks/networks_16.html">16</a> and <a href="http://math.ucr.edu/home/baez/networks/networks_20.html">20</a>) a self-adjoint matrix generates a continuous-time <b>quantum walk</b>.</p>
<div style="background:#fff1f1;border:solid black;border-width:2px 1px;padding:0 1em;margin:0 1em;overflow:auto;">
To recap from the <a href="http://math.ucr.edu/home/baez/networks/">series</a>, a quantum walk is an evolution arising from a quantum walker moving on a network.</p>
<p>A <b>state</b> of a quantum walk is represented by a size <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> complex column vector <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" />. Each element <img src="https://s0.wp.com/latex.php?latex=%5Clangle+i+%2C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle i , &#92;psi &#92;rangle" class="latex" /> of this vector is the so-called <b>amplitude</b> associated with node <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> and the <b>probability</b> of the walker being found on that node (if measured) is the modulus of the amplitude squared <img src="https://s0.wp.com/latex.php?latex=%7C%5Clangle+i+%2C+%5Cpsi+%5Crangle%7C%5E2.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;langle i , &#92;psi &#92;rangle|^2." class="latex" />  Here <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> is the standard basis vector with a single non-zero <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th entry equal to unity, and <img src="https://s0.wp.com/latex.php?latex=%5Clangle+u+%2C+v+%5Crangle+%3D+u%5E%5Cdagger+v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle u , v &#92;rangle = u^&#92;dagger v" class="latex" /> is the usual inner product.</p>
<p>A quantum walk evolves in time according to the <b>Schr&ouml;dinger equation</b></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%7D%7Bd+t%7D+%5Cpsi%28t%29%3D+-+i+H+%5Cpsi%28t%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d}{d t} &#92;psi(t)= - i H &#92;psi(t) } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> is called the <b>Hamiltonian</b>. If the initial state is <img src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(0)" class="latex" /> then the solution is written as</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi%28t%29+%3D+%5Cexp%28-+i+t+H%29+%5Cpsi%280%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(t) = &#92;exp(- i t H) &#92;psi(0) " class="latex" /></p>
<p>The probabilities <img src="https://s0.wp.com/latex.php?latex=%7C+%5Clangle+i+%2C+%5Cpsi+%28t%29+%5Crangle+%7C%5E2+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;langle i , &#92;psi (t) &#92;rangle |^2 " class="latex" /> are guaranteed to be correctly normalized when the Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> is self-adjoint.
</div>
<p>There are other matrices that are defined by the graph. Perhaps the most familiar is the <b>Laplacian</b>, which has recently been a topic on this blog (see parts <a href="http://math.ucr.edu/home/baez/networks/networks_15.html">15</a>, <a href="http://math.ucr.edu/home/baez/networks/networks_16.html">16</a> and <a href="http://math.ucr.edu/home/baez/networks/networks_20.html">20</a> of the <a href="http://math.ucr.edu/home/baez/networks/">series</a>, and this <a href="https://johncarlosbaez.wordpress.com/2013/05/19/graph-laplacians/">recent post</a>).</p>
<p>The Laplacian <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" /> is the <img src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n &#92;times n" class="latex" /> matrix </p>
<p><img src="https://s0.wp.com/latex.php?latex=L+%3D+D+-+A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L = D - A" class="latex" /> </p>
<p>where the <b>degree matrix</b> <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D" class="latex" /> is an <img src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n &#92;times n" class="latex" /> diagonal matrix with elements given by the degrees</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+D_%7Bi+i%7D%3D%5Csum_%7Bj%7D+A_%7Bi+j%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ D_{i i}=&#92;sum_{j} A_{i j} } " class="latex" /></p>
<p>For the graph drawn above, the degree matrix and Laplacian are:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%28+%5Cbegin%7Bmatrix%7D+2+%26+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+2+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+3+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+3+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%26+2+%5Cend%7Bmatrix%7D+%5Cright%29++%5Cqquad+%5Cmathrm%7Band%7D+%5Cqquad+%5Cleft%28+%5Cbegin%7Bmatrix%7D+2+%26+-1+%26+0+%26+-1+%26+0+%5C%5C+-1+%26+2+%26+-1+%26+0+%26+0+%5C%5C+0+%26+-1+%26+3+%26+-1+%26+-1+%5C%5C+-1+%26+0+%26+-1+%26+3+%26+-1+%5C%5C+0+%26+0+%26+-1+%26+-1+%26+2+%5Cend%7Bmatrix%7D+%5Cright%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;left( &#92;begin{matrix} 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &#92;&#92; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &#92;&#92; 0 &amp; 0 &amp; 3 &amp; 0 &amp; 0 &#92;&#92; 0 &amp; 0 &amp; 0 &amp; 3 &amp; 0 &#92;&#92; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &#92;end{matrix} &#92;right)  &#92;qquad &#92;mathrm{and} &#92;qquad &#92;left( &#92;begin{matrix} 2 &amp; -1 &amp; 0 &amp; -1 &amp; 0 &#92;&#92; -1 &amp; 2 &amp; -1 &amp; 0 &amp; 0 &#92;&#92; 0 &amp; -1 &amp; 3 &amp; -1 &amp; -1 &#92;&#92; -1 &amp; 0 &amp; -1 &amp; 3 &amp; -1 &#92;&#92; 0 &amp; 0 &amp; -1 &amp; -1 &amp; 2 &#92;end{matrix} &#92;right) " class="latex" /></p>
<p>The Laplacian is self-adjoint and generates a quantum walk. </p>
<p>The Laplacian has another property; it is <b>infinitesimal stochastic</b>. This means that its off diagonal elements are non-positive and its columns sum to zero. This is interesting because an infinitesimal stochastic matrix generates a continuous-time <b>stochastic walk</b>. </p>
<div style="background:#fff1f1;border:solid black;border-width:2px 1px;padding:0 1em;margin:0 1em;overflow:auto;">
To recap from the <a href="http://math.ucr.edu/home/baez/networks/">series</a>, a stochastic walk is an evolution arising from a stochastic walker moving on a network.</p>
<p>A <b>state</b> of a stochastic walk is represented by a size <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> non-negative column vector <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" />. Each element <img src="https://s0.wp.com/latex.php?latex=%5Clangle+i+%2C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle i , &#92;psi &#92;rangle" class="latex" /> of this vector is the <b>probability</b> of the walker being found on node <img src="https://s0.wp.com/latex.php?latex=i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i." class="latex" />  </p>
<p>A stochastic walk evolves in time according to the <b>master equation</b></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%7D%7Bd+t%7D+%5Cpsi%28t%29%3D+-+H+%5Cpsi%28t%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d}{d t} &#92;psi(t)= - H &#92;psi(t) } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> is called the stochastic <b>Hamiltonian</b>. If the initial state is <img src="https://s0.wp.com/latex.php?latex=%5Cpsi%280%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(0)" class="latex" /> then the solution is written </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi%28t%29+%3D+%5Cexp%28-+t+H%29+%5Cpsi%280%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(t) = &#92;exp(- t H) &#92;psi(0) " class="latex" /></p>
<p>The probabilities <img src="https://s0.wp.com/latex.php?latex=%5Clangle+i+%2C+%5Cpsi+%28t%29+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle i , &#92;psi (t) &#92;rangle" class="latex" /> are guaranteed to be non-negative and correctly normalized when the stochastic Hamiltonian <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> is infinitesimal stochastic.
</div>
<p>So far, I have just presented what has been covered on Azimuth previously. However, to analyze the important uniform escape model we need to go beyond the class of (<a href="http://math.ucr.edu/home/baez/networks/networks_16.html">Dirichlet</a>) generators that produce both quantum and stochastic walks. Further, we have to somehow find a related quantum walk. We&#8217;ll see below that both tasks are achieved by considering the normalized Laplacians: one generating the uniform escape stochastic walk and the other a related quantum walk.</p>
<h3> Normalized Laplacians </h3>
<p>The two normalized Laplacians are:</p>
<p>&bull; the <b>asymmetric normalized Laplacian</b> <img src="https://s0.wp.com/latex.php?latex=S+%3D+L+D%5E%7B-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = L D^{-1}" class="latex" /> (that generates the uniform escape <i>S</i>tochastic walk) and</p>
<p>&bull; the <b>symmetric normalized Laplacian</b> <img src="https://s0.wp.com/latex.php?latex=Q+%3D+D%5E%7B-1%2F2%7D+L+D%5E%7B-1%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q = D^{-1/2} L D^{-1/2}" class="latex" /> (that generates a <i>Q</i>uantum walk).</p>
<p>For the graph drawn above the asymmetric normalized Laplacian <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> is</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%28+%5Cbegin%7Bmatrix%7D+1+%26+-1%2F2+%26+0+%26+-1%2F3+%26+0+%5C%5C+-1%2F2+%26+1+%26+-1%2F3+%26+0+%26+0+%5C%5C+0+%26+-1%2F2+%26+1+%26+-1%2F3+%26+-1%2F2+%5C%5C+-1%2F2+%26+0+%26+-1%2F3+%26+1+%26+-1%2F2+%5C%5C+0+%26+0+%26+-1%2F3+%26+-1%2F3+%26+1+%5Cend%7Bmatrix%7D+%5Cright%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;left( &#92;begin{matrix} 1 &amp; -1/2 &amp; 0 &amp; -1/3 &amp; 0 &#92;&#92; -1/2 &amp; 1 &amp; -1/3 &amp; 0 &amp; 0 &#92;&#92; 0 &amp; -1/2 &amp; 1 &amp; -1/3 &amp; -1/2 &#92;&#92; -1/2 &amp; 0 &amp; -1/3 &amp; 1 &amp; -1/2 &#92;&#92; 0 &amp; 0 &amp; -1/3 &amp; -1/3 &amp; 1 &#92;end{matrix} &#92;right) " class="latex" /></p>
<p>The identical diagonal elements indicates that the total rates of leaving each node are identical, and the equality within each column of the other non-zero elements indicates that the walker is equally likely to hop to any node connected to its current node. This is the uniform escape model! </p>
<p>For the same graph the symmetric normalized Laplacian <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> is </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%28+%5Cbegin%7Bmatrix%7D+1+%26+-1%2F2+%26+0+%26+-1%2F%5Csqrt%7B6%7D++%26+0+%5C%5C+-1%2F2+%26+1+%26+-1%2F%5Csqrt%7B6%7D++%26+0+%26+0+%5C%5C+0+%26+-1%2F%5Csqrt%7B6%7D++%26+1+%26+-1%2F3+%26+-1%2F%5Csqrt%7B6%7D++%5C%5C+-1%2F%5Csqrt%7B6%7D+%26+0+%26+-1%2F3+%26+1+%26+-1%2F%5Csqrt%7B6%7D++%5C%5C+0+%26+0+%26+-1%2F%5Csqrt%7B6%7D++%26+-1%2F%5Csqrt%7B6%7D++%26+1+%5Cend%7Bmatrix%7D+%5Cright%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;left( &#92;begin{matrix} 1 &amp; -1/2 &amp; 0 &amp; -1/&#92;sqrt{6}  &amp; 0 &#92;&#92; -1/2 &amp; 1 &amp; -1/&#92;sqrt{6}  &amp; 0 &amp; 0 &#92;&#92; 0 &amp; -1/&#92;sqrt{6}  &amp; 1 &amp; -1/3 &amp; -1/&#92;sqrt{6}  &#92;&#92; -1/&#92;sqrt{6} &amp; 0 &amp; -1/3 &amp; 1 &amp; -1/&#92;sqrt{6}  &#92;&#92; 0 &amp; 0 &amp; -1/&#92;sqrt{6}  &amp; -1/&#92;sqrt{6}  &amp; 1 &#92;end{matrix} &#92;right) " class="latex" /></p>
<p>That the diagonal elements are identical in the quantum case indicates that all nodes are of equal energy, this is type of quantum walk usually considered.</p>
<p><b>Puzzle 1.</b> Show that in general <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> is infinitesimal stochastic but not self-adjoint.</p>
<p><b>Puzzle 2.</b> Show that in general <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> is self-adjoint but not infinitesimal stochastic.</p>
<p>So a graph defines two matrices: one <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> that generates a stochastic walk, and one <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> that generates a quantum walk. The natural question to ask is whether these walks are related. The answer is that they are!</p>
<p>Underpinning this relationship is the mathematical property that <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> are <a href="http://en.wikipedia.org/wiki/Matrix_similarity">similar</a>. They are related by the following similarity transformation </p>
<p><img src="https://s0.wp.com/latex.php?latex=S+%3D+D%5E%7B1%2F2%7D+Q+D%5E%7B-1%2F2%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = D^{1/2} Q D^{-1/2} " class="latex" /></p>
<p>which means that any eigenvector <img src="https://s0.wp.com/latex.php?latex=%5Cphi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_k" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> associated to eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;epsilon_k" class="latex" /> gives a vector </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpi_k+%5Cpropto+D%5E%7B1%2F2%7D+%5Cphi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi_k &#92;propto D^{1/2} &#92;phi_k" class="latex" /> </p>
<p>that is an eigenvector of <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> with the same eigenvalue! To show this, insert the identity <img src="https://s0.wp.com/latex.php?latex=I+%3D+D%5E%7B-1%2F2%7D+D%5E%7B1%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="I = D^{-1/2} D^{1/2}" class="latex" /> into</p>
<p><img src="https://s0.wp.com/latex.php?latex=Q+%5Cphi_k+%3D+%5Cepsilon_k+%5Cphi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q &#92;phi_k = &#92;epsilon_k &#92;phi_k" class="latex" /></p>
<p>and multiply from the left with <img src="https://s0.wp.com/latex.php?latex=D%5E%7B1%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D^{1/2}" class="latex" /> to obtain</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28D%5E%7B1%2F2%7D++Q+D%5E%7B-1%2F2%7D+%29+%28D%5E%7B1%2F2%7D+%5Cphi_k%29+%26%3D+%5Cepsilon_k+%28+D%5E%7B1%2F2%7D+%5Cphi_k+%29+%5C%5C+S+%5Cpi_k+%26%3D+%5Cepsilon_k+%5Cpi_k++%5Cend%7Baligned%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{aligned} (D^{1/2}  Q D^{-1/2} ) (D^{1/2} &#92;phi_k) &amp;= &#92;epsilon_k ( D^{1/2} &#92;phi_k ) &#92;&#92; S &#92;pi_k &amp;= &#92;epsilon_k &#92;pi_k  &#92;end{aligned} " class="latex" /></p>
<p>The same works in the opposite direction. Any eigenvector <img src="https://s0.wp.com/latex.php?latex=%5Cpi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;pi_k" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> gives an eigenvector </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cphi_k+%5Cpropto+D%5E%7B-1%2F2%7D+%5Cpi_k+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_k &#92;propto D^{-1/2} &#92;pi_k " class="latex" /> </p>
<p>of <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> with the same eigenvalue <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon_k.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;epsilon_k." class="latex" /></p>
<p>The mathematics is particularly nice because <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> is self-adjoint. A self-adjoint matrix is <a href="http://en.wikipedia.org/wiki/Diagonalizable_matrix">diagonalizable</a>, and has real eigenvalues and orthogonal eigenvectors.</p>
<p>As a result, the symmetric normalized Laplacian can be decomposed as </p>
<p><img src="https://s0.wp.com/latex.php?latex=Q+%3D+%5Csum_k+%5Cepsilon_k+%5CPhi_k+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q = &#92;sum_k &#92;epsilon_k &#92;Phi_k " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;epsilon_k" class="latex" /> is real and <img src="https://s0.wp.com/latex.php?latex=%5CPhi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Phi_k" class="latex" /> are orthogonal <a href="http://en.wikipedia.org/wiki/Projection_%28linear_algebra%29#Properties_and_classification">projectors</a>. Each <img src="https://s0.wp.com/latex.php?latex=%5CPhi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Phi_k" class="latex" /> acts as the identity only on vectors in the space spanned by <img src="https://s0.wp.com/latex.php?latex=%5Cphi_k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_k" class="latex" /> and as zero on all others, such that </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CPhi_k+%5CPhi_%5Cell+%3D+%5Cdelta_%7Bk+%5Cell%7D+%5CPhi_k.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Phi_k &#92;Phi_&#92;ell = &#92;delta_{k &#92;ell} &#92;Phi_k." class="latex" /></p>
<p>Multiplying from the left by <img src="https://s0.wp.com/latex.php?latex=D%5E%7B1%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D^{1/2}" class="latex" /> and the right by <img src="https://s0.wp.com/latex.php?latex=D%5E%7B-1%2F2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D^{-1/2}" class="latex" /> results in a similar decomposition for <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=S+%3D+%5Csum_k+%5Cepsilon_k+%5CPi_k+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = &#92;sum_k &#92;epsilon_k &#92;Pi_k " class="latex" /></p>
<p>with orthogonal projectors </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CPi_k++%3D+D%5E%7B1%2F2%7D+%5CPhi_k+D%5E%7B-1%2F2%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Pi_k  = D^{1/2} &#92;Phi_k D^{-1/2} " class="latex" /></p>
<p>I promised above that I would explain the following diagram:</p>
<div align="center"><a href="http://arxiv.org/abs/1305.6078"><img alt="Diagram outlining the main concepts (again)" src="https://i0.wp.com/www.tomijohnson.co.uk/Images/quantum-stochastic-scheme.png" width="450" /></a></div>
<p>Let&#8217;s summarize what it represents now:</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G" class="latex" /> is a simple graph that specifies</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> the adjacency matrix (generator of a quantum walk), which subtracted from</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D" class="latex" /> the diagonal matrix of the degrees gives</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" /> the symmetric Laplacian (generator of stochastic and quantum walks), which when normalized by <img src="https://s0.wp.com/latex.php?latex=D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D" class="latex" /> returns both</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> the generator of the uniform escape stochastic walk and</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> the quantum walk generator to which it is similar!</p>
<h3> What next? </h3>
<p>Sadly, this is where we&#8217;ll finish for now. </p>
<p>We have all the ingredients necessary to study the walks generated by the normalized Laplacians and exploit the relationship between them. </p>
<p>Next time, in part 2, I’ll talk you through the mathematics of the uniform escape stochastic walk <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> and how it connects to the degrees of the nodes in the long-time limit. Then I’ll show you how this helps us solve aspects of the quantum walk generated by <img src="https://s0.wp.com/latex.php?latex=Q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q." class="latex" /></p>
<h3> In other news </h3>
<p>Before I leave you, let me tell you about a workshop the ISI team recently attended (in fact helped organize) at the Institute of Quantum Computing, on the topic of quantum computation and complex networks.  Needless to say, there were talks on papers related to quantum mechanics and networks!  </p>
<p>Some researchers at the workshop gave exciting talks based on numerical examinations of what happens if a quantum walk is used instead of a stochastic walk to rank the nodes of a network:</p>
<p>&bull; Giuseppe Davide Paparo and Miguel Angel Mart&iacute;n-Delgado, <a href="http://arxiv.org/abs/1112.2079">Google in a quantum network</a>, <a href="http://dx.doi.org/doi:10.1038/srep00444"><i>Sci. Rep.</i></a> <b>2</b> (2012), 444.</p>
<p>&bull; Eduardo S&aacute;nchez-Burillo, Jordi Duch, Jes&uacute;s G&oacute;mez-Gardenes and David Zueco, <a href="http://arxiv.org/abs/1202.3471">Quantum navigation and ranking in complex networks</a>, <a href="http://dx.doi.org/doi:10.1038/srep00605"><i>Sci. Rep.</i></a> <b>2</b> (2012), 605.</p>
<p>Others attending the workshop have numerically examined what happens when using quantum computers to represent the stationary state of a stochastic process:</p>
<p>&bull; Silvano Garnerone, Paolo Zanardi and Daniel A. Lidar, <a href="http://arxiv.org/abs/1109.6546">Adiabatic quantum algorithm for search engine ranking</a>, <a href="http://dx.doi.org/10.1103/PhysRevLett.108.230506"><i>Phys. Rev. Lett.</i></a> <b>108</b> (2012), 230506.</p>
<p>It was a fun workshop and we plan to organize/attend more in the future!  </p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/08/05/quantum-network-theory-part-1/#comments">33 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/networks/" rel="category tag">networks</a>, <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/08/05/quantum-network-theory-part-1/" rel="bookmark" title="Permanent Link to Quantum Network Theory (Part&nbsp;1)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-16530 post type-post status-publish format-standard hentry category-climate category-mathematics category-oceans category-probability" id="post-16530">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/" rel="bookmark">Monte Carlo Methods in Climate&nbsp;Science</a></h2>
				<small>23 July, 2013</small><br />


				<div class="entry">
					<p><i>joint with <b><a href="http://www.azimuthproject.org/azimuth/show/David+Tweed">David Tweed</a></b></i></p>
<p>One way the Azimuth Project can help save the planet is to get bright young students interested in ecology, climate science, green technology, and stuff like that.  So, we are writing an article for <i><a href="http://www.maa.org/publications/periodicals/math-horizons">Math Horizons</a></i>, an American magazine for undergraduate math majors.  This blog article is a draft of that.  You can also see it in PDF form <a href="http://math.ucr.edu/home/baez/horizons.pdf">here</a>.</p>
<p>We’d really like to hear your comments!  There are severe limits on including more detail, since the article should be easy to read and short.  So please don&#8217;t ask us to explain more stuff: we&#8217;re most interested to know if you sincerely don’t understand something, or feel that students would have trouble understanding something.   For comparison, you can see sample <i>Math Horizons</i> articles <a href="http://www.maa.org/publications/periodicals/math-horizons/math-horizons-sample-articles">here</a>.</p>
<h3>Introduction</h3>
<p>They look placid lapping against the beach on a calm day, but the oceans are actually quite dynamic. The ocean currents act as &#8216;conveyor belts&#8217;, transporting heat both vertically between the water&#8217;s surface and the depths and laterally from one area of the globe to another. This effect is so significant that the temperature and precipitation patterns can change dramatically when currents do.</p>
<p>For example: shortly after the last ice age, northern Europe experienced a shocking change in climate from 10,800 to 9,500 BC.  At the start of this period temperatures plummeted in a matter of decades.  It became 7&deg; Celsius colder, and glaciers started forming in England!  The cold spell lasted for over a thousand years, but it ended as suddenly as it had begun.</p>
<p>Why?  The most popular theory is that that a huge lake in North America formed by melting glaciers burst its bank&#8212;and in a massive torrent lasting for years, the water from this lake rushed out to the northern Atlantic ocean. By floating atop the denser salt water, this fresh water blocked a major current: the Atlantic Meridional Overturning Circulation. This current brings warm water north and helps keep northern Europe warm. So, when iit shut down, northern Europe was plunged into a deep freeze.</p>
<p>Right now global warming is causing ice sheets in Greenland to melt and release fresh water into the North Atlantic.  Could this shut down the Atlantic Meridional Overturning Circulation and make the climate of Northern Europe much colder?  In 2010, Keller and Urban [KU] tackled this question using a simple climate model, historical data, probability theory, and lots of computing power.  Their goal was to understand the spectrum of possible futures compatible with what we know today.</p>
<p>Let us look at some of the ideas underlying their work.</p>
<h3>Box models</h3>
<p>The earth&#8217;s physical behaviour, including the climate is far too complex to simulate from the bottom up using basic physical principles, at least for now.  The most detailed models today can take days to run on very powerful computers.  So to make reasonable predictions on a laptop in a tractable time-frame, geophysical modellers use some tricks.</p>
<p>First, it is possible to split geophysical phenomena into &#8216;boxes&#8217; containing strongly related things.  For example: atmospheric gases, particulate levels and clouds all affect each other strongly; likewise the heat content, currents and salinity of the oceans all interact strongly. However, the interactions <i>between</i> the atmosphere and the oceans are weaker, and we can approximately describe them using just a few settings, such as the amount of atmospheric CO<sub>2</sub> entering or leaving the oceans. Clearly these interactions must be consistent&#8212;for example, the amount of CO<sub>2</sub> leaving the atmosphere box must equal the amount entering the ocean box&#8212;but breaking a complicated system into parts lets different specialists focus on different aspects; then we can combine these parts and get an approximate model of entire planet. The box model used by Keller and Urban is shown in Figure 1.</p>
<div align="center">
<a href="http://math.ucr.edu/home/baez/horizons/fig1.jpg"><br />
<img width="450" src="https://i0.wp.com/math.ucr.edu/home/baez/horizons/fig1.jpg" /></a><br />
1.  The box model used by Keller and Urban.
</div>
<p>&nbsp;<br />
Second, it turn out that simple but effective box models can be distilled from the complicated physics in terms of forcings and feedbacks. Essentially a <b>forcing</b> is a measured input to the system, such as solar radiation or CO<sub>2</sub> released by burning fossil fuels. As an analogy, consider a child on a swing: the adult&#8217;s push every so often is a forcing. Similarly a <b>feedback</b> describes how the current &#8216;box variables&#8217; influence future ones. In the swing analogy, one feedback is how the velocity will influence the future height. Specifying feedbacks typically uses knowledge of the detailed low-level physics to derive simple, tractable functional relationships between groups of large-scale observables, a bit like how we derive the physics of a gas by thinking about collisions of lots of particles.</p>
<p>However, it is often not feasible to get actual settings for the parameters in our model starting from first principles.  In other words, often we can get the general form of the equations in our model, but they contain a lot of constants that we can estimate only by looking at historical data.</p>
<h3>Probability modeling</h3>
<p>Suppose we have a box model that depends on some settings <img src="https://s0.wp.com/latex.php?latex=S.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S." class="latex" /> For example, in Keller and Urban&#8217;s model, <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> is a list of 18 numbers.  To keep things simple, suppose the settings are element of some finite set.  Suppose we also have huge hard disc full of historical measurements, and we want to use this to find the best estimate of <img src="https://s0.wp.com/latex.php?latex=S.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S." class="latex" />  Because our data is full of &#8216;noise&#8217; from other, unmodeled phenomena we generally cannot unambiguously deduce a single set of settings.  Instead we have to look at things in terms of probabilities. More precisely, we need to study the probability that <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> take some value <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> given that the measurements take some value.  Let&#8217;s call the measurements <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M" class="latex" />, and again let&#8217;s keep things simple by saying <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M" class="latex" /> takes values in some finite set of possible measurements.</p>
<p>The probability that <img src="https://s0.wp.com/latex.php?latex=S+%3D+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = s" class="latex" /> given that <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M" class="latex" /> takes some value <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m" class="latex" /> is called the <b>conditional probability</b> <img src="https://s0.wp.com/latex.php?latex=P%28S%3Ds+%7C+M%3Dm%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S=s | M=m)." class="latex" />  How can we compute this conditional probability?  This is a somewhat tricky problem.</p>
<p>One thing we can more easily do is repeatedly run our model with randomly chosen settings and see what measurements it predicts.  By doing this, we can compute the probability that given setting values <img src="https://s0.wp.com/latex.php?latex=S+%3D+s%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = s," class="latex" /> the model predicts measurements <img src="https://s0.wp.com/latex.php?latex=M%3Dm.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M=m." class="latex" />  This again is a conditional probability, but now it is called <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm%7CS%3Ds%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m|S=s)." class="latex" /></p>
<p>This is <i>not</i> what we want: it&#8217;s backwards!   But here <b>Bayes&#8217; rule</b> comes to the rescue, relating what we want to what we can more easily compute:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28S+%3D+s+%7C+M+%3D+m%29+%3D+P%28M+%3D+m%7C+S+%3D+s%29+%5Cfrac%7BP%28S+%3D+s%29%7D%7BP%28M+%3D+m%29%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(S = s | M = m) = P(M = m| S = s) &#92;frac{P(S = s)}{P(M = m)} } " class="latex" /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s)" class="latex" /> is the probability that the settings take a specific value <img src="https://s0.wp.com/latex.php?latex=s%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s," class="latex" /> and similarly for <img src="https://s0.wp.com/latex.php?latex=P%28M+%3D+m%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M = m)." class="latex" />  Bayes&#8217; rule is quite easy to prove, and it is actually a general rule that applies to any random  variables, not just the settings and the measurements in our problem [Y].  It underpins most methods of figuring out hidden quantities from observed ones. For this reason, it is widely used in modern statistics and data analysis [K].</p>
<p>How does Bayes&#8217; rule help us here?  When we repeatedly run our model with randomly chosen settings, we have control over <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s)." class="latex" />  As mentioned, we can compute <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm%7C+S%3Ds%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m| S=s)." class="latex" />  Finally, <img src="https://s0.wp.com/latex.php?latex=P%28M+%3D+m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M = m)" class="latex" /> is independent of our choice of settings.  So, we can use Bayes&#8217; rule to compute <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s+%7C+M+%3D+m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s | M = m)" class="latex" /> up to a constant factor.  And since probabilities must sum to 1, we can figure out this constant.</p>
<p>This lets us do many things.  It lets us find the most likely values of the settings for our model, given our hard disc full of observed data.  It also lets us find the probability that the settings lie within some set.  This is important: if we&#8217;re facing the possibility of a climate disaster, we don&#8217;t just want to know the most likely outcome.  We would like to know to know that with 95% probability, the outcome will lie in some range.</p>
<h3>An example</h3>
<p>Let us look at an example much simpler than that considered by Keller and Urban.   Suppose our measurements are real numbers <img src="https://s0.wp.com/latex.php?latex=m_0%2C%5Cdots%2C+m_T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m_0,&#92;dots, m_T" class="latex" /> related by</p>
<p><img src="https://s0.wp.com/latex.php?latex=m_%7Bt%2B1%7D+%3D+s+m_t+-+m_%7Bt-1%7D+%2B+N_t+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m_{t+1} = s m_t - m_{t-1} + N_t " class="latex" /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=s%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s," class="latex" /> a real constant, is our &#8216;setting&#8217;, while <img src="https://s0.wp.com/latex.php?latex=N_t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N_t" class="latex" /> is some &#8216;noise&#8217;: an independent Gaussian random variable for each time <img src="https://s0.wp.com/latex.php?latex=t%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t," class="latex" /> each with mean zero and some fixed standard  deviation.  Then the measurements <img src="https://s0.wp.com/latex.php?latex=m_t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m_t" class="latex" /> will have roughly sinusoidal behavior but with irregularity added by the noise at each time step, as illustrated in Figure 2.  </p>
<div align="center">
<a href="http://math.ucr.edu/home/baez/horizons/fig2.jpg"><br />
<img width="450" src="https://i1.wp.com/math.ucr.edu/home/baez/horizons/fig2.jpg" /></a><br />
2.  The example system: red are predicted measurements for a given value of the settings, green is another simulation for the same <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> value and blue is a simulation for a slightly different <img src="https://s0.wp.com/latex.php?latex=s.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s." class="latex" />
</div>
<p>&nbsp;<br />
Note how there is  no clear signal from either the curves or the differences that the green curve is at the correct setting value while the blue one has the wrong one: the noise makes it nontrivial to estimate <img src="https://s0.wp.com/latex.php?latex=s.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s." class="latex" />   This is a baby version of the problem faced by Keller and Urban.</p>
<h3>Markov Chain Monte Carlo</h3>
<p>Having glibly said that we can compute the conditional probability <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm+%7C+S%3Ds%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m | S=s)," class="latex" /> how do we actually do this?  The simplest way would be to run our model many, many times with the settings set at <img src="https://s0.wp.com/latex.php?latex=S%3Ds&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S=s" class="latex" /> and determine the fraction of times it predicts measurements equal to <img src="https://s0.wp.com/latex.php?latex=m.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m." class="latex" />  This gives us an estimate of <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm+%7C+S%3Ds%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m | S=s)." class="latex" />  Then we can use Bayes&#8217; rule to work out <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm%7CS%3Ds%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m|S=s)," class="latex" /> at least up to a constant factor.</p>
<p>Doing all this by hand would be incredibly time consuming and error prone, so computers are used for this task.  In our example, we do this in Figure 3.  As we keep running our model over and over, the curve showing <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm+%7CS%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m |S=s)" class="latex" /> as a function of <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> settles down to the right answer.</p>
<div align="center">
<a href="http://math.ucr.edu/home/baez/horizons/fig3.jpg"><br />
<img width="450" src="https://i1.wp.com/math.ucr.edu/home/baez/horizons/fig3.jpg" /></a></p>
<p>3.  The estimates of <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm+%7C+S%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m | S=s)" class="latex" /> as a function of <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> using uniform sampling, ending up with 480 samples at each point.
</div>
<p>&nbsp;</p>
<p>However, this is computationally inefficient, as shown in the probability distribution for small numbers of samples.  This has quite a few &#8216;kinks&#8217;, which only disappear later.  The problem is that there are lots of possible choices of <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> to try.  And this is for a very simple model!</p>
<p>When dealing with the 18 settings involved in the model of Keller and Urban, trying every combination would take far too long. A way to avoid this is <b>Markov Chain Monte Carlo</b> sampling.  Monte Carlo is famous for its casinos, so a &#8216;Monte Carlo&#8217; algorithm is one that uses randomness.  A &#8216;Markov chain&#8217; is a random walk: for example, where you repeatedly flip a coin and take one step right when you get heads, and one step right when you get tails.  So, in Markov Chain Monte Carlo, we perform a random walk through the collection of all possible settings, collecting samples.</p>
<p>The key to making this work is that at each step on the walk a proposed modification <img src="https://s0.wp.com/latex.php?latex=s%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s&#039;" class="latex" /> to the current settings <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> is generated randomly&#8212;but it may be rejected if it does not seem to improve the estimates. The essence of the rule is:</p>
<blockquote><p>
The modification <img src="https://s0.wp.com/latex.php?latex=s+%5Cmapsto+s%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s &#92;mapsto s&#039;" class="latex" /> is randomly accepted with a probability equal to the ratio</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7BP%28M%3Dm+%7C+S%3Ds%27%29%7D%7B+P%28M%3Dm+%7C+S%3Ds%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{P(M=m | S=s&#039;)}{ P(M=m | S=s)} }" class="latex" /></p>
<p>Otherwise the walk stays at the current position.
</p></blockquote>
<p>If the modification is better, so that the ratio is greater than 1, the new state is always accepted.  With some additional tricks&#8212;such as discarding the very beginning of the walk&#8212;this gives a set of samples from which can be used to compute <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm+%7C+S%3Ds%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m | S=s)." class="latex" />  Then we can compute <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s+%7C+M+%3D+m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s | M = m)" class="latex" /> using Bayes&#8217; rule.</p>
<p>Figure 4 shows the results of using the Markov Chain Monte Carlo procedure to figure out <img src="https://s0.wp.com/latex.php?latex=P%28S%3D+s%7C+M%3D+m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S= s| M= m)" class="latex" /> in our example.</p>
<div align="center">
<a href="http://math.ucr.edu/home/baez/horizons/fig4.jpg"><br />
<img src="https://i1.wp.com/math.ucr.edu/home/baez/horizons/fig4.jpg" /></a></p>
<p>4.  The estimates of <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s%7CM+%3D+m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s|M = m)" class="latex" /> curves using Markov Chain Monte Carlo, showing the current distribution estimate at increasing intervals. The red line shows the current position of the random   walk. Again the kinks are almost gone in the final distribution.
</div>
<p>&nbsp;</p>
<p>Note that the final distribution has only peformed about 66 thousand simulations <i>in total</i>, while the full sampling peformed over 1.5 million. The key advantage of Markov Chain Monte Carlo is that it avoids performing many simulations in areas where the probability is low, as we can see from the way the walk path remains under the big peak in the probability density almost all the time. What is more impressive is that it achieves this without any <i>global view</i> of the probability density, just by looking at how <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm+%7C+S%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m | S=s)" class="latex" /> changes when we make small changes in the settings.  This becomes even more important as we move to dealing with systems with many more dimensions and settings, where it proves very effective at finding regions of high probability density whatever their shape.</p>
<p>Why is it worth doing so much work to estimate the probability distribution for settings for a climate model?  One reason is that we can then estimate probabilities of <i>future</i> events, such as the collapse of the Atlantic Meridional Ocean Current.  And what&#8217;s the answer? According to Keller and Urban&#8217;s calculation, this current will likely weaken by about a fifth in the 21st century, but a complete collapse is unlikely before 2300.  This claim needs to be checked in many ways&#8212;for example, using more detailed models.  But the importance of the issue is clear, and we hope we have made the importance of good mathematical ideas for climate science clear as well.</p>
<h3>Exploring the topic</h3>
<p>The Azimuth Project is a group of scientists, engineers and computer programmers interested in questions like this [A].  If you have questions, or want to help out, just email us.  Versions of the computer programs we used in this paper will be made available here in a while.</p>
<p>Here are some projects you can try, perhaps with the help of Kruschke&#8217;s textbook [K]:</p>
<p>&bull; There are other ways to do setting estimation using time series: compare some to MCMC in terms of accuracy and robustness.</p>
<p>&bull; We&#8217;ve seen a 1-dimensional system with one setting. Simulate some multi-dimensional and multi-setting systems. What new issues arise?</p>
<p><b>Acknowledgements.</b> We thank Nathan Urban and other<br />
members of the Azimuth Project for many helpful discussions.</p>
<h3> References </h3>
<p>[A] Azimuth Project, <a href="http://www.azimuthproject.org"></a><a href="http://www.azimuthproject.org" rel="nofollow">http://www.azimuthproject.org</a>.</p>
<p>[KU] Klaus Keller and Nathan Urban, Probabilistic hindcasts and projections of the coupled climate, carbon cycle and Atlantic meridional overturning circulation system: a Bayesian fusion of century-scale measurements with a simple model, <i>Tellus A</i> <b>62</b> (2010), 737&#8211;750.  Also available <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.140.9169">free online</a>.</p>
<p>[K] John K. Kruschke, <i>Doing Bayesian Data Analysis: A Tutorial with R and BUGS</i>, Academic Press, New York, 2010.</p>
<p>[Y] Eliezer S. Yudkowsky, <a href="http://yudkowsky.net/rational/bayes">An intuitive explanation of Bayes&#8217; theorem</a>.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comments">21 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/climate/" rel="category tag">climate</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/oceans/" rel="category tag">oceans</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/" rel="bookmark" title="Permanent Link to Monte Carlo Methods in Climate&nbsp;Science">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-16495 post type-post status-publish format-standard hentry category-mathematics category-probability" id="post-16495">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/07/19/negative-probabilities/" rel="bookmark">Negative Probabilities</a></h2>
				<small>19 July, 2013</small><br />


				<div class="entry">
					<p> </p>
<div align="center">
<img src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/negative_thinking.jpg" /></div>
<p>The physicists Dirac and Feynman, both bold when it came to new mathematical ideas, both said we should think about negative probabilities.</p>
<p>These days, <a href="http://en.wikipedia.org/wiki/Probability_axioms">Kolmogorov&#8217;s axioms for probabilities</a> are used to justify formulating probability theory in terms of measure theory. Mathematically, the theory of measures that take <a href="http://en.wikipedia.org/wiki/Signed_measure">negative</a> or even <a href="https://en.wikipedia.org/wiki/Complex_measure">complex</a> values is well-developed. So, to the extent that probability theory is just measure theory, you can say a lot is known about negative probabilities.</p>
<p>But probability theory is <i>not</i> just measure theory; it adds its own distinctive ideas.  To get these into the picture, we really need to ask some basic questions, like: what could it mean to say something had a negative chance of happening?</p>
<p>I really have no idea.</p>
<p>In this paper:</p>
<p>• Paul Dirac, The physical interpretation of quantum mechanics, <i>Proc. Roy. Soc. London A</i> <b>180</b> (1942), 1–39.</p>
<p>Dirac wrote:</p>
<blockquote><p>
Negative energies and probabilities should not be considered as nonsense. They are well-defined concepts mathematically, like a negative of money.
</p></blockquote>
<p>In fact, I think negative money could have been the origin of negative numbers.   Venetian bankers started writing numbers in red to symbolize debts&#8212;hence the phrase &#8216;in the red&#8217; for being in debt.   So, you could say negative numbers were invented to formalize the idea of debt and make accounting easier.  Bankers couldn&#8217;t really get rich if negative money didn&#8217;t exist.</p>
<p>A negative dollar is a dollar you owe someone.  But how can you owe someone a probability?﻿  I haven&#8217;t figured this out.</p>
<p>Unsurprisingly, the clearest writing about negative probabilities that I&#8217;ve found is by Feynman:</p>
<p>• Richard P. Feynman, <a href="http://cds.cern.ch/record/154856/files/pre-27827.pdf">Negative probability</a>, in <i>Quantum Implications: Essays in Honour of David Bohm</i>, eds. F. David Peat and Basil Hiley, Routledge &amp; Kegan Paul Ltd, London, 1987, pp. 235&ndash;248.</p>
<p>He emphasizes that even if the final answer of a calculation must be positive, negative numbers are often allowed to appear in intermediate steps&#8230; and that this can happen with probabilities.</p>
<p>Let me quote some:</p>
<blockquote><p>
Some twenty years ago one problem we theoretical physicists had was that if we combined the principles of quantum mechanics and those of relativity plus certain tacit assumptions, we seemed only able to produce theories (the quantum field theories) which gave infinity for the answer to certain questions. These infinities are kept in abeyance (and now possibly eliminated altogether) by the awkward process of renormalization. In an attempt to understand all this better, and perhaps to make a theory which would give only finite answers from the start, I looked into the&#8221; tacit assumptions&#8221; to see if they could be altered.</p>
<p>One of the assumptions was that the probability for an event must always be a positive number. Trying to think of negative probabilities gave me cultural shock at first, but when I finally got easy with the concept I wrote myself a note so I wouldn&#8217;t forget my thoughts. I think that Prof. Bohm has just the combination of imagination and boldness to find them interesting and amusing. I am delighted to have this opportunity to publish them in such an appropriate place. I have taken the opportunity to add some further, more recent, thoughts about applications to two state systems.</p>
<p>Unfortunately I never did find out how to use the freedom of allowing probabilities to be negative to solve the original problem of infinities in quantum field theory!</p>
<hr />
<p>It is usual to suppose that, since the probabilities of events must be positive, a theory which gives negative numbers for such quantities must be absurd. I should show here how negative probabilities might be interpreted. A negative number, say of apples, seems like an absurdity. A man starting a day with five apples who gives away ten and is given eight during the day has three left. I can calculate this in two steps: 5 -10 = -5 and -5 + 8 + 3.  The final answer is satisfactorily positive and correct although in the intermediate steps of calculation negative numbers appear. In the real situation there must be special limitations of the time in which the various apples are received and given since he never really has a negative number, yet the use of negative numbers as an abstract calculation permits us freedom to do our mathematical calculations in any order simplifying the analysis enormously, and permitting us to disregard inessential details. The idea of negative numbers is an exceedingly fruitful mathematical invention. Today a person who balks at making a calculation in this way is considered backward or ignorant, or to have some kind of a mental block. It is the purpose of this paper to point out that we have a similar strong block against negative probabilities. By discussing a number of examples, I hope to show that they are entirely rational of course, and that their use simplifies calculation and thought in a number of applications in physics.</p>
<p>First let us consider a simple probability problem, and how we usually calculate things and then see what would happen if we allowed some of our normal probabilities in the calculations to be negative. Let us imagine a roulette wheel with, for simplicity, just three numbers: 1, 2, 3.  Suppose however, the operator by control of a switch under the table can put the wheel into one of two conditions A, B in each of which the probability of 1, 2, 3 are different. If the wheel is in condition A, the probability of 1 is p<sub>1A</sub> = 0.3 say, of 2 is p<sub>2A</sub> = 0.6, of 3 is p<sub>3A</sub> =0.1. But if the wheel is in condition B, these probabilities are </p>
<div align="center">
p<sub>1B</sub> = 0.1, p<sub>2B</sub> = 0.4, p<sub>3B</sub> = 0.5
</div>
<p>say as in the table. </p>
<div align="center">
<table border="1">
<tr>
<td>       </td>
<td>Cond. A     </td>
<td>Cond. B</td>
</tr>
<tr>
<td>1</td>
<td>0.3</td>
<td>0.1</td>
</tr>
<tr>
<td>2</td>
<td>0.6</td>
<td>0.4</td>
</tr>
<td>3</td>
<td>0.1</td>
<td>0.5</td>
</table>
</div>
<p>We, of course, use the table in this way: suppose the operator puts the wheel into condition A 7/10 of the time and into B the other 3/10 of the time at random.  (That is the probability of condition A, p<sub>A</sub> = 0.7, and of B, p<sub>B</sub> = 0.3.)   Then the probability of getting 1 is </p>
<div align="center">
Prob. 1 = 0.7 (0.3) + 0.3 (0.1) = 0.24,
</div>
<p>etc. </p>
<p>[&#8230;]</p>
<p>Now, however, suppose that some of the conditional probabilities are negative, suppose the table reads so that, as we shall say, if the system is in condition B the probability of getting 1 is -0.4. This sounds absurd but we must say it this way if we wish that our way of thought and language be precisely the same whether the actual quantities p<sub>i α</sub> in our calculations are positive or negative. That is the essence of the mathematical use of negative numbers&#8212;to permit an efficiency in reasoning so that various cases can be considered together by the same line of reasoning, being assured that intermediary steps which are not readily interpreted (like -5 apples) will not lead to absurd results. Let us see what p<sub>1B</sub> = -0.4 &#8220;means&#8221; by seeing how we calculate with it.
</p></blockquote>
<p>He gives an example showing how meaningful end results can sometimes arise even if the conditional probabilities like p<sub>1B</sub> are negative or greater than 1.</p>
<blockquote><p>
It is not my intention here to contend that the final probability of a verifiable physical event can be negative. On the other hand, conditional probabilities and probabilities of imagined intermediary states may be negative in a calculation of probabilities of physical events or states. If a physical theory for calculating probabilities yields a negative probability for a given situation under certain assumed conditions, we need not conclude the theory is incorrect. Two other possibilities of interpretation exist. One is that the conditions (for example, initial conditions) may not be capable of being realized in the physical world. The other possibility is that the situation for which the probability appears to be negative is not one that can be verified directly. A combination of these two, limitation of verifiability and freedom in initial conditions, may also be a solution to the apparent difficulty.</p>
<p>The rest of this paper illustrates these points with a number of examples drawn from physics which are less artificial than our roulette wheel. Since the result must ultimately have a positive probability, the question may be asked, why not rearrange the calculation so that the probabilities are positive in all the intermediate states? The same question might be asked of an accountant who subtracts the total disbursements before adding the total receipts. He stands a chance of going through an intermediary negative sum.  Why not rearrange the calculation? Why bother? There is nothing mathematically wrong with this method of calculating and it frees the mind to think clearly and simply in a situation otherwise quite complicated. An analysis in terms of various states or conditions may simplify a calculation at the expense of requiring negative probabilities for these states. It is not really much expense.</p>
<p>Our first physical example is one in which one· usually uses negative probabilities without noticing it. It is not a very profound example and is practically the same in content as our previous example. A particle diffusing in one dimension in a rod has a probability of being at <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> at time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=P%28x%2Ct%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(x,t)" class="latex" /> satisfying </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cpartial+P%28x%2Ct%29%2F%5Cpartial+t+%3D+-%5Cpartial%5E2+P%28x%2Ct%29%2F%5Cpartial+x%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial P(x,t)/&#92;partial t = -&#92;partial^2 P(x,t)/&#92;partial x^2" class="latex" />
</div>
<p>Suppose at <img src="https://s0.wp.com/latex.php?latex=x+%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x =0" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=x+%3D%5Cpi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x =&#92;pi" class="latex" /> the rod has absorbers at both ends so that <img src="https://s0.wp.com/latex.php?latex=P%28x%2Ct%29+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(x,t) = 0" class="latex" /> there. Let the probability of being at <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> at <img src="https://s0.wp.com/latex.php?latex=t+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t = 0" class="latex" /> be given as <img src="https://s0.wp.com/latex.php?latex=P%28x%2C0%29+%3Df%28x%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(x,0) =f(x)." class="latex" /> What is <img src="https://s0.wp.com/latex.php?latex=P%28x%2Ct%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(x,t)" class="latex" /> thereafter? It is</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28x%2Ct%29+%3D+%5Csum_%7Bn%3D1%7D%5E%5Cinfty+P_n+%5C%3B+%5Csin+x+%5C%3B%5Cexp%28-n%5E2+t%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(x,t) = &#92;sum_{n=1}^&#92;infty P_n &#92;; &#92;sin x &#92;;&#92;exp(-n^2 t) } " class="latex" />
</div>
<p>where <img src="https://s0.wp.com/latex.php?latex=P_n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P_n" class="latex" /> is given by</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=x+%5Cdisplaystyle%7B++f%28x%29+%3D+%5Csum_%7Bn+%3D+1%7D%5E%5Cinfty+P_n+%5C%3B+%5Csin+n+x+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &#92;displaystyle{  f(x) = &#92;sum_{n = 1}^&#92;infty P_n &#92;; &#92;sin n x } " class="latex" />
</div>
<p>or</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=x+%5Cdisplaystyle%7B+P_n+%3D+%5Cfrac%7B2%7D%7B%5Cpi%7D+%5Cint_0%5E%5Cpi+f%28x%29+%5Csin+nx++%5C%3B+dx+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &#92;displaystyle{ P_n = &#92;frac{2}{&#92;pi} &#92;int_0^&#92;pi f(x) &#92;sin nx  &#92;; dx }" class="latex" />
</div>
<p>The easiest way of analyzing this (and the way used if <img src="https://s0.wp.com/latex.php?latex=P%28x%2Ct%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(x,t)" class="latex" /> is a temperature, for example) is to say that there are certain distributions that behave in an especially simple way. If <img src="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(x)" class="latex" /> starts as <img src="https://s0.wp.com/latex.php?latex=%5Csin+nx&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sin nx" class="latex" /> it will remain that shape, simply decreasing with time, as <img src="https://s0.wp.com/latex.php?latex=e%5E%7B-n%5E2+t%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="e^{-n^2 t}" class="latex" /> Any distribution <img src="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(x)" class="latex" /> can be thought of as a superposition of such sine waves. But <img src="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(x)" class="latex" /> cannot be <img src="https://s0.wp.com/latex.php?latex=%5Csin+nx&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sin nx" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(x)" class="latex" /> is a probability and probabilities must always be positive. Yet the analysis is so simple this way that no one has really objected for long.</p>
</blockquote>
<p>He also gives examples from quantum mechanics, but the interesting thing about the examples above is that they&#8217;re purely classical&#8212;and the second one, at least, is something physicists are quite used to.</p>
<p>Sometimes it&#8217;s good to temporarily put aside making sense of ideas and just see if you can develop rules to consistently work with them.  For example: the square root of -1.  People had to get good at using it before they understood what it really was: a rotation by a quarter turn in the plane.</p>
<p>Along those, lines, here&#8217;s an interesting attempt to work with negative probabilities:</p>
<p>• Gábor J. Székely, <a href="http://www.wilmott.com/pdfs/100609_gjs.pdf">Half of a coin: negative probabilities</a>, <i>Wilmott Magazine</i> (July 2005), 66–68.</p>
<p>He uses rigorous mathematics to study something that sounds absurd: &#8216;half a coin&#8217;.  Suppose you make a bet with an ordinary fair coin, where you get 1 dollar if it comes up heads and 0 dollars if it comes up tails.  Next, suppose you want this bet to be the same as making two bets involving two separate &#8216;half coins&#8217;.  Then you can do it <i>if</i> a half coin has infinitely many sides numbered 0,1,2,3, etc., and you win <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> dollars when side number <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> comes up&#8230;.</p>
<p>&#8230; and <i>if</i> the probability of side <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> coming up obeys a special formula&#8230;</p>
<p>and <i>if</i> this probability can be negative sometimes!</p>
<p>This seems very bizarre, but the math is solid, even if the problem of interpreting it may drive you insane.</p>
<p>Let&#8217;s see how it works.  Consider a game <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G" class="latex" /> where the probability of winning <img src="https://s0.wp.com/latex.php?latex=n+%3D+0%2C+1%2C+2%2C+%5Cdots&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n = 0, 1, 2, &#92;dots" class="latex" /> dollars is <img src="https://s0.wp.com/latex.php?latex=g%28n%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="g(n)." class="latex" />  Then we can summarize this game using a <b>generating function</b>:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+G%28z%29+%3D+%5Csum_%7Bn+%3D+0%7D%5E%5Cinfty+g%28n%29+%2C+z%5En+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ G(z) = &#92;sum_{n = 0}^&#92;infty g(n) , z^n }" class="latex" />
</div>
<p>Now suppose you play two independent games like this, <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G" class="latex" /> and another one, say <img src="https://s0.wp.com/latex.php?latex=H%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H," class="latex" /> with generating function</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+H%28z%29+%3D+%5Csum_%7Bn+%3D+0%7D%5E%5Cinfty+h%28n%29+%2C+z%5En+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ H(z) = &#92;sum_{n = 0}^&#92;infty h(n) , z^n }" class="latex" />
</div>
<p>Then there&#8217;s a new game <img src="https://s0.wp.com/latex.php?latex=GH&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="GH" class="latex" /> that consists of playing both games.  The reason I&#8217;m writing it as <img src="https://s0.wp.com/latex.php?latex=GH&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="GH" class="latex" /> is that its generating function is the product</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+G%28z%29+H%28z%29+%3D+%5Csum_%7Bm%2Cn+%3D+0%7D%5E%5Cinfty+g%28m%29+h%28n%29+z%5E%7Bm%2Bn%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ G(z) H(z) = &#92;sum_{m,n = 0}^&#92;infty g(m) h(n) z^{m+n} }" class="latex" />
</div>
<p>See why?  With probability <img src="https://s0.wp.com/latex.php?latex=g%28m%29+h%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="g(m) h(n)" class="latex" /> you win <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m" class="latex" /> dollars in game <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> dollars in game <img src="https://s0.wp.com/latex.php?latex=H%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H," class="latex" /> for a total of <img src="https://s0.wp.com/latex.php?latex=m+%2B+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m + n" class="latex" /> dollars.</p>
<p>The game where you flip a fair coin and win 1 dollar if it lands heads up and 0 dollars if lands tails up has generating function</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+G%28z%29+%3D+%5Cfrac%7B1%7D%7B2%7D%281+%2B+z%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ G(z) = &#92;frac{1}{2}(1 + z) }" class="latex" />
</div>
<p>The <b>half-coin</b> is an imaginary game <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> such that playing two copies of this game is the same as playing the game <img src="https://s0.wp.com/latex.php?latex=G.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G." class="latex" />  If such a game really existed, we would have</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=G%28z%29+%3D+H%28z%29%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G(z) = H(z)^2" class="latex" />
</div>
<p>so</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+H%28z%29+%3D+%5Csqrt%7B%5Cfrac%7B1%7D%7B2%7D%281+%2B+z%29%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ H(z) = &#92;sqrt{&#92;frac{1}{2}(1 + z)} } " class="latex" />
</div>
<p>However, if you work out the Taylor series of this function, every even term is negative except for the zeroth term.  So, this game can exist only if we allow negative probabilities.</p>
<p>(Experts on generating functions and combinatorics will enjoy how the coefficients of the Taylor series of <img src="https://s0.wp.com/latex.php?latex=H%28z%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H(z)" class="latex" /> involves the <a href="http://en.wikipedia.org/wiki/Catalan_number">Catalan numbers</a>.)</p>
<p>By the way, it&#8217;s worth remembering that for a long time mathematicians believed that negative numbers made no sense.  As late as 1758 the British mathematician Francis Maseres claimed that negative numbers</p>
<blockquote><p>
&#8230; darken the very whole doctrines of the equations and make dark of the things which are in their nature excessively obvious and simple.</p></blockquote>
<p>So opinions on these things can change.  And since I&#8217;ve spent a lot of time working on &#8216;sets with fractional cardinality&#8217;, and have made lots of progress on that idea, and other strange ideas, I like to spend a little time now and then investigating other nonsensical-sounding generalizations of familiar concepts.﻿</p>
<p>This paper by Mark Burgin has a nice collection of references on negative probability:</p>
<p>• Mark Burgin, <a href="http://arxiv.org/abs/1008.1287">Interpretations of negative probability</a>.</p>
<p>He valiantly tries to provide a frequentist interpretation of negative probabilities.  He needs &#8216;negative events&#8217; to get negative frequencies of events occurring, and he gives this example:</p>
<blockquote><p>
To better understand how negative elementary events appear and how negative probability emerges, consider the following example.  Let us consider the situation when an attentive person A with the high knowledge of English writes some text T. We may ask what the probability is for the word “texxt” or “wrod” to appear in his text T. Conventional probability theory gives 0 as the answer. However, we all know that there are usually misprints. So, due to such a misprint this word may appear but then it would be corrected. In terms of extended probability, a negative value (say, -0.1) of the probability for the word “texxt” to appear in his text T means that this word may appear due to a misprint but then it’ll be corrected and will not be present in the text T.
</p></blockquote>
<p>Maybe he&#8217;s saying that the misprint occurs with probability 0.1 and then it &#8216;de-occurs&#8217; with the same probability, giving a total probability of</p>
<p><img src="https://s0.wp.com/latex.php?latex=0.1+-+0.1+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0.1 - 0.1 = 0" class="latex" /></p>
<p>I&#8217;m not sure.</p>
<p>Here&#8217;s another paper on the subject:</p>
<p>•  Espen Gaarder Haug, <a href="http://www.espenhaug.com/NegativeProbabilitiesHaug.pdf">Why so negative to negative probabilities?</a>, <i>Wilmott Magazine</i>.</p>
<p>It certainly gets points for a nice title!  However, like Burgin&#8217;s paper, I find it a lot less clear than what Feynman wrote.</p>
<p>Notice that like Székely&#8217;s paper, Haug&#8217;s originally appeared in the <i>Wilmott Magazine</i>.  I hadn&#8217;t heard of that, but it&#8217;s about finance.  So it seems that the bankers, having invented negative numbers to get us into debt, are now struggling to invent negative probabilities!   In fact Haug&#8217;s article tries some applications of negative probabilities to finance.</p>
<p>Scary.</p>
<p>For further discussion, with some nice remarks by the quantum physics experts Matt Leifer and Michael Nielsen, see the comments on my <a href="https://plus.google.com/u/0/117663015413546257905/posts/JvK4qCCgQyM">Google+ post</a> on this topic.  Matt Leifer casts cold water on the idea of using negative probabilities in quantum theory. On the other hand, Michael Nielsen points out some interesting features of the <a href="http://en.wikipedia.org/wiki/Wigner_quasiprobability_distribution">Wigner quasiprobability distribution</a>, which is the best possible attempt to assign a probability density for a quantum particle to have any given position and momentum.  It can be negative!  But if you integrate it over all momenta, you get the probability density for the particle having any given position:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%28x%29%7C%5E2+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi(x)|^2 " class="latex" /></p>
<p>And if you integrate it over all positions, you get the probability density for the particle having any given momentum:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Cwidehat%7B%5Cpsi%7D%28p%29%7C%5E2+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;widehat{&#92;psi}(p)|^2 " class="latex" /></p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/07/19/negative-probabilities/#comments">51 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/07/19/negative-probabilities/" rel="bookmark" title="Permanent Link to Negative Probabilities">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-16438 post type-post status-publish format-standard hentry category-chemistry category-mathematics category-physics category-probability" id="post-16438">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/07/10/coherence-for-solutions-of-the-master-equation/" rel="bookmark">Coherence for Solutions of the Master&nbsp;Equation</a></h2>
				<small>10 July, 2013</small><br />


				<div class="entry">
					<p><i>guest post by <b><a href="http://arjunjainblog.wordpress.com/about/">Arjun Jain</a></b></i></p>
<p>I am a master&#8217;s student in the physics department of the Indian Institute of Technology Roorkee.  I&#8217;m originally from Delhi. Since some time now, I&#8217;ve been wanting to go into Mathematical Physics.  I hope to do a PhD in that. Apart from maths and physics, I am also quite passionate about art and music.  </p>
<p>Right now I am visiting John Baez at the Centre for Quantum Technologies, and we&#8217;re working on chemical reaction networks.  This post can be considered as an annotation to the last paragraph of John&#8217;s paper, <a href="http://arxiv.org/abs/1306.3451">Quantum Techniques for Reaction Networks</a>, where he raises the question of when a solution to the master equation that starts as a coherent state will remain coherent for all times.   Remember, the &#8216;master equation&#8217; describes the random evolution of collections of classical particles, and a &#8216;coherent state&#8217; is one where the probability distribution of particles of each type is a Poisson distribution.</p>
<p>If you&#8217;ve been following the <a href="http://math.ucr.edu/home/baez/networks/">network theory series</a> on this blog, you&#8217;ll know these concepts, and you&#8217;ll know the Anderson-Craciun-Kurtz theorem gives many examples of coherent states that remain coherent.  However, all these are <i>equilibrium</i> solutions of the master equation: they don&#8217;t change with time.  Moreover they are <i>complex balanced</i> equilibria: the rate at which any complex is produced equals the rate at which it is consumed.</p>
<p>There are also non-equilibrium examples where coherent states remain coherent.  But they seem rather rare, and I would like to explain why.  So, I will give a necessary condition for it to happen.  I&#8217;ll give the proof first, and then discuss some simple examples.  We will see that while the condition is necessary, it is not sufficient.</p>
<p>First, recall the setup.  If you&#8217;ve been following the <a href="http://math.ucr.edu/home/baez/networks/">network theory</a> series, you can skip the next section.</p>
<h3> Reaction networks </h3>
<p><b>Definition.</b>  A <b>reaction network</b> consists of:</p>
<p>&bull; a finite set <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> of <b>species</b>,</p>
<p>&bull; a finite set <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="K" class="latex" /> of complexes, where a <b>complex</b> is a finite sum of species, or in other words, an element of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BN%7D%5ES%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{N}^S," class="latex" /> </p>
<p>&bull; a graph with <img src="https://s0.wp.com/latex.php?latex=K&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="K" class="latex" /> as its set of vertices and some set <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" /> of edges.  </p>
<p>You should have in mind something like this:</p>
<div align="center">
<img width="200" src="https://i1.wp.com/math.ucr.edu/home/baez/networks/chemical_reaction_network_part_17_II.png" />
</div>
<p>where our set of species is <img src="https://s0.wp.com/latex.php?latex=S+%3D+%5C%7BA%2CB%2CC%2CD%2CE%5C%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = &#92;{A,B,C,D,E&#92;}," class="latex" /> the complexes are things like <img src="https://s0.wp.com/latex.php?latex=A+%2B+E%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A + E," class="latex" /> and the arrows are the elements of <img src="https://s0.wp.com/latex.php?latex=T%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T," class="latex" /> called <b>transitions</b> or <b>reactions</b>.  So, we have functions </p>
<p><img src="https://s0.wp.com/latex.php?latex=s+%2C+t+%3A+T+%5Cto+K+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s , t : T &#92;to K " class="latex" /> </p>
<p>saying the <b>source</b> and <b>target</b> of each transition.</p>
<p>Next:</p>
<p><b>Definition.</b> A <b>stochastic reaction network</b> is a reaction network together with a function <img src="https://s0.wp.com/latex.php?latex=r%3A+T+%5Cto+%280%2C%5Cinfty%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r: T &#92;to (0,&#92;infty)" class="latex" /> assigning a <b>rate constant</b> to each reaction.</p>
<p>From this we can write down the <b>master equation</b>, which describes how a stochastic state evolves in time:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%7D%7Bdt%7D+%5CPsi%28t%29+%3D+H+%5CPsi%28t%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d}{dt} &#92;Psi(t) = H &#92;Psi(t) } " class="latex" /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=%5CPsi%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi(t)" class="latex" /> is a vector in the <b>stochastic Fock space</b>, which is the space of formal power series in a bunch of variables, one for each species, and <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> is an operator on this space, called the <b>Hamiltonian</b>.</p>
<p>From now on I&#8217;ll number the species with numbers from <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=k%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k," class="latex" /> so</p>
<p><img src="https://s0.wp.com/latex.php?latex=S+%3D+%5C%7B1%2C+%5Cdots%2C+k%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = &#92;{1, &#92;dots, k&#92;}" class="latex" /></p>
<p>Then the stochastic Fock space consists of real formal power series in variables that I&#8217;ll call <img src="https://s0.wp.com/latex.php?latex=z_1%2C+%5Cdots%2C+z_k.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z_1, &#92;dots, z_k." class="latex" />   We can write any of these power series as</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5CPsi+%3D+%5Csum_%7B%5Cell+%5Cin+%5Cmathbb%7BN%7D%5Ek%7D+%5Cpsi_%5Cell+z%5E%5Cell+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;Psi = &#92;sum_{&#92;ell &#92;in &#92;mathbb{N}^k} &#92;psi_&#92;ell z^&#92;ell }" class="latex" /></p>
<p>where </p>
<p><img src="https://s0.wp.com/latex.php?latex=z%5E%5Cell+%3D+z_1%5E%7B%5Cell_1%7D+%5Ccdots+z_k%5E%7B%5Cell_k%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z^&#92;ell = z_1^{&#92;ell_1} &#92;cdots z_k^{&#92;ell_k}" class="latex" /></p>
<p>We have <b>annihilation</b> and <b>creation</b> operators on the stochastic Fock space:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+a_i+%5CPsi+%3D+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+z_i%7D+%5CPsi+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ a_i &#92;Psi = &#92;frac{&#92;partial}{&#92;partial z_i} &#92;Psi }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+a_i%5E%5Cdagger+%5CPsi+%3D+z_i+%5CPsi+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ a_i^&#92;dagger &#92;Psi = z_i &#92;Psi }" class="latex" /></p>
<p>and the Hamiltonian is built from these as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+H+%3D+%5Csum_%7B%5Ctau+%5Cin+T%7D+r%28%5Ctau%29+%5C%2C+%28%7Ba%5E%5Cdagger%7D%5E%7Bt%28%5Ctau%29%7D+-+%7Ba%5E%5Cdagger%7D%5E%7Bs%28%5Ctau%29%7D%29+%5C%2C+a%5E%7Bs%28%5Ctau%29%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ H = &#92;sum_{&#92;tau &#92;in T} r(&#92;tau) &#92;, ({a^&#92;dagger}^{t(&#92;tau)} - {a^&#92;dagger}^{s(&#92;tau)}) &#92;, a^{s(&#92;tau)} } " class="latex" /></p>
<p>John explained this <a href="http://math.ucr.edu/home/baez/networks/networks_8.html#master_equation">here</a> (using slightly different notation), so I won&#8217;t go into much detail now, but I&#8217;ll say what all the symbols mean.  Remember that the source of a transition <img src="https://s0.wp.com/latex.php?latex=%5Ctau&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;tau" class="latex" /> is a complex, or list of natural numbers:</p>
<p><img src="https://s0.wp.com/latex.php?latex=s%28%5Ctau%29+%3D+%28s_1%28%5Ctau%29%2C+%5Cdots%2C+s_k%28%5Ctau%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s(&#92;tau) = (s_1(&#92;tau), &#92;dots, s_k(&#92;tau))" class="latex" /></p>
<p>So, the power <img src="https://s0.wp.com/latex.php?latex=a%5E%7Bs%28%5Ctau%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a^{s(&#92;tau)}" class="latex" /> is really an abbreviation for a big product of annihilation operators, like this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+a%5E%7Bs%28%5Ctau%29%7D+%3D+a_1%5E%7Bs_1%28%5Ctau%29%7D+%5Ccdots+a_k%5E%7Bs_k%28%5Ctau%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ a^{s(&#92;tau)} = a_1^{s_1(&#92;tau)} &#92;cdots a_k^{s_k(&#92;tau)} }" class="latex" /></p>
<p>This describes the annihilation of all the inputs to the transition <img src="https://s0.wp.com/latex.php?latex=%5Ctau.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;tau." class="latex" />  Similarly, we define</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%7Ba%5E%5Cdagger%7D%5E%7Bs%28%5Ctau%29%7D+%3D+%7Ba_1%5E%5Cdagger%7D%5E%7Bs_1%28%5Ctau%29%7D+%5Ccdots+%7Ba_k%5E%5Cdagger%7D%5E%7Bs_k%28%5Ctau%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ {a^&#92;dagger}^{s(&#92;tau)} = {a_1^&#92;dagger}^{s_1(&#92;tau)} &#92;cdots {a_k^&#92;dagger}^{s_k(&#92;tau)} }" class="latex" /></p>
<p>and</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%7Ba%5E%5Cdagger%7D%5E%7Bt%28%5Ctau%29%7D+%3D+%7Ba_1%5E%5Cdagger%7D%5E%7Bt_1%28%5Ctau%29%7D+%5Ccdots+%7Ba_k%5E%5Cdagger%7D%5E%7Bt_k%28%5Ctau%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ {a^&#92;dagger}^{t(&#92;tau)} = {a_1^&#92;dagger}^{t_1(&#92;tau)} &#92;cdots {a_k^&#92;dagger}^{t_k(&#92;tau)} }" class="latex" /></p>
<h3> The result </h3>
<p>Here&#8217;s the result:</p>
<p><b>Theorem.</b>  If a solution <img src="https://s0.wp.com/latex.php?latex=%5CPsi%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi(t)" class="latex" /> of the master equation is a coherent state for all times <img src="https://s0.wp.com/latex.php?latex=t+%5Cge+0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t &#92;ge 0," class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=%5CPsi%280%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi(0)" class="latex" /> must be complex balanced except for complexes of degree 0 or 1.</p>
<p>This requires some explanation.  </p>
<p>First, saying that <img src="https://s0.wp.com/latex.php?latex=%5CPsi%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi(t)" class="latex" /> is a <b>coherent state</b> means that it is an eigenvector of all the annihilation operators.  Concretely this means</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CPsi+%28t%29+%3D+%5Cdisplaystyle%7B%5Cfrac%7Be%5E%7Bc%28t%29+%5Ccdot+z%7D%7D%7Be%5E%7Bc_1%28t%29+%2B+%5Ccdots+%2B+c_k%28t%29%7D%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi (t) = &#92;displaystyle{&#92;frac{e^{c(t) &#92;cdot z}}{e^{c_1(t) + &#92;cdots + c_k(t)}}}" class="latex" /> </p>
<p>where </p>
<p><img src="https://s0.wp.com/latex.php?latex=c%28t%29+%3D+%28c_1%28t%29%2C+%5Cdots%2C+c_k%28t%29%29+%5Cin+%5B0%2C%5Cinfty%29%5Ek&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c(t) = (c_1(t), &#92;dots, c_k(t)) &#92;in [0,&#92;infty)^k" class="latex" /> </p>
<p>and </p>
<p><img src="https://s0.wp.com/latex.php?latex=z+%3D+%28z_1%2C+%5Cdots%2C+z_k%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z = (z_1, &#92;dots, z_k)" class="latex" /> </p>
<p>It will be helpful to write</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7B1%7D%3D+%281%2C1%2C1%2C...%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbf{1}= (1,1,1,...)" class="latex" /> </p>
<p>so we can write</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CPsi+%28t%29+%3D+%5Cdisplaystyle%7B+e%5E%7Bc%28t%29+%5Ccdot+%28z+-+%5Cmathbf%7B1%7D%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi (t) = &#92;displaystyle{ e^{c(t) &#92;cdot (z - &#92;mathbf{1})} }" class="latex" /> </p>
<p>Second, we say that a complex has <b>degree</b> <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="d" class="latex" /> if it is a sum of exactly <img src="https://s0.wp.com/latex.php?latex=d&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="d" class="latex" /> species.  For example, in this reaction network:</p>
<div align="center">
<img width="200" src="https://i1.wp.com/math.ucr.edu/home/baez/networks/chemical_reaction_network_part_17_II.png" />
</div>
<p>the complexes <img src="https://s0.wp.com/latex.php?latex=A+%2B+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A + C" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B+%2B+E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B + E" class="latex" /> have degree 2, while the rest have degree 1.  We use the word &#8216;degree&#8217; because each complex <img src="https://s0.wp.com/latex.php?latex=%5Cell&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ell" class="latex" /> gives a monomial</p>
<p><img src="https://s0.wp.com/latex.php?latex=z%5E%5Cell+%3D+z_1%5E%7B%5Cell_1%7D+%5Ccdots+z_k%5E%7B%5Cell_k%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z^&#92;ell = z_1^{&#92;ell_1} &#92;cdots z_k^{&#92;ell_k}" class="latex" /></p>
<p>and the degree of the complex is the degree of this monomial, namely</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cell_1+%2B+%5Ccdots+%2B+%5Cell_k+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ell_1 + &#92;cdots + &#92;ell_k " class="latex" /></p>
<p>Third and finally, we say a solution <img src="https://s0.wp.com/latex.php?latex=%5CPsi%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi(t)" class="latex" /> of the master equation is <b>complex balanced</b> for a specific complex <img src="https://s0.wp.com/latex.php?latex=%5Cell&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ell" class="latex" /> if the total rate at which that complex is produced equals the total rate at which it&#8217;s destroyed. </p>
<p>Now we are ready to prove the theorem:</p>
<p><b>Proof.</b>  Consider the master equation</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7B+%5Cfrac%7Bd+%5CPsi+%28t%29%7D%7Bd+t%7D+%3D+H+%5Cpsi+%28t%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle { &#92;frac{d &#92;Psi (t)}{d t} = H &#92;psi (t) }" class="latex" /></p>
<p>Assume that <img src="https://s0.wp.com/latex.php?latex=%5CPsi%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi(t)" class="latex" /> is a coherent state for all <img src="https://s0.wp.com/latex.php?latex=t+%5Cge+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t &#92;ge 0." class="latex" />  This means</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CPsi+%28t%29+%3D+%5Cdisplaystyle%7B+e%5E%7Bc%28t%29+%5Ccdot+%28z+-+%5Cmathbf%7B1%7D%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi (t) = &#92;displaystyle{ e^{c(t) &#92;cdot (z - &#92;mathbf{1})} }" class="latex" /></p>
<p>For convenience, we write <img src="https://s0.wp.com/latex.php?latex=c%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c(t)" class="latex" /> simply as <img src="https://s0.wp.com/latex.php?latex=c%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c," class="latex" /> and similarly for the components <img src="https://s0.wp.com/latex.php?latex=c_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c_i" class="latex" />.   Then we have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%5CPsi%28t%29%7D%7Bdt%7D++%3D+%28%5Cdot%7Bc%7D+%5Ccdot+%28z+-+%5Cmathbf%7B1%7D%29%29+%5C%2C+e%5E%7Bc+%5Ccdot+%28z+-+%5Cmathbf%7B1%7D%29%7D+++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d&#92;Psi(t)}{dt}  = (&#92;dot{c} &#92;cdot (z - &#92;mathbf{1})) &#92;, e^{c &#92;cdot (z - &#92;mathbf{1})}   } " class="latex" /></p>
<p>On the other hand, the master equation gives</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+%5Cdisplaystyle+%7B%5Cfrac%7Bd%5CPsi%28t%29%7D%7Bdt%7D%7D+%26%3D%26++%5Cdisplaystyle%7B+%5Csum_%7B%5Ctau+%5Cin+T%7D+r%28%5Ctau%29+%5C%2C+%28%7Ba%5E%5Cdagger%7D%5E%7Bt%28%5Ctau%29%7D+-+%7Ba%5E%5Cdagger%7D%5E%7Bs%28%5Ctau%29%7D%29+%5C%2C+a%5E%7Bs%28%5Ctau%29%7D+e%5E%7Bc+%5Ccdot+%28z+-+%5Cmathbf%7B1%7D%29%7D+%7D+%5C%5C++%5C%5C++%26%3D%26+%5Cdisplaystyle%7B%5Csum_%7B%5Ctau+%5Cin+T%7D+c%5E%7Bt%28%5Ctau%29%7D+r%28%5Ctau%29+%5C%2C+%28%7Bz%7D%5E%7Bt%28%5Ctau%29%7D+-+%7Bz%7D%5E%7Bs%28%5Ctau%29%7D%29+e%5E%7Bc+%5Ccdot+%28z+-+%5Cmathbf%7B1%7D%29%7D+%7D+%5Cend%7Barray%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} &#92;displaystyle {&#92;frac{d&#92;Psi(t)}{dt}} &amp;=&amp;  &#92;displaystyle{ &#92;sum_{&#92;tau &#92;in T} r(&#92;tau) &#92;, ({a^&#92;dagger}^{t(&#92;tau)} - {a^&#92;dagger}^{s(&#92;tau)}) &#92;, a^{s(&#92;tau)} e^{c &#92;cdot (z - &#92;mathbf{1})} } &#92;&#92;  &#92;&#92;  &amp;=&amp; &#92;displaystyle{&#92;sum_{&#92;tau &#92;in T} c^{t(&#92;tau)} r(&#92;tau) &#92;, ({z}^{t(&#92;tau)} - {z}^{s(&#92;tau)}) e^{c &#92;cdot (z - &#92;mathbf{1})} } &#92;end{array} " class="latex" /></p>
<p>So, </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%28%5Cdot%7Bc%7D+%5Ccdot+%28z+-+%5Cmathbf%7B1%7D%29%29+%5C%2C+e%5E%7Bc+%5Ccdot+%28z+-+%5Cmathbf%7B1%7D%29%7D++%3D%5Csum_%7B%5Ctau+%5Cin+T%7D+c%5E%7Bt%28%5Ctau%29%7D+r%28%5Ctau%29+%5C%2C+%28%7Bz%7D%5E%7Bt%28%5Ctau%29%7D+-+%7Bz%7D%5E%7Bs%28%5Ctau%29%7D%29+e%5E%7Bc+%5Ccdot+%28z+-+%5Cmathbf%7B1%7D%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ (&#92;dot{c} &#92;cdot (z - &#92;mathbf{1})) &#92;, e^{c &#92;cdot (z - &#92;mathbf{1})}  =&#92;sum_{&#92;tau &#92;in T} c^{t(&#92;tau)} r(&#92;tau) &#92;, ({z}^{t(&#92;tau)} - {z}^{s(&#92;tau)}) e^{c &#92;cdot (z - &#92;mathbf{1})} }" class="latex" /></p>
<p>As a result, we get </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%5Cdot%7Bc%7D%5Ccdot+z+-%5Cdot%7Bc%7D%5Ccdot%5Cmathbf%7B1%7D+%3D++%5Csum_%7B%5Ctau+%5Cin+T%7D+c%5E%7Bs%28%5Ctau%29%7D+r%28%5Ctau%29+%5C%2C+%28%7Bz%7D%5E%7Bt%28%5Ctau%29%7D+-+%7Bz%7D%5E%7Bs%28%5Ctau%29%7D%29++%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  &#92;dot{c}&#92;cdot z -&#92;dot{c}&#92;cdot&#92;mathbf{1} =  &#92;sum_{&#92;tau &#92;in T} c^{s(&#92;tau)} r(&#92;tau) &#92;, ({z}^{t(&#92;tau)} - {z}^{s(&#92;tau)})  }." class="latex" /></p>
<p>Comparing the coefficients of all <img src="https://s0.wp.com/latex.php?latex=z%5E%5Cell%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z^&#92;ell," class="latex" /> we obtain the following.  For <img src="https://s0.wp.com/latex.php?latex=%5Cell+%3D+0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ell = 0," class="latex" /> which is the only complex of degree zero, we get</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7B+%5Csum_%7B%5Ctau%3A+t%28%5Ctau%29%3D0%7D+r%28%5Ctau%29+c%5E%7Bs%28%5Ctau%29%7D+-+%5Csum_%7B%5Ctau%5C%3B%3A%5C%3B+s%28%5Ctau%29%3D+0%7D+r%28%5Ctau%29+c%5E%7Bs%28%5Ctau%29%7D+%3D+-%5Cdot%7Bc%7D%5Ccdot%5Cmathbf%7B1%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle { &#92;sum_{&#92;tau: t(&#92;tau)=0} r(&#92;tau) c^{s(&#92;tau)} - &#92;sum_{&#92;tau&#92;;:&#92;; s(&#92;tau)= 0} r(&#92;tau) c^{s(&#92;tau)} = -&#92;dot{c}&#92;cdot&#92;mathbf{1} }" class="latex" /></p>
<p>For the complexes <img src="https://s0.wp.com/latex.php?latex=%5Cell&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ell" class="latex" /> of degree one, we get these equations:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7B+%5Csum_%7B%5Ctau%5C%3B%3A%5C%3B+t%28%5Ctau%29%3D%281%2C0%2C0%2C%5Cdots%29%7D+r%28%5Ctau%29+c%5E%7Bs%28%5Ctau%29%7D+-+%5Csum_%7B%5Ctau+%5C%3B%3A%5C%3Bs%28%5Ctau%29%3D%281%2C0%2C0%2C%5Cdots%29%7D+r%28%5Ctau%29+c%5E%7Bs%28%5Ctau%29%7D%3D+%5Cdot%7Bc_1%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle { &#92;sum_{&#92;tau&#92;;:&#92;; t(&#92;tau)=(1,0,0,&#92;dots)} r(&#92;tau) c^{s(&#92;tau)} - &#92;sum_{&#92;tau &#92;;:&#92;;s(&#92;tau)=(1,0,0,&#92;dots)} r(&#92;tau) c^{s(&#92;tau)}= &#92;dot{c_1} }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7B+%5Csum_%7B%5Ctau%5C%3B+%3A%5C%3B+t%28%5Ctau%29%3D%280%2C1%2C0%2C%5Cdots%29%7D+r%28%5Ctau%29+c%5E%7Bs%28%5Ctau%29%7D+-+%5Csum_%7B%5Ctau%5C%3B%3A%5C%3B+s%28%5Ctau%29%3D%280%2C1%2C0%2C%5Cdots%29%7D+r%28%5Ctau%29+c%5E%7Bs%28%5Ctau%29%7D+%3D+%5Cdot%7Bc_2%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle { &#92;sum_{&#92;tau&#92;; :&#92;; t(&#92;tau)=(0,1,0,&#92;dots)} r(&#92;tau) c^{s(&#92;tau)} - &#92;sum_{&#92;tau&#92;;:&#92;; s(&#92;tau)=(0,1,0,&#92;dots)} r(&#92;tau) c^{s(&#92;tau)} = &#92;dot{c_2} }" class="latex" /></p>
<p>and so on.   For all the remaining complexes <img src="https://s0.wp.com/latex.php?latex=%5Cell&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ell" class="latex" /> we have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7B+%5Csum_%7B%5Ctau%5C%3B%3A%5C%3B+t%28%5Ctau%29%3D%5Cell%7D+r%28%5Ctau%29+c%5E%7Bs%28%5Ctau%29%7D+%3D+%5Csum_%7B%5Ctau+%5C%3B%3A%5C%3B+s%28%5Ctau%29%3D%5Cell%7D+r%28%5Ctau%29+c%5E%7Bs%28%5Ctau%29%7D+%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle { &#92;sum_{&#92;tau&#92;;:&#92;; t(&#92;tau)=&#92;ell} r(&#92;tau) c^{s(&#92;tau)} = &#92;sum_{&#92;tau &#92;;:&#92;; s(&#92;tau)=&#92;ell} r(&#92;tau) c^{s(&#92;tau)} }." class="latex" /></p>
<p>This says that the total rate at which this complex is produced equals the total rate at which it&#8217;s destroyed.  So, our solution of the master equation is complex balanced for all complexes <img src="https://s0.wp.com/latex.php?latex=%5Cell&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ell" class="latex" /> of degree greater than one.  This is our necessary condition.  &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;    &#9608;</p>
<p>To illustrate the theorem, I&#8217;ll consider three simple examples. The third example shows that the condition in the theorem, though necessary, is not sufficient.  Note that our proof also gives a necessary <i>and sufficient</i> condition for a coherent state to remain coherent: namely, that <i>all</i> the equations we listed hold, not just initially but for all times.  But this condition seems a bit complicated.</p>
<h3>Introducing amoebae into a Petri dish</h3>
<div align="center"><img width="100" src="https://i2.wp.com/math.ucr.edu/home/baez/networks/amoebae1.png" /></div>
<p>Suppose that there is an inexhaustible supply of amoebae, randomly floating around in a huge pond. Each time an amoeba comes into our collection area, we catch it and add it to the population of amoebae in the Petri dish.  Suppose that the rate constant for this process is 3.</p>
<p>So, the Hamiltonian is <img src="https://s0.wp.com/latex.php?latex=3%28a%5E%5Cdagger+-1%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="3(a^&#92;dagger -1)." class="latex" /> If we start with a coherent state, say </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7B+%5CPsi%280%29%3D%5Cfrac%7Be%5E%7Bcz%7D%7D%7Be%5Ec%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle { &#92;Psi(0)=&#92;frac{e^{cz}}{e^c} }" class="latex" /> </p>
<p>then </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7B+%5CPsi%28t%29+%3D+e%5E%7B3%28a%5E%5Cdagger+-1%29t%7D+%5C%3B+%5Cfrac%7Be%5E%7Bcz%7D%7D%7Be%5Ec%7D++%3D+%5Cfrac%7Be%5E%7B%28c%2B3t%29z%7D%7D%7Be%5E%7Bc%2B3t%7D%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle { &#92;Psi(t) = e^{3(a^&#92;dagger -1)t} &#92;; &#92;frac{e^{cz}}{e^c}  = &#92;frac{e^{(c+3t)z}}{e^{c+3t}} }" class="latex" /> </p>
<p>which is coherent at all times.</p>
<p>We can see that the condition of the theorem is satisfied, as all the complexes in the reaction network have degree 0 or 1.</p>
<h3>Amoebae reproducing and competing</h3>
<div align="center"><img width="450" src="https://i1.wp.com/math.ucr.edu/home/baez/networks/amoebae2.png" /></div>
<p>This example shows a Petri dish with one species, amoebae, and two transitions: fission and competition. We suppose that the rate constant for fission is 2, while that for competition is 1. The Hamiltonian is then</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%3D+2%28%7Ba%5E%5Cdagger%7D%5E2-a%5E%5Cdagger%29a+%2B+%28a%5E%5Cdagger-%7Ba%5E%5Cdagger%7D%5E2%29a%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H= 2({a^&#92;dagger}^2-a^&#92;dagger)a + (a^&#92;dagger-{a^&#92;dagger}^2)a^2" class="latex" /> </p>
<p>If we start off with the coherent state </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5CPsi%280%29+%3D+%5Cfrac%7Be%5E%7B2z%7D%7D%7Be%5E2%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;Psi(0) = &#92;frac{e^{2z}}{e^2}}" class="latex" /> </p>
<p>we find that </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7B%5CPsi%28t%29%3De%5E%7B2%28z%5E2-z%292%2B%28z-z%5E2%294%7D+%5C%3B+%5CPsi%280%29%7D%3D%5CPsi%280%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle {&#92;Psi(t)=e^{2(z^2-z)2+(z-z^2)4} &#92;; &#92;Psi(0)}=&#92;Psi(0)" class="latex" /></p>
<p>which is coherent.  It should be noted that the chosen initial state</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Be%5E%7B2z%7D%7D%7Be%5E2%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{e^{2z}}{e^2}}" class="latex" /></p>
<p>was a complex balanced equilibrium solution. So, the Anderson–Craciun–Kurtz Theorem applies to this case.</p>
<h3>Amoebae reproducing, competing, and being introduced</h3>
<div align="center"><img width="450" src="https://i1.wp.com/math.ucr.edu/home/baez/networks/amoebae3.png" /></div>
<p>This is a combination of the previous two examples, where apart from ongoing reproduction and competition, amoebae are being introduced into the dish with a rate constant 3.</p>
<p>As in the above examples, we might think that coherent states could remain coherent forever here too. Let&#8217;s check that.</p>
<p>Assuming that this was true,  if  </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5CPsi%28t%29+%3D+%5Cfrac%7Be%5E%7Bc%28t%29z%7D%7D%7Be%5E%7Bc%28t%29%7D%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;Psi(t) = &#92;frac{e^{c(t)z}}{e^{c(t)}} }" class="latex" /> </p>
<p>then <img src="https://s0.wp.com/latex.php?latex=c%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c(t)" class="latex" /> would have to satisfy the following:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdot%7Bc%7D%28t%29+%3D+c%28t%29%5E2+%2B+3+-2c%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;dot{c}(t) = c(t)^2 + 3 -2c(t)" class="latex" /> </p>
<p>and</p>
<p><img src="https://s0.wp.com/latex.php?latex=c%28t%29%5E2%3D2c%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c(t)^2=2c(t)" class="latex" /></p>
<p>Using the second equation, we get  </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdot%7Bc%7D%28t%29+%3D+3+%5CRightarrow+c+%3D+3t%2B+c_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;dot{c}(t) = 3 &#92;Rightarrow c = 3t+ c_0" class="latex" /> </p>
<p>But this is certainly not a solution of the second equation. So, here we find that initially coherent states do not remain remain coherent for all times.  </p>
<p>However, if we choose </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5CPsi%280%29+%3D+%5Cfrac%7Be%5E%7B2z%7D%7D%7Be%5E2%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;Psi(0) = &#92;frac{e^{2z}}{e^2}}" class="latex" /></p>
<p>then this coherent state is complex balanced except for complexes of degree 1, since it was in the previous example, and the only new feature of this example, at time zero, is that single amoebas are being introduced&#8212;and these are complexes of degree 1.  So, the condition of the theorem does hold.</p>
<p>So, the condition in the theorem is necessary but not sufficient.  However, it is easy to check, and we can use it to show that in many cases, coherent states must cease to be coherent.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/07/10/coherence-for-solutions-of-the-master-equation/#comments">15 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/chemistry/" rel="category tag">chemistry</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/07/10/coherence-for-solutions-of-the-master-equation/" rel="bookmark" title="Permanent Link to Coherence for Solutions of the Master&nbsp;Equation">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-16399 post type-post status-publish format-standard hentry category-mathematics category-physics category-probability" id="post-16399">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/" rel="bookmark">The Large-Number Limit for Reaction Networks (Part&nbsp;2)</a></h2>
				<small>6 July, 2013</small><br />


				<div class="entry">
					<p>I&#8217;ve been talking a lot about &#8216;stochastic mechanics&#8217;, which is like quantum mechanics but with probabilities replacing amplitudes.  In <a href="https://johncarlosbaez.wordpress.com/2013/07/01/poisson-brackets-for-reaction-networks-2/">Part 1</a> of this mini-series I started telling you about the &#8216;large-number limit&#8217; in stochastic mechanics.  It turns out this is mathematically analogous to the &#8216;classical limit&#8217; of quantum mechanics, where Planck&#8217;s constant <img src="https://s0.wp.com/latex.php?latex=%5Chbar&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar" class="latex" /> goes to zero.  </p>
<p>There&#8217;s a lot more I need to say about this, and lots more I need to figure out.   But here&#8217;s one rather easy thing. </p>
<p>In quantum mechanics, <a href="http://en.wikipedia.org/wiki/Coherent_states">&#8216;coherent states&#8217;</a> are a special class of quantum states that are very easy to calculate with.  In a certain precise sense they are the best quantum approximations to classical states.  This makes them good tools for studying the classical limit of quantum mechanics.  As <img src="https://s0.wp.com/latex.php?latex=%5Chbar+%5Cto+0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar &#92;to 0," class="latex" /> they reduce to classical states where, for example, a particle has a definite position and momentum. </p>
<p>We can borrow this strategy to study the large-number limit of stochastic mechanics.  We&#8217;ve run into coherent states <a href="http://math.ucr.edu/home/baez/networks/networks_9.html">before</a> in our discussions here.  Now let&#8217;s see how they work in the large-number limit!</p>
<h3> Coherent states </h3>
<p>For starters, let&#8217;s recall what coherent states are.  We&#8217;ve got <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k" class="latex" /> different kinds of particles, and we call each kind a <b>species</b>.  We describe the probability that we have some number of particles of each kind using a &#8216;stochastic state&#8217;.  For starters, this is a formal power series in variables <img src="https://s0.wp.com/latex.php?latex=z_1%2C+%5Cdots%2C+z_k.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z_1, &#92;dots, z_k." class="latex" />  We write it as</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5CPsi+%3D+%5Csum_%7B%5Cell+%5Cin+%5Cmathbb%7BN%7D%5Ek%7D+%5Cpsi_%5Cell+z%5E%5Cell+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;Psi = &#92;sum_{&#92;ell &#92;in &#92;mathbb{N}^k} &#92;psi_&#92;ell z^&#92;ell }" class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=z%5E%5Cell&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z^&#92;ell" class="latex" /> is an abbreviation for </p>
<p><img src="https://s0.wp.com/latex.php?latex=z_1%5E%7B%5Cell_1%7D+%5Ccdots+z_k%5E%7B%5Cell_k%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z_1^{&#92;ell_1} &#92;cdots z_k^{&#92;ell_k} " class="latex" /></p>
<p>But for <img src="https://s0.wp.com/latex.php?latex=%5CPsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi" class="latex" /> to be a <b>stochastic state</b> the numbers <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_%5Cell&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi_&#92;ell" class="latex" /> need to be probabilities, so we require that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi_%5Cell+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi_&#92;ell &#92;ge 0" class="latex" /></p>
<p>and </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Csum_%7B%5Cell+%5Cin+%5Cmathbb%7BN%7D%5Ek%7D+%5Cpsi_%5Cell+%3D+1%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;sum_{&#92;ell &#92;in &#92;mathbb{N}^k} &#92;psi_&#92;ell = 1} " class="latex" /></p>
<p>Sums of coefficients like this show up so often that it&#8217;s good to have an abbreviation for them:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clangle+%5CPsi+%5Crangle+%3D++%5Csum_%7B%5Cell+%5Cin+%5Cmathbb%7BN%7D%5Ek%7D+%5Cpsi_%5Cell%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;langle &#92;Psi &#92;rangle =  &#92;sum_{&#92;ell &#92;in &#92;mathbb{N}^k} &#92;psi_&#92;ell} " class="latex" /></p>
<p>Now, a <b>coherent state</b> is a stochastic state where the numbers of particles of each species are <a href="http://en.wikipedia.org/wiki/Independence_%28probability_theory%29">independent</a> random variables, and the number of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th species is distributed according to a <a href="http://en.wikipedia.org/wiki/Poisson_distribution">Poisson distribution</a>.</p>
<p>Since we can pick ithe means of these Poisson distributions to be whatever we want, we get a coherent state <img src="https://s0.wp.com/latex.php?latex=%5CPsi_c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi_c" class="latex" /> for each list of numbers <img src="https://s0.wp.com/latex.php?latex=c+%5Cin+%5B0%2C%5Cinfty%29%5Ek%3A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c &#92;in [0,&#92;infty)^k:" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5CPsi_c+%3D+%5Cfrac%7Be%5E%7Bc+%5Ccdot+z%7D%7D%7Be%5Ec%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;Psi_c = &#92;frac{e^{c &#92;cdot z}}{e^c} } " class="latex" /></p>
<p>Here I&#8217;m using another abbreviation:</p>
<p><img src="https://s0.wp.com/latex.php?latex=e%5E%7Bc%7D+%3D+e%5E%7Bc_1+%2B+%5Ccdots+%2B+c_k%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="e^{c} = e^{c_1 + &#92;cdots + c_k} " class="latex" /></p>
<p>If you calculate a bit, you&#8217;ll see</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%5CPsi_c+%3D+e%5E%7B-%28c_1+%2B+%5Ccdots+%2B+c_k%29%7D+%5C%2C+%5Csum_%7Bn+%5Cin+%5Cmathbb%7BN%7D%5Ek%7D+%5Cfrac%7Bc_1%5E%7Bn_1%7D+%5Ccdots+c_k%5E%7Bn_k%7D%7D+%7Bn_1%21+%5C%2C+%5Ccdots+%5C%2C+n_k%21+%7D+%5C%2C+z_1%5E%7Bn_1%7D+%5Ccdots+z_k%5E%7Bn_k%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  &#92;Psi_c = e^{-(c_1 + &#92;cdots + c_k)} &#92;, &#92;sum_{n &#92;in &#92;mathbb{N}^k} &#92;frac{c_1^{n_1} &#92;cdots c_k^{n_k}} {n_1! &#92;, &#92;cdots &#92;, n_k! } &#92;, z_1^{n_1} &#92;cdots z_k^{n_k} } " class="latex" /></p>
<p>Thus, the probability of having <img src="https://s0.wp.com/latex.php?latex=n_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n_i" class="latex" /> things of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th species is equal to </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++e%5E%7B-c_i%7D+%5C%2C+%5Cfrac%7Bc_i%5E%7Bn_i%7D%7D%7Bn_i%21%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  e^{-c_i} &#92;, &#92;frac{c_i^{n_i}}{n_i!} } " class="latex" /></p>
<p>This is precisely the definition of a <a href="http://en.wikipedia.org/wiki/Poisson_distribution"><b>Poisson distribution</b></a> with mean equal to <img src="https://s0.wp.com/latex.php?latex=c_i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c_i." class="latex" />  </p>
<p>What are the main properties of coherent states?  For starters, they are indeed states:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5CPsi_c+%5Crangle+%3D+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;Psi_c &#92;rangle = 1" class="latex" /></p>
<p>More interestingly, they are eigenvectors of the annihilation operators</p>
<p><img src="https://s0.wp.com/latex.php?latex=a_i+%3D+%5Cdisplaystyle%7B+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+z_i%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a_i = &#92;displaystyle{ &#92;frac{&#92;partial}{&#92;partial z_i} }" class="latex" /></p>
<p>since when you differentiate an exponential you get back an exponential:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+a_i+%5CPsi_c+%26%3D%26++%5Cdisplaystyle%7B+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+z_i%7D+%5Cfrac%7Be%5E%7Bc+%5Ccdot+z%7D%7D%7Be%5Ec%7D+%7D+%5C%5C+%5C%5C+++%26%3D%26+c_i+%5CPsi_c+%5Cend%7Barray%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} a_i &#92;Psi_c &amp;=&amp;  &#92;displaystyle{ &#92;frac{&#92;partial}{&#92;partial z_i} &#92;frac{e^{c &#92;cdot z}}{e^c} } &#92;&#92; &#92;&#92;   &amp;=&amp; c_i &#92;Psi_c &#92;end{array}" class="latex" /></p>
<p>We can use this fact to check that in this coherent state, the mean number of particles of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th species really is <img src="https://s0.wp.com/latex.php?latex=c_i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c_i." class="latex" />  For this, we introduce the number operator</p>
<p><img src="https://s0.wp.com/latex.php?latex=N_i+%3D+a_i%5E%5Cdagger+a_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N_i = a_i^&#92;dagger a_i " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=a_i%5E%5Cdagger&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a_i^&#92;dagger" class="latex" /> is the creation operator:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28a_i%5E%5Cdagger+%5CPsi%29%28z%29+%3D+z_i+%5CPsi%28z%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(a_i^&#92;dagger &#92;Psi)(z) = z_i &#92;Psi(z) " class="latex" /></p>
<p>The number operator has the property that </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+N_i+%5CPsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle N_i &#92;Psi &#92;rangle" class="latex" /></p>
<p>is the mean number of particles of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th species.  If we calculate this for our coherent state <img src="https://s0.wp.com/latex.php?latex=%5CPsi_c%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi_c," class="latex" /> we get</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+%5Clangle+a_i%5E%5Cdagger+a_i+%5CPsi_c+%5Crangle+%26%3D%26+c_i+%5Clangle+a_i%5E%5Cdagger+%5CPsi_c+%5Crangle+%5C%5C++%5C%5C+%26%3D%26+c_i+%5Clangle+%5CPsi_c+%5Crangle+%5C%5C+%5C%5C+%26%3D%26+c_i+%5Cend%7Barray%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} &#92;langle a_i^&#92;dagger a_i &#92;Psi_c &#92;rangle &amp;=&amp; c_i &#92;langle a_i^&#92;dagger &#92;Psi_c &#92;rangle &#92;&#92;  &#92;&#92; &amp;=&amp; c_i &#92;langle &#92;Psi_c &#92;rangle &#92;&#92; &#92;&#92; &amp;=&amp; c_i &#92;end{array} " class="latex" /></p>
<p>Here in the second step we used the general rule</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+a_i%5E%5Cdagger+%5CPhi+%5Crangle+%3D+%5Clangle+%5CPhi+%5Crangle+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle a_i^&#92;dagger &#92;Phi &#92;rangle = &#92;langle &#92;Phi &#92;rangle " class="latex" /></p>
<p>which is easy to check.</p>
<h3>  Rescaling </h3>
<p>Now let&#8217;s see how coherent states work in the large-numbers limit.  For this, let&#8217;s use the rescaled annihilation, creation and number operators from <a href="https://johncarlosbaez.wordpress.com/2013/07/01/poisson-brackets-for-reaction-networks-2/">Part 1</a>.  They look like this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=A_i+%3D+%5Chbar+%5C%2C+a_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A_i = &#92;hbar &#92;, a_i " class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=C_i+%3D+a_i%5E%5Cdagger+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C_i = a_i^&#92;dagger " class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BN%7D_i+%3D+C_i+A_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;widetilde{N}_i = C_i A_i" class="latex" /></p>
<p>Since </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BN%7D_i+%3D+%5Chbar+N_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;widetilde{N}_i = &#92;hbar N_i" class="latex" /></p>
<p>the point is that the rescaled number operator counts particles not one at a time, but in bunches of size <img src="https://s0.wp.com/latex.php?latex=1%2F%5Chbar.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/&#92;hbar." class="latex" />   For example, if <img src="https://s0.wp.com/latex.php?latex=%5Chbar&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar" class="latex" /> is the reciprocal of Avogadro&#8217;s number, we are counting particles in &#8216;moles&#8217;.  So, <img src="https://s0.wp.com/latex.php?latex=%5Chbar+%5Cto+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar &#92;to 0" class="latex" /> corresponds to a large-number limit.</p>
<p>To flesh out this idea some more, let&#8217;s define rescaled coherent states:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7B%5CPsi%7D_c+%3D+%5CPsi_%7Bc%2F%5Chbar%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;widetilde{&#92;Psi}_c = &#92;Psi_{c/&#92;hbar}" class="latex" /></p>
<p>These are eigenvectors of the rescaled annihilation operators:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+A_i+%5Cwidetilde%7B%5CPsi%7D_c+%26%3D%26+%5Chbar+a_i+%5CPsi_%7Bc%2F%5Chbar%7D++%5C%5C++%5C%5C++%26%3D%26+c_i+%5CPsi_%7Bc%2F%5Chbar%7D+%5C%5C+%5C%5C++%26%3D%26+c_i+%5Cwidetilde%7B%5CPsi%7D_c++%5Cend%7Barray%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} A_i &#92;widetilde{&#92;Psi}_c &amp;=&amp; &#92;hbar a_i &#92;Psi_{c/&#92;hbar}  &#92;&#92;  &#92;&#92;  &amp;=&amp; c_i &#92;Psi_{c/&#92;hbar} &#92;&#92; &#92;&#92;  &amp;=&amp; c_i &#92;widetilde{&#92;Psi}_c  &#92;end{array} " class="latex" /></p>
<p>This in turn means that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+%5Clangle+%5Cwidetilde%7BN%7D_i+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle+%26%3D%26+%5Clangle+C_i+A_i+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle+%5C%5C++%5C%5C++%26%3D%26+c_i+%5Clangle++C_i+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle+%5C%5C++%5C%5C+%26%3D%26+c_i+%5Clangle+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle+%5C%5C+%5C%5C+%26%3D%26+c_i+%5Cend%7Barray%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} &#92;langle &#92;widetilde{N}_i &#92;widetilde{&#92;Psi}_c &#92;rangle &amp;=&amp; &#92;langle C_i A_i &#92;widetilde{&#92;Psi}_c &#92;rangle &#92;&#92;  &#92;&#92;  &amp;=&amp; c_i &#92;langle  C_i &#92;widetilde{&#92;Psi}_c &#92;rangle &#92;&#92;  &#92;&#92; &amp;=&amp; c_i &#92;langle &#92;widetilde{&#92;Psi}_c &#92;rangle &#92;&#92; &#92;&#92; &amp;=&amp; c_i &#92;end{array} " class="latex" /></p>
<p>Here we used the general rule</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+C_i+%5CPhi+%5Crangle+%3D+%5Clangle+%5CPhi+%5Crangle+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle C_i &#92;Phi &#92;rangle = &#92;langle &#92;Phi &#92;rangle " class="latex" /></p>
<p>which holds because the &#8216;rescaled&#8217; creation operator <img src="https://s0.wp.com/latex.php?latex=C_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C_i" class="latex" /> is really just the usual creation operator, which obeys this rule.</p>
<p>What&#8217;s the point of all this fiddling around?  Simply this.  The equation</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cwidetilde%7BN%7D_i+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle+%3D+c_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;widetilde{N}_i &#92;widetilde{&#92;Psi}_c &#92;rangle = c_i " class="latex" /></p>
<p>says the expected number of particles of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th species in the state <img src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7B%5CPsi%7D_c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;widetilde{&#92;Psi}_c" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=c_i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c_i," class="latex" /> <i>if we count these particles not one at a time, but in bunches of size <img src="https://s0.wp.com/latex.php?latex=1%2F%5Chbar.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/&#92;hbar." class="latex" /></i></p>
<h3> A simple test </h3>
<p>As a simple test of this idea, let&#8217;s check that as <img src="https://s0.wp.com/latex.php?latex=%5Chbar+%5Cto+0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar &#92;to 0," class="latex" /> the standard deviation of the number of particles in the state <img src="https://s0.wp.com/latex.php?latex=%5CPsi_c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Psi_c" class="latex" /> goes to zero&#8230; where we count particle using the rescaled number operator.</p>
<p>The variance of the rescaled number operator is, by definition,</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cwidetilde%7BN%7D_i%5E2+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle+-+++%5Clangle+%5Cwidetilde%7BN%7D_i%5E2+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle%5E2+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;widetilde{N}_i^2 &#92;widetilde{&#92;Psi}_c &#92;rangle -   &#92;langle &#92;widetilde{N}_i^2 &#92;widetilde{&#92;Psi}_c &#92;rangle^2 " class="latex" /></p>
<p>and the standard deviation is the square root of the variance.</p>
<p>We already know the mean of the rescaled number operator:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cwidetilde%7BN%7D_i+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle+%3D+c_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;widetilde{N}_i &#92;widetilde{&#92;Psi}_c &#92;rangle = c_i " class="latex" /></p>
<p>So, the main thing we need to calculate is the mean of its square:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cwidetilde%7BN%7D_i%5E2+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;widetilde{N}_i^2 &#92;widetilde{&#92;Psi}_c &#92;rangle" class="latex" /> </p>
<p>For this we will use the commutation relation derived last time:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5BA_i+%2C+C_i%5D+%3D+%5Chbar++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="[A_i , C_i] = &#92;hbar  " class="latex" /></p>
<p>This implies</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+%5Cwidetilde%7BN%7D_i%5E2+%26%3D%26+C_i+A_i+C_i+A_i+%5C%5C++%5C%5C++%26%3D%26++C_i+%28C_i+A_i+%2B+%5Chbar%29+A_i+%5C%5C+%5C%5C++%26%3D%26++C_i%5E2+A_i%5E2+%2B+%5Chbar+C_i+A_i+%5Cend%7Barray%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} &#92;widetilde{N}_i^2 &amp;=&amp; C_i A_i C_i A_i &#92;&#92;  &#92;&#92;  &amp;=&amp;  C_i (C_i A_i + &#92;hbar) A_i &#92;&#92; &#92;&#92;  &amp;=&amp;  C_i^2 A_i^2 + &#92;hbar C_i A_i &#92;end{array} " class="latex" /></p>
<p>so </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+%5Clangle+%5Cwidetilde%7BN%7D_i%5E2%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle+%26%3D%26+%5Clangle+%28C_i%5E2+A_i%5E2+%2B+%5Chbar+C_i+A_i%29+%5CPsi_c+%5Crangle+%5C%5C+++%5C%5C++%26%3D%26++c_i%5E2+%2B+%5Chbar+c_i++%5Cend%7Barray%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} &#92;langle &#92;widetilde{N}_i^2&#92;widetilde{&#92;Psi}_c &#92;rangle &amp;=&amp; &#92;langle (C_i^2 A_i^2 + &#92;hbar C_i A_i) &#92;Psi_c &#92;rangle &#92;&#92;   &#92;&#92;  &amp;=&amp;  c_i^2 + &#92;hbar c_i  &#92;end{array}" class="latex" /></p>
<p>where we used our friends</p>
<p><img src="https://s0.wp.com/latex.php?latex=A_i+%5CPsi_c+%3D+c_i+%5CPsi_c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A_i &#92;Psi_c = c_i &#92;Psi_c" class="latex" /> </p>
<p>and </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+C_i+%5CPhi+%5Crangle+%3D+%5Clangle+%5CPhi+%5Crangle+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle C_i &#92;Phi &#92;rangle = &#92;langle &#92;Phi &#92;rangle " class="latex" /></p>
<p>So, the variance of the rescaled number of particles is</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+%5Clangle+%5Cwidetilde%7BN%7D_i%5E2+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle++-+++%5Clangle+%5Cwidetilde%7BN%7D_i+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle%5E2++%26%3D%26+c_i%5E2+%2B+%5Chbar+c_i+-+c_i%5E2+%5C%5C++%5C%5C++%26%3D%26+%5Chbar+c_i+%5Cend%7Barray%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} &#92;langle &#92;widetilde{N}_i^2 &#92;widetilde{&#92;Psi}_c &#92;rangle  -   &#92;langle &#92;widetilde{N}_i &#92;widetilde{&#92;Psi}_c &#92;rangle^2  &amp;=&amp; c_i^2 + &#92;hbar c_i - c_i^2 &#92;&#92;  &#92;&#92;  &amp;=&amp; &#92;hbar c_i &#92;end{array} " class="latex" /></p>
<p>and the standard deviation is </p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Chbar+c_i%29%5E%7B1%2F2%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;hbar c_i)^{1/2} " class="latex" /></p>
<p>Good, it goes to zero as <img src="https://s0.wp.com/latex.php?latex=%5Chbar+%5Cto+0%21&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar &#92;to 0!" class="latex" /> And the square root is just what you’d expect if you’ve thought about stuff like <a href="http://en.wikipedia.org/wiki/Random_walks#One-dimensional_random_walk">random walks</a> or the <a href="http://en.wikipedia.org/wiki/Central_limit_theorem#Classical_CLT">central limit theorem</a>.</p>
<h3> A puzzle</h3>
<p>I feel sure that in any coherent state, not only the variance but also all the higher moments of the rescaled number operators go to zero as <img src="https://s0.wp.com/latex.php?latex=%5Chbar+%5Cto+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar &#92;to 0." class="latex" /> Can you prove this?</p>
<p>Here I mean the moments after the mean has been subtracted. The <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" />th moment is then</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+%28%5Cwidetilde%7BN%7D_i+-+c_i%29%5Ep+%5C%3B+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle (&#92;widetilde{N}_i - c_i)^p &#92;; &#92;widetilde{&#92;Psi}_c &#92;rangle" class="latex" /></p>
<p>I want this to go to zero as <img src="https://s0.wp.com/latex.php?latex=%5Chbar+%5Cto+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar &#92;to 0." class="latex" /></p>
<p>Here’s a clue that should help. First, there’s a <a href="http://en.wikipedia.org/wiki/Poisson_distribution#Higher_moments">textbook formula</a> for the higher moments of Poisson distributions without the mean subtracted. If I understand it correctly, it gives this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clangle+N_i%5Em+%5C%3B+%5CPsi_c+%5Crangle+%3D+%5Csum_%7Bj+%3D+1%7D%5Em+%7Bc_i%7D%5Ej+%5C%3B+%5Cleft%5C%7B+%5Cbegin%7Barray%7D%7Bc%7D+m+%5C%5C+j+%5Cend%7Barray%7D+%5Cright%5C%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;langle N_i^m &#92;; &#92;Psi_c &#92;rangle = &#92;sum_{j = 1}^m {c_i}^j &#92;; &#92;left&#92;{ &#92;begin{array}{c} m &#92;&#92; j &#92;end{array} &#92;right&#92;} }" class="latex" /></p>
<p>Here</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cleft%5C%7B+%5Cbegin%7Barray%7D%7Bc%7D+m+%5C%5C+j+%5Cend%7Barray%7D+%5Cright%5C%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;left&#92;{ &#92;begin{array}{c} m &#92;&#92; j &#92;end{array} &#92;right&#92;} }" class="latex" /></p>
<p>is the number of ways to partition an <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m" class="latex" />-element set into <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j" class="latex" /> nonempty subsets. This is called <a href="http://en.wikipedia.org/wiki/Stirling_numbers_of_the_second_kind">Stirling’s number of the second kind</a>.  This suggests that there&#8217;s some fascinating combinatorics involving coherent states.  That&#8217;s exactly the kind of thing I enjoy, so I would like to understand this formula someday&#8230; but not today!  I just want something to go to zero!</p>
<p>If I rescale the above formula, I seem to get</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D+%5Clangle+%5Cwidetilde%7BN%7D_i%5Em+%5C%3B+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle+%26%3D%26+%5Chbar%5Em+%5Clangle+N_i%5Em+%5CPsi_%7Bc%2F%5Chbar%7D+%5Crangle+%5C%5C+%5C%5C+%26%3D%26+%5Chbar%5Em+%5C%3B+%5Cdisplaystyle%7B+%5Csum_%7Bj+%3D+1%7D%5Em+%5Cleft%28%5Cfrac%7Bc_i%7D%7B%5Chbar%7D%5Cright%29%5Ej+%5Cleft%5C%7B+%5Cbegin%7Barray%7D%7Bc%7D+m+%5C%5C+j+%5Cend%7Barray%7D+%5Cright%5C%7D+%7D+%5Cend%7Barray%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl} &#92;langle &#92;widetilde{N}_i^m &#92;; &#92;widetilde{&#92;Psi}_c &#92;rangle &amp;=&amp; &#92;hbar^m &#92;langle N_i^m &#92;Psi_{c/&#92;hbar} &#92;rangle &#92;&#92; &#92;&#92; &amp;=&amp; &#92;hbar^m &#92;; &#92;displaystyle{ &#92;sum_{j = 1}^m &#92;left(&#92;frac{c_i}{&#92;hbar}&#92;right)^j &#92;left&#92;{ &#92;begin{array}{c} m &#92;&#92; j &#92;end{array} &#92;right&#92;} } &#92;end{array} " class="latex" /></p>
<p>We could plug this formula into</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+%28%5Cwidetilde%7BN%7D_i+-+c_i%29%5Ep+%5C%3B+%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle+%3D++%5Cdisplaystyle%7B+%5Csum_%7Bm+%3D+0%7D%5Ep+%5C%2C+%5Cbinom%7Bm%7D%7Bp%7D+%5C%3B+%5Clangle+%5Cwidetilde%7BN%7D_i%5Em+%5C%3B++%5Cwidetilde%7B%5CPsi%7D_c+%5Crangle+%5C%2C+%28-c_i%29%5E%7Bp+-+m%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle (&#92;widetilde{N}_i - c_i)^p &#92;; &#92;widetilde{&#92;Psi}_c &#92;rangle =  &#92;displaystyle{ &#92;sum_{m = 0}^p &#92;, &#92;binom{m}{p} &#92;; &#92;langle &#92;widetilde{N}_i^m &#92;;  &#92;widetilde{&#92;Psi}_c &#92;rangle &#92;, (-c_i)^{p - m} } " class="latex" /></p>
<p>and then try to show the result goes to zero as <img src="https://s0.wp.com/latex.php?latex=%5Chbar+%5Cto+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar &#92;to 0." class="latex" />   But I don&#8217;t have the energy to do that&#8230; not right now, anyway!  </p>
<p>Maybe you do.  Or maybe you can think of a better approach to solving this problem.  The answer must be well-known, since the large-number limit of a Poisson distribution is a very important thing.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comments">30 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/" rel="bookmark" title="Permanent Link to The Large-Number Limit for Reaction Networks (Part&nbsp;2)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-16054 post type-post status-publish format-standard hentry category-mathematics" id="post-16054">
				<h2><a href="https://johncarlosbaez.wordpress.com/2013/07/05/symmetry-and-the-fourth-dimension-part-13/" rel="bookmark">Symmetry and the Fourth Dimension (Part&nbsp;13)</a></h2>
				<small>5 July, 2013</small><br />


				<div class="entry">
					<p> </p>
<div align="center"><a href="http://homepage.math.uiowa.edu/~goodman/algebrabook.dir/images.html"><img src="https://i1.wp.com/math.ucr.edu/home/baez/mathematical/octahedron_in_cube.gif" alt="" /></a><a></a></div>
<p>Now let&#8217;s start thinking about 4d Platonic solids. We&#8217;ve seen the 4-cube&#8230; what else is there? Well, in 3d we can take a cube and build an octahedron as shown here. The same trick works in any dimension. In <i>n</i> dimensions, we get something called the <i>n</i>-dimensional <b>cross-polytope</b>, which has one corner at the center of each (<i>n</i>-1)-dimensional face of the <i>n</i>-cube.</p>
<p><b>Puzzle 1.</b> What&#8217;s a 2d cross-polytope?</p>
<p>It&#8217;s worth noting the relationship between cubes and cross-polytopes is symmetrical.  In other words, we can also build an <i>n</i>-cube by putting one corner at the center of each (<i>n</i>-1)-dimensional face of the <i>n</i>-dimensional cross-polytope!  For example:</p>
<div align="center"><a href="http://homepage.math.uiowa.edu/~goodman/algebrabook.dir/images.html"><img src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/cube_in_octahedron.gif" alt="" /></a><a></a></div>
<p>It gets tiring to say &#8216;(<i>n</i>-1)-dimensional face&#8217;, so people use the word <b>facet</b> for an (<i>n</i>-1)-dimensional face of an <i>n</i>-dimensional thing.</p>
<p>Now let&#8217;s think a bit more carefully about what happens in 4 dimensions.  Since the 4-cube has 8 facets (each being a cube), the 4d cross-polytope must have 8 corners. And since the 4-cube has 16 corners, the 4d cross-polytope must have 16 facets. This is why it&#8217;s also called the <a href="http://en.wikipedia.org/wiki/16-cell"><b>16-cell</b></a>.</p>
<p>It also has other names.  Amusingly, the <a href="https://simple.wikipedia.org/wiki/16-cell">Simple English Wikipedia</a> says:</p>
<blockquote><p>
In four dimensional geometry, a <b>16-cell</b> is a regular convex polychoron, or polytope existing in four dimensions. It is also known as the <b>hexadecachoron</b>.   It is one of the six regular convex polychora first described by the Swiss mathematician Ludwig Schläfli in the mid-19th century.   Conway calls it an <b>orthoplex</b> for &#8216;orthant complex&#8217;, as well as the entire class of cross-polytopes.
</p></blockquote>
<p>Simple English, eh?  <img src="https://i2.wp.com/math.ucr.edu/home/baez/emoticons/uhh.gif" alt="" /> That would really demoralize me if I were a non-native speaker.</p>
<h3> The 4d cross-polytope </h3>
<p>But let&#8217;s sidestep the fancy words and think about what the 4d cross-polytope looks like.  To draw a cross-polytope in <i>n</i> dimensions, we can draw the <i>n</i> coordinate axes and draw a dot one inch from the origin along each axis in each direction.  Then connect each dot to every other one <i>except</i> the opposite one on the same axis.  Then erase the coordinate axes.</p>
<p>In 3 dimensions you get this:</p>
<div align="center"><a href="http://en.wikipedia.org/wiki/File:3-orthoplex.svg"><img width="300" src="https://i1.wp.com/math.ucr.edu/home/baez/mathematical/600px-3-orthoplex.png" /></a></div>
<p>It may not look like much, but it&#8217;s a perspective picture of the vertices and edges of an octahedron, or 3d cross-polytope.</p>
<p><b>Puzzle 2.</b> How many line segments going between red dots are in this picture?  These are the edges of the 3d cross-polytope.</p>
<p><b>Puzzle 3.</b> How many triangles with red corners can you see in this picture?  These are the triangular faces of the 3d cross-polytope.</p>
<p>Now let&#8217;s do the same sort of thing in 4 dimensions!  For this we can start with 4 axes in the plane, each at a 45° angle from the next.  We can then draw a dot one inch from the origin along each axis in each direction&#8230; and connect each dot to each other <i>except</i> the opposite one on the same axis.   We get this:</p>
<div align="center">
<a href="http://math.ucr.edu/home/baez/octonions/conway_smith/"><br />
<img width="350" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/cross_polytope_with_no_quaternions.jpg" /></a></div>
<p>If we then erase the axes, we get this:</p>
<div align="center"><a href="http://en.m.wikipedia.org/wiki/File:4-orthoplex.svg"><img width="300" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/600px-4-orthoplex.png" /></a></div>
<p>This a perspective picture of a 4d cross-polytope!</p>
<p><b>Puzzle 4.</b> How many line segments going between red dots are in this picture?  These are the edges of the 4d cross-polytope.</p>
<p><b>Puzzle 5.</b> How many triangles with red corners can you see in this picture?  These are the triangular 2-dimensional faces of the 4d cross-polytope.</p>
<p>Let&#8217;s say that 4d polytope has:</p>
<p>• 0-dimensional <b>vertices</b>,</p>
<p>• 1-dimensional <b>edges</b>,</p>
<p>• 2-dimensional <b>faces</b>, and</p>
<p>• 3-dimensional <b>facets</b>.</p>
<p>In general, the <a href="http://en.wikipedia.org/wiki/Facet_%28geometry%29"><b>facets</b></a> of an <i>n</i>-dimensional thing are its (<i>n</i>-1)-dimensional parts, while the parts of every dimension below <i>n</i> are often called <a href="http://en.wikipedia.org/wiki/Face_%28geometry%29"><b>faces</b></a>.  But in 4d we have enough words to be completely unambiguous, so let&#8217;s use the words as above.  And in 3d, let&#8217;s use face in its traditional sense, to mean a 2d face.</p>
<p>So, as long as I talk only about 3d and 4d geometry, you can be sure that when I say <b>face</b> I mean a 2-dimensional face.  When I say <b>facet</b>, I&#8217;ll mean a 3-dimensional face.</p>
<p><b>Puzzle 6.</b> What shape are the facets of the 4d cross-polytope?</p>
<h3> 4-cube versus 4d cross-polytope </h3>
<div align="center"><a href="http://commons.wikimedia.org/wiki/File:Hypercube_star.png"><img width="200" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/325px-hypercube_star.png" /></a></p>
<p><a href="http://en.wikipedia.org/wiki/File:4-cube_t3.svg"><br />
<img width="170" src="https://i0.wp.com/math.ucr.edu/home/baez/mathematical/325px-4d_cross-polytope.png" /></a></div>
<p>On top you see the 4-cube. At right, the 4d cross-polytope. Both are projected down to the plane in the same way.</p>
<p>So, the 4d cross-polytope has</p>
<div align="center">
2 × 4 = 8
</div>
<p>vertices: one centered at each cubical facet of the 4-cube. To see how this works, mentally move the cross-polytope up and put it on top of the 4-cube.</p>
<p>On the other hand, the 4d cross-polytope has</p>
<div align="center">
2<sup>4</sup> = 16
</div>
<p>facets: one for each corner of the 4-cube.</p>
<p>And this is a general pattern.  As I already observed, the <i>n</i>-dimensional cross-polytope has one vertex in the middle of each facet of the <i>n</i>-cube, and vice versa.  For this reason we say they are <b>Poincaré dual</b> to each other, or simply <b>dual</b>.  The <i>n</i>-cube has</p>
<div align="center">
2 × <i>n</i>
</div>
<p>vertices and</p>
<div align="center">
2<sup><i>n</i></sup>
</div>
<p>facets, but for the <i>n</i>-dimensional cross-polytope it&#8217;s the other way around.</p>
<h3> Figure credits and more </h3>
<p>The picture of the octahedron in cube and cube in octahedron are from <a href="http://homepage.math.uiowa.edu/~goodman/algebrabook.dir/images.html">Frederick J. Goodman</a>, who has written a book about this stuff called <i>Algebra: Abstract and Concrete</i>.</p>
<p>The other images are on Wikimedia Commons, and all have been released into the public domain except this one:</p>
<div align="center"><a href="http://commons.wikimedia.org/wiki/File:Hypercube_star.png"><img width="200" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/325px-hypercube_star.png" /></a></div>
<p>which was made by Markus Krötzsch.</p>
<p>For more on cross-polytopes, see this:</p>
<p>• <a href="http://en.wikipedia.org/wiki/Cross-polytope">Cross-polytope</a>, Wikipedia.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/07/05/symmetry-and-the-fourth-dimension-part-13/#comments">14 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2013/07/05/symmetry-and-the-fourth-dimension-part-13/" rel="bookmark" title="Permanent Link to Symmetry and the Fourth Dimension (Part&nbsp;13)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
		<div class="navigation">
			<div class="alignleft"><a href="https://johncarlosbaez.wordpress.com/category/mathematics/page/35/" >&laquo; Previous Entries</a></div>
			<div class="alignright"><a href="https://johncarlosbaez.wordpress.com/category/mathematics/page/33/" >Next Entries &raquo;</a></div>
		</div>

	
	</div>

	<div id="sidebar">
				<ul>

		 <li>

				<p>You are currently browsing the archives for the mathematics category.</p>

					</li> 
		<li id="recent-posts-3" class="widget widget_recent_entries">
		<h2 class="widgettitle">latest posts:</h2>

		<ul>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/26/classical-mechanics-versus-thermodynamics-part-4/">Classical Mechanics versus Thermodynamics (Part&nbsp;4)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/">Classical Mechanics versus Thermodynamics (Part&nbsp;3)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/22/maxwells-relations-part-3/">Maxwell&#8217;s Relations (Part&nbsp;3)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/18/maxwells-relations-part-two/">Maxwell&#8217;s Relations (Part&nbsp;2)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/17/maxwells-relations-part-1/">Maxwell&#8217;s Relations (Part&nbsp;1)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/13/the-cyclic-identity-for-partial-derivatives/">The Cyclic Identity for Partial&nbsp;Derivatives</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/17/information-geometry-part-21/">Information Geometry (Part&nbsp;21)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/14/information-geometry-part-20/">Information Geometry (Part&nbsp;20)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/08/information-geometry-part-19/">Information Geometry (Part&nbsp;19)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/05/information-geometry-part-18/">Information Geometry (Part&nbsp;18)</a>
									</li>
					</ul>

		</li>
<li id="recent-comments-2" class="widget widget_recent_comments"><h2 class="widgettitle">latest comments:</h2>
				<table class="recentcommentsavatar" cellspacing="0" cellpadding="0" border="0">
					<tr><td title="Peter Morgan" class="recentcommentsavatartop" style="height:32px; width:32px;"><img alt='' src='https://0.gravatar.com/avatar/cd90f0688cecdf25a11b4ba396151b5f?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstexttop" style="">Peter Morgan on <a href="https://johncarlosbaez.wordpress.com/2021/09/26/classical-mechanics-versus-thermodynamics-part-4/#comment-172599">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="Toby Bartels" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://tobybartels.name/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/68c7b083965f5073c50bf7c8d2aac358?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://tobybartels.name/" rel="nofollow">Toby Bartels</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172598">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="David Corfield" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">David Corfield on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172597">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="Toby Bartels" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://tobybartels.name/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/68c7b083965f5073c50bf7c8d2aac358?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://tobybartels.name/" rel="nofollow">Toby Bartels</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/26/classical-mechanics-versus-thermodynamics-part-4/#comment-172596">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="David Corfield" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://lh3.googleusercontent.com/a/AATXAJxXcoKzwm_cY3LJp3qldhAQvZVoBimQd4xe5tDl=s96-c' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">David Corfield on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172590">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="amarashiki" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://gravatar.com/amarashiki" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/62b2df0762257e75433ad6f161488c3a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://gravatar.com/amarashiki" rel="nofollow">amarashiki</a> on <a href="https://johncarlosbaez.wordpress.com/2012/01/23/classical-mechanics-versus-thermodynamics-part-2/#comment-172566">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="John Baez" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://math.ucr.edu/home/baez/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://math.ucr.edu/home/baez/" rel="nofollow">John Baez</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172560">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="domenico" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://2.gravatar.com/avatar/ba06491deb8346d20356ac2ae05893ee?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">domenico on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172559">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="domenico" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://2.gravatar.com/avatar/ba06491deb8346d20356ac2ae05893ee?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">domenico on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172558">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="Maxwell Relations | Equivalent eXchange" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow"></a></td><td class="recentcommentstextend" style=""><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow">Maxwell Relations |&hellip;</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/22/maxwells-relations-part-3/#comment-172557">Maxwell&#8217;s Relations (Par&hellip;</a></td></tr>				</table>
				</li>
<li id="text-3" class="widget widget_text"><h2 class="widgettitle">How To Write Math Here:</h2>
			<div class="textwidget"><p>You can <a href="http://en.wikibooks.org/wiki/LaTeX/Mathematics">include math in your comments using LaTeX</a>,  but you need to do it this way:</p>
<p>&#036;latex  E = mc^2&#036;</p>
<p>You need the word 'latex' right after the first dollar sign, and it needs a space after it.  Double dollar signs don't work, and other limitations apply, some described <a href="http://en.support.wordpress.com/latex/">here</a>.  You can't preview comments here, but I'm happy to fix errors.</p>
</div>
		</li>
<li id="categories-2" class="widget widget_categories"><h2 class="widgettitle">Read Posts On:</h2>

			<ul>
					<li class="cat-item cat-item-177"><a href="https://johncarlosbaez.wordpress.com/category/art/">art</a> (3)
</li>
	<li class="cat-item cat-item-4003"><a href="https://johncarlosbaez.wordpress.com/category/astronomy/">astronomy</a> (29)
</li>
	<li class="cat-item cat-item-8262191"><a href="https://johncarlosbaez.wordpress.com/category/azimuth/">azimuth</a> (60)
</li>
	<li class="cat-item cat-item-86856"><a href="https://johncarlosbaez.wordpress.com/category/biodiversity/">biodiversity</a> (38)
</li>
	<li class="cat-item cat-item-4936"><a href="https://johncarlosbaez.wordpress.com/category/biology/">biology</a> (107)
</li>
	<li class="cat-item cat-item-355244"><a href="https://johncarlosbaez.wordpress.com/category/carbon-emissions/">carbon emissions</a> (78)
</li>
	<li class="cat-item cat-item-5936"><a href="https://johncarlosbaez.wordpress.com/category/chemistry/">chemistry</a> (74)
</li>
	<li class="cat-item cat-item-6108"><a href="https://johncarlosbaez.wordpress.com/category/climate/">climate</a> (155)
</li>
	<li class="cat-item cat-item-5043"><a href="https://johncarlosbaez.wordpress.com/category/computer-science/">computer science</a> (57)
</li>
	<li class="cat-item cat-item-9204"><a href="https://johncarlosbaez.wordpress.com/category/conferences/">conferences</a> (81)
</li>
	<li class="cat-item cat-item-1098"><a href="https://johncarlosbaez.wordpress.com/category/culture/">culture</a> (4)
</li>
	<li class="cat-item cat-item-657"><a href="https://johncarlosbaez.wordpress.com/category/economics/">economics</a> (32)
</li>
	<li class="cat-item cat-item-1212"><a href="https://johncarlosbaez.wordpress.com/category/energy/">energy</a> (50)
</li>
	<li class="cat-item cat-item-25393"><a href="https://johncarlosbaez.wordpress.com/category/engineering/">engineering</a> (11)
</li>
	<li class="cat-item cat-item-14852"><a href="https://johncarlosbaez.wordpress.com/category/mathematics/game-theory/">game theory</a> (29)
</li>
	<li class="cat-item cat-item-1215"><a href="https://johncarlosbaez.wordpress.com/category/geography/">geography</a> (4)
</li>
	<li class="cat-item cat-item-337"><a href="https://johncarlosbaez.wordpress.com/category/health/">health</a> (4)
</li>
	<li class="cat-item cat-item-678"><a href="https://johncarlosbaez.wordpress.com/category/history/">history</a> (2)
</li>
	<li class="cat-item cat-item-23375499"><a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/">information and entropy</a> (92)
</li>
	<li class="cat-item cat-item-3558"><a href="https://johncarlosbaez.wordpress.com/category/jobs/">jobs</a> (11)
</li>
	<li class="cat-item cat-item-5465"><a href="https://johncarlosbaez.wordpress.com/category/journals/">journals</a> (5)
</li>
	<li class="cat-item cat-item-3582 current-cat"><a aria-current="page" href="https://johncarlosbaez.wordpress.com/category/mathematics/">mathematics</a> (479)
</li>
	<li class="cat-item cat-item-18"><a href="https://johncarlosbaez.wordpress.com/category/music/">music</a> (3)
</li>
	<li class="cat-item cat-item-3968"><a href="https://johncarlosbaez.wordpress.com/category/networks/">networks</a> (185)
</li>
	<li class="cat-item cat-item-154934"><a href="https://johncarlosbaez.wordpress.com/category/oceans/">oceans</a> (13)
</li>
	<li class="cat-item cat-item-1211"><a href="https://johncarlosbaez.wordpress.com/category/physics/">physics</a> (205)
</li>
	<li class="cat-item cat-item-10451"><a href="https://johncarlosbaez.wordpress.com/category/probability/">probability</a> (92)
</li>
	<li class="cat-item cat-item-4909"><a href="https://johncarlosbaez.wordpress.com/category/psychology/">psychology</a> (6)
</li>
	<li class="cat-item cat-item-3330"><a href="https://johncarlosbaez.wordpress.com/category/publishing/">publishing</a> (19)
</li>
	<li class="cat-item cat-item-46615"><a href="https://johncarlosbaez.wordpress.com/category/puzzles/">puzzles</a> (14)
</li>
	<li class="cat-item cat-item-4140243"><a href="https://johncarlosbaez.wordpress.com/category/quantum-technologies/">quantum technologies</a> (28)
</li>
	<li class="cat-item cat-item-562"><a href="https://johncarlosbaez.wordpress.com/category/questions/">questions</a> (3)
</li>
	<li class="cat-item cat-item-93974"><a href="https://johncarlosbaez.wordpress.com/category/risks/">risks</a> (48)
</li>
	<li class="cat-item cat-item-37893"><a href="https://johncarlosbaez.wordpress.com/category/seminars/">seminars</a> (21)
</li>
	<li class="cat-item cat-item-581"><a href="https://johncarlosbaez.wordpress.com/category/software/">software</a> (19)
</li>
	<li class="cat-item cat-item-39438"><a href="https://johncarlosbaez.wordpress.com/category/strategies/">strategies</a> (36)
</li>
	<li class="cat-item cat-item-6877"><a href="https://johncarlosbaez.wordpress.com/category/sustainability/">sustainability</a> (71)
</li>
	<li class="cat-item cat-item-66608272"><a href="https://johncarlosbaez.wordpress.com/category/the-practice-of-science/">the practice of science</a> (27)
</li>
	<li class="cat-item cat-item-61590"><a href="https://johncarlosbaez.wordpress.com/category/this-weeks-finds/">this week&#039;s finds</a> (18)
</li>
			</ul>

			</li>
<li id="linkcat-20924250" class="widget widget_links"><h2 class="widgettitle">also visit these:</h2>

	<ul class='xoxo blogroll'>
<li><a href="http://www.azimuthproject.org/azimuth/show/Azimuth+Blog" title="Go here to see what’s on this blog, organized by topic or author!">Azimuth Blog Overview</a></li>
<li><a href="http://www.azimuthproject.org/azimuth/show/HomePage" title="for scientists and engineers who want to save the planet">Azimuth Project</a></li>
<li><a href="http://bittooth.blogspot.com/" title="David Summers on energy: oil, gas and more">Bit Tooth Energy</a></li>
<li><a href="http://bravenewclimate.com/" title="Barry Brooks on climate and energy policy">Brave New Climate</a></li>
<li><a href="http://physics.ucsd.edu/do-the-math/" title="UC San Diego prof uses physics and estimation to assess energy, growth, options">Do the Math</a></li>
<li><a href="http://dotearth.blogs.nytimes.com/" title="Andrew Revkin’s environmental blog on the New York Times">Dot Earth</a></li>
<li><a href="http://e360.yale.edu/" title="News from the Yale School of Forestry &amp; Environmental Studies">Environment 360</a></li>
<li><a href="http://planet3.org/" title="A metablog on sustainability">Planet3.0</a></li>
<li><a href="http://www.realclimate.org/" title="climate science from climate scientists">RealClimate</a></li>
<li><a href="http://www.easterbrook.ca/steve/" title="Steve Easterbrook&#8217;s blog on software engineering and climate modeling">Serendipity</a></li>
<li><a href="http://scienceofdoom.com/" title="climate science in perspective">The Science of Doom</a></li>
<li><a href="http://e360.yale.edu/" title="opinion, analysis, reporting and debate on environmental issues">Yale Environment 360</a></li>

	</ul>
</li>

<li id="rss_links-3" class="widget widget_rss_links"><h2 class="widgettitle">RSS feeds:</h2>
<p class="size-small"><a class="feed-image-link" href="https://johncarlosbaez.wordpress.com/feed/" title="Subscribe to Posts"><img src="https://johncarlosbaez.wordpress.com/i/rss/red-small.png?m=1391188133h" alt="RSS Feed" /></a>&nbsp;<a href="https://johncarlosbaez.wordpress.com/feed/" title="Subscribe to Posts">RSS - Posts</a></p><p class="size-small"><a class="feed-image-link" href="https://johncarlosbaez.wordpress.com/comments/feed/" title="Subscribe to Comments"><img src="https://johncarlosbaez.wordpress.com/i/rss/red-small.png?m=1391188133h" alt="RSS Feed" /></a>&nbsp;<a href="https://johncarlosbaez.wordpress.com/comments/feed/" title="Subscribe to Comments">RSS - Comments</a></p>
</li>
<li id="blog_subscription-3" class="widget widget_blog_subscription jetpack_subscription_widget"><h2 class="widgettitle"><label for="subscribe-field">Email Subscription:</label></h2>

			<form
				action="https://subscribe.wordpress.com"
				method="post"
				accept-charset="utf-8"
				id=""
			>
				<p>Enter your email address to subscribe to this blog and receive notifications of new posts by email.</p>
					<div class="jetpack-subscribe-count">
						<p>
						Join 5,211 other followers						</p>
					</div>
									<p id="subscribe-email">
					<label
						id="subscribe-field-label"
						for="subscribe-field"
						class="screen-reader-text"
					>
						Email Address:					</label>

					<input
							type="email"
							name="email"
							
							style="width: 95%; padding: 1px 10px"
							placeholder="Enter your email address"
							value=""
							id="subscribe-field"
						/>				</p>

				<p id="subscribe-submit"
									>
                    <input type="hidden" name="action" value="subscribe"/>
                    <input type="hidden" name="blog_id" value="12777403"/>
                    <input type="hidden" name="source" value="https://johncarlosbaez.wordpress.com/category/mathematics/page/34/"/>
                    <input type="hidden" name="sub-type" value="widget"/>
                    <input type="hidden" name="redirect_fragment" value="blog_subscription-3"/>
					<input type="hidden" id="_wpnonce" name="_wpnonce" value="ffcb185558" />                    <button type="submit"
	                    	                        class="wp-block-button__link"
	                    		                	                >
	                    Sign me up!                    </button>
                </p>
            </form>
			
</li>
<li id="search-3" class="widget widget_search"><h2 class="widgettitle">SEARCH:</h2>
<form method="get" id="searchform" action="https://johncarlosbaez.wordpress.com/">
<div><label for="s" class="search-label">Search</label><input type="text" value="" name="s" id="s" />
<input type="submit" id="searchsubmit" value="Search" />
</div>
</form></li>
<li id="blog-stats-2" class="widget widget_blog-stats"><h2 class="widgettitle">Blog Stats:</h2>
		<ul>
			<li>4,177,668 hits</li>
		</ul>
		</li>
		</ul>
	</div>



<div id="footer">
	<p>
	<br />
	<a href="https://wordpress.com/?ref=footer_blog" rel="nofollow">Blog at WordPress.com.</a>
	</p>
</div>

</div>

				<script type="text/javascript">
		//<![CDATA[
		var infiniteScroll = JSON.parse( decodeURIComponent( '%7B%22settings%22%3A%7B%22id%22%3A%22content%22%2C%22ajaxurl%22%3A%22https%3A%5C%2F%5C%2Fjohncarlosbaez.wordpress.com%5C%2F%3Finfinity%3Dscrolling%22%2C%22type%22%3A%22scroll%22%2C%22wrapper%22%3Atrue%2C%22wrapper_class%22%3A%22infinite-wrap%22%2C%22footer%22%3Atrue%2C%22click_handle%22%3A%221%22%2C%22text%22%3A%22Older%20posts%22%2C%22totop%22%3A%22Scroll%20back%20to%20top%22%2C%22currentday%22%3A%2205.07.13%22%2C%22order%22%3A%22DESC%22%2C%22scripts%22%3A%5B%5D%2C%22styles%22%3A%5B%5D%2C%22google_analytics%22%3Afalse%2C%22offset%22%3A34%2C%22history%22%3A%7B%22host%22%3A%22johncarlosbaez.wordpress.com%22%2C%22path%22%3A%22%5C%2Fcategory%5C%2Fmathematics%5C%2Fpage%5C%2F%25d%5C%2F%22%2C%22use_trailing_slashes%22%3Atrue%2C%22parameters%22%3A%22%22%7D%2C%22query_args%22%3A%7B%22paged%22%3A34%2C%22category_name%22%3A%22mathematics%22%2C%22error%22%3A%22%22%2C%22m%22%3A%22%22%2C%22p%22%3A0%2C%22post_parent%22%3A%22%22%2C%22subpost%22%3A%22%22%2C%22subpost_id%22%3A%22%22%2C%22attachment%22%3A%22%22%2C%22attachment_id%22%3A0%2C%22name%22%3A%22%22%2C%22pagename%22%3A%22%22%2C%22page_id%22%3A0%2C%22second%22%3A%22%22%2C%22minute%22%3A%22%22%2C%22hour%22%3A%22%22%2C%22day%22%3A0%2C%22monthnum%22%3A0%2C%22year%22%3A0%2C%22w%22%3A0%2C%22tag%22%3A%22%22%2C%22cat%22%3A3582%2C%22tag_id%22%3A%22%22%2C%22author%22%3A%22%22%2C%22author_name%22%3A%22%22%2C%22feed%22%3A%22%22%2C%22tb%22%3A%22%22%2C%22meta_key%22%3A%22%22%2C%22meta_value%22%3A%22%22%2C%22preview%22%3A%22%22%2C%22s%22%3A%22%22%2C%22sentence%22%3A%22%22%2C%22title%22%3A%22%22%2C%22fields%22%3A%22%22%2C%22menu_order%22%3A%22%22%2C%22embed%22%3A%22%22%2C%22category__in%22%3A%5B%5D%2C%22category__not_in%22%3A%5B%5D%2C%22category__and%22%3A%5B%5D%2C%22post__in%22%3A%5B%5D%2C%22post__not_in%22%3A%5B%5D%2C%22post_name__in%22%3A%5B%5D%2C%22tag__in%22%3A%5B%5D%2C%22tag__not_in%22%3A%5B%5D%2C%22tag__and%22%3A%5B%5D%2C%22tag_slug__in%22%3A%5B%5D%2C%22tag_slug__and%22%3A%5B%5D%2C%22post_parent__in%22%3A%5B%5D%2C%22post_parent__not_in%22%3A%5B%5D%2C%22author__in%22%3A%5B%5D%2C%22author__not_in%22%3A%5B%5D%2C%22lazy_load_term_meta%22%3Afalse%2C%22posts_per_page%22%3A10%2C%22ignore_sticky_posts%22%3Afalse%2C%22suppress_filters%22%3Afalse%2C%22cache_results%22%3Afalse%2C%22update_post_term_cache%22%3Atrue%2C%22update_post_meta_cache%22%3Atrue%2C%22post_type%22%3A%22%22%2C%22nopaging%22%3Afalse%2C%22comments_per_page%22%3A%22100%22%2C%22no_found_rows%22%3Afalse%2C%22order%22%3A%22DESC%22%7D%2C%22query_before%22%3A%222021-09-26%2018%3A39%3A20%22%2C%22last_post_date%22%3A%222013-07-05%2008%3A15%3A38%22%2C%22body_class%22%3A%22infinite-scroll%20neverending%22%2C%22loading_text%22%3A%22Loading%20new%20page%22%2C%22stats%22%3A%22blog%3D12777403%26v%3Dwpcom%26tz%3D0%26user_id%3D0%26subd%3Djohncarlosbaez%26x_pagetype%3Dinfinite%22%7D%7D' ) );
		//]]>
		</script>
		<!--  -->
<script src='//0.gravatar.com/js/gprofiles.js?ver=202138y' id='grofiles-cards-js'></script>
<script id='wpgroho-js-extra'>
var WPGroHo = {"my_hash":""};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s1.wp.com/wp-content/mu-plugins/gravatar-hovercards/wpgroho.js?m=1610363240h'></script>

	<script>
		// Initialize and attach hovercards to all gravatars
		( function() {
			function init() {
				if ( typeof Gravatar === 'undefined' ) {
					return;
				}

				if ( typeof Gravatar.init !== 'function' ) {
					return;
				}

				Gravatar.profile_cb = function ( hash, id ) {
					WPGroHo.syncProfileData( hash, id );
				};

				Gravatar.my_hash = WPGroHo.my_hash;
				Gravatar.init( 'body', '#wp-admin-bar-my-account' );
			}

			if ( document.readyState !== 'loading' ) {
				init();
			} else {
				document.addEventListener( 'DOMContentLoaded', init );
			}
		} )();
	</script>

		<div style="display:none">
	<div class="grofile-hash-map-cd90f0688cecdf25a11b4ba396151b5f">
	</div>
	<div class="grofile-hash-map-68c7b083965f5073c50bf7c8d2aac358">
	</div>
	<div class="grofile-hash-map-34784534843022b3541c8ddd693718cb">
	</div>
	<div class="grofile-hash-map-7d52fbe20c8ac05886a296e9ee2159b1">
	</div>
	<div class="grofile-hash-map-62b2df0762257e75433ad6f161488c3a">
	</div>
	<div class="grofile-hash-map-ba06491deb8346d20356ac2ae05893ee">
	</div>
	</div>
		<div id="infinite-footer">
			<div class="container">
				<div class="blog-info">
					<a id="infinity-blog-title" href="https://johncarlosbaez.wordpress.com/" rel="home">
						Azimuth					</a>
				</div>
				<div class="blog-credits">
					<a href="https://wordpress.com/?ref=footer_blog" rel="nofollow">Blog at WordPress.com.</a> 				</div>
			</div>
		</div><!-- #infinite-footer -->
		
<script>
window.addEventListener( "load", function( event ) {
	var link = document.createElement( "link" );
	link.href = "https://s0.wp.com/wp-content/mu-plugins/actionbar/actionbar.css?v=20210915";
	link.type = "text/css";
	link.rel = "stylesheet";
	document.head.appendChild( link );

	var script = document.createElement( "script" );
	script.src = "https://s0.wp.com/wp-content/mu-plugins/actionbar/actionbar.js?v=20210920";
	script.defer = true;
	document.body.appendChild( script );
} );
</script>

			<div id="jp-carousel-loading-overlay">
			<div id="jp-carousel-loading-wrapper">
				<span id="jp-carousel-library-loading">&nbsp;</span>
			</div>
		</div>
		<div class="jp-carousel-overlay" style="display: none;">

		<div class="jp-carousel-container">
			<!-- The Carousel Swiper -->
			<div
				class="jp-carousel-wrap swiper-container jp-carousel-swiper-container jp-carousel-transitions"
				itemscope
				itemtype="https://schema.org/ImageGallery">
				<div class="jp-carousel swiper-wrapper"></div>
				<div class="jp-swiper-button-prev swiper-button-prev">
					<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
						<mask id="maskPrev" mask-type="alpha" maskUnits="userSpaceOnUse" x="8" y="6" width="9" height="12">
							<path d="M16.2072 16.59L11.6496 12L16.2072 7.41L14.8041 6L8.8335 12L14.8041 18L16.2072 16.59Z" fill="white"/>
						</mask>
						<g mask="url(#maskPrev)">
							<rect x="0.579102" width="23.8823" height="24" fill="#FFFFFF"/>
						</g>
					</svg>
				</div>
				<div class="jp-swiper-button-next swiper-button-next">
					<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
						<mask id="maskNext" mask-type="alpha" maskUnits="userSpaceOnUse" x="8" y="6" width="8" height="12">
							<path d="M8.59814 16.59L13.1557 12L8.59814 7.41L10.0012 6L15.9718 12L10.0012 18L8.59814 16.59Z" fill="white"/>
						</mask>
						<g mask="url(#maskNext)">
							<rect x="0.34375" width="23.8822" height="24" fill="#FFFFFF"/>
						</g>
					</svg>
				</div>
			</div>
			<!-- The main close buton -->
			<div class="jp-carousel-close-hint">
				<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
					<mask id="maskClose" mask-type="alpha" maskUnits="userSpaceOnUse" x="5" y="5" width="15" height="14">
						<path d="M19.3166 6.41L17.9135 5L12.3509 10.59L6.78834 5L5.38525 6.41L10.9478 12L5.38525 17.59L6.78834 19L12.3509 13.41L17.9135 19L19.3166 17.59L13.754 12L19.3166 6.41Z" fill="white"/>
					</mask>
					<g mask="url(#maskClose)">
						<rect x="0.409668" width="23.8823" height="24" fill="#FFFFFF"/>
					</g>
				</svg>
			</div>
			<!-- Image info, comments and meta -->
			<div class="jp-carousel-info">
				<div class="jp-carousel-info-footer">
					<div class="jp-carousel-pagination-container">
						<div class="jp-swiper-pagination swiper-pagination"></div>
						<div class="jp-carousel-pagination"></div>
					</div>
					<div class="jp-carousel-photo-title-container">
						<h2 class="jp-carousel-photo-caption"></h2>
					</div>
					<div class="jp-carousel-photo-icons-container">
						<a href="#" class="jp-carousel-icon-btn jp-carousel-icon-info" aria-label="Toggle photo metadata visibility">
							<span class="jp-carousel-icon">
								<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
									<mask id="maskInfo" mask-type="alpha" maskUnits="userSpaceOnUse" x="2" y="2" width="21" height="20">
										<path fill-rule="evenodd" clip-rule="evenodd" d="M12.7537 2C7.26076 2 2.80273 6.48 2.80273 12C2.80273 17.52 7.26076 22 12.7537 22C18.2466 22 22.7046 17.52 22.7046 12C22.7046 6.48 18.2466 2 12.7537 2ZM11.7586 7V9H13.7488V7H11.7586ZM11.7586 11V17H13.7488V11H11.7586ZM4.79292 12C4.79292 16.41 8.36531 20 12.7537 20C17.142 20 20.7144 16.41 20.7144 12C20.7144 7.59 17.142 4 12.7537 4C8.36531 4 4.79292 7.59 4.79292 12Z" fill="white"/>
									</mask>
									<g mask="url(#maskInfo)">
										<rect x="0.8125" width="23.8823" height="24" fill="#FFFFFF"/>
									</g>
								</svg>
							</span>
						</a>
												<a href="#" class="jp-carousel-icon-btn jp-carousel-icon-comments" aria-label="Toggle photo comments visibility">
							<span class="jp-carousel-icon">
								<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
									<mask id="maskComments" mask-type="alpha" maskUnits="userSpaceOnUse" x="2" y="2" width="21" height="20">
										<path fill-rule="evenodd" clip-rule="evenodd" d="M4.3271 2H20.2486C21.3432 2 22.2388 2.9 22.2388 4V16C22.2388 17.1 21.3432 18 20.2486 18H6.31729L2.33691 22V4C2.33691 2.9 3.2325 2 4.3271 2ZM6.31729 16H20.2486V4H4.3271V18L6.31729 16Z" fill="white"/>
									</mask>
									<g mask="url(#maskComments)">
										<rect x="0.34668" width="23.8823" height="24" fill="#FFFFFF"/>
									</g>
								</svg>

								<span class="jp-carousel-has-comments-indicator" aria-label="This image has comments."></span>
							</span>
						</a>
											</div>
				</div>
				<div class="jp-carousel-info-extra">
					<div class="jp-carousel-info-content-wrapper">
						<div class="jp-carousel-photo-title-container">
							<h2 class="jp-carousel-photo-title"></h2>
						</div>
						<div class="jp-carousel-comments-wrapper">
															<div id="jp-carousel-comments-loading">
									<span>Loading Comments...</span>
								</div>
								<div class="jp-carousel-comments"></div>
								<div id="jp-carousel-comment-form-container">
									<span id="jp-carousel-comment-form-spinner">&nbsp;</span>
									<div id="jp-carousel-comment-post-results"></div>
																														<form id="jp-carousel-comment-form">
												<label for="jp-carousel-comment-form-comment-field" class="screen-reader-text">Write a Comment...</label>
												<textarea
													name="comment"
													class="jp-carousel-comment-form-field jp-carousel-comment-form-textarea"
													id="jp-carousel-comment-form-comment-field"
													placeholder="Write a Comment..."
												></textarea>
												<div id="jp-carousel-comment-form-submit-and-info-wrapper">
													<div id="jp-carousel-comment-form-commenting-as">
																													<fieldset>
																<label for="jp-carousel-comment-form-email-field">Email (Required)</label>
																<input type="text" name="email" class="jp-carousel-comment-form-field jp-carousel-comment-form-text-field" id="jp-carousel-comment-form-email-field" />
															</fieldset>
															<fieldset>
																<label for="jp-carousel-comment-form-author-field">Name (Required)</label>
																<input type="text" name="author" class="jp-carousel-comment-form-field jp-carousel-comment-form-text-field" id="jp-carousel-comment-form-author-field" />
															</fieldset>
															<fieldset>
																<label for="jp-carousel-comment-form-url-field">Website</label>
																<input type="text" name="url" class="jp-carousel-comment-form-field jp-carousel-comment-form-text-field" id="jp-carousel-comment-form-url-field" />
															</fieldset>
																											</div>
													<input
														type="submit"
														name="submit"
														class="jp-carousel-comment-form-button"
														id="jp-carousel-comment-form-button-submit"
														value="Post Comment" />
												</div>
											</form>
																											</div>
													</div>
						<div class="jp-carousel-image-meta">
							<div class="jp-carousel-title-and-caption">
								<div class="jp-carousel-photo-info">
									<h3 class="jp-carousel-caption" itemprop="caption description"></h3>
								</div>

								<div class="jp-carousel-photo-description"></div>
							</div>
							<ul class="jp-carousel-image-exif" style="display: none;"></ul>
							<a class="jp-carousel-image-download" target="_blank" style="display: none;">
								<svg width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
									<mask id="mask0" mask-type="alpha" maskUnits="userSpaceOnUse" x="3" y="3" width="19" height="18">
										<path fill-rule="evenodd" clip-rule="evenodd" d="M5.84615 5V19H19.7775V12H21.7677V19C21.7677 20.1 20.8721 21 19.7775 21H5.84615C4.74159 21 3.85596 20.1 3.85596 19V5C3.85596 3.9 4.74159 3 5.84615 3H12.8118V5H5.84615ZM14.802 5V3H21.7677V10H19.7775V6.41L9.99569 16.24L8.59261 14.83L18.3744 5H14.802Z" fill="white"/>
									</mask>
									<g mask="url(#mask0)">
										<rect x="0.870605" width="23.8823" height="24" fill="#FFFFFF"/>
									</g>
								</svg>
								<span class="jp-carousel-download-text"></span>
							</a>
							<div class="jp-carousel-image-map" style="display: none;"></div>
						</div>
					</div>
				</div>
			</div>
		</div>

		</div>
		<link rel='stylesheet' id='all-css-0-2' href='https://s1.wp.com/_static/??-eJyFy00OQDAQQOELGUP8xUKcpWoiZVTTadO4vVhY2LB8L/kwOdCHDWQD7hEcx8VYQa38EYUYJRlHHqZoZ6Zci2T4I1YKTukNnvGFgmGaYVHM5M933Wzch7Ktir5p+rpbL+lvP34=?cssminify=yes' type='text/css' media='all' />
<script id='jetpack-carousel-js-extra'>
var jetpackSwiperLibraryPath = {"url":"\/wp-content\/mu-plugins\/carousel\/swiper-bundle.js"};
var jetpackCarouselStrings = {"widths":[370,700,1000,1200,1400,2000],"is_logged_in":"","lang":"en","ajaxurl":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/admin-ajax.php","nonce":"805b669379","display_exif":"1","display_comments":"1","display_geo":"1","single_image_gallery":"1","single_image_gallery_media_file":"","background_color":"black","comment":"Comment","post_comment":"Post Comment","write_comment":"Write a Comment...","loading_comments":"Loading Comments...","download_original":"View full size <span class=\"photo-size\">{0}<span class=\"photo-size-times\">\u00d7<\/span>{1}<\/span>","no_comment_text":"Please be sure to submit some text with your comment.","no_comment_email":"Please provide an email address to comment.","no_comment_author":"Please provide your name to comment.","comment_post_error":"Sorry, but there was an error posting your comment. Please try again later.","comment_approved":"Your comment was approved.","comment_unapproved":"Your comment is in moderation.","camera":"Camera","aperture":"Aperture","shutter_speed":"Shutter Speed","focal_length":"Focal Length","copyright":"Copyright","comment_registration":"0","require_name_email":"1","login_url":"https:\/\/johncarlosbaez.wordpress.com\/wp-login.php?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2013%2F09%2F29%2Flevels-of-excellence%2F","blog_id":"12777403","meta_data":["camera","aperture","shutter_speed","focal_length","copyright"],"stats_query_args":"blog=12777403&v=wpcom&tz=0&user_id=0&subd=johncarlosbaez","is_public":"1"};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s1.wp.com/_static/??-eJyNUMtuwzAM+6EpRnIo0MOwb3FsNZDr1yy5af5+ztAMbTYEO0mURVKmmjOYFAWjKMfK4o0M5nvn+E09PYUK2deJIiuKF4oky09zsKttoAijLipoFiytAynaXHlPat7us2JZHqWbs0kBckn3BQq2GcvGoWh8tcgrqUEMI9quGR0cYnRJldErh5KbP2yDA85MdkJhxXVkUygLpch/3cDzJY0OjezFNqUbWUxKM69y7oFzQf4Vw5O9kEcLk/Z+TeUF/eOj8J3fDjbeR3jvT8P53A/DqXdfJ9bAHw=='></script>
<script type="text/javascript">
// <![CDATA[
(function() {
try{
  if ( window.external &&'msIsSiteMode' in window.external) {
    if (window.external.msIsSiteMode()) {
      var jl = document.createElement('script');
      jl.type='text/javascript';
      jl.async=true;
      jl.src='/wp-content/plugins/ie-sitemode/custom-jumplist.php';
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(jl, s);
    }
  }
}catch(e){}
})();
// ]]>
</script><script type="text/javascript">
			(function() {
				var extend = function(out) {
					out = out || {};

					for (var i = 1; i < arguments.length; i++) {
						if (!arguments[i])
						continue;

						for (var key in arguments[i]) {
						if (arguments[i].hasOwnProperty(key))
							out[key] = arguments[i][key];
						}
					}

					return out;
				};
				extend( window.infiniteScroll.settings.scripts, ["postmessage","mobile-useragent-info","rlt-proxy","jquery-core","jquery-migrate","jquery","wpcom-actionbar-placeholder","grofiles-cards","wpgroho","devicepx","the-neverending-homepage","wpcom-masterbar-tracks-js","jquery.wpcom-proxy-request","wp-embed","jetpack-carousel","jetpack-subscriptions-js","swfobject","videopress","tiled-gallery","carousel-wpcom"] );
				extend( window.infiniteScroll.settings.styles, ["the-neverending-homepage","infinity-contempt","wp-block-library","mediaelement","wp-mediaelement","jetpack-layout-grid","jetpack-ratings","coblocks-frontend","wpcom-core-compat-playlist-styles","wpcom-text-widget-styles","wpcom-bbpress2-staff-css","contempt","geo-location-flair","reblogging","a8c-global-print","h4-global","global-styles","jetpack-global-styles-frontend-style","jetpack-carousel-swiper-css","jetpack-carousel","tiled-gallery"] );
			})();
		</script>
				<span id="infinite-aria" aria-live="polite"></span>
		<script src="//stats.wp.com/w.js?62" defer></script> <script type="text/javascript">
_tkq = window._tkq || [];
_stq = window._stq || [];
_tkq.push(['storeContext', {'blog_id':'12777403','blog_tz':'0','user_lang':'en','blog_lang':'en','user_id':'0'}]);
_stq.push(['view', {'blog':'12777403','v':'wpcom','tz':'0','user_id':'0','subd':'johncarlosbaez'}]);
_stq.push(['extra', {'crypt':'UE40eW5QN0p8M2Y/RE1TaVhzUzFMbjdWNHpwZGhTayxPSUFCMGNrd29+Smw0TDhnZmRTK0hlRi9QSGh6bi9GXVhBJWIlZlR5U1JMLU8/MkNtblkvY1d6eVImTEouL2UleTBRZmlNdkp0aWJaNFJhPS0uTVpHa1hIc25EbVJyQmw/SkZ+Q3lLcjU/NDBvQTY5Wk1+c0h1XTBjcWE3elh6QzRrREN8Z11GXWpnRXhHLVgmeE1sNDdDaC5NXWUvNlg1bk1WUUguZENGSlEuTWxdck02W2lPd1k5Vy9KUSszWDZSdiYvP0clZEQtOXVfYTVOVHI3TnFrYltFRWFQcUdEeWtLOWlrVCZmeFBDQlFOZS13aUksMy5NZ2tSeF84UDB3fjRES2g4aVVKP11IJixra3N0QlBMNCwwMF9QbGVCejU/bCxaLXRhbkVRQkRXY1REdHQscWw0'}]);
_stq.push([ 'clickTrackerInit', '12777403', '0' ]);
	</script>
<noscript><img src="https://pixel.wp.com/b.gif?v=noscript" style="height:1px;width:1px;overflow:hidden;position:absolute;bottom:1px;" alt="" /></noscript>
<script>
if ( 'object' === typeof wpcom_mobile_user_agent_info ) {

	wpcom_mobile_user_agent_info.init();
	var mobileStatsQueryString = "";
	
	if( false !== wpcom_mobile_user_agent_info.matchedPlatformName )
		mobileStatsQueryString += "&x_" + 'mobile_platforms' + '=' + wpcom_mobile_user_agent_info.matchedPlatformName;
	
	if( false !== wpcom_mobile_user_agent_info.matchedUserAgentName )
		mobileStatsQueryString += "&x_" + 'mobile_devices' + '=' + wpcom_mobile_user_agent_info.matchedUserAgentName;
	
	if( wpcom_mobile_user_agent_info.isIPad() )
		mobileStatsQueryString += "&x_" + 'ipad_views' + '=' + 'views';

	if( "" != mobileStatsQueryString ) {
		new Image().src = document.location.protocol + '//pixel.wp.com/g.gif?v=wpcom-no-pv' + mobileStatsQueryString + '&baba=' + Math.random();
	}
	
}
</script>
</body>
</html>
<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	>

<channel>
	<title>game theory &#8211; Azimuth</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/category/mathematics/game-theory/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com</link>
	<description></description>
	<lastBuildDate>Sun, 25 Oct 2020 23:07:53 +0000</lastBuildDate>
	<language>en</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
<cloud domain='johncarlosbaez.wordpress.com' port='80' path='/?rsscloud=notify' registerProcedure='' protocol='http-post' />
<image>
		<url>https://s0.wp.com/i/buttonw-com.png</url>
		<title>game theory &#8211; Azimuth</title>
		<link>https://johncarlosbaez.wordpress.com</link>
	</image>
	<atom:link rel="search" type="application/opensearchdescription+xml" href="https://johncarlosbaez.wordpress.com/osd.xml" title="Azimuth" />
	<atom:link rel='hub' href='https://johncarlosbaez.wordpress.com/?pushpress=hub'/>
	<item>
		<title>Exponential Discounting</title>
		<link>https://johncarlosbaez.wordpress.com/2020/10/25/exponential-discounting/</link>
					<comments>https://johncarlosbaez.wordpress.com/2020/10/25/exponential-discounting/#comments</comments>
		
		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sun, 25 Oct 2020 19:28:58 +0000</pubDate>
				<category><![CDATA[economics]]></category>
		<category><![CDATA[game theory]]></category>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29140</guid>

					<description><![CDATA[Most of us seem to agree that the promise of a dollar in the future is worth less to us than a dollar today, even if the promise is certain to be fulfilled. Economists often assume &#8216;exponential discounting&#8217;, which says that a dollar promised at some time is worth dollars in hand at time The [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Most of us seem to agree that the promise of a dollar in the future is worth less to us than a dollar today, even if the promise is certain to be fulfilled.  Economists often assume <a href="https://en.wikipedia.org/wiki/Exponential_discounting">&#8216;exponential discounting&#8217;</a>, which says that a dollar promised at some time <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> is worth</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cexp%28-%5Calpha%28s+-+t%29%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;exp(-&#92;alpha(s - t)) " class="latex" /></div>
<p>dollars in hand at time <img src="https://s0.wp.com/latex.php?latex=t.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t." class="latex" />    The constant <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha" class="latex" /> is connected to the &#8216;interest rate&#8217;.</p>
<p>Why are economists so wedded to exponential discounting?  The main reason is probably that it&#8217;s mathematically simple.  But one argument for it goes roughly like this: if your decisions today are to look rational at any future time, you need to use exponential discounting.</p>
<p>In practice, humans, pigeons and rats do <i>not</i> use exponential discounting.  So, economists say they are &#8216;dynamically inconsistent&#8217;:</p>
<p>• Wikipedia, <a href="https://en.wikipedia.org/wiki/Dynamic_inconsistency">Dynamic inconsistency</a>.</p>
<blockquote><p> In economics, dynamic inconsistency or time inconsistency is a situation in which a decision-maker&#8217;s preferences change over time in such a way that a preference can become inconsistent at another point in time. This can be thought of as there being many different &#8220;selves&#8221; within decision makers, with each &#8220;self&#8221; representing the decision-maker at a different point in time; the inconsistency occurs when not all preferences are aligned.</p></blockquote>
<p>I this &#8216;inconsistent&#8217; could be a misleading term for what&#8217;s going on here. It suggests that something <i>bad</i> is happening. That may not be true.</p>
<p>Anyway, some of the early research on this was done by <a href="https://en.wikipedia.org/wiki/Hyperbolic_discounting#Observations">George Ainslie</a>, and here is what he found:</p>
<blockquote><p>
Ainslie&#8217;s research showed that a substantial number of subjects reported that they would prefer $50 immediately rather than $100 in six months, but would NOT prefer $50 in 3 months rather than $100 in nine months, even though this was the same choice seen at 3 months’ greater distance. More significantly, those subjects who said they preferred $50 in 3 months to $100 in 9 months said they would NOT prefer $50 in 12 months to $100 in 18 months—again, the same pair of options at a different distance—showing that the preference-reversal effect did not depend on the excitement of getting an immediate reward. Nor does it depend on human culture; the first preference reversal findings were in rats and pigeons.</p></blockquote>
<p>Let me give a mathematical argument for exponential discounting.  Of course it will rely on some assumptions.  I&#8217;m not claiming these assumptions are true!  Far from it.   I&#8217;m just claiming that if we <i>don&#8217;t</i> use exponential discounting, we are violating one or more of these assumptions&#8230; or breaking out of the whole framework of my argument.   The widespread prevalence of &#8216;dynamic inconsistency&#8217; suggests that the argument doesn&#8217;t apply to real life.</p>
<p>Here&#8217;s the argument:</p>
<p>Suppose the value to us at any time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t" class="latex" /> of a dollar given to us at some other time <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=V%28t%2Cs%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V(t,s)." class="latex" /></p>
<p>Let us assume:</p>
<p>1) The ratio</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7BV%28t%2Cs_2%29%7D%7BV%28t%2Cs_1%29%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{V(t,s_2)}{V(t,s_1)} } " class="latex" /></div>
<p>is independent of <img src="https://s0.wp.com/latex.php?latex=t.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t." class="latex" />   E.g., the ratio of value of a &#8220;dollar on Friday&#8221; to &#8220;a dollar on Thursday&#8221; is the same if you&#8217;re computing it on Monday, or on Tuesday, or on Wednesday.</p>
<p>2) The quantity <img src="https://s0.wp.com/latex.php?latex=V%28t%2Cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V(t,s)" class="latex" /> depends only on the difference <img src="https://s0.wp.com/latex.php?latex=s+-+t.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s - t." class="latex" /></p>
<p>3)  The quantity <img src="https://s0.wp.com/latex.php?latex=V%28t%2Cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V(t,s)" class="latex" /> is a continuous function of <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=t.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t." class="latex" /></p>
<p>Then we can show</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=V%28t%2Cs%29+%3D+k+%5Cexp%28-%5Calpha%28s-t%29%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V(t,s) = k &#92;exp(-&#92;alpha(s-t)) " class="latex" /></div>
<p>for some constants <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=k.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k." class="latex" />  Typically we assume <img src="https://s0.wp.com/latex.php?latex=k+%3D+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k = 1" class="latex" /> since the value of a dollar given to us right now is 1.  But let&#8217;s just see how we get this formula for <img src="https://s0.wp.com/latex.php?latex=V%28t%2Cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V(t,s)" class="latex" /> out of assumptions 1), 2) and 3).</p>
<p>The proof goes like this.    By 2) we know</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=V%28t%2Cs%29+%3D+F%28s-t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V(t,s) = F(s-t)" class="latex" /></div>
<p>for some function <img src="https://s0.wp.com/latex.php?latex=F&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F" class="latex" />.   By 1) it follows that</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7BF%28s_2+-+t%29%7D%7BF%28s_1+-+t%29%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{F(s_2 - t)}{F(s_1 - t)} } " class="latex" /></div>
<p>is independent of <img src="https://s0.wp.com/latex.php?latex=t%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t," class="latex" /> so</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7BF%28s_2+-+t%29%7D%7BF%28s_1+-+t%29%7D+%3D++%5Cfrac%7BF%28s_2%29%7D%7BF%28s_1%29%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{F(s_2 - t)}{F(s_1 - t)} =  &#92;frac{F(s_2)}{F(s_1)} } " class="latex" /></div>
<p>or in other words</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=F%28s_2+-+t%29+F%28s_1%29+%3D+F%28s_2%29+F%28s_1+-+t%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F(s_2 - t) F(s_1) = F(s_2) F(s_1 - t) " class="latex" /></div>
<p>Ugh!  What next?  Well, if we take <img src="https://s0.wp.com/latex.php?latex=s_1+%3D+t%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_1 = t," class="latex" /> we get a simpler equation that&#8217;s probably still good enough to get the job done:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=F%28s_2+-+t%29+F%28t%29+%3D+F%28s_2%29+F%280%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F(s_2 - t) F(t) = F(s_2) F(0) " class="latex" /></div>
<p>Now let&#8217;s make up a variable <img src="https://s0.wp.com/latex.php?latex=t%27+%3D+s_2+-+t%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t&#039; = s_2 - t," class="latex" /> so that <img src="https://s0.wp.com/latex.php?latex=s_2+%3D+t+%2B+t%27.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_2 = t + t&#039;." class="latex" />  Then we can rewrite our equation as</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=F%28t%27%29+F%28t%29+%3D+F%28t%2Bt%27%29+F%280%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F(t&#039;) F(t) = F(t+t&#039;) F(0) " class="latex" /></div>
<p>or</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=F%28t%29+F%28t%27%29+%3D+F%28t%2Bt%27%29+F%280%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F(t) F(t&#039;) = F(t+t&#039;) F(0) " class="latex" /></div>
<p>This is beautiful except for the constant <img src="https://s0.wp.com/latex.php?latex=F%280%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F(0)." class="latex" />  Let&#8217;s call that <img src="https://s0.wp.com/latex.php?latex=k&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="k" class="latex" /> and factor it out by writing</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=F%28t%29+%3D+k+G%28t%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F(t) = k G(t) " class="latex" /></div>
<p>Then we get</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=G%28t%29+G%28t%27%29+%3D+G%28t%2Bt%27%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G(t) G(t&#039;) = G(t+t&#039;) " class="latex" /></div>
<p>A <a href="https://en.wikipedia.org/wiki/Cauchy%27s_functional_equation">theorem of Cauchy</a> implies that any continuous solution of this equation is of the form</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=G%28t%29+%3D+%5Cexp%28-%5Calpha+t%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G(t) = &#92;exp(-&#92;alpha t) " class="latex" /></div>
<p>So, we get</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=F%28t%29+%3D+k+%5Cexp%28-%5Calpha+t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F(t) = k &#92;exp(-&#92;alpha t)" class="latex" /></div>
<p>or</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=V%28t%2Cs%29+%3D+k+%5Cexp%28-%5Calpha%28s-t%29%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V(t,s) = k &#92;exp(-&#92;alpha(s-t)) " class="latex" /></div>
<p>as desired!</p>
<p>By the way, we don&#8217;t need to assume <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G" class="latex" /> is continuous: it&#8217;s enough to assume <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G" class="latex" /> is measurable.  You can get bizarre nonmeasurable solutions of <img src="https://s0.wp.com/latex.php?latex=G%28t%29+G%28t%27%29+%3D+G%28t%2Bt%27%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="G(t) G(t&#039;) = G(t+t&#039;)" class="latex" /> using the axiom of choice, but they are not of practical interest.</p>
<p>So, assumption 3) is not the assumption I&#8217;d want to attack in trying to argue against exponential discounting.   In fact both assumptions 1) and 2) are open to quite a few objections.  Can you name some?   Here&#8217;s one: in real life the interest rate changes with time.  There must be some reason.</p>
<p>By the way, nothing in the argument I gave shows that <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cge+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;ge 0." class="latex" />  So there could be people who obey assumptions 1)&#8211;3) yet believe the promise of a dollar in the future is worth <i>more</i> than a dollar in hand today.</p>
<p>Also, nothing in my argument for the form of <img src="https://s0.wp.com/latex.php?latex=V%28t%2Cs%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V(t,s)" class="latex" /> assumes that <img src="https://s0.wp.com/latex.php?latex=s+%5Cge+t.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s &#92;ge t." class="latex" />  That is, my assumptions as stated also concern the value of a dollar that was promised in the <i>past</i>.  So, you might have fun seeing what changes, or does not change, if you restrict the assumptions to say they only apply when <img src="https://s0.wp.com/latex.php?latex=s+%5Cge+t.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s &#92;ge t." class="latex" />   The arrow of time seems to be built into economics, after all.</p>
<p>Also, you may enjoy finding the place in my derivation where I might have divided by zero, and figure out to do about that.</p>
<p>If you don&#8217;t like exponential discounting&#8212;for example, because people use it to argue against spending money <i>now</i> to fight climate change&#8212;you might prefer hyperbolic discounting:</p>
<p>• Wikipedia, <a href="https://en.wikipedia.org/wiki/Hyperbolic_discounting">Hyperbolic discounting</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://johncarlosbaez.wordpress.com/2020/10/25/exponential-discounting/feed/</wfw:commentRss>
			<slash:comments>20</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">John Baez</media:title>
		</media:content>
	</item>
		<item>
		<title>Compositional Game Theory and Climate Microeconomics</title>
		<link>https://johncarlosbaez.wordpress.com/2020/10/05/compositional-game-theory-and-climate-microeconomics/</link>
					<comments>https://johncarlosbaez.wordpress.com/2020/10/05/compositional-game-theory-and-climate-microeconomics/#comments</comments>
		
		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Mon, 05 Oct 2020 04:05:00 +0000</pubDate>
				<category><![CDATA[economics]]></category>
		<category><![CDATA[game theory]]></category>
		<category><![CDATA[strategies]]></category>
		<category><![CDATA[sustainability]]></category>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=28867</guid>

					<description><![CDATA[guest post by Jules Hedges Hi all This is a post I&#8217;ve been putting off for a long time until I was sure I was ready. I am the &#8220;lead developer&#8221; of a thing called compositional game theory (CGT). It&#8217;s an approach to game theory based on category theory, but we are now at the [&#8230;]]]></description>
										<content:encoded><![CDATA[<p><i>guest post by <b><a href="https://julesh.com/">Jules Hedges</a></b></i></p>
<p>Hi all</p>
<p>This is a post I&#8217;ve been putting off for a long time until I was sure I was ready. I am the &#8220;lead developer&#8221; of a thing called compositional game theory (CGT). It&#8217;s an approach to game theory based on category theory, but we are now at the point where you don&#8217;t need to know that anymore: it&#8217;s an approach to game theory that has certain specific benefits over the traditional approach.</p>
<p>I would like to start a conversation about &#8220;using my powers for good&#8221;. I am hoping particularly that it is possible to model microeconomic aspects of climate science. This seems to be a very small field and I&#8217;m not really hopeful that anyone on Azimuth will have the right background, but it&#8217;s worth a shot. The kind of thing I&#8217;m imagining (possibly completely wrongly) is to create models that will suggest when a technically-feasible solution is not socially feasible. Social dilemmas and tragedies of the commons are at the heart of the climate crisis, and modelling instances of them is in scope.</p>
<p>I have a software tool (<a href="https://github.com/jules-hedges/open-games-hs" rel="nofollow">https://github.com/jules-hedges/open-games-hs</a>) that is designed to be an assistant for game-theoretic modelling. This I can&#8217;t emphasise enough: A human with expertise in game-theoretic modelling is the most important thing, CGT is merely an assistant. (Right now the tool also probably can&#8217;t be used without me being in the loop, but that&#8217;s not an inherent thing.)</p>
<p>To give an idea what sort of things CGT can do, my 2 current ongoing research collaborations are: (1) a social science project modelling examples of institution governance, and (2) a cryptoeconomics project modelling an attack against a protocol using bribes. On a technical level the best fit is for Bayesian games, which are finite-horizon, have common knowledge priors, and private knowledge with agents who do Bayesian updating.</p>
<p>A lot of the (believed) practical benefits of CGT come from the fact that the model is code (in a high level language designed specifically for expressing games) and thus the model can be structured according to existing wisdom for structuring code. Really stress-testing this claim is an ongoing research project. My tool does equilibrium-checking for all games (the technical term is &#8220;model checker&#8221;), and we&#8217;ve had some success doing other things by looping an equilibrium check over a parameter space. It makes no attempt to be an equilibrium solver, that is left for the human.</p>
<p>This is not me trying to push my pet project (I do that elsewhere) but me trying to find a niche where I can do some genuine good, even if small. If you are a microeconomist (or a social scientist who uses applied game theory) and share the goals of Azimuth, I would like to hear from you, even if it&#8217;s just for some discussion.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://johncarlosbaez.wordpress.com/2020/10/05/compositional-game-theory-and-climate-microeconomics/feed/</wfw:commentRss>
			<slash:comments>10</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">John Baez</media:title>
		</media:content>
	</item>
		<item>
		<title>Open Games: the Long Road to Practical Applications</title>
		<link>https://johncarlosbaez.wordpress.com/2020/04/13/open-games-the-long-road-to-practical-applications/</link>
					<comments>https://johncarlosbaez.wordpress.com/2020/04/13/open-games-the-long-road-to-practical-applications/#comments</comments>
		
		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Mon, 13 Apr 2020 20:37:03 +0000</pubDate>
				<category><![CDATA[game theory]]></category>
		<category><![CDATA[mathematics]]></category>
		<category><![CDATA[seminars]]></category>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=27981</guid>

					<description><![CDATA[In the third talk of the ACT@UCR seminar, Jules Hedges spoke about open games! He gave his talk on Wednesday April 15th. Afterwards we discussed it at the Category Theory Community Server, here: https://categorytheory.zulipchat.com/ You can view or join the conversation there if you sign in. You can see his slides here, or download a [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>In the third talk of the <a href="https://sites.google.com/ucr.edu/actucr/">ACT@UCR seminar</a>, <a href="https://julesh.com/">Jules Hedges</a> spoke about open games!</p>
<p>He gave his talk on Wednesday April 15th.  Afterwards we discussed it at the Category Theory Community Server, here:</p>
<p><a href="https://categorytheory.zulipchat.com/#narrow/stream/229966-ACT.40UCR-seminar/topic/April.2015th.3A.20Jules.20Hedges">https://categorytheory.zulipchat.com/</a></p>
<p>You can view or join the conversation there if you <a href="https://johncarlosbaez.wordpress.com/2020/03/25/category-theory-community-server/">sign in</a>.</p>
<p>You can <a href="http://math.ucr.edu/home/baez/mathematical/ACTUCR/Hedges_Open_Games.pdf">see his slides here</a>, or <a href="http://math.ucr.edu/home/baez/mathematical/ACTUCR/Hedges_Open_Games.mp4">download a video here</a>, or watch the video here:</p>
<iframe class="youtube-player" width="560" height="315" src="https://www.youtube.com/embed/Kwflmrd2AfM?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe>
<p>• April 15, Jules Hedges: <a href="http://math.ucr.edu/home/baez/mathematical/ACTUCR/Hedges_Open_Games.pdf">Open games: the long road to practical applications</a>.</p>
<blockquote><p>
  <strong>Abstract.</strong>  I will talk about open games, and the closely related concepts of lenses/optics and open learners. My goal is to report on the successes and failures of an ongoing effort to try to realise the often-claimed benefits of categories and compositionality in actual practice. I will introduce what little theory is needed along the way. Here are some things I plan to talk about:</p>
<p>  — Lenses as an abstraction of the chain rule</p>
<p>  — Comb diagrams</p>
<p>  — Surprising applications of open games: Bayesian inference, value function iteration</p>
<p>  — The state of tool support</p>
<p>  — Open games in their natural habitat: microeconomics</p>
<p>  — Sociological aspects of working with economics
</p></blockquote>
<p><a href="https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg"><img loading="lazy" data-attachment-id="27985" data-permalink="https://johncarlosbaez.wordpress.com/2020/04/13/open-games-the-long-road-to-practical-applications/hedges_slide/" data-orig-file="https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg" data-orig-size="876,508" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Hedges_slide" data-image-description="" data-image-caption="" data-medium-file="https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg?w=300" data-large-file="https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg?w=450" src="https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg?w=450&#038;h=261" alt="" width="450" height="261" class="aligncenter size-full wp-image-27985" srcset="https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg?w=450&amp;h=261 450w, https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg?w=150&amp;h=87 150w, https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg?w=300&amp;h=174 300w, https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg?w=768&amp;h=445 768w, https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg 876w" sizes="(max-width: 450px) 100vw, 450px" /></a></p>
]]></content:encoded>
					
					<wfw:commentRss>https://johncarlosbaez.wordpress.com/2020/04/13/open-games-the-long-road-to-practical-applications/feed/</wfw:commentRss>
			<slash:comments>6</slash:comments>
		
		<enclosure url="http://math.ucr.edu/home/baez/mathematical/ACTUCR/Hedges_Open_Games.mp4" length="253072347" type="video/mp4" />

		
		<media:thumbnail url="https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg" />
		<media:content url="https://johncarlosbaez.files.wordpress.com/2020/04/hedges_slide.jpg" medium="image">
			<media:title type="html">Hedges_slide</media:title>
		</media:content>

		<media:content url="https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">John Baez</media:title>
		</media:content>
	</item>
		<item>
		<title>Correlated Equilibria in Game Theory</title>
		<link>https://johncarlosbaez.wordpress.com/2017/07/24/correlated-equilibria-in-game-theory/</link>
					<comments>https://johncarlosbaez.wordpress.com/2017/07/24/correlated-equilibria-in-game-theory/#comments</comments>
		
		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Mon, 24 Jul 2017 02:54:31 +0000</pubDate>
				<category><![CDATA[economics]]></category>
		<category><![CDATA[game theory]]></category>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=23712</guid>

					<description><![CDATA[Erica Klarreich is one of the few science journalists who explains interesting things I don&#8217;t already know clearly enough so I can understand them. I recommend her latest article: • Erica Klarreich, In game theory, no clear path to equilibrium, Quanta, 18 July 2017. Economists like the concept of &#8216;Nash equilibrium&#8217;, but it&#8217;s problematic in [&#8230;]]]></description>
										<content:encoded><![CDATA[<p><a href="https://www.quantamagazine.org/authors/erica-klarreich/">Erica Klarreich</a> is one of the few science journalists who explains interesting things I don&#8217;t already know clearly enough so I can understand them.  I recommend her latest article:</p>
<p>• Erica Klarreich, <a href="https://www.quantamagazine.org/in-game-theory-no-clear-path-to-equilibrium-20170718/">In game theory, no clear path to equilibrium</a>, <em>Quanta</em>, 18 July 2017.</p>
<p>Economists like the concept of <a href="https://en.wikipedia.org/wiki/Nash_equilibrium">&#8216;Nash equilibrium&#8217;</a>, but it&#8217;s problematic in some ways.  This matters for society at large.</p>
<p>In a Nash equilibrium for a multi-player game, no player can improve their payoff by unilaterally changing their strategy.  This doesn&#8217;t mean everyone is happy: it&#8217;s possible to be trapped in a Nash equilibrium where everyone is miserable, because anyone changing their strategy unilaterally would be even <em>more</em> miserable.  (Think &#8216;global warming&#8217;.)</p>
<p>The great thing about Nash equilibria is that their meaning is easy to fathom, and they exist.  John Nash won a Nobel prize for a paper proving that they exist.  His paper was less than one page long.  But he proved the existence of Nash equilibria for arbitrary multi-player games using a nonconstructive method: a fixed point theorem that doesn&#8217;t actually tell you how to <em>find</em> the equilibrium!</p>
<p>Given this, it&#8217;s not surprising that Nash equilibria can be hard to find.  Last September a paper came out making this precise, in a strong way:</p>
<p>• Yakov Babichenko and Aviad Rubinstein, <a href="https://arxiv.org/abs/1608.06580">Communication complexity of approximate Nash equilibria</a>.</p>
<p>The authors show there’s no guaranteed method for players to find even an approximate Nash equilibrium unless they tell each other almost everything about their preferences.  This makes finding the Nash equilibrium prohibitively difficult to find when there are lots of players&#8230; <em>in general</em>.  There are particular games where it&#8217;s not difficult, and that makes these games important: for example, if you&#8217;re trying to run a government well.  (A laughable notion these days, but still one can hope.)</p>
<p>Klarreich&#8217;s article in <em>Quanta</em> gives a nice readable account of this work and also a more practical alternative to the concept of Nash equilibrium.  It&#8217;s called a &#8216;correlated equilibrium&#8217;, and it was invented by the mathematician Robert Aumann in 1974.  You can see an attempt to define it here:</p>
<p>• Wikipedia, <a href="https://en.wikipedia.org/wiki/Correlated_equilibrium">Correlated equilibrium</a>.</p>
<p>The precise mathematical definition near the start of this article is a pretty good example of how you shouldn&#8217;t explain something: it contains a big fat equation containing symbols not mentioned previously, and so on.  By thinking about it for a while, I was able to fight my way through it.  Someday I should improve it&#8212;and someday I should explain the idea here!  But for now, I&#8217;ll just quote this passage, which roughly explains the idea in words:</p>
<blockquote><p>
  The idea is that each player chooses their action according to their observation of the value of the same public signal. A strategy assigns an action to every possible observation a player can make. If no player would want to deviate from the recommended strategy (assuming the others don&#8217;t deviate), the distribution is called a <strong>correlated equilibrium</strong>.
</p></blockquote>
<p>According to Erica Klarreich it&#8217;s a useful notion.  She even makes it sound revolutionary:</p>
<blockquote><p>
  This might at first sound like an arcane construct, but in fact we use correlated equilibria all the time&#8212;whenever, for example, we let a coin toss decide whether we’ll go out for Chinese or Italian, or allow a traffic light to dictate which of us will go through an intersection first.</p>
<p>  In [some] examples, each player knows exactly what advice the “mediator” is giving to the other player, and the mediator’s advice essentially helps the players coordinate which Nash equilibrium they will play. But when the players don’t know exactly what advice the others are getting&#8212;only how the different kinds of advice are correlated with each other&#8212;Aumann showed that the set of correlated equilibria can contain more than just combinations of Nash equilibria: it can include forms of play that aren’t Nash equilibria at all, but that sometimes result in a more positive societal outcome than any of the Nash equilibria. For example, in some games in which cooperating would yield a higher total payoff for the players than acting selfishly, the mediator can sometimes beguile players into cooperating by withholding just what advice she’s giving the other players. This finding, Myerson said, was “a bolt from the blue.”
</p></blockquote>
<p>(<a href="http://home.uchicago.edu/rmyerson/">Roger Myerson</a> is an economics professor at the University of Chicago who won a Nobel prize for his work on game theory.)</p>
<blockquote><p>
  And even though a mediator can give many different kinds of advice, the set of correlated equilibria of a game, which is represented by a collection of linear equations and inequalities, is more mathematically tractable than the set of Nash equilibria. “This other way of thinking about it, the mathematics is so much more beautiful,” Myerson said.</p>
<p>  While Myerson has called Nash’s vision of game theory “one of the outstanding intellectual advances of the 20th century,” he sees correlated equilibrium as perhaps an even more natural concept than Nash equilibrium. He has opined on numerous occasions that “if there is intelligent life on other planets, in a majority of them they would have discovered correlated equilibrium before Nash equilibrium.”</p>
<p>  When it comes to repeated rounds of play, many of the most natural ways that players could choose to adapt their strategies converge, in a particular sense, to correlated equilibria. Take, for example, “regret minimization” approaches, in which before each round, players increase the probability of using a given strategy if they regret not having played it more in the past. Regret minimization is a method “which does bear some resemblance to real life — paying attention to what’s worked well in the past, combined with occasionally experimenting a bit,” Roughgarden said.
</p></blockquote>
<p>(<a href="http://theory.stanford.edu/~tim/">Tim Roughgarden</a> is a theoretical computer scientist at Stanford University.)</p>
<blockquote><p>
  For many regret-minimizing approaches, researchers have shown that play will rapidly converge to a correlated equilibrium in the following surprising sense: after maybe 100 rounds have been played, the game history will look essentially the same as if a mediator had been advising the players all along. It’s as if “the [correlating] device was somehow implicitly found, through the interaction,” said Constantinos Daskalakis, a theoretical computer scientist at the Massachusetts Institute of Technology.</p>
<p>  As play continues, the players won’t necessarily stay at the same correlated equilibrium — after 1,000 rounds, for instance, they may have drifted to a new equilibrium, so that now their 1,000-game history looks as if it had been guided by a different mediator than before. The process is reminiscent of what happens in real life, Roughgarden said, as societal norms about which equilibrium should be played gradually evolve.</p>
<p>  In the kinds of complex games for which Nash equilibrium is hard to reach, correlated equilibrium is “the natural leading contender” for a replacement solution concept, Nisan said.
</p></blockquote>
<p>As Klarreich hints, you can find correlated equilibria using a technique called <a href="https://en.wikipedia.org/wiki/Linear_programming">linear programming</a>.  That was proved here, I think:</p>
<p>• Christos H. Papadimitriou and Tim Roughgarden, <a href="http://theory.stanford.edu/~tim/papers/cor.pdf">Computing correlated equilibria in multi-player games</a>, <em>J. ACM</em> <strong>55</strong> (2008), 14:1-14:29.</p>
<p>Do you know something about correlated equilibria that I should know?  If so, please tell me!</p>
]]></content:encoded>
					
					<wfw:commentRss>https://johncarlosbaez.wordpress.com/2017/07/24/correlated-equilibria-in-game-theory/feed/</wfw:commentRss>
			<slash:comments>22</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">John Baez</media:title>
		</media:content>
	</item>
		<item>
		<title>Information Geometry (Part 16)</title>
		<link>https://johncarlosbaez.wordpress.com/2017/02/01/information-geometry-part-16/</link>
					<comments>https://johncarlosbaez.wordpress.com/2017/02/01/information-geometry-part-16/#comments</comments>
		
		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Wed, 01 Feb 2017 01:18:26 +0000</pubDate>
				<category><![CDATA[biology]]></category>
		<category><![CDATA[game theory]]></category>
		<category><![CDATA[information and entropy]]></category>
		<category><![CDATA[probability]]></category>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=23248</guid>

					<description><![CDATA[This week I&#8217;m giving a talk on biology and information: • John Baez, Biology as information dynamics, talk for Biological Complexity: Can it be Quantified?, a workshop at the Beyond Center, 2 February 2017. While preparing this talk, I discovered a cool fact. I doubt it&#8217;s new, but I haven&#8217;t exactly seen it elsewhere. I [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>This week I&#8217;m giving a talk on biology and information:</p>
<p>• John Baez, <a href="http://math.ucr.edu/home/baez/bio_asu/">Biology as information dynamics</a>, talk for <a href="https://beyond.asu.edu/workshop/biological-complexity-can-it-be-quantified">Biological Complexity: Can it be Quantified?</a>, a workshop at the <a href="https://beyond.asu.edu/">Beyond Center</a>, 2 February 2017.</p>
<p>While preparing this talk, I discovered a cool fact.  I doubt it&#8217;s new, but I haven&#8217;t exactly seen it elsewhere.   I came up with it while trying to give a precise and general statement of &#8216;Fisher&#8217;s fundamental theorem of natural selection&#8217;.   I <i>won&#8217;t</i> start by explaining that theorem, since my version looks rather different than Fisher&#8217;s, and I came up with mine precisely because I had trouble understanding his.  I&#8217;ll say a bit more about this at the end.</p>
<p>Here&#8217;s my version:</p>
<blockquote><p>
The square of the rate at which a population learns information is the variance of its fitness.
</p></blockquote>
<p>This is a nice advertisement for the virtues of diversity: more variance means faster learning.   But it requires some explanation!</p>
<h3> The setup </h3>
<p>Let&#8217;s start by assuming we have <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> different kinds of self-replicating entities with populations <img src="https://s0.wp.com/latex.php?latex=P_1%2C+%5Cdots%2C+P_n.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P_1, &#92;dots, P_n." class="latex" />  As usual, these could be all sorts of things:</p>
<p>• molecules of different chemicals<br />
• organisms belonging to different species<br />
• genes of different alleles<br />
• restaurants belonging to different chains<br />
• people with different beliefs<br />
• game-players with different strategies<br />
• etc.</p>
<p>I&#8217;ll call them <b>replicators</b> of different <b>species</b>.</p>
<p>Let&#8217;s suppose each population <img src="https://s0.wp.com/latex.php?latex=P_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P_i" class="latex" /> is a function of time that grows at a rate equal to this population times its &#8216;fitness&#8217;.   I explained the resulting equation back in <a href="http://math.ucr.edu/home/baez/information/information_geometry_9.html">Part 9</a>, but it&#8217;s pretty simple:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%7D%7Bd+t%7D+P_i%28t%29+%3D+f_i%28P_1%28t%29%2C+%5Cdots%2C+P_n%28t%29%29+%5C%2C+P_i%28t%29+++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d}{d t} P_i(t) = f_i(P_1(t), &#92;dots, P_n(t)) &#92;, P_i(t)   } " class="latex" /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=f_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_i" class="latex" /> is a completely arbitrary smooth function of all the populations!  We call it the <b>fitness</b> of the <i>i</i>th species.</p>
<p>This equation is important, so we want a short way to write it.  I&#8217;ll often write <img src="https://s0.wp.com/latex.php?latex=f_i%28P_1%28t%29%2C+%5Cdots%2C+P_n%28t%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_i(P_1(t), &#92;dots, P_n(t))" class="latex" /> simply as <img src="https://s0.wp.com/latex.php?latex=f_i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_i," class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=P_i%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P_i(t)" class="latex" /> simply as <img src="https://s0.wp.com/latex.php?latex=P_i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P_i." class="latex" />  With these abbreviations, which any red-blooded physicist would take for granted, our equation becomes simply this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7BdP_i%7D%7Bd+t%7D++%3D+f_i+%5C%2C+P_i+++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{dP_i}{d t}  = f_i &#92;, P_i   } " class="latex" /></p>
<p>Next, let <img src="https://s0.wp.com/latex.php?latex=p_i%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i(t)" class="latex" /> be the probability that a randomly chosen organism is of the <i>i</i>th species:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_i%28t%29+%3D+%5Cfrac%7BP_i%28t%29%7D%7B%5Csum_j+P_j%28t%29%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_i(t) = &#92;frac{P_i(t)}{&#92;sum_j P_j(t)} } " class="latex" /></p>
<p>Starting from our equation describing how the populations evolve, we can figure out how these probabilities evolve.  The answer is called the <a href="https://en.wikipedia.org/wiki/Replicator_equation"><b>replicator equation</b></a>:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%7D%7Bd+t%7D+p_i%28t%29++%3D+%28+f_i+-+%5Clangle+f+%5Crangle+%29+%5C%2C+p_i%28t%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d}{d t} p_i(t)  = ( f_i - &#92;langle f &#92;rangle ) &#92;, p_i(t) }" class="latex" /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=%5Clangle+f+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle f &#92;rangle" class="latex" /> is the average fitness of all the replicators, or <b>mean fitness</b>:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clangle+f+%5Crangle+%3D+%5Csum_j+f_j%28P_1%28t%29%2C+%5Cdots%2C+P_n%28t%29%29+%5C%2C+p_j%28t%29++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;langle f &#92;rangle = &#92;sum_j f_j(P_1(t), &#92;dots, P_n(t)) &#92;, p_j(t)  } " class="latex" /></p>
<p>In what follows I&#8217;ll abbreviate the replicator equation as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bdp_i%7D%7Bd+t%7D++%3D+%28+f_i+-+%5Clangle+f+%5Crangle+%29+%5C%2C+p_i+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{dp_i}{d t}  = ( f_i - &#92;langle f &#92;rangle ) &#92;, p_i }" class="latex" /></p>
<h3> The result </h3>
<p>Okay, now let&#8217;s figure out how fast the probability distribution</p>
<p><img src="https://s0.wp.com/latex.php?latex=p%28t%29+%3D+%28p_1%28t%29%2C+%5Cdots%2C+p_n%28t%29%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t) = (p_1(t), &#92;dots, p_n(t)) " class="latex" /></p>
<p>changes with time.  For this we need to choose a way to measure the length of the vector</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%5Cfrac%7Bdp%7D%7Bdt%7D+%3D+%28%5Cfrac%7Bd%7D%7Bdt%7D+p_1%28t%29%2C+%5Cdots%2C+%5Cfrac%7Bd%7D%7Bdt%7D+p_n%28t%29%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  &#92;frac{dp}{dt} = (&#92;frac{d}{dt} p_1(t), &#92;dots, &#92;frac{d}{dt} p_n(t)) } " class="latex" /></p>
<p>And here information geometry comes to the rescue!   We can use the <a href="https://en.wikipedia.org/wiki/Fisher_information_metric">Fisher information metric</a>, which is a Riemannian metric on the space of probability distributions.</p>
<p>I&#8217;ve talked about the Fisher information metric in many ways in this series.  The most important fact is that as a probability distribution <img src="https://s0.wp.com/latex.php?latex=p%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t)" class="latex" /> changes with time, its speed</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%5Cleft%5C%7C+%5Cfrac%7Bdp%7D%7Bdt%7D+%5Cright%5C%7C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  &#92;left&#92;| &#92;frac{dp}{dt} &#92;right&#92;|} " class="latex" /></p>
<p>as measured using the Fisher information metric can be seen as the <i>rate at which information is learned</i>.  I&#8217;ll explain that later.  Right now I just want a simple <i>formula</i> for the Fisher information metric.  Suppose <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="v" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="w" class="latex" /> are two tangent vectors to the point <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> in the space of probability distributions.  Then the <b>Fisher information metric</b> is given as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clangle+v%2C+w+%5Crangle+%3D+%5Csum_i+%5Cfrac%7B1%7D%7Bp_i%7D+%5C%2C+v_i+w_i+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;langle v, w &#92;rangle = &#92;sum_i &#92;frac{1}{p_i} &#92;, v_i w_i } " class="latex" /></p>
<p>Using this we can calculate the speed at which <img src="https://s0.wp.com/latex.php?latex=p%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t)" class="latex" /> moves when it obeys the replicator equation.  Actually the square of the speed is simpler:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D++%5Cdisplaystyle%7B+%5Cleft%5C%7C+%5Cfrac%7Bdp%7D%7Bdt%7D++%5Cright%5C%7C%5E2+%7D+%26%3D%26+%5Cdisplaystyle%7B+%5Csum_i+%5Cfrac%7B1%7D%7Bp_i%7D+%5Cleft%28+%5Cfrac%7Bdp_i%7D%7Bdt%7D+%5Cright%29%5E2+%7D+%5C%5C+%5C%5C++%26%3D%26+%5Cdisplaystyle%7B+%5Csum_i+%5Cfrac%7B1%7D%7Bp_i%7D+%5Cleft%28+%28+f_i+-+%5Clangle+f+%5Crangle+%29+%5C%2C+p_i+%5Cright%29%5E2+%7D+%5C%5C+%5C%5C++%26%3D%26+%5Cdisplaystyle%7B+%5Csum_i++%28+f_i+-+%5Clangle+f+%5Crangle+%29%5E2+p_i+%7D+++%5Cend%7Barray%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl}  &#92;displaystyle{ &#92;left&#92;| &#92;frac{dp}{dt}  &#92;right&#92;|^2 } &amp;=&amp; &#92;displaystyle{ &#92;sum_i &#92;frac{1}{p_i} &#92;left( &#92;frac{dp_i}{dt} &#92;right)^2 } &#92;&#92; &#92;&#92;  &amp;=&amp; &#92;displaystyle{ &#92;sum_i &#92;frac{1}{p_i} &#92;left( ( f_i - &#92;langle f &#92;rangle ) &#92;, p_i &#92;right)^2 } &#92;&#92; &#92;&#92;  &amp;=&amp; &#92;displaystyle{ &#92;sum_i  ( f_i - &#92;langle f &#92;rangle )^2 p_i }   &#92;end{array}  " class="latex" /></p>
<p>The answer has a nice meaning, too!  It&#8217;s just the <a href="https://en.wikipedia.org/wiki/Variance">variance</a> of the fitness: that is, the square of its <a href="https://en.wikipedia.org/wiki/Standard_deviation">standard deviation</a>.</p>
<p>So, if you&#8217;re willing to buy my claim that the speed <img src="https://s0.wp.com/latex.php?latex=%5C%7Cdp%2Fdt%5C%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;|dp/dt&#92;|" class="latex" /> is the rate at which our population learns new information, then we&#8217;ve seen that <i>the square of the rate at which a population learns information is the variance of its fitness!</i></p>
<h3> Fisher&#8217;s fundamental theorem </h3>
<p>Now, how is this related to Fisher&#8217;s fundamental theorem of natural selection?    First of all, what <i>is</i> Fisher&#8217;s fundamental theorem?  Here&#8217;s what <a href="https://en.wikipedia.org/wiki/Fisher's_fundamental_theorem_of_natural_selection" rel="nofollow">Wikipedia says</a> about it:</p>
<blockquote><p>
  It uses some mathematical notation but is not a theorem in the mathematical sense.</p>
<p>  It states:</p>
<blockquote><p>
  &#8220;The rate of increase in fitness of any organism at any time is equal to its genetic variance in fitness at that time.&#8221;
</p></blockquote>
<p>  Or in more modern terminology:</p>
<blockquote><p>
  &#8220;The rate of increase in the mean fitness of any organism at any time ascribable to natural selection acting through changes in gene frequencies is exactly equal to its genetic variance in fitness at that time&#8221;.
</p></blockquote>
<p>  Largely as a result of Fisher&#8217;s feud with the American geneticist Sewall Wright about adaptive landscapes, the theorem was widely misunderstood to mean that the average fitness of a population would always increase, even though models showed this not to be the case. In 1972, George R. Price showed that Fisher&#8217;s theorem was indeed correct (and that Fisher&#8217;s proof was also correct, given a typo or two), but did not find it to be of great significance. The sophistication that Price pointed out, and that had made understanding difficult, is that the theorem gives a formula for part of the change in gene frequency, and not for all of it. This is a part that can be said to be due to natural selection
</p></blockquote>
<p>Price&#8217;s paper is here:</p>
<p>• George R. Price, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.366.4070&amp;rep=rep1&amp;type=pdf" rel="nofollow">Fisher&#8217;s &#8216;fundamental theorem&#8217; made clear</a>, <em>Annals of Human Genetics</em> <strong>36</strong> (1972), 129–140.</p>
<p>I don&#8217;t find it very clear, perhaps because I didn&#8217;t spend enough time on it.  But I think I get the idea.</p>
<p>My result <i>is</i> a theorem in the mathematical sense, though quite an easy one.  I assume a population distribution evolves according to the replicator equation and derive an equation whose right-hand side matches that of Fisher&#8217;s original equation: the variance of the fitness.</p>
<p>But my left-hand side is different: it&#8217;s the square of the speed of the corresponding probability distribution, where speed is measured using the &#8216;Fisher information metric&#8217;.  This metric was discovered by the same guy, Ronald Fisher, but I don&#8217;t think he used it in <em>his</em> work on the fundamental theorem!</p>
<p>Something a bit similar to my statement appears as Theorem 2 of this paper:</p>
<p>• Marc Harper, <a href="http://arxiv.org/abs/0911.1383" rel="nofollow">Information geometry and evolutionary game theory</a>.</p>
<p>and for that theorem he cites:</p>
<p>• Josef Hofbauer and Karl Sigmund, <em>Evolutionary Games and Population Dynamics</em>, Cambridge University Press, Cambridge, 1998.</p>
<p>However, his Theorem 2 really concerns the rate of increase of fitness, like Fisher&#8217;s fundamental theorem.  Moreover, he assumes that the probability distribution <img src="https://s0.wp.com/latex.php?latex=p%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t)" class="latex" /> flows along the gradient of a function, and I&#8217;m not assuming that.  Indeed, my version applies to situations where the probability distribution moves round and round in periodic orbits!</p>
<h3> Relative information and the Fisher information metric </h3>
<p>The key to generalizing Fisher&#8217;s fundamental theorem is thus to focus on the speed at which <img src="https://s0.wp.com/latex.php?latex=p%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t)" class="latex" /> moves, rather than the increase in fitness.  Why do I call this speed the &#8216;rate at which the population learns information&#8217;?  It&#8217;s because we&#8217;re measuring this speed using the Fisher information metric, which is closely connected to <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">relative information</a>, also known as relative entropy or the Kullback&ndash;Leibler divergence.</p>
<p>I explained this back in <a href="http://math.ucr.edu/home/baez/information/information_geometry_7.html">Part 7</a>, but that explanation seems hopelessly technical to me now, so here&#8217;s a faster one, which I created while preparing my talk.</p>
<p>The information of a probability distribution <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> <b>relative to</b> a probability distribution <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> is</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+++++I%28q%2Cp%29+%3D+%5Csum_%7Bi+%3D1%7D%5En+q_i+%5Clog%5Cleft%28%5Cfrac%7Bq_i%7D%7Bp_i%7D%5Cright%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{     I(q,p) = &#92;sum_{i =1}^n q_i &#92;log&#92;left(&#92;frac{q_i}{p_i}&#92;right) }" class="latex" /></p>
<p>It says how much information you learn if you start with a hypothesis <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> saying that the probability of the <i>i</i>th situation was <img src="https://s0.wp.com/latex.php?latex=p_i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i," class="latex" /> and then update this to a new hypothesis <img src="https://s0.wp.com/latex.php?latex=q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q." class="latex" /></p>
<p>Now suppose you have a hypothesis that&#8217;s changing with time in a smooth way, given by a time-dependent probability <img src="https://s0.wp.com/latex.php?latex=p%28t%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t)." class="latex" />   Then a calculation shows that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cleft.%5Cfrac%7Bd%7D%7Bdt%7D+I%28p%28t%29%2Cp%28t_0%29%29+%5Cright%7C_%7Bt+%3D+t_0%7D+%3D+0+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;left.&#92;frac{d}{dt} I(p(t),p(t_0)) &#92;right|_{t = t_0} = 0 } " class="latex" /></p>
<p>for all times <img src="https://s0.wp.com/latex.php?latex=t_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t_0" class="latex" />.  This seems paradoxical at first.  I like to jokingly put it this way:</p>
<blockquote><p>
To first order, you&#8217;re never learning anything.
</p></blockquote>
<p>However, as long as the velocity <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7Bd%7D%7Bdt%7Dp%28t_0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;frac{d}{dt}p(t_0)" class="latex" /> is nonzero, we have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cleft.%5Cfrac%7Bd%5E2%7D%7Bdt%5E2%7D+I%28p%28t%29%2Cp%28t_0%29%29+%5Cright%7C_%7Bt+%3D+t_0%7D+%3E+0+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;left.&#92;frac{d^2}{dt^2} I(p(t),p(t_0)) &#92;right|_{t = t_0} &gt; 0 } " class="latex" /></p>
<p>so we can say</p>
<blockquote><p>
To second order, you&#8217;re always learning something&#8230; unless your opinions are fixed.
</p></blockquote>
<p>This lets us define a &#8216;rate of learning&#8217;&#8212;that is, a &#8216;speed&#8217; at which the probability distribution <img src="https://s0.wp.com/latex.php?latex=p%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t)" class="latex" /> moves.  <i>And this is precisely the speed given by the Fisher information metric!</i></p>
<p>In other words:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cleft%5C%7C%5Cfrac%7Bdp%7D%7Bdt%7D%28t_0%29%5Cright%5C%7C%5E2+%3D++%5Cleft.%5Cfrac%7Bd%5E2%7D%7Bdt%5E2%7D+I%28p%28t%29%2Cp%28t_0%29%29+%5Cright%7C_%7Bt+%3D+t_0%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;left&#92;|&#92;frac{dp}{dt}(t_0)&#92;right&#92;|^2 =  &#92;left.&#92;frac{d^2}{dt^2} I(p(t),p(t_0)) &#92;right|_{t = t_0} } " class="latex" /></p>
<p>where the length is given by Fisher information metric.   Indeed, this formula can be used to <i>define</i> the Fisher information metric.  From this definition we can easily work out the concrete formula I gave earlier.</p>
<p>In summary: as a probability distribution moves around, the relative information between the new probability distribution and the original one grows approximately as the <i>square</i> of time, not linearly.  So, to talk about a &#8216;rate at which information is learned&#8217;, we need to use the above formula, involving a second time derivative.  This rate is just the speed at which the probability distribution moves, measured using the Fisher information metric.  And when we have a probability distribution describing how many replicators are of different species, and it&#8217;s evolving according to the replicator equation, this speed is also just the variance of the fitness!</p>
]]></content:encoded>
					
					<wfw:commentRss>https://johncarlosbaez.wordpress.com/2017/02/01/information-geometry-part-16/feed/</wfw:commentRss>
			<slash:comments>29</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">John Baez</media:title>
		</media:content>
	</item>
		<item>
		<title>Biology as Information Dynamics (Part 1)</title>
		<link>https://johncarlosbaez.wordpress.com/2017/01/31/biology-as-information-dynamics/</link>
					<comments>https://johncarlosbaez.wordpress.com/2017/01/31/biology-as-information-dynamics/#comments</comments>
		
		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Tue, 31 Jan 2017 05:17:03 +0000</pubDate>
				<category><![CDATA[biology]]></category>
		<category><![CDATA[game theory]]></category>
		<category><![CDATA[information and entropy]]></category>
		<category><![CDATA[probability]]></category>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=23239</guid>

					<description><![CDATA[This is my talk for the workshop Biological Complexity: Can It Be Quantified? • John Baez, Biology as information dynamics, 2 February 2017. Abstract. If biology is the study of self-replicating entities, and we want to understand the role of information, it makes sense to see how information theory is connected to the &#8216;replicator equation&#8217;—a [&#8230;]]]></description>
										<content:encoded><![CDATA[<div align="center">
<img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/bio_asu/Forest-fruits-from-Barro-Colorado.png" />
</div>
<p>This is my talk for the workshop <a href="https://johncarlosbaez.wordpress.com/2017/01/23/quantifying-biological-complexity/">Biological Complexity: Can It Be Quantified?</a></p>
<p>• John Baez, <a href="http://math.ucr.edu/home/baez/bio_asu/bio_asu_web.pdf">Biology as information dynamics</a>, 2 February 2017.</p>
<blockquote><p>
<b>Abstract.</b> If biology is the study of self-replicating entities, and we want to understand the role of information, it makes sense to see how information theory is connected to the &#8216;replicator equation&#8217;—a simple model of population dynamics for self-replicating entities. The relevant concept of information turns out to be the information of one probability distribution relative to another, also known as the Kullback–Leibler divergence. Using this we can get a new outlook on free energy, see evolution as a learning process, and give a clean general formulation of Fisher&#8217;s fundamental theorem of natural selection.
</p></blockquote>
<p>For more, read:</p>
<p>• Marc Harper, <a href="http://arxiv.org/abs/0911.1763">The replicator equation as an inference dynamic</a>.</p>
<p>• Marc Harper, <a href="http://arxiv.org/abs/0911.1383">Information geometry and evolutionary game theory</a>.</p>
<p>• Barry Sinervo and Curt M. Lively, <a href="http://www.indiana.edu/~curtweb/L567/readings/Sinervo&amp;Lively1996.pdf">The rock-paper-scissors game and the evolution of alternative male strategies</a>, <i>Nature</i> <b>380</b> (1996), 240–243.</p>
<p>• John Baez, <a href="http://math.ucr.edu/home/baez/biodiversity/">Diversity, entropy and thermodynamics</a>.</p>
<p>• John Baez, <a href="http://math.ucr.edu/home/baez/">Information geometry</a>.</p>
<p>The last reference contains proofs of the equations shown in red in my slides.<br />
In particular, <a href="../information/information_geometry_16.html">Part 16</a> contains a proof of my updated version of Fisher&#8217;s fundamental theorem.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://johncarlosbaez.wordpress.com/2017/01/31/biology-as-information-dynamics/feed/</wfw:commentRss>
			<slash:comments>6</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">John Baez</media:title>
		</media:content>

		<media:content url="http://math.ucr.edu/home/baez/bio_asu/Forest-fruits-from-Barro-Colorado.png" medium="image" />
	</item>
		<item>
		<title>The Game of Googol</title>
		<link>https://johncarlosbaez.wordpress.com/2015/07/20/the-game-of-googol/</link>
					<comments>https://johncarlosbaez.wordpress.com/2015/07/20/the-game-of-googol/#comments</comments>
		
		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Mon, 20 Jul 2015 07:55:18 +0000</pubDate>
				<category><![CDATA[game theory]]></category>
		<category><![CDATA[mathematics]]></category>
		<category><![CDATA[probability]]></category>
		<category><![CDATA[puzzles]]></category>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=19942</guid>

					<description><![CDATA[Here&#8217;s a puzzle from a recent issue of Quanta, an online science magazine: Puzzle 1: I write down two different numbers that are completely unknown to you, and hold one in my left hand and one in my right. You have absolutely no idea how I generated these two numbers. Which is larger? You can [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Here&#8217;s a puzzle from a recent issue of <i>Quanta</i>, an online science magazine:</p>
<blockquote><p>
  <strong>Puzzle 1</strong>: I write down two different numbers that are completely unknown to you, and hold one in my left hand and one in my right. You have absolutely no idea how I generated these two numbers. Which is larger?</p>
<p>  You can point to one of my hands, and I will show you the number in it. Then you can decide to either select the number you have seen or switch to the number you have not seen, held in the other hand.  Is there a strategy that will give you a greater than 50% chance of choosing the larger number, no matter which two numbers I write down?
</p></blockquote>
<p>At first it seems the answer is no.  Whatever number you see, the other number could be larger or smaller.  There&#8217;s no way to tell.  So obviously you can&#8217;t get a better than 50% chance of picking the hand with the largest number&#8212;even if you&#8217;ve seen one of those numbers!</p>
<p>But &#8220;obviously&#8221; is not a proof.  Sometimes &#8220;obvious&#8221; things are wrong!</p>
<p>It turns out that, amazingly, the answer to the puzzle is <i>yes!</i>  You can find a strategy to do better than 50%.  But the strategy uses randomness.  So, this puzzle is a great illustration of the power of randomness.</p>
<p>If you want to solve it yourself, stop now or read <i>Quanta</i> magazine for some clues&#8212;they offered a small prize for the best answer:</p>
<p>&bull;  Pradeep Mutalik, <a href="https://www.quantamagazine.org/20150707-can-information-rise-from-randomness/">Can information rise from randomness?</a>, <i>Quanta</i>, 7 July 2015.</p>
<p>Greg Egan gave a nice solution in the comments to this magazine article, and I&#8217;ll reprint it below along with two followup puzzles.  So don&#8217;t look down there unless you want a spoiler.</p>
<p>I should add: the most common mistake among educated readers seems to be assuming that the first player, the one who chooses the two numbers, chooses them according to some probability distribution.  Don&#8217;t assume that.  They are simply <i>arbitrary numbers</i>.</p>
<h3> The history of this puzzle </h3>
<p>I&#8217;d seen this puzzle before&#8212;do you know who invented it?  <a href="https://plus.google.com/u/0/117663015413546257905/posts/EVYdMhSqtWu">On G+</a>, Hans Havermann wrote:</p>
<blockquote><p>
  I believe the origin of this puzzle goes back to (at least) John Fox and Gerald Marnie&#8217;s 1958 betting game <a href="https://en.wikipedia.org/wiki/Secretary_problem#The_game_of_googol">&#8216;Googol&#8217;</a>. Martin Gardner mentioned it in his February 1960 column in <em>Scientific American</em>. Wikipedia mentions it under the heading <a href="https://en.wikipedia.org/wiki/Secretary_problem#The_game_of_googol">&#8216;Secretary problem&#8217;</a>. Gardner suggested that a variant of the game was proposed by Arthur Cayley in 1875.﻿
</p></blockquote>
<p>Actually the game of Googol is a <em>generalization</em> of the puzzle that we&#8217;ve been discussing.  Martin Gardner explained it thus:</p>
<blockquote><p>
  Ask someone to take as many slips of paper as he pleases, and on each slip write a different positive number. The numbers may range from small fractions of 1 to a number the size of a googol (1 followed by a hundred 0s) or even larger. These slips are turned face down and shuffled over the top of a table. One at a time you turn the slips face up. The aim is to stop turning when you come to the number that you guess to be the largest of the series. You cannot go back and pick a previously turned slip. If you turn over all the slips, then of course you must pick the last one turned.
</p></blockquote>
<p>So, the puzzle I just showed you is the special case when there are just 2 slips of paper.  I seem to recall that Gardner incorrectly dismissed this case as trivial!</p>
<p>There&#8217;s been a lot of work on Googol.   Julien Berestycki writes:</p>
<blockquote><p>
  I heard about this puzzle a few years ago from Sasha Gnedin.  He has a very nice paper about this</p>
<p>  &bull; Alexander V. Gnedin, <a href="https://projecteuclid.org/euclid.aop/1176988613">A solution to the game of Googol</a>, <i>Annals of Probability</i> (1994), 1588&#8211;1595.</p>
<p>  One of the many beautiful ideas in this paper is that it asks what is the best strategy for the guy who writes the numbers! It also cites a paper by Gnedin and Berezowskyi (of oligarchic fame). ﻿
</p></blockquote>
<h3> Egan&#8217;s solution </h3>
<p>Okay, here is Greg Egan&#8217;s solution, paraphrased a bit:</p>
<p>Pick some function <img src="https://s0.wp.com/latex.php?latex=f+%3A+%5Cmathbb%7BR%7D+%5Cto+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f : &#92;mathbb{R} &#92;to &#92;mathbb{R}" class="latex" /> such that:</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clim_%7Bx+%5Cto+-%5Cinfty%7D+f%28x%29+%3D+0+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;lim_{x &#92;to -&#92;infty} f(x) = 0 }" class="latex" /></p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clim_%7Bx+%5Cto+%2B%5Cinfty%7D+f%28x%29+%3D+1+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;lim_{x &#92;to +&#92;infty} f(x) = 1 }" class="latex" /></p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f" class="latex" /> is strictly increasing: if <img src="https://s0.wp.com/latex.php?latex=x+%3E+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &gt; y" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=f%28x%29+%3E+f%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(x) &gt; f(y)" class="latex" /></p>
<p>There are lots of functions like this, for example</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7Bf%28x%29+%3D+%5Cfrac%7Be%5Ex%7D%7Be%5Ex+%2B+1%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{f(x) = &#92;frac{e^x}{e^x + 1} }" class="latex" /></p>
<p>Next, pick one of the first player&#8217;s hands at random. If the number you are shown is <img src="https://s0.wp.com/latex.php?latex=a%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a," class="latex" /> compute <img src="https://s0.wp.com/latex.php?latex=f%28a%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(a)." class="latex" />  Then generate a uniformly distributed random number <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z" class="latex" /> between 0 and 1.  If <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z" class="latex" /> is less than or equal to <img src="https://s0.wp.com/latex.php?latex=f%28a%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(a)" class="latex" /> guess that <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> is the larger number, but if <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z" class="latex" /> is greater than <img src="https://s0.wp.com/latex.php?latex=f%28a%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(a)" class="latex" /> guess that the larger number is in the other hand.</p>
<p>The probability of guessing correctly can be calculated as the probability of seeing the larger number initially and then, correctly, sticking with it, plus the probability of seeing the smaller number initially and then, correctly, choosing the other hand.</p>
<p>Say the larger number is <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> and the smaller one is <img src="https://s0.wp.com/latex.php?latex=y.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y." class="latex" />  Then the probability of guessing correctly is</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D+f%28x%29+%2B+%5Cfrac%7B1%7D%7B2%7D+%281+-+f%28y%29%29+%3D++%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B1%7D%7B2%7D+%28f%28x%29+-+f%28y%29%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;frac{1}{2} f(x) + &#92;frac{1}{2} (1 - f(y)) =  &#92;frac{1}{2} + &#92;frac{1}{2} (f(x) - f(y)) " class="latex" /></p>
<p>This is strictly greater than <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;frac{1}{2}" class="latex" /> since <img src="https://s0.wp.com/latex.php?latex=x+%3E+y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &gt; y" class="latex" /> so <img src="https://s0.wp.com/latex.php?latex=f%28x%29+-+f%28y%29+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(x) - f(y) &gt; 0" class="latex" />.</p>
<p>So, you have a more than 50% chance of winning!  But as you play the game, there&#8217;s no way to tell how much more than 50%.  If the numbers on the other players hands are very large, or very small, your chance will be just slightly more than 50%.</p>
<h3> Followup puzzles </h3>
<p>Here are two more puzzles:</p>
<p><strong>Puzzle 2:</strong> Prove that no deterministic strategy can guarantee you have a more than 50% chance of choosing the larger number.</p>
<p><strong>Puzzle 3:</strong> There are perfectly specific but &#8216;algorithmically random&#8217; sequences of bits, which can&#8217;t predicted well by any program.  If we use these to generate a uniform algorithmically random number between 0 and 1, and use the strategy Egan describes, will our chance of choosing the larger number be more than 50%, or not?﻿</p>
<p>But watch out&#8212;here come Egan&#8217;s solutions to those!</p>
<h3> Solutions </h3>
<p>Egan writes:</p>
<blockquote><p> Here are my answers to your two puzzles on G+.</p>
<p><b>Puzzle 2:</b><b> Prove that no deterministic strategy can guarantee you have a more than 50% chance of choosing the larger number.</p>
<p></b><b>Answer:</b> If we adopt a deterministic strategy, that means there is a function <img src="https://s0.wp.com/latex.php?latex=S%3A+%5Cmathbb%7BR%7D+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S: &#92;mathbb{R} &#92;to &#92;{0,1&#92;}" class="latex" /> that tells us whether on not we stick with the number x when we see it.  If <img src="https://s0.wp.com/latex.php?latex=S%28x%29%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(x)=1" class="latex" /> we stick with it, if <img src="https://s0.wp.com/latex.php?latex=S%28x%29%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(x)=0" class="latex" /> we swap it for the other number.</p>
<p>If the two numbers are <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y," class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=x+%3E+y%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &gt; y," class="latex" /> then the probability of success will be:</p>
<p><img src="https://s0.wp.com/latex.php?latex=P+%3D+0.5+%2B+0.5%28S%28x%29-S%28y%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P = 0.5 + 0.5(S(x)-S(y))" class="latex" /></p>
<p>This is exactly the same as the formula we obtained when we stuck with <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> with probability <img src="https://s0.wp.com/latex.php?latex=f%28x%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(x)," class="latex" /> but we have specialised to functions <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> valued in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{0,1&#92;}." class="latex" /></p>
<p>We can only guarantee a more than 50% chance of choosing the larger number if <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> is monotonically increasing everywhere, i.e. <img src="https://s0.wp.com/latex.php?latex=S%28x%29+%3E+S%28y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(x) &gt; S(y)" class="latex" /> whenever <img src="https://s0.wp.com/latex.php?latex=x+%3E+y.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &gt; y." class="latex" />  But this is impossible for a function valued in <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{0,1&#92;}." class="latex" />  To prove this, define <img src="https://s0.wp.com/latex.php?latex=x_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_0" class="latex" /> to be any number in <img src="https://s0.wp.com/latex.php?latex=%5B1%2C2%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="[1,2]" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=S%28x_0%29%3D0%3B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(x_0)=0;" class="latex" /> such an <img src="https://s0.wp.com/latex.php?latex=x_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_0" class="latex" /> must exist, otherwise <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> would be constant on <img src="https://s0.wp.com/latex.php?latex=%5B1%2C2%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="[1,2]" class="latex" /> and hence not monotonically increasing.  Similarly define <img src="https://s0.wp.com/latex.php?latex=x_1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_1" class="latex" /> to be any number in <img src="https://s0.wp.com/latex.php?latex=%5B-2%2C-1%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="[-2,-1]" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=S%28x_1%29+%3D+1.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(x_1) = 1." class="latex" />  We then have <img src="https://s0.wp.com/latex.php?latex=x_0+%3E+x_1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_0 &gt; x_1" class="latex" /> but <img src="https://s0.wp.com/latex.php?latex=S%28x_0%29+%3C+S%28x_1%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(x_0) &lt; S(x_1)." class="latex" /></p>
<p><b>Puzzle 3:</b> There are perfectly specific but &#8216;algorithmically random&#8217; sequences of bits, which can&#8217;t predicted well by any program.  If we use these to generate a uniform algorithmically random number between 0 and 1, and use the strategy Egan describes, will our chance of choosing the larger number be more than 50%, or not?﻿</p>
<p><b>Answer:</b> As Philip Gibbs noted, a deterministic pseudo-random number generator is still deterministic.  Using a specific sequence of algorithmically random bits </p>
<p><img src="https://s0.wp.com/latex.php?latex=%28b_1%2C+b_2%2C+%5Cdots+%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(b_1, b_2, &#92;dots ) " class="latex" /> </p>
<p>to construct a number <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z" class="latex" /> between <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1" class="latex" /> means <img src="https://s0.wp.com/latex.php?latex=z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z" class="latex" /> takes on the specific value:</p>
<p><img src="https://s0.wp.com/latex.php?latex=z_0+%3D+%5Csum_i+b_i+2%5E%7B-i%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z_0 = &#92;sum_i b_i 2^{-i} " class="latex" /></p>
<p>So rather than sticking with <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> with probability <img src="https://s0.wp.com/latex.php?latex=f%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(x)" class="latex" /> for our monotonically increasing function <img src="https://s0.wp.com/latex.php?latex=f%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f," class="latex" /> we end up always sticking with <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=z_0+%5Cle+f%28x%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z_0 &#92;le f(x)," class="latex" /> and always swapping if <img src="https://s0.wp.com/latex.php?latex=z_0+%3E+f%28x%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z_0 &gt; f(x)." class="latex" />  This is just using a function <img src="https://s0.wp.com/latex.php?latex=S%3A%5Cmathbb%7BR%7D+%5Cto+%5C%7B0%2C1%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S:&#92;mathbb{R} &#92;to &#92;{0,1&#92;}" class="latex" /> as in Puzzle 2, with:</p>
<p><img src="https://s0.wp.com/latex.php?latex=S%28x%29+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(x) = 0" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=x+%3C+f%5E%7B-1%7D%28z_0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &lt; f^{-1}(z_0)" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=S%28x%29+%3D+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(x) = 1" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=x+%5Cge+f%5E%7B-1%7D%28z_0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &#92;ge f^{-1}(z_0)" class="latex" /></p>
<p>So all the same consequences as in Puzzle 2 apply, and we cannot guarantee a more than 50% chance of choosing the larger number.</p>
</blockquote>
<p>Puzzle 3 emphasizes the huge gulf between &#8216;true randomness&#8217;, where we only have a probability distribution of numbers <img src="https://s0.wp.com/latex.php?latex=z%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z," class="latex" /> and the situation where we have a specific number <img src="https://s0.wp.com/latex.php?latex=z_0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z_0," class="latex" /> generated by any means whatsoever.</p>
<p>We could generate <img src="https://s0.wp.com/latex.php?latex=z_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z_0" class="latex" /> using a pseudorandom number generator, radioactive decay of atoms, an oracle whose randomness is certified by all the Greek gods, or whatever.  No matter how randomly <img src="https://s0.wp.com/latex.php?latex=z_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="z_0" class="latex" /> is generated, once we have it, we know there exist choices for the first player that will guarantee our defeat!</p>
<p>This may seem weird at first, but if you think about simple games of luck you&#8217;ll see it&#8217;s completely ordinary.  We can have a more than 50% chance of winning such a game even if for any particular play we make the other player has a move that ensures our defeat.  That&#8217;s just how randomness works.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://johncarlosbaez.wordpress.com/2015/07/20/the-game-of-googol/feed/</wfw:commentRss>
			<slash:comments>39</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">John Baez</media:title>
		</media:content>
	</item>
		<item>
		<title>Relative Entropy in Evolutionary Dynamics</title>
		<link>https://johncarlosbaez.wordpress.com/2014/01/22/relative-entropy-in-evolutionary-dynamics/</link>
					<comments>https://johncarlosbaez.wordpress.com/2014/01/22/relative-entropy-in-evolutionary-dynamics/#comments</comments>
		
		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Wed, 22 Jan 2014 01:00:45 +0000</pubDate>
				<category><![CDATA[biology]]></category>
		<category><![CDATA[game theory]]></category>
		<category><![CDATA[information and entropy]]></category>
		<category><![CDATA[mathematics]]></category>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17311</guid>

					<description><![CDATA[guest post by Marc Harper In John&#8217;s information geometry series, he mentioned some of my work in evolutionary dynamics. Today I&#8217;m going to tell you about some exciting extensions! The replicator equation First a little refresher. For a population of replicating types, such as individuals with different eye colors or a gene with distinct alleles, [&#8230;]]]></description>
										<content:encoded><![CDATA[<p><i>guest post by <b><a href="http://www.marcallenharper.com/">Marc Harper</a></b></i></p>
<p>In John&#8217;s <a href="http://math.ucr.edu/home/baez/information/index.html">information geometry</a> series, he mentioned some of my work in evolutionary dynamics. Today I&#8217;m going to tell you about some exciting extensions!</p>
<h3> The replicator equation </h3>
<p>First a little refresher. For a population of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> replicating types, such as individuals with different eye colors or a gene with <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> distinct <a href="http://en.wikipedia.org/wiki/Allele">alleles</a>, the &#8216;replicator equation&#8217; expresses the main idea of natural selection: the relative rate of growth of each type should be proportional to the difference between the fitness of the type and the mean fitness in the population.</p>
<p>To see why this equation should be true, let <img src="https://s0.wp.com/latex.php?latex=P_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P_i" class="latex" /> be the population of individuals of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th type, which we allow to be any nonnegative real number.  We can list all these numbers and get a vector:</p>
<p><img src="https://s0.wp.com/latex.php?latex=P+%3D+%28P_1%2C+%5Cdots%2C+P_n%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P = (P_1, &#92;dots, P_n) " class="latex" /></p>
<p>The <b>Lotka&ndash;Volterra equation</b> is a very general rule for how these numbers can change with time:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+P_i%7D%7Bd+t%7D+%3D+f_i%28P%29+P_i+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d P_i}{d t} = f_i(P) P_i } " class="latex" /></p>
<p>Each population grows at a rate proportional to itself, where the &#8216;constant of proportionality&#8217;, <img src="https://s0.wp.com/latex.php?latex=f_i%28P%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_i(P)," class="latex" /> is not necessarily constant: it can be any real-valued function of <img src="https://s0.wp.com/latex.php?latex=P.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P." class="latex" />  This function is called the <b>fitness</b> of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th type.  Taken all together, these functions <img src="https://s0.wp.com/latex.php?latex=f_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_i" class="latex" /> are called the <b>fitness landscape</b>.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> be the fraction of individuals who are of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th type:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_i+%3D+%5Cfrac%7BP_i%7D%7B%5Csum_%7Bi+%3D1%7D%5En+P_i+%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_i = &#92;frac{P_i}{&#92;sum_{i =1}^n P_i } }" class="latex" /></p>
<p>These numbers <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> are between 0 and 1, and they add up to 1.  So, we can also think of them as probabilities: <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> is the probability that a randomly chosen individual is of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th type.  This is how probability theory, and eventually entropy, gets into the game.</p>
<p>Again, we can bundle these numbers into a vector:</p>
<p><img src="https://s0.wp.com/latex.php?latex=p+%3D+%28p_1%2C+%5Cdots%2C+p_n%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p = (p_1, &#92;dots, p_n) " class="latex" /></p>
<p>which we call the <b>population distribution</b>.  It turns out that the Lotka&ndash;Volterra equation implies the <b>replicator equation</b>:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+p_i%7D%7Bd+t%7D+%3D+%5Cleft%28+f_i%28P%29+-+%5Clangle+f%28P%29+%5Crangle+%5Cright%29+%5C%2C+p_i+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d p_i}{d t} = &#92;left( f_i(P) - &#92;langle f(P) &#92;rangle &#92;right) &#92;, p_i } " class="latex" /></p>
<p>where</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Clangle+f%28P%29+%5Crangle+%3D+%5Csum_%7Bi+%3D1%7D%5En++f_i%28P%29++p_i++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;langle f(P) &#92;rangle = &#92;sum_{i =1}^n  f_i(P)  p_i  } " class="latex" /></p>
<p>is the <b>mean fitness</b> of all the individuals.  You can see the proof in <a href="http://math.ucr.edu/home/baez/information/information_geometry_9.html">Part 9</a> of the information geometry series.</p>
<p>By the way: if each fitness <img src="https://s0.wp.com/latex.php?latex=f_i%28P%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_i(P)" class="latex" /> only depends on the fraction of individuals of each type, not the total numbers, we can write the replicator equation in a simpler way:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+p_i%7D%7Bd+t%7D+%3D+%5Cleft%28+f_i%28p%29+-+%5Clangle+f%28p%29+%5Crangle+%5Cright%29+%5C%2C+p_i+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d p_i}{d t} = &#92;left( f_i(p) - &#92;langle f(p) &#92;rangle &#92;right) &#92;, p_i } " class="latex" /></p>
<p>From now on, when talking about this equation, that&#8217;s what I&#8217;ll do.</p>
<p>Anyway, the take-home message is this: the replicator equation says the fraction of individuals of any type changes at a rate proportional to fitness of that type minus the mean fitness.</p>
<p>Now, it has been known since the late 1970s or early 1980s, thanks to the work of Akin, Bomze, Hofbauer, Shahshahani, and others, that the replicator equation has some very interesting properties.   For one thing, it often makes &#8216;relative entropy&#8217; decrease.   For another, it&#8217;s often an example of &#8216;gradient flow&#8217;.   Let&#8217;s look at both of these in turn, and then talk about some new generalizations of these facts.</p>
<h3> Relative entropy as a Lyapunov function </h3>
<p>I mentioned that we can think of a population distribution as a probability distribution.  This lets us take ideas from probability theory and even information theory and apply them to evolutionary dynamics!  For example, given two population distributions <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q," class="latex" /> the <b>information</b> of <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> <b>relative to</b> <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> is</p>
<p><img src="https://s0.wp.com/latex.php?latex=I%28q%2Cp%29+%3D+%5Cdisplaystyle%7B+%5Csum_i+q_i+%5Cln+%5Cleft%28%5Cfrac%7Bq_i%7D%7Bp_i+%7D%5Cright%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="I(q,p) = &#92;displaystyle{ &#92;sum_i q_i &#92;ln &#92;left(&#92;frac{q_i}{p_i }&#92;right)} " class="latex" /></p>
<p>This measures how much information you gain if you have a hypothesis about some state of affairs given by the probability distribution <img src="https://s0.wp.com/latex.php?latex=p%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p," class="latex" /> and then someone tells you &#8220;no, the best hypothesis is <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" />!”</p>
<p>It may seem weird to treat a <i>population distribution</i> as a <i>hypothesis</i>, but this turns out to be a good idea.  Evolution can then be seen as a learning process: a process of improving the hypothesis.</p>
<p>We can make this precise by seeing how the relative information changes with the passage of time.  Suppose we have two population distributions <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=p.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p." class="latex" />   Suppose <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> is fixed, while <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> evolves in time according to the replicator equation.  Then</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%5Cfrac%7Bd%7D%7Bd+t%7D+I%28q%2Cp%29++%3D++%5Csum_i+f_i%28P%29+%28p_i+-+q_i%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  &#92;frac{d}{d t} I(q,p)  =  &#92;sum_i f_i(P) (p_i - q_i) } " class="latex" /></p>
<p>For the proof, see <a href="https://johncarlosbaez.wordpress.com/2012/06/07/information-geometry-part-11/">Part 11</a> of the information geometry series.</p>
<p>So, the information of <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> relative to <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> will decrease as <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> evolves according to the replicator equation if</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%5Csum_i+f_i%28P%29+%28p_i+-+q_i%29+%7D+%5Cle+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  &#92;sum_i f_i(P) (p_i - q_i) } &#92;le 0 " class="latex" /></p>
<p>If <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> makes this true for all <img src="https://s0.wp.com/latex.php?latex=p%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p," class="latex" /> we say <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> is an <b>evolutionarily stable state</b>.   For some reasons why, see <a href="https://johncarlosbaez.wordpress.com/2012/06/26/information-geometry-part-13/">Part 13</a>.</p>
<p>What matters now is that when <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> is an evolutionarily stable state, <img src="https://s0.wp.com/latex.php?latex=I%28q%2Cp%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="I(q,p)" class="latex" /> says how much information the population has &#8216;left to learn&#8217;&mdash;and we&#8217;re seeing that this always <i>decreases</i>.  Moreover, it turns out that we always have</p>
<p><img src="https://s0.wp.com/latex.php?latex=I%28q%2Cp%29+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="I(q,p) &#92;ge 0" class="latex" /></p>
<p>and <img src="https://s0.wp.com/latex.php?latex=I%28q%2Cp%29+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="I(q,p) = 0" class="latex" /> precisely when <img src="https://s0.wp.com/latex.php?latex=p+%3D+q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p = q." class="latex" /></p>
<p>People summarize all this by saying that relative information is a &#8216;Lyapunov function&#8217;.  Very roughly, a Lyapunov function is something that decreases with the passage of time, and is zero only at the unique stable state.   To be a bit more precise, suppose we have a differential equation like</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%5Cfrac%7Bd%7D%7Bd+t%7D+x%28t%29+%3D+v%28x%28t%29%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  &#92;frac{d}{d t} x(t) = v(x(t)) } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=x%28t%29+%5Cin+%5Cmathbb%7BR%7D%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x(t) &#92;in &#92;mathbb{R}^n" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="v" class="latex" /> is some smooth vector field on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5En.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}^n." class="latex" />  Then a smooth function</p>
<p><img src="https://s0.wp.com/latex.php?latex=V+%3A+%5Cmathbb%7BR%7D%5En+%5Cto+%5Cmathbb%7BR%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V : &#92;mathbb{R}^n &#92;to &#92;mathbb{R} " class="latex" /></p>
<p>is a <b>Lyapunov function</b> if</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=V%28x%29+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V(x) &#92;ge 0" class="latex" /> for all <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /></p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=V%28x%29+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V(x) = 0" class="latex" /> iff <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> is some particular point <img src="https://s0.wp.com/latex.php?latex=x_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_0" class="latex" /></p>
<p>and</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%7D%7Bd+t%7D+V%28x%28t%29%29+%5Cle+0+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d}{d t} V(x(t)) &#92;le 0 }" class="latex" /> for every solution of our differential equation.</p>
<p>In this situation, the point <img src="https://s0.wp.com/latex.php?latex=x_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_0" class="latex" /> is a stable equilibrium for our differential equation: this is <b><a href="http://control.ee.ethz.ch/~ifalst/docs/lyapunov.pdf">Lyapunov&#8217;s theorem</a></b>.</p>
<h3> The replicator equation as a gradient flow equation </h3>
<p>The basic idea of Lyapunov&#8217;s theorem is that when a ball likes to roll downhill and the landscape has just one bottom point, that point will be the unique stable equilibrium for the ball.</p>
<p>The idea of gradient flow is similar, but different: sometimes things like to roll downhill <i>as efficiently as possible</i>: they move in the exactly the <i>best direction</i> to make some quantity smaller!  Under certain conditions, the replicator equation is an example of this phenomenon.</p>
<p>Let&#8217;s fill in some details.  For starters, suppose we have some function</p>
<p><img src="https://s0.wp.com/latex.php?latex=F+%3A+%5Cmathbb%7BR%7D%5En+%5Cto+%5Cmathbb%7BR%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F : &#92;mathbb{R}^n &#92;to &#92;mathbb{R} " class="latex" /></p>
<p>Think of <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V" class="latex" /> as &#8216;height&#8217;.  Then the <b>gradient flow equation</b> says how a point <img src="https://s0.wp.com/latex.php?latex=x%28t%29+%5Cin+%5Cmathbb%7BR%7D%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x(t) &#92;in &#92;mathbb{R}^n" class="latex" /> will move if it&#8217;s always trying its very best to go downhill:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%7D%7Bd+t%7D+x%28t%29+%3D+-+%5Cnabla+V%28x%28t%29%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d}{d t} x(t) = - &#92;nabla V(x(t)) } " class="latex" /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=%5Cnabla&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;nabla" class="latex" /> is the usual gradient in Euclidean space:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cnabla+V+%3D+%5Cleft%28%5Cpartial_1+V%2C+%5Cdots%2C+%5Cpartial_n+V+%5Cright%29++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;nabla V = &#92;left(&#92;partial_1 V, &#92;dots, &#92;partial_n V &#92;right)  } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Cpartial_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial_i" class="latex" /> is short for the partial derivative with respect to the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th coordinate.</p>
<p>The interesting thing is that under certain conditions, the replicator equation is an example of a gradient flow equation&#8230; but typically <i>not</i> one where <img src="https://s0.wp.com/latex.php?latex=%5Cnabla&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;nabla" class="latex" /> is the usual gradient in Euclidean space.  Instead, it&#8217;s the gradient on some other space, the space of all population distributions, which has a non-Euclidean geometry!</p>
<p>The space of all population distributions is a <a href="https://en.wikipedia.org/wiki/Simplex">simplex</a>:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5C%7B+p+%5Cin+%5Cmathbb%7BR%7D%5En+%3A+%5C%3B+p_i+%5Cge+0%2C+%5C%3B+%5Csum_%7Bi+%3D+1%7D%5En+p_i+%3D+1+%5C%7D+.+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{ p &#92;in &#92;mathbb{R}^n : &#92;; p_i &#92;ge 0, &#92;; &#92;sum_{i = 1}^n p_i = 1 &#92;} . " class="latex" /></p>
<p>For example, it&#8217;s an equilateral triangle when <img src="https://s0.wp.com/latex.php?latex=n+%3D+3.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n = 3." class="latex" />  The equilateral triangle looks flat, but if we measure distances another way it becomes round, exactly like a portion of a sphere, and that&#8217;s the non-Euclidean geometry we need!</p>
<div align="center"><img width="400" src="https://i0.wp.com/math.ucr.edu/home/baez/mathematical/harper/simplex_eighth-sphere.png" /></div>
<p>In fact this trick works in any dimension.  The idea is to give the simplex a special <a href="https://en.wikipedia.org/wiki/Metric_tensor">Riemannian metric</a>, the &#8216;Fisher information metric&#8217;.  The usual metric on Euclidean space is</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdelta_%7Bi+j%7D+%3D+%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bccl%7D+1+%26+%5Cmathrm%7B+if+%7D+%26+i+%3D+j+%5C%5C+++++++++++++++++++++++++++++++++++++++0+%26%5Cmathrm%7B+if+%7D+%26+i+%5Cne+j+%5Cend%7Barray%7D+%5Cright.+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;delta_{i j} = &#92;left&#92;{&#92;begin{array}{ccl} 1 &amp; &#92;mathrm{ if } &amp; i = j &#92;&#92;                                       0 &amp;&#92;mathrm{ if } &amp; i &#92;ne j &#92;end{array} &#92;right. " class="latex" /></p>
<p>This simply says that two standard basis vectors like <img src="https://s0.wp.com/latex.php?latex=%280%2C1%2C0%2C0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(0,1,0,0)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%280%2C0%2C1%2C0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(0,0,1,0)" class="latex" /> have dot product zero if the 1&#8217;s are in different places, and one if they&#8217;re in the same place.  The <b>Fisher information metric</b> is a bit more complicated:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+g_%7Bi+j%7D+%3D+%5Cfrac%7B%5Cdelta_%7Bi+j%7D%7D%7Bp_i%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ g_{i j} = &#92;frac{&#92;delta_{i j}}{p_i} } " class="latex" /></p>
<p>As before, <img src="https://s0.wp.com/latex.php?latex=g_%7Bi+j%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="g_{i j}" class="latex" /> is a formula for the dot product of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th and <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j" class="latex" />th standard basis vectors, but now it depends on where you are in the simplex of population distributions.</p>
<p>We saw how this formula arises from information theory back in <a href="http://math.ucr.edu/home/baez/information/information_geometry_7.html">Part 7</a>.  I won&#8217;t repeat the calculation, but the idea is this.  Fix a population distribution <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> and consider the information of another one, say <img src="https://s0.wp.com/latex.php?latex=q%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q," class="latex" /> relative to this.  We get <img src="https://s0.wp.com/latex.php?latex=I%28q%2Cp%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="I(q,p)." class="latex" />  If <img src="https://s0.wp.com/latex.php?latex=q+%3D+p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q = p" class="latex" /> this is zero:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cleft.+I%28q%2Cp%29%5Cright%7C_%7Bq+%3D+p%7D+%3D+0+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;left. I(q,p)&#92;right|_{q = p} = 0 } " class="latex" /></p>
<p>and this point is a local minimum for the relative information. So, the first derivative of <img src="https://s0.wp.com/latex.php?latex=I%28q%2Cp%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="I(q,p)" class="latex" /> as we change <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> must be zero:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cleft.+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+q_i%7D+I%28q%2Cp%29+%5Cright%7C_%7Bq+%3D+p%7D+%3D+0+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;left. &#92;frac{&#92;partial}{&#92;partial q_i} I(q,p) &#92;right|_{q = p} = 0 } " class="latex" /></p>
<p>But the second derivatives are not zero. In fact, since we&#8217;re at a local minimum, it should not be surprising that we get a positive definite <a href="https://en.wikipedia.org/wiki/Hessian_matrix">matrix of second derivatives</a>:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++g_%7Bi+j%7D+%3D+%5Cleft.+%5Cfrac%7B%5Cpartial%5E2%7D%7B%5Cpartial+q_i+%5Cpartial+q_j%7D+I%28q%2Cp%29+%5Cright%7C_%7Bq+%3D+p%7D+%3D+0+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  g_{i j} = &#92;left. &#92;frac{&#92;partial^2}{&#92;partial q_i &#92;partial q_j} I(q,p) &#92;right|_{q = p} = 0 } " class="latex" /></p>
<p>And, this is the Fisher information metric!  So, the Fisher information metric is a way of taking dot products between vectors in the simplex of population distribution that&#8217;s based on the concept of relative information.</p>
<p>This is not the place to explain <a href="https://en.wikipedia.org/wiki/Riemannian_geometry">Riemannian geometry</a>, but any metric gives a way to measure angles and distances, and thus a way to define the gradient of a function.  After all, the gradient of a function should point at right angles to the level sets of that function, and its length should equal the slope of that function:</p>
<div align="center">
<a href="http://www.math.udel.edu/~driscoll/teaching/243/maple/Gradients.html"><img src="https://i0.wp.com/math.ucr.edu/home/baez/mathematical/harper/gradient.gif" /></a>
</div>
<p>So, if we change our way of measuring angles and distances, we get a new concept of gradient!  The <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th component of this new gradient vector field turns out to b</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Cnabla_g+V%29%5Ei+%3D+g%5E%7Bi+j%7D+%5Cpartial_j+V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;nabla_g V)^i = g^{i j} &#92;partial_j V" class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=g%5E%7Bi+j%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="g^{i j}" class="latex" /> is the inverse of the matrix <img src="https://s0.wp.com/latex.php?latex=g_%7Bi+j%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="g_{i j}," class="latex" /> and we sum over the repeated index <img src="https://s0.wp.com/latex.php?latex=j.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j." class="latex" />   As a sanity check, make sure you see why this is the usual Euclidean gradient when <img src="https://s0.wp.com/latex.php?latex=g_%7Bi+j%7D+%3D+%5Cdelta_%7Bi+j%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="g_{i j} = &#92;delta_{i j}." class="latex" /></p>
<p>Now suppose the fitness landscape is the good old Euclidean gradient of some function.  Then it turns out that the replicator equation is a special case of gradient flow on the space of population distributions&#8230; but where we use the Fisher information metric to define our concept of gradient!</p>
<p>To get a feel for this, it&#8217;s good to start with the Lotka&ndash;Volterra equation, which describes how the total number of individuals of each type changes.  Suppose the fitness landscape is the Euclidean gradient of some function <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V" class="latex" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+f_i%28P%29+%3D+%5Cfrac%7B%5Cpartial+V%7D%7B%5Cpartial+P_i%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ f_i(P) = &#92;frac{&#92;partial V}{&#92;partial P_i} } " class="latex" /></p>
<p>Then the Lotka&ndash;Volterra equation becomes this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+P_i%7D%7Bd+t%7D+%3D+%5Cfrac%7B%5Cpartial+V%7D%7B%5Cpartial+P_i%7D+%5C%2C+P_i+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d P_i}{d t} = &#92;frac{&#92;partial V}{&#92;partial P_i} &#92;, P_i } " class="latex" /></p>
<p>This doesn&#8217;t look like the gradient flow equation, thanks to that annoying <img src="https://s0.wp.com/latex.php?latex=P_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P_i" class="latex" /> on the right-hand side!  It certainly ain&#8217;t the gradient flow coming from the function <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V" class="latex" /> and the usual Euclidean gradient.  However, it <i>is</i> gradient flow coming from <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V" class="latex" /> and some <i>other</i> metric on the space</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5C%7B+P+%5Cin+%5Cmathbb%7BR%7D%5En+%3A+%5C%3B+P_i+%5Cge+0+%5C%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{ P &#92;in &#92;mathbb{R}^n : &#92;; P_i &#92;ge 0 &#92;}  " class="latex" /></p>
<p>For a proof, and the formula for this other metric, see Section 3.7 in this survey:</p>
<p>&bull; Marc Harper, <a href="http://arxiv.org/abs/0911.1383">Information geometry and evolutionary game theory</a>.</p>
<p>Now let&#8217;s turn to the replicator equation:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+p_i%7D%7Bd+t%7D+%3D+%5Cleft%28+f_i%28p%29++-+%5Clangle+f%28p%29+%5Crangle+%5Cright%29+%5C%2C+p_i+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d p_i}{d t} = &#92;left( f_i(p)  - &#92;langle f(p) &#92;rangle &#92;right) &#92;, p_i } " class="latex" /></p>
<p>Again, if the fitness landscape is a Euclidean gradient, we can rewrite the replicator equation as a gradient flow equation&#8230; but again, not with respect to the Euclidean metric.  This time we need to use the Fisher information metric! I sketch a proof in my paper above.</p>
<p>In fact, both these results were first worked out by Shahshahani:</p>
<p>&bull; Siavash Shahshahani, <i>A New Mathematical Framework for the Study of Linkage and Selection</i>, <i>Memoirs of the AMS</i> <b>17</b>, 1979.</p>
<h3> New directions </h3>
<p>All this is just the beginning!  The ideas I just explained are unified in information geometry, where distance-like quantities such as the relative entropy and the Fisher information metric are studied.  From here it&#8217;s a short walk to a very nice version of <a href="https://en.wikipedia.org/wiki/Fisher%27s_fundamental_theorem_of_natural_selection">Fisher&#8217;s fundamental theorem of natural selection</a>, which is familiar to researchers both in evolutionary dynamics and in information geometry.</p>
<p>You can see some very nice versions of this story for maximum likelihood estimators and linear programming here:</p>
<p>&bull; Akio Fujiwara and Shun-ichi Amari, Gradient systems in view of information geometry, <a href="http://www.sciencedirect.com/science/article/pii/016727899400175P"><i>Physica D: Nonlinear Phenomena</i></a> <b>80</b> (1995), 317&ndash;327.</p>
<p>Indeed, this seems to be the first paper discussing the similarities between evolutionary game theory and information geometry.</p>
<p>Dash Fryer (at Pomona College) and I have generalized this story in several interesting ways.</p>
<p>First, there are two famous ways to generalize the usual formula for entropy: <a href="http://en.wikipedia.org/wiki/Tsallis_entropy">Tsallis entropy</a> and <a href="http://en.wikipedia.org/wiki/R%C3%A9nyi_entropy">R&eacute;nyi entropy</a>, both of which involve a parameter <img src="https://s0.wp.com/latex.php?latex=q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q." class="latex" />  There are Tsallis and R&eacute;nyi versions of relative entropy and the Fisher information metric as well.  Everything I just explained about:</p>
<p>&bull; conditions under which relative entropy is a Lyapunov function for the replicator equation, and</p>
<p>&bull; conditions under which the replicator equation is a special case of gradient flow</p>
<p>generalize to these cases!  However, these generalized entropies give modified versions of the replicator equation.  When we set <img src="https://s0.wp.com/latex.php?latex=q%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q=1" class="latex" /> we get back the usual story.  See</p>
<p>&bull; Marc Harper, <a href="http://arxiv.org/abs/0911.1764">Escort evolutionary game theory</a>.</p>
<p>My initial interest in these alternate entropies was mostly mathematical&#8212;what is so special about the corresponding geometries?&#8212;but now researchers are starting to find populations that evolve according to these kinds of modified population dynamics!  For example:</p>
<p>&bull; A. Hernando <i>et al</i>, <a href="http://arxiv.org/abs/1201.0905">The workings of the Maximum Entropy Principle in collective human behavior</a>.</p>
<p>There&#8217;s an interesting special case worth some attention. Lots of people fret about the relative entropy not being a distance function obeying the axioms that mathematicians like: for example, it doesn&#8217;t obey the triangle inequality.   Many describe the relative entropy as a <i>distance-like</i> function, and this is often a valid interpretation contextually.  On the other hand, the <img src="https://s0.wp.com/latex.php?latex=q%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q=0" class="latex" /> relative entropy is one-half the Euclidean distance squared!  In this case the modified version of the replicator equation looks like this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+p_i%7D%7Bd+t%7D+%3D+f_i%28p%29+-+%5Cfrac%7B1%7D%7Bn%7D+%5Csum_%7Bj+%3D+1%7D%5En+f_j%28p%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d p_i}{d t} = f_i(p) - &#92;frac{1}{n} &#92;sum_{j = 1}^n f_j(p) } " class="latex" /></p>
<p>This equation is called the <b>projection dynamic</b>.</p>
<p>Later, I showed that there is a reasonable definition of relative entropy for a much larger family of geometries that satisfies a similar <i>distance minimization</i> property.</p>
<p>In a different direction, Dash showed that you can change the way that selection acts by using a variety of alternative ‘incentives’, extending the story to some other well-known equations describing evolutionary dynamics. By replacing the terms <img src="https://s0.wp.com/latex.php?latex=x_i+f_i%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_i f_i(x)" class="latex" /> in the replicator equation with a variety of other functions, called <b>incentives</b>, we can generate many commonly studied models of evolutionary dynamics. For instance if we exponentiate the fitness landscape (to make it always positive), we get what is commonly known as the <b>logit dynamic</b>.  This amounts to changing the fitness landscape as follows:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+f_i+%5Cmapsto+%5Cfrac%7Bx_i+e%5E%7B%5Cbeta+f_i%7D%7D%7B%5Csum_j%7Bx_j+e%5E%7B%5Cbeta+f_j%7D%7D%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ f_i &#92;mapsto &#92;frac{x_i e^{&#92;beta f_i}}{&#92;sum_j{x_j e^{&#92;beta f_j}}} } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> is known as an <b>inverse temperature</b> in statistical thermodynamics and as an <b>intensity of selection</b> in evolutionary dynamics. There are lots of modified versions of the replicator equation, like the best-reply and projection dynamics, more common in economic applications of evolutionary game theory, and they can all be captured in this family. (There are also other ways to simultaneously capture such families, such as Bill Sandholm&#8217;s revision protocols, which were introduced earlier in his exploration of the foundations of game dynamics.)</p>
<p>Dash showed that there is a natural generalization of evolutionarily stable states to &#8216;incentive stable states&#8217;, and that for incentive stable states, the relative entropy is decreasing to zero when the trajectories get near the equilibrium. For the logit and projection dynamics, incentive stable states are simply evolutionarily stable states, and this happens frequently, but not always.</p>
<p>The third generalization is to look at different &#8216;time-scales&#8217;&#8212;that is, different ways of describing time!  We can make up the symbol <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BT%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{T}" class="latex" /> for a general choice of &#8216;time-scale&#8217;.  So far I&#8217;ve been treating time as a real number, so</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BT%7D+%3D+%5Cmathbb%7BR%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{T} = &#92;mathbb{R} " class="latex" /></p>
<p>But we can also treat time as coming in discrete evenly spaced steps, which amounts to treating time as an integer:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BT%7D+%3D+%5Cmathbb%7BZ%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{T} = &#92;mathbb{Z} " class="latex" /></p>
<p>More generally, we can make the steps have duration <img src="https://s0.wp.com/latex.php?latex=h%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="h," class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="h" class="latex" /> is any positive real number:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BT%7D+%3D+h%5Cmathbb%7BZ%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{T} = h&#92;mathbb{Z} " class="latex" /></p>
<p>There is a nice way to simultaneously describe the cases <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BT%7D+%3D+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{T} = &#92;mathbb{R}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BT%7D+%3D+h%5Cmathbb%7BZ%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{T} = h&#92;mathbb{Z}" class="latex" /> using the <a href="http://en.wikipedia.org/wiki/Time-scale_calculus">time-scale calculus</a> and time-scale derivatives. For the time-scale <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BT%7D+%3D+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{T} = &#92;mathbb{R}" class="latex" /> the time-scale derivative is just the ordinary derivative. For the time-scale <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BT%7D+%3D+h%5Cmathbb%7BZ%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{T} = h&#92;mathbb{Z}," class="latex" /> the time-scale derivative is given by the difference quotient from first year calculus:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+f%5E%7B%5CDelta%7D%28z%29+%3D+%5Cfrac%7Bf%28z%2Bh%29+-+f%28z%29%7D%7Bh%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ f^{&#92;Delta}(z) = &#92;frac{f(z+h) - f(z)}{h} } " class="latex" /></p>
<p>and using this as a substitute for the derivative gives difference equations like a discrete-time version of the replicator equation.  There are many other choices of time-scale, such as the <b>quantum time-scale</b> given by <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BT%7D+%3D+q%5E%7B%5Cmathbb%7BZ%7D%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{T} = q^{&#92;mathbb{Z}}," class="latex" /> in which case the time-scale derivative is called the <a href="https://en.wikipedia.org/wiki/Q-derivative"><i>q</i>-derivative</a>, but that&#8217;s a tale for another time.  In any case, the fact that the successive relative entropies are decreasing can be simply state by saying they have negative <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BT%7D+%3D+h%5Cmathbb%7BZ%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{T} = h&#92;mathbb{Z}" class="latex" /> time-scale derivative.   The continuous case we started with corresponds to <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BT%7D+%3D+%5Cmathbb%7BR%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{T} = &#92;mathbb{R}." class="latex" /></p>
<p>Remarkably, Dash and I were able to show that you can combine all three of these generalizations into one theorem, and even allow for multiple interacting populations! This produces some really neat population trajectories, such as the following two populations with three types, with fitness functions corresponding to the <a href="https://en.wikipedia.org/wiki/Rock-paper-scissors#Rock-paper-scissors_analogies_in_nature">rock-paper-scissors game</a>. On top we have the replicator equation, which goes along with the Fisher information metric; on the bottom we have the logit dynamic, which goes along with the Euclidean metric on the simplex:</p>
<div align="center">
<img src="https://i1.wp.com/math.ucr.edu/home/baez/mathematical/harper/figure_8_1.png" width="300" /></p>
<p><img src="https://i0.wp.com/math.ucr.edu/home/baez/mathematical/harper/figure_8_2.png" width="300" />
</div>
<p>From our theorem, it follows that the relative entropy (ordinary relative entropy on top, the <img src="https://s0.wp.com/latex.php?latex=q+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q = 0" class="latex" /> entropy on bottom) converges to zero along the population trajectories.</p>
<p>The final form of the theorem is loosely as follows. Pick a Riemannian geometry given by a metric <img src="https://s0.wp.com/latex.php?latex=g&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="g" class="latex" /> (obeying some mild conditions) and an incentive for each population, as well as a time scale (<img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=h+%5Cmathbb%7BZ%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="h &#92;mathbb{Z}" class="latex" />) for every population. This gives an evolutionary dynamic with a natural generalization of evolutionarily stable states, and a suitable version of the relative entropy.   Then, if there is an evolutionarily stable state in the interior of the simplex, the time-scale derivative of sum of the relative entropies for each population will decrease as the trajectories converge to the stable state!</p>
<p>When there isn&#8217;t such a stable state, we still get some interesting population dynamics, like the following:</p>
<div align="center">
<img src="https://i1.wp.com/math.ucr.edu/home/baez/mathematical/harper/figure_9_1.png" width="300" /><br />
<img src="https://i0.wp.com/math.ucr.edu/home/baez/mathematical/harper/figure_9_2.png" width="300" />
</div>
<p>See this paper for details:</p>
<p>&bull; Marc Harper and Dashiell E. A. Fryer, <a href="http://arxiv.org/abs/1210.5539">Stability of evolutionary dynamics on time scales</a>.</p>
<p>Next time we&#8217;ll see how to make the main idea work in finite populations, without derivatives or deterministic trajectories!</p>
]]></content:encoded>
					
					<wfw:commentRss>https://johncarlosbaez.wordpress.com/2014/01/22/relative-entropy-in-evolutionary-dynamics/feed/</wfw:commentRss>
			<slash:comments>30</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">John Baez</media:title>
		</media:content>

		<media:content url="http://math.ucr.edu/home/baez/mathematical/harper/simplex_eighth-sphere.png" medium="image" />

		<media:content url="http://math.ucr.edu/home/baez/mathematical/harper/gradient.gif" medium="image" />

		<media:content url="http://math.ucr.edu/home/baez/mathematical/harper/figure_8_1.png" medium="image" />

		<media:content url="http://math.ucr.edu/home/baez/mathematical/harper/figure_8_2.png" medium="image" />

		<media:content url="http://math.ucr.edu/home/baez/mathematical/harper/figure_9_1.png" medium="image" />

		<media:content url="http://math.ucr.edu/home/baez/mathematical/harper/figure_9_2.png" medium="image" />
	</item>
		<item>
		<title>Game Theory (Part 20)</title>
		<link>https://johncarlosbaez.wordpress.com/2013/03/11/game-theory-part-20/</link>
					<comments>https://johncarlosbaez.wordpress.com/2013/03/11/game-theory-part-20/#comments</comments>
		
		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Mon, 11 Mar 2013 22:41:36 +0000</pubDate>
				<category><![CDATA[game theory]]></category>
		<category><![CDATA[mathematics]]></category>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=15427</guid>

					<description><![CDATA[Last time we tackled von Neumann&#8217;s minimax theorem: Theorem. For every zero-sum 2-player normal form game, where ranges over player A&#8217;s mixed strategies and ranges over player B&#8217;s mixed strategies. We reduced the proof to two geometrical lemmas. Now let&#8217;s prove those&#8230; and finish up the course! But first, let me chat a bit about [&#8230;]]]></description>
										<content:encoded><![CDATA[<p><a href="https://johncarlosbaez.wordpress.com/2013/03/07/game-theory-part-19/">Last time</a> we tackled von Neumann&#8217;s minimax theorem:</p>
<p><b>Theorem.</b> For every zero-sum 2-player normal form game,</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5Cmin_%7Bq%27%7D+%5Cmax_%7Bp%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27+%3D+%5Cmax_%7Bp%27%7D+%5Cmin_%7Bq%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;min_{q&#039;} &#92;max_{p&#039;} &#92;; p&#039; &#92;cdot A q&#039; = &#92;max_{p&#039;} &#92;min_{q&#039;} &#92;; p&#039; &#92;cdot A q&#039;}" class="latex" />
</div>
<p>where <img src="https://s0.wp.com/latex.php?latex=p%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p&#039;" class="latex" /> ranges over player A&#8217;s mixed strategies and <img src="https://s0.wp.com/latex.php?latex=q%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q&#039;" class="latex" /> ranges over player B&#8217;s mixed strategies.</p>
<p>We reduced the proof to two geometrical lemmas.  Now let&#8217;s prove those&#8230; and finish up the course!</p>
<p>But first, let me chat a bit about this theorem.  Von Neumann first proved it in 1928.  He later wrote:</p>
<blockquote><p>
As far as I can see, there could be no theory of games … without that theorem … I thought there was nothing worth publishing until the Minimax Theorem was proved.
</p></blockquote>
<p>Von Neumann&#8217;s gave several proofs of this result:</p>
<p>&bull;  Tinne Hoff Kjeldesen, <a href="http://www.theoremoftheday.org/Docs/Kjeldsen.pdf">John von Neumann’s conception of the minimax theorem: a journey through different mathematical contexts</a>, <i>Arch. Hist. Exact Sci.</i> <b>56</b> (2001) 39&#8211;68.</p>
<p>In 1937 he gave a proof which became quite famous, based on an important result in topology: <a href="http://en.wikipedia.org/wiki/Brouwer_fixed-point_theorem">Brouwer&#8217;s fixed point theorem</a>.  This says that if you have a ball </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=B+%3D+%5C%7B+x+%5Cin+%5Cmathbb%7BR%7D%5En+%3A+%5C%7Cx%5C%7C+%5Cle+1+%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B = &#92;{ x &#92;in &#92;mathbb{R}^n : &#92;|x&#92;| &#92;le 1 &#92;}" class="latex" />
</div>
<p>and a continuous function</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=f%3A+B+%5Cto+B+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f: B &#92;to B " class="latex" />
</div>
<p>then this function has a <b>fixed point</b>, meaning a point <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x &#92;in B" class="latex" /> with</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=f%28x%29+%3D+x+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(x) = x " class="latex" />
</div>
<p>You&#8217;ll often seen Brouwer&#8217;s fixed point theorem in a first course on algebraic topology, though John Milnor came up with a proof using just <a href="http://people.ucsc.edu/~lewis/Math208/hairyball.pdf">multivariable calculus and a bit more</a>.  </p>
<p>After von Neumann proved his minimax theorem using Brouwer&#8217;s fixed point theorem, the mathematician Shizuo Kakutani proved another fixed-point theorem in 1941, which let him get the minimax theorem in a different way.  This is now called <a href="http://en.wikipedia.org/wiki/Kakutani_fixed-point_theorem">Kakutani fixed-point theorem</a>.  </p>
<p>In 1949, John Nash generalized von Neumann&#8217;s result to nonzero-sum games with any number of players: they all have Nash equilibria if we let ourselves use mixed strategies!  His proof is <a href="http://www.pnas.org/content/36/1/48.full">just one page long</a>, and it won him the Nobel prize!  </p>
<p>Nash&#8217;s proof used the Kakutani fixed-point theorem.   There is also a proof of Nash&#8217;s theorem using Brouwer&#8217;s fixed-point theorem; see <a href="http://math.uchicago.edu/~shmuel/AAT-readings/Econ%20segment/nash.pdf">here</a> for the 2-player case and <a href="http://www.damas.ift.ulaval.ca/_seminar/filesH08/NashExistence.pdf">here</a> for the <i>n</i>-player case. </p>
<p>Apparently when Nash explained his result to von Neumann, the latter said:</p>
<blockquote><p>
    That&#8217;s trivial, you know. That&#8217;s just a fixed point theorem.
</p></blockquote>
<p>Maybe von Neumann was a bit jealous?</p>
<p>I don&#8217;t know a proof of Nash&#8217;s theorem that doesn&#8217;t use a fixed-point theorem.  But von Neumann&#8217;s original minimax theorem seems to be easier.  The proof I showed you last time comes from Andrew Colman&#8217;s book <i>Game Theory and its Applications in the Social and Biological Sciences</i>.  In it, he writes:</p>
<blockquote><p>
    In common with many people, I first encountered game theory in non-mathematical books, and I soon became intrigued by the minimax theorem but frustrated by the way the books tiptoed around it without proving it. It seems reasonable to suppose that I am not the only person who has encountered this problem, but I have not found any source to which mathematically unsophisticated readers can turn for a proper understanding of the theorem, so I have attempted in the pages that follow to provide a simple, self-contained proof with each step spelt out as clearly as possible both in symbols and words.
</p></blockquote>
<p>There are other proofs that avoid fixed-point theorems: for example, there&#8217;s one in Ken Binmore&#8217;s book <i>Playing for Real</i>.  But this one uses transfinite induction, which seems a bit scary and distracting!  So far, Colman&#8217;s proof seems simplest, but I&#8217;ll keep trying to do better.</p>
<h3> The lemmas </h3>
<p>Now let&#8217;s prove the two lemmas from <a href="https://johncarlosbaez.wordpress.com/2013/03/07/game-theory-part-19/">last time</a>.  A lemma is an unglamorous result which we use to prove a theorem we&#8217;re interested in.  The mathematician Paul Taylor has written:</p>
<blockquote><p>
Lemmas do the work in mathematics: theorems, like management, just take the credit.
</p></blockquote>
<p>Let&#8217;s remember what we were doing.  We had a zero-sum 2-player normal-form game with an <img src="https://s0.wp.com/latex.php?latex=m+%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m &#92;times n" class="latex" /> payoff matrix <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" />.  The entry <img src="https://s0.wp.com/latex.php?latex=A_%7Bij%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A_{ij}" class="latex" /> of this matrix says A&#8217;s payoff when player A makes choice <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> and player B makes choice <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j" class="latex" />.  We defined this set:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=C+%3D+%5C%7B++A+q%27+%3A+%5C%3B+q%27+%5Ctextrm%7B+is+a+mixed+strategy+for+B%7D+%5C%7D+%5Csubseteq+%5Cmathbb%7BR%7D%5Em+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C = &#92;{  A q&#039; : &#92;; q&#039; &#92;textrm{ is a mixed strategy for B} &#92;} &#92;subseteq &#92;mathbb{R}^m " class="latex" />
</div>
<p>For example, if </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+A+%3D+%5Cleft%28+%5Cbegin%7Barray%7D%7Brrr%7D+2+%26+10+%26++4+%5C%5C-2+%26+1+%26+6+%5Cend%7Barray%7D+%5Cright%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ A = &#92;left( &#92;begin{array}{rrr} 2 &amp; 10 &amp;  4 &#92;&#92;-2 &amp; 1 &amp; 6 &#92;end{array} &#92;right) } " class="latex" />
</div>
<p>then <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" /> looks like this:</p>
<div align="center">
<img width="250" src="https://i0.wp.com/math.ucr.edu/home/baez/mathematical/minimax_1.jpg" />
</div>
<p>We assumed that</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cmin_%7Bq%27%7D+%5Cmax_%7Bp%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27+%3E+0%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;min_{q&#039;} &#92;max_{p&#039;} &#92;; p&#039; &#92;cdot A q&#039; &gt; 0} " class="latex" />
</div>
<p>This means there exists <img src="https://s0.wp.com/latex.php?latex=p%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p&#039;" class="latex" /> with</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++p%27+%5Ccdot+A+q%27+%3E+0%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  p&#039; &#92;cdot A q&#039; &gt; 0} " class="latex" />
</div>
<p>and this implies that at least one of the numbers <img src="https://s0.wp.com/latex.php?latex=%28Aq%27%29_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(Aq&#039;)_i" class="latex" /> must be positive.  So, if we define a set <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> by</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+N+%3D+%5C%7B%28x_1%2C+%5Cdots%2C+x_m%29+%3A+x_i+%5Cle+0+%5Ctextrm%7B+for+all+%7D+i%5C%7D+%5Csubseteq+%5Cmathbb%7BR%7D%5Em+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ N = &#92;{(x_1, &#92;dots, x_m) : x_i &#92;le 0 &#92;textrm{ for all } i&#92;} &#92;subseteq &#92;mathbb{R}^m }" class="latex" />
</div>
<p>then <img src="https://s0.wp.com/latex.php?latex=Aq%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Aq&#039;" class="latex" /> can&#8217;t be in this set:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+Aq%27+%5Cnotin+N+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ Aq&#039; &#92;notin N }" class="latex" />
</div>
<p>In other words, the set <img src="https://s0.wp.com/latex.php?latex=C+%5Ccap+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C &#92;cap N" class="latex" /> is empty.</p>
<p>Here&#8217;s what <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> look like in our example: </p>
<div align="center">
<img width="250" src="https://i0.wp.com/math.ucr.edu/home/baez/mathematical/minimax_2.jpg" />
</div>
<p>Next, we choose a point in <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> and a point in <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" />:</p>
<p>&bull; let <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" /> be a point in <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> that&#8217;s as close as possible to <img src="https://s0.wp.com/latex.php?latex=C%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C," class="latex" /> </p>
<p>and</p>
<p>&bull; let <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> be a point in <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" /> that&#8217;s as close as possible to <img src="https://s0.wp.com/latex.php?latex=r%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r," class="latex" /></p>
<p>These points <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> need to be different, since <img src="https://s0.wp.com/latex.php?latex=C+%5Ccap+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C &#92;cap N" class="latex" /> is empty.  Here&#8217;s what these points and the vector <img src="https://s0.wp.com/latex.php?latex=s+-+r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s - r" class="latex" /> look like in our example:</p>
<div align="center">
<img width="250" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/minimax_3.jpg" />
</div>
<p>To finish the job, we need to prove two lemmas:</p>
<p><b>Lemma 1.</b>  <img src="https://s0.wp.com/latex.php?latex=r+%5Ccdot+%28s-r%29+%3D+0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r &#92;cdot (s-r) = 0," class="latex" /> <img src="https://s0.wp.com/latex.php?latex=s_i+-+r_i+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i - r_i &#92;ge 0" class="latex" /> for all <img src="https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i," class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=s_i+-+r_i+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i - r_i &gt; 0" class="latex" /> for at least one <img src="https://s0.wp.com/latex.php?latex=i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i." class="latex" /></p>
<p><b>Proof.</b>  Suppose <img src="https://s0.wp.com/latex.php?latex=r%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r&#039;" class="latex" /> is any point in <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> whose coordinates are all the same those of <img src="https://s0.wp.com/latex.php?latex=r%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r," class="latex" /> except perhaps one, namely the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th coordinate for one particular choice of <img src="https://s0.wp.com/latex.php?latex=i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i." class="latex" />   By the way we&#8217;ve defined <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" />, this point <img src="https://s0.wp.com/latex.php?latex=r%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r&#039;" class="latex" /> can&#8217;t be closer to <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> than <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" /> is:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5C%7C+r%27+-+s+%5C%7C+%5Cge++%5C%7C+r+-+s+%5C%7C++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;| r&#039; - s &#92;| &#92;ge  &#92;| r - s &#92;|  " class="latex" />
</div>
<p>This means that</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Csum_%7Bj+%3D+1%7D%5Em++%28r_j%27+-+s_j%29%5E2+%5Cge++%5Csum_%7Bj+%3D+1%7D%5Em++%28r_j+-+s_j%29%5E2++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;sum_{j = 1}^m  (r_j&#039; - s_j)^2 &#92;ge  &#92;sum_{j = 1}^m  (r_j - s_j)^2  } " class="latex" />
</div>
<p>But since <img src="https://s0.wp.com/latex.php?latex=r_j%27+%3D+r_j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r_j&#039; = r_j" class="latex" /> except when <img src="https://s0.wp.com/latex.php?latex=j+%3D+i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j = i," class="latex" /> this implies</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%28r_i%27+-+s_i%29%5E2+%5Cge++%28r_i+-+s_i%29%5E2+++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(r_i&#039; - s_i)^2 &#92;ge  (r_i - s_i)^2   " class="latex" />
</div>
<p>Now, if <img src="https://s0.wp.com/latex.php?latex=s_i+%5Cle+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i &#92;le 0" class="latex" /> we can take <img src="https://s0.wp.com/latex.php?latex=r%27_i+%3D+s_i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r&#039;_i = s_i." class="latex" />  In this case we get </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=0+%5Cge++%28r_i+-+s_i%29%5E2+++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0 &#92;ge  (r_i - s_i)^2   " class="latex" />
</div>
<p>so <img src="https://s0.wp.com/latex.php?latex=r_i+%3D+s_i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r_i = s_i." class="latex" />  On the other hand, if <img src="https://s0.wp.com/latex.php?latex=s_i+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i &gt; 0" class="latex" /> we can take <img src="https://s0.wp.com/latex.php?latex=r%27_i+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r&#039;_i = 0" class="latex" /> and get</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=s_i%5E2+%5Cge++%28r_i+-+s_i%29%5E2+++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i^2 &#92;ge  (r_i - s_i)^2   " class="latex" />
</div>
<p>which simplifies to</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=2+r_i+s_i+%5Cge+r_i%5E2++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="2 r_i s_i &#92;ge r_i^2  " class="latex" />
</div>
<p>But <img src="https://s0.wp.com/latex.php?latex=r_i+%5Cle+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r_i &#92;le 0" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=s_i+%3E+0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i &gt; 0," class="latex" /> so this can only be true if <img src="https://s0.wp.com/latex.php?latex=r_i+%3D+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r_i = 0." class="latex" />  </p>
<p>In short, we know that either</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=r_i+%3D+s_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r_i = s_i" class="latex" /> </p>
<p>or </p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=s_i+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i &gt; 0" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=r_i+%3D+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r_i = 0." class="latex" />  </p>
<p>So, either way we get  </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%28s_i+-+r_i%29+r_i+%3D+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(s_i - r_i) r_i = 0 " class="latex" />
</div>
<p>Since <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> was arbitrary, this implies</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%28s+-+r%29+%5Ccdot+r+%3D+%5Csum_%7Bi+%3D+1%7D%5Em+%28s_i+-+r_i%29+r_i+%3D+0+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ (s - r) &#92;cdot r = &#92;sum_{i = 1}^m (s_i - r_i) r_i = 0 }" class="latex" />
</div>
<p>which is the first thing we wanted to show.  Also, either way we get</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=s_i+-+r_i+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i - r_i &#92;ge 0" class="latex" />
</div>
<p>which is the second thing we wanted.  Finally, <img src="https://s0.wp.com/latex.php?latex=s_i+-+r_i+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i - r_i &#92;ge 0" class="latex" /> but we know <img src="https://s0.wp.com/latex.php?latex=s+%5Cne+r%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s &#92;ne r," class="latex" /> so </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=s_i+-+r_i+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i - r_i &gt; 0" class="latex" />
</div>
<p>for at least one choice of <img src="https://s0.wp.com/latex.php?latex=i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i." class="latex" />   And this is the third thing we wanted! &nbsp;  &#9608; </p>
<p><b>Lemma 2.</b>  If <img src="https://s0.wp.com/latex.php?latex=Aq%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Aq&#039;" class="latex" /> is any point in <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" />, then</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%28s-r%29+%5Ccdot+Aq%27+%5Cge+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(s-r) &#92;cdot Aq&#039; &#92;ge 0 " class="latex" />
</div>
<p><b>Proof.</b>  Let&#8217;s write </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=Aq%27+%3D+a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Aq&#039; = a" class="latex" />
</div>
<p>for short.  For any number <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t" class="latex" /> between <img src="https://s0.wp.com/latex.php?latex=0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1" class="latex" />, the point</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=ta+%2B+%281-t%29s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="ta + (1-t)s" class="latex" />
</div>
<p>is on the line segment connecting the points <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=s.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s." class="latex" />  Since both these points are in <img src="https://s0.wp.com/latex.php?latex=C%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C," class="latex" />, so is this point <img src="https://s0.wp.com/latex.php?latex=ta+%2B+%281-t%29s%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="ta + (1-t)s," class="latex" /> because the set <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" /> is <a href="http://en.wikipedia.org/wiki/Convex_set">convex</a>.  So, by the way we&#8217;ve defined <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" />, this point can&#8217;t be closer to <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" /> than <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> is:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5C%7C+r+-+%28ta+%2B+%281-t%29s%29+%5C%7C+%5Cge++%5C%7C+r+-+s+%5C%7C++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;| r - (ta + (1-t)s) &#92;| &#92;ge  &#92;| r - s &#92;|  " class="latex" />
</div>
<p>This means that</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%28r+%2B+%281-t%29s+-+ta%29+%5Ccdot++%28r+%2B+%281-t%29s+-+ta%29+%5Cge+%28r+-+s%29+%5Ccdot+%28r+-+s%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  (r + (1-t)s - ta) &#92;cdot  (r + (1-t)s - ta) &#92;ge (r - s) &#92;cdot (r - s) } " class="latex" />
</div>
<p>With some algebra, this gives</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+2+%28a+-+s%29%5Ccdot+%28s+-+r%29+%5Cge+-t+%28a+-+s%29+%5Ccdot+%28a+-+s%29++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ 2 (a - s)&#92;cdot (s - r) &#92;ge -t (a - s) &#92;cdot (a - s)  } " class="latex" />
</div>
<p>Since we can make <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t" class="latex" /> as small as we want, this implies that</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%28a+-+s%29%5Ccdot++%28s+-+r%29+%5Cge+0++%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  (a - s)&#92;cdot  (s - r) &#92;ge 0  } " class="latex" />
</div>
<p>or </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+a+%5Ccdot+%28s+-+r%29+%5Cge++s+%5Ccdot+%28s+-+r%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ a &#92;cdot (s - r) &#92;ge  s &#92;cdot (s - r)} " class="latex" />
</div>
<p>or</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+a+%5Ccdot+%28s+-+r%29+%5Cge++%28s+-+r%29+%5Ccdot+%28s+-+r%29+%2B+r+%5Ccdot+%28s+-+r%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ a &#92;cdot (s - r) &#92;ge  (s - r) &#92;cdot (s - r) + r &#92;cdot (s - r)} " class="latex" />
</div>
<p>By Lemma 1 we have <img src="https://s0.wp.com/latex.php?latex=r+%5Ccdot+%28s+-+r%29+%5Cge+0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r &#92;cdot (s - r) &#92;ge 0," class="latex" /> and the dot product of any vector with itself is nonnegative, so it follows that</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+a+%5Ccdot+%28s+-+r%29+%5Cge+0%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ a &#92;cdot (s - r) &#92;ge 0} " class="latex" />
</div>
<p>And this is what we wanted to show!  &nbsp;  &#9608; </p>
<h3> Conclusion  </h3>
<p>Proving lemmas is hard work, and unglamorous.  But if you remember the big picture, you&#8217;ll see how great this stuff is.  </p>
<p>We started with a very general concept of two-person game.  Then we introduced probability theory and the concept of &#8216;mixed strategy&#8217;.  Then we realized that the expected payoff of each player could be computed using a dot product!  This brings geometry into the subject.   Using geometry, we&#8217;ve seen that every zero-sum game has at least one &#8216;Nash equilibrium&#8217;, where neither player is motivated to change what they do&#8212;at least if they&#8217;re rational agents.  </p>
<p>And this is how math works: by taking a simple concept and thinking about it very hard, over a long time, we can figure out things that are not at all obvious.   </p>
<p>For game theory, the story goes much further than we went in this course.  For starters, we should look at nonzero-sum games, and games with more than two players.  John Nash showed these more general games still have Nash equilibria!  </p>
<p>Then we should think about how to actually find these equilibria.  Merely knowing that they exist is not good enough!  For zero-sum games, finding the equilibria uses a subject called <a href="http://en.wikipedia.org/wiki/Linear_programming">linear programming</a>.  This is a way to maximize a linear function given a bunch of linear constraints.  It&#8217;s used all over the place&#8212;in planning, routing, scheduling, and so on.</p>
<p>Game theory is used a lot by economists, for example in studying competition between firms, and in setting up antitrust regulations.  For that, try this book:</p>
<p>&bull; Lynne Pepall, Dan Richards and George Norman, <i>Industrial Organization: Contemporary Theory and Empirical Applications</i>, Blackwell, 2008.</p>
<p>For these applications, we need to think about how people actually play games and make economic decisions.  We aren&#8217;t always rational agents!  So, psychologists, sociologists and economists do experiments to study what people actually do.  The book above has a lot of case studies, and you can learn more here:</p>
<p>&bull; Andrew Colman, <i>Game Theory and its Applications in the Social and Biological Sciences</i>, Routledge, London, 1982.</p>
<p>As this book title hints, we should also think about how game theory enters into biology.  Evolution can be seen as a game where the winning genes reproduce and the losers don&#8217;t.  But it&#8217;s not all about competition: there&#8217;s a lot of cooperation involved.  Life is not a zero-sum game!   Here&#8217;s a good introduction to some of the math:</p>
<p>&bull; William H. Sandholm, <a href="http://www.ssc.wisc.edu/~whs/research/egt.pdf">Evolutionary game theory</a>, 12 November 2007.</p>
<p>For more on the biology, get ahold of this classic text:</p>
<p>&bull; John Maynard Smith, <i>Evolution and the Theory of Games</i>, Cambridge University Press, 1982.</p>
<p>And so on.  We&#8217;ve just scratched the surface!</p>
]]></content:encoded>
					
					<wfw:commentRss>https://johncarlosbaez.wordpress.com/2013/03/11/game-theory-part-20/feed/</wfw:commentRss>
			<slash:comments>4</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">John Baez</media:title>
		</media:content>

		<media:content url="http://math.ucr.edu/home/baez/mathematical/minimax_1.jpg" medium="image" />

		<media:content url="http://math.ucr.edu/home/baez/mathematical/minimax_2.jpg" medium="image" />

		<media:content url="http://math.ucr.edu/home/baez/mathematical/minimax_3.jpg" medium="image" />
	</item>
		<item>
		<title>Game Theory (Part 19)</title>
		<link>https://johncarlosbaez.wordpress.com/2013/03/07/game-theory-part-19/</link>
					<comments>https://johncarlosbaez.wordpress.com/2013/03/07/game-theory-part-19/#comments</comments>
		
		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Thu, 07 Mar 2013 02:12:23 +0000</pubDate>
				<category><![CDATA[game theory]]></category>
		<category><![CDATA[mathematics]]></category>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=15186</guid>

					<description><![CDATA[Okay, we&#8217;re almost done! We&#8217;ve been studying Nash equilibria for zero-sum 2-player normal form games. We proved a lot of things about them, but now we&#8217;ll wrap up the story by proving this: Grand Theorem. For every zero-sum 2-player normal-form game, a Nash equilibrium exists. Moreover, a pair of mixed strategies for the two players [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Okay, we&#8217;re almost done!  We&#8217;ve been studying Nash equilibria for zero-sum 2-player normal form games.  We proved a lot of things about them, but now we&#8217;ll wrap up the story by proving this:</p>
<p><b>Grand Theorem.</b> For every zero-sum 2-player normal-form game, a Nash equilibrium exists.  Moreover, a pair of mixed strategies <img src="https://s0.wp.com/latex.php?latex=%28p%2Cq%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(p,q)" class="latex" /> for the two players is a Nash equilibrium if and only if each strategy is a maximin strategy.</p>
<h3> Review </h3>
<p>Let&#8217;s remember what we&#8217;ve proved in <a href="">Part 16</a> and <a href="https://johncarlosbaez.wordpress.com/2013/03/05/game-theory-part-18/">Part 18</a>:</p>
<p><b>Theorem 1.</b>   For any zero-sum 2-player normal form game,</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cmin_%7Bq%27%7D+%5Cmax_%7Bp%27%7D+p%27+%5Ccdot+A+q%27+%5Cge+%5Cmax_%7Bp%27%7D+%5Cmin_%7Bq%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;min_{q&#039;} &#92;max_{p&#039;} p&#039; &#92;cdot A q&#039; &#92;ge &#92;max_{p&#039;} &#92;min_{q&#039;} &#92;; p&#039; &#92;cdot A q&#039;}" class="latex" />
</div>
<p><b>Theorem 2.</b>  Given a zero-sum 2-player normal form game for which a Nash equilibrium exists, we have</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5Cmin_%7Bq%27%7D+%5Cmax_%7Bp%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27+%3D+%5Cmax_%7Bp%27%7D+%5Cmin_%7Bq%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;min_{q&#039;} &#92;max_{p&#039;} &#92;; p&#039; &#92;cdot A q&#039; = &#92;max_{p&#039;} &#92;min_{q&#039;} &#92;; p&#039; &#92;cdot A q&#039;}" class="latex" /> &nbsp; &nbsp; &#9733;
</div>
<p><b>Theorem 3.</b>  If <img src="https://s0.wp.com/latex.php?latex=%28p%2Cq%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(p,q)" class="latex" /> is a Nash equilibrium for a zero-sum 2-player normal-form game, then <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> is a maximin strategy for player A and <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> is a maximin strategy for player B.</p>
<p><b>Theorem 4.</b>   Suppose we have a zero-sum 2-player normal form game for which &#9733; holds.   If <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> is a maximin strategy for player A and <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> is a maximin strategy for player B, then <img src="https://s0.wp.com/latex.php?latex=%28p%2Cq%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(p,q)" class="latex" /> is a Nash equilibrium.</p>
<h3> The plan </h3>
<p>Today we&#8217;ll prove two more results.  The first one is easy if you know some topology.  The second one is the real heart of the whole subject:</p>
<p><b>Theorem 5.</b>  For every zero-sum 2-player normal-form game, a maximin strategy exists for each player.</p>
<p><b>Theorem 6.</b> For every zero-sum 2-player normal-form game, &#9733; holds.</p>
<p>Putting all these results together, it&#8217;s easy to get our final result:</p>
<p><b>Grand Theorem.</b> For every zero-sum 2-player normal-form game, a Nash equilibrium exists.  Moreover, a pair of mixed strategies <img src="https://s0.wp.com/latex.php?latex=%28p%2Cq%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(p,q)" class="latex" /> for the two players is a Nash equilibrium if and only if each strategy is a maximin strategy.</p>
<p><b>Proof.</b>  By Theorem 6 we know that &#9733; holds.  By Theorem 5 we know that there exist maximin strategies for each player, say <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q." class="latex" />.    Theorem 4 says that if <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> are maximin strategies and &#9733; holds, then <img src="https://s0.wp.com/latex.php?latex=%28p%2Cq%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(p,q)" class="latex" /> is a Nash equilibrium.  So, a Nash equilibrium exists.</p>
<p>Moreover, if <img src="https://s0.wp.com/latex.php?latex=%28p%2Cq%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(p,q)" class="latex" /> is <i>any</i> Nash equilibrium, Theorem 3 says <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> are maximin strategies.  Conversely, since &#9733; holds, Theorem 4 says that if <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> are maximin strategies, <img src="https://s0.wp.com/latex.php?latex=%28p%2Cq%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(p,q)" class="latex" /> is a Nash equilibrium.   &nbsp;  &#9608;</p>
<h3> Minimax strategies exist </h3>
<p>Okay, let&#8217;s dive in and get to work:</p>
<p><b>Theorem 5.</b>  For every zero-sum 2-player normal-form game, a maximin strategy exists for each player.</p>
<p><b>Proof.</b>  We&#8217;ll prove this only for player A, since the proof for player B is similar.  Remember that a maximin strategy for player A is a mixed strategy that maximizes A&#8217;s security level, which is a function</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+f%28p%27%29+%3D+%5Cmin_%7Bq%27%7D+p%27+%5Ccdot+A+q%27+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ f(p&#039;) = &#92;min_{q&#039;} p&#039; &#92;cdot A q&#039; } " class="latex" />
</div>
<p>So, we just need to show that this function <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f" class="latex" /> really has a maximum.  To do this, we note that </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=f+%3A+%5C%7B+%5Ctextrm%7BA%27s+mixed+strategies%7D+%5C%7D+%5Cto+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f : &#92;{ &#92;textrm{A&#039;s mixed strategies} &#92;} &#92;to &#92;mathbb{R}" class="latex" />
</div>
<p>is a continuous function defined on a compact set.   As mentioned at the start of <a href="https://johncarlosbaez.wordpress.com/2013/02/27/game-theory-part-17/">Part 17</a>, this guarantees that <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f" class="latex" /> has a maximum.  &nbsp;  &#9608;</p>
<p>I apologize if this proof is hard to understand.  All this stuff is standard if you know some topology, and a huge digression if you don&#8217;t, so I won&#8217;t go through the details.  This is a nice example of how topology can be useful in other subjects!</p>
<h3> The key theorem </h3>
<p>Now we finally reach the heart of the whole subject: <a href="http://en.wikipedia.org/wiki/Minimax#Game_theory">von Neumann&#8217;s minimax theorem</a>.  Our proof will be a condensed version of the one in Andrew Colman&#8217;s 1982 book <i>Game Theory and its Applications in the Social and Biological Sciences</i>. </p>
<p><b>Theorem 6.</b> For every zero-sum 2-player normal-form game,</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5Cmin_%7Bq%27%7D+%5Cmax_%7Bp%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27+%3D+%5Cmax_%7Bp%27%7D+%5Cmin_%7Bq%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;min_{q&#039;} &#92;max_{p&#039;} &#92;; p&#039; &#92;cdot A q&#039; = &#92;max_{p&#039;} &#92;min_{q&#039;} &#92;; p&#039; &#92;cdot A q&#039;}" class="latex" /> &nbsp; &nbsp; &#9733;
</div>
<p>holds.</p>
<p><b>Proof.</b>   Let&#8217;s write</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%5Cmax_%7Bp%27%7D+%5Cmin_%7Bq%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27+%3D+V%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  &#92;max_{p&#039;} &#92;min_{q&#039;} &#92;; p&#039; &#92;cdot A q&#039; = V}" class="latex" />
</div>
<p>and</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cmin_%7Bq%27%7D+%5Cmax_%7Bp%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27+%3D+W%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;min_{q&#039;} &#92;max_{p&#039;} &#92;; p&#039; &#92;cdot A q&#039; = W} " class="latex" />
</div>
<p>Our goal is to prove &#9733;, which says <img src="https://s0.wp.com/latex.php?latex=V+%3D+W.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V = W." class="latex" />  By Theorem 1 we know </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=V+%5Cle+W+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V &#92;le W " class="latex" />
</div>
<p>So, we just need to prove</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=V+%5Cge+W+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V &#92;ge W " class="latex" />
</div>
<p>Here&#8217;s how we will do this.  We will prove </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7Bif+%7D+W+%3E+0+%5Ctextrm%7B+then+%7D+V+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;textrm{if } W &gt; 0 &#92;textrm{ then } V &#92;ge 0" class="latex" />
</div>
<p>Since we&#8217;ll prove this for <i>any</i> game of the sort we&#8217;re studying, it&#8217;ll be true even if we add some real number <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c" class="latex" /> to each entry of the payoff matrix <img src="https://s0.wp.com/latex.php?latex=A_%7Bij%7D.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A_{ij}." class="latex" />  Doing this adds <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c" class="latex" /> to the expected payoff <img src="https://s0.wp.com/latex.php?latex=p%27+%5Ccdot+A+q%27%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p&#039; &#92;cdot A q&#039;," class="latex" /> so it adds <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=W.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="W." class="latex" />  So, it will follow that</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7Bif+%7D+V+%2B+c+%3E+0+%5Ctextrm%7B+then+%7D+W+%2B+c%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;textrm{if } V + c &gt; 0 &#92;textrm{ then } W + c&#92;ge 0" class="latex" />
</div>
<p>for any real number <img src="https://s0.wp.com/latex.php?latex=c%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c," class="latex" /> and this implies</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=V+%5Cge+W+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V &#92;ge W " class="latex" />
</div>
<p>So, let&#8217;s get going.  </p>
<p>Assume <img src="https://s0.wp.com/latex.php?latex=W+%3E+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="W &gt; 0." class="latex" />   To prove that <img src="https://s0.wp.com/latex.php?latex=V+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V &#92;ge 0" class="latex" />, remember that </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+V+%3D+%5Cmax_%7Bp%27%7D+%5Cmin_%7Bq%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ V = &#92;max_{p&#039;} &#92;min_{q&#039;} &#92;; p&#039; &#92;cdot A q&#039;}" class="latex" />
</div>
<p>To show this is greater than or equal to zero, we just need to find <i>some</i> mixed strategy <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> for player A such that</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cmin_%7Bq%27%7D+%5C%3B+p+%5Ccdot+A+q%27+%5Cge+0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;min_{q&#039;} &#92;; p &#92;cdot A q&#039; &#92;ge 0}" class="latex" />
</div>
<p>In other words, we need to find <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> such that</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p+%5Ccdot+A+q%27+%5Cge+0%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p &#92;cdot A q&#039; &#92;ge 0}" class="latex" /> &nbsp; &nbsp; &#9733;&#9733;
</div>
<p>for all mixed strategies <img src="https://s0.wp.com/latex.php?latex=q%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q&#039;" class="latex" /> for player B.</p>
<p>How can we find <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> for which this &#9733;&#9733; is true?  The key is to consider the set</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=C+%3D+%5C%7B++A+q%27+%3A+%5C%3B+q%27+%5Ctextrm%7B+is+a+mixed+strategy+for+B%7D+%5C%7D+%5Csubseteq+%5Cmathbb%7BR%7D%5Em+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C = &#92;{  A q&#039; : &#92;; q&#039; &#92;textrm{ is a mixed strategy for B} &#92;} &#92;subseteq &#92;mathbb{R}^m " class="latex" />
</div>
<p>For example, if </p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+A+%3D+%5Cleft%28+%5Cbegin%7Barray%7D%7Brrr%7D+2+%26+10+%26++4+%5C%5C-2+%26+1+%26+6+%5Cend%7Barray%7D+%5Cright%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ A = &#92;left( &#92;begin{array}{rrr} 2 &amp; 10 &amp;  4 &#92;&#92;-2 &amp; 1 &amp; 6 &#92;end{array} &#92;right) } " class="latex" />
</div>
<p>then <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" /> looks like this:</p>
<div align="center">
<img width="250" src="https://i0.wp.com/math.ucr.edu/home/baez/mathematical/minimax_1.jpg" />
</div>
<p>Since <img src="https://s0.wp.com/latex.php?latex=W+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="W &gt; 0" class="latex" />, for any <img src="https://s0.wp.com/latex.php?latex=Aq%27+%5Cin+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Aq&#039; &#92;in C" class="latex" /> we have</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cmax_%7Bp%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27+%5Cge+%5Cmin_%7Bq%27%7D+%5Cmax_%7Bp%27%7D+%5C%3B+p%27+%5Ccdot+A+q%27+%3D+W+%3E+0%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;max_{p&#039;} &#92;; p&#039; &#92;cdot A q&#039; &#92;ge &#92;min_{q&#039;} &#92;max_{p&#039;} &#92;; p&#039; &#92;cdot A q&#039; = W &gt; 0} " class="latex" />
</div>
<p>so there must exist <img src="https://s0.wp.com/latex.php?latex=p%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p&#039;" class="latex" /> with</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++p%27+%5Ccdot+A+q%27+%5Cge+W+%3E+0%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  p&#039; &#92;cdot A q&#039; &#92;ge W &gt; 0} " class="latex" />
</div>
<p>Since <img src="https://s0.wp.com/latex.php?latex=p%27+%3D+%28p%27_1%2C+%5Cdots%2C+p%27_m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p&#039; = (p&#039;_1, &#92;dots, p&#039;_m)" class="latex" /> is a mixed strategy, we have <img src="https://s0.wp.com/latex.php?latex=p%27_i+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p&#039;_i &#92;ge 0" class="latex" /> for all <img src="https://s0.wp.com/latex.php?latex=1+%5Cle+i+%5Cle+m.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1 &#92;le i &#92;le m." class="latex" />  But since we&#8217;ve just seen</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Csum_%7Bi%3D1%7D%5Em+p%27_i+%28Aq%27%29_i+%3D+p%27+%5Ccdot+A+q%27+%5Cge+W+%3E+0%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;sum_{i=1}^m p&#039;_i (Aq&#039;)_i = p&#039; &#92;cdot A q&#039; &#92;ge W &gt; 0} " class="latex" />
</div>
<p>at least one of the numbers <img src="https://s0.wp.com/latex.php?latex=%28Aq%27%29_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(Aq&#039;)_i" class="latex" /> must be positive.  In other words, if we define a set <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> by</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+N+%3D+%5C%7B%28x_1%2C+%5Cdots%2C+x_m%29+%3A+x_i+%5Cle+0+%5Ctextrm%7B+for+all+%7D+i%5C%7D+%5Csubseteq+%5Cmathbb%7BR%7D%5Em+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ N = &#92;{(x_1, &#92;dots, x_m) : x_i &#92;le 0 &#92;textrm{ for all } i&#92;} &#92;subseteq &#92;mathbb{R}^m }" class="latex" />
</div>
<p>then <img src="https://s0.wp.com/latex.php?latex=Aq%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Aq&#039;" class="latex" /> can&#8217;t be in this set:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+Aq%27+%5Cnotin+N+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ Aq&#039; &#92;notin N }" class="latex" />
</div>
<p>So, we&#8217;ve seen that no point in <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" /> can be in <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" />:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=C+%5Ccap+N+%3D+%5Cemptyset&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C &#92;cap N = &#92;emptyset" class="latex" />
</div>
<p>Here&#8217;s what it looks like in our example: </p>
<div align="center">
<img width="250" src="https://i0.wp.com/math.ucr.edu/home/baez/mathematical/minimax_2.jpg" />
</div>
<p>Now the trick is to:</p>
<p>&bull; let <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" /> be a point in <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> that&#8217;s as close as possible to <img src="https://s0.wp.com/latex.php?latex=C%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C," class="latex" /> </p>
<p>and</p>
<p>&bull; let <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> be a point in <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" /> that&#8217;s as close as possible to <img src="https://s0.wp.com/latex.php?latex=r%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r," class="latex" /></p>
<p>We need to use a bit of topology to be sure these points exist, since it means finding the minima of certain functions (namely, distances).  But let&#8217;s not worry about that now!  We&#8217;ll complete the proof with two lemmas:</p>
<p><b>Lemma 1.</b>  <img src="https://s0.wp.com/latex.php?latex=r+%5Ccdot+%28s-r%29+%3D+0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r &#92;cdot (s-r) = 0," class="latex" /> <img src="https://s0.wp.com/latex.php?latex=s_i+-+r_i+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i - r_i &#92;ge 0" class="latex" /> for all <img src="https://s0.wp.com/latex.php?latex=i%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i," class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=s_i+-+r_i+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i - r_i &gt; 0" class="latex" /> for at least one <img src="https://s0.wp.com/latex.php?latex=i.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i." class="latex" /></p>
<p><b>Lemma 2.</b>  If <img src="https://s0.wp.com/latex.php?latex=Aq%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Aq&#039;" class="latex" /> is any point in <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" />, then</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%28s-r%29+%5Ccdot+Aq%27+%5Cge+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(s-r) &#92;cdot Aq&#039; &#92;ge 0 " class="latex" />
</div>
<p>Here&#8217;s what the points <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r" class="latex" /> and the vector <img src="https://s0.wp.com/latex.php?latex=s+-+r&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s - r" class="latex" /> look like in our example:</p>
<div align="center">
<img width="250" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/minimax_3.jpg" />
</div>
<p>Check to see that Lemmas 1 and 2 are true in this example!  We&#8217;ll prove the lemmas later; right now let&#8217;s see how they get the job done.  </p>
<p>First, by Lemma 1,  the numbers <img src="https://s0.wp.com/latex.php?latex=s_i+-+r_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_i - r_i" class="latex" /> are nonnegative and at least one is positive.  So, we can define a mixed strategy <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> for player A by defining</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_i+%3D+%5Cfrac%7B1%7D%7Bc%7D+%28s_i+-+r_i%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_i = &#92;frac{1}{c} (s_i - r_i) }" class="latex" />
</div>
<p>where <img src="https://s0.wp.com/latex.php?latex=c+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c &gt; 0" class="latex" /> is a number chosen to make sure <img src="https://s0.wp.com/latex.php?latex=%5Csum_i+p_i+%3D+1.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sum_i p_i = 1." class="latex" />  (Remember, the probabilities <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> must be <img src="https://s0.wp.com/latex.php?latex=%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ge 0" class="latex" /> and must sum to 1.)   In other words,</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p+%3D+%5Cfrac%7B1%7D%7Bc%7D+%28s+-+r%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p = &#92;frac{1}{c} (s - r) }" class="latex" />
</div>
<p>Now, for any mixed strategy <img src="https://s0.wp.com/latex.php?latex=q%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q&#039;" class="latex" /> for player B, we have <img src="https://s0.wp.com/latex.php?latex=Aq%27+%5Cin+C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Aq&#039; &#92;in C" class="latex" /> and thus by Lemma 1</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%28s-r%29+%5Ccdot+Aq%27+%5Cge+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(s-r) &#92;cdot Aq&#039; &#92;ge 0 " class="latex" />
</div>
<p>Dividing by <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c" class="latex" />, we get</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=p+%5Ccdot+Aq%27+%5Cge+0+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p &#92;cdot Aq&#039; &#92;ge 0 " class="latex" />
</div>
<p>for all <img src="https://s0.wp.com/latex.php?latex=q%27.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q&#039;." class="latex" />  But this is &#9733;&#9733;, which is what we wanted to prove!  So we are done!   &nbsp;  &#9608;</p>
<p>I will give the proofs of Lemmas 1 and 2 in the next part. </p>
]]></content:encoded>
					
					<wfw:commentRss>https://johncarlosbaez.wordpress.com/2013/03/07/game-theory-part-19/feed/</wfw:commentRss>
			<slash:comments>3</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">John Baez</media:title>
		</media:content>

		<media:content url="http://math.ucr.edu/home/baez/mathematical/minimax_1.jpg" medium="image" />

		<media:content url="http://math.ucr.edu/home/baez/mathematical/minimax_2.jpg" medium="image" />

		<media:content url="http://math.ucr.edu/home/baez/mathematical/minimax_3.jpg" medium="image" />
	</item>
	</channel>
</rss>

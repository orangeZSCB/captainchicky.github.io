<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Entropy and Uncertainty | Azimuth</title>
<link rel="profile" href="http://gmpg.org/xfn/11" />
<link rel="pingback" href="https://johncarlosbaez.wordpress.com/xmlrpc.php" />
<meta name='robots' content='max-image-preview:large, noindex, follow' />
<link rel='dns-prefetch' href='//s2.wp.com' />
<link rel='dns-prefetch' href='//s0.wp.com' />
<link rel='dns-prefetch' href='//s.wordpress.com' />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Feed" href="https://johncarlosbaez.wordpress.com/feed/" />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Comments Feed" href="https://johncarlosbaez.wordpress.com/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Entropy and Uncertainty Comments Feed" href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/feed/" />
	<script type="text/javascript">
		/* <![CDATA[ */
		function addLoadEvent(func) {
			var oldonload = window.onload;
			if (typeof window.onload != 'function') {
				window.onload = func;
			} else {
				window.onload = function () {
					oldonload();
					func();
				}
			}
		}
		/* ]]> */
	</script>
			<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/72x72\/","ext":".png","svgUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/s1.wp.com\/wp-includes\/js\/wp-emoji-release.min.js?m=1625065786h&ver=5.8.1"}};
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([10084,65039,8205,55357,56613],[10084,65039,8203,55357,56613])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='all-css-0-1' href='https://s0.wp.com/_static/??-eJyNkdtSAyEMhl9INkWnOl44PguHiKnAMhCsvL3Zepi1tdUbhj/Jl/yTwL4oN2fGzJC6KrEHyg0qRsPoVZkbH6nJtXYFv2OUnygTD+BnTNigdAuHslT4hPuCQhdpsQbJVIRXraftpMF2ih5snN2LimSrqQMaj4jfjSi72L2M2TVI6MlglKmLo5Uo0QysKmIwbkyJ8t+45Nb6B3Te/MGpNEMuZrFsxtxZhUr+yPa/W1TDlEM7g6/WvuxN4qmYU/MXsD35gHJeKfn8K8a3y0iRMcraUrE1JW+intTHtRfuMT3o2xt9d7/dbK5375l75CE=?cssminify=yes' type='text/css' media='all' />
<style id='wp-block-library-inline-css'>
.has-text-align-justify {
	text-align:justify;
}
</style>
<style id='global-styles-inline-css'>
body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--normal: 16px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--huge: 42px;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-normal-font-size{font-size: var(--wp--preset--font-size--normal) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-huge-font-size{font-size: var(--wp--preset--font-size--huge) !important;}
</style>
<link rel='stylesheet' id='all-css-2-1' href='https://s0.wp.com/_static/??-eJx9i0EKgCAQAD+ULYJRHaK3qJhY666o0fezW126zcAMGNR09LaUDq4kLFN1VCGeIuHpAxXwjgWy1TUwfURsqEP+W7MzyL6hh1a99JnWuEg1zEpNo1T7DZLtMYQ=?cssminify=yes' type='text/css' media='all' />
<link rel='stylesheet' id='print-css-3-1' href='https://s2.wp.com/wp-content/mu-plugins/global-print/global-print.css?m=1465851035h&cssminify=yes' type='text/css' media='print' />
<style id='jetpack-global-styles-frontend-style-inline-css'>
:root { --font-headings: unset; --font-base: unset; --font-headings-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif; --font-base-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif;}
</style>
<link rel='stylesheet' id='all-css-6-1' href='https://s0.wp.com/wp-content/themes/h4/global.css?m=1420737423h&cssminify=yes' type='text/css' media='all' />
<script id='jetpack_related-posts-js-extra'>
var related_posts_js_options = {"post_heading":"h4"};
</script>
<script id='wpcom-actionbar-placeholder-js-extra'>
var actionbardata = {"siteID":"12777403","siteName":"Azimuth","siteURL":"http:\/\/johncarlosbaez.wordpress.com","siteHost":"johncarlosbaez.wordpress.com","icon":"<img alt='' src='https:\/\/s2.wp.com\/i\/logo\/wpcom-gray-white.png' class='avatar avatar-50' height='50' width='50' \/>","canManageOptions":"","canCustomizeSite":"","isFollowing":"","themeSlug":"pub\/contempt","signupURL":"https:\/\/wordpress.com\/start\/","loginURL":"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2010%2F10%2F19%2Fentropy-and-uncertainty%2F&signup_flow=account","themeURL":"","xhrURL":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/admin-ajax.php","nonce":"c031e776ae","isSingular":"1","isFolded":"","isLoggedIn":"","isMobile":"","subscribeNonce":"<input type=\"hidden\" id=\"_wpnonce\" name=\"_wpnonce\" value=\"8f1337fe87\" \/>","referer":"https:\/\/johncarlosbaez.wordpress.com\/2010\/10\/19\/entropy-and-uncertainty\/?replytocom=2104","canFollow":"1","feedID":"62242","statusMessage":"","subsEmailDefault":"instantly","customizeLink":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/customize.php?url=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2010%2F10%2F19%2Fentropy-and-uncertainty%2F%3Freplytocom%3D2104","postID":"1308","shortlink":"https:\/\/wp.me\/pRBZ9-l6","canEditPost":"","editLink":"https:\/\/wordpress.com\/post\/johncarlosbaez.wordpress.com\/1308","statsLink":"https:\/\/wordpress.com\/stats\/post\/1308\/johncarlosbaez.wordpress.com","i18n":{"view":"View site","follow":"Follow","following":"Following","edit":"Edit","login":"Log in","signup":"Sign up","customize":"Customize","report":"Report this content","themeInfo":"Get theme: Contempt","shortlink":"Copy shortlink","copied":"Copied","followedText":"New posts from this site will now appear in your <a href=\"https:\/\/wordpress.com\/read\">Reader<\/a>","foldBar":"Collapse this bar","unfoldBar":"Expand this bar","editSubs":"Manage subscriptions","viewReader":"View site in Reader","viewReadPost":"View post in Reader","subscribe":"Sign me up","enterEmail":"Enter your email address","followers":"Join 5,227 other followers","alreadyUser":"Already have a WordPress.com account? <a href=\"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2010%2F10%2F19%2Fentropy-and-uncertainty%2F&signup_flow=account\">Log in now.<\/a>","stats":"Stats","notifyNewPosts":"Notify me of new posts","notifyNewPostsDetails":"Receive web and mobile notifications for new posts from this site.","emailNewPosts":"Email me new posts","emailNewPostsDetails":"You can customize your notification settings further <a href=\"https:\/\/wordpress.com\/following\/manage?s=johncarlosbaez.wordpress.com\">here<\/a>.","emailNewComments":"Email me new comments","instantly":"Instantly","daily":"Daily","weekly":"Weekly"}};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s0.wp.com/_static/??-eJyFjcEKwjAQRH/IbQxSPYnfUtu1bMhuYnZD7d/bQj1YBE/D8B4zbsrQJzEUc0FdTmqMqt2ITdCD+6ac7hQRqmJZBDEgeaS9xxVyrCOJuoKxMxxgXd21H+slGuSSXvOHkfSxDqgrDM+KZd6iYZK/EjCNZTnc5Btf/fnkL8fW+za8ASssW38='></script>
<script type='text/javascript'>
	window.addEventListener( 'DOMContentLoaded', function() {
		rltInitialize( {"token":null,"iframeOrigins":["https:\/\/widgets.wp.com"]} );
	} );
</script>
<link rel='stylesheet' id='all-css-0-2' href='https://s0.wp.com/wp-content/mu-plugins/highlander-comments/style.css?m=1625210320h&cssminify=yes' type='text/css' media='all' />
<!--[if lt IE 8]>
<link rel='stylesheet' id='highlander-comments-ie7-css'  href='https://s2.wp.com/wp-content/mu-plugins/highlander-comments/style-ie7.css?m=1351637563h&#038;ver=20110606' media='all' />
<![endif]-->
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://johncarlosbaez.wordpress.com/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://s1.wp.com/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress.com" />
<link rel="canonical" href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/" />
<link rel='shortlink' href='https://wp.me/pRBZ9-l6' />
<link rel="alternate" type="application/json+oembed" href="https://public-api.wordpress.com/oembed/?format=json&amp;url=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2010%2F10%2F19%2Fentropy-and-uncertainty%2F&amp;for=wpcom-auto-discovery" /><link rel="alternate" type="application/xml+oembed" href="https://public-api.wordpress.com/oembed/?format=xml&amp;url=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2010%2F10%2F19%2Fentropy-and-uncertainty%2F&amp;for=wpcom-auto-discovery" />
<!-- Jetpack Open Graph Tags -->
<meta property="og:type" content="article" />
<meta property="og:title" content="Entropy and Uncertainty" />
<meta property="og:url" content="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/" />
<meta property="og:description" content="There&#8217;s a formulation of the uncertainty principle that involves entropy!" />
<meta property="article:published_time" content="2010-10-19T07:17:11+00:00" />
<meta property="article:modified_time" content="2010-10-24T05:59:24+00:00" />
<meta property="og:site_name" content="Azimuth" />
<meta property="og:image" content="http://math.ucr.edu/home/baez/emoticons/uhh.gif" />
<meta property="og:locale" content="en_US" />
<meta name="twitter:site" content="@wordpressdotcom" />
<meta name="twitter:text:title" content="Entropy and Uncertainty" />
<meta name="twitter:image" content="http://math.ucr.edu/home/baez/emoticons/uhh.gif?w=144" />
<meta name="twitter:card" content="summary" />
<meta property="fb:app_id" content="249643311490" />
<meta property="article:publisher" content="https://www.facebook.com/WordPresscom" />

<!-- End Jetpack Open Graph Tags -->
<link rel="shortcut icon" type="image/x-icon" href="https://s1.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48" />
<link rel="icon" type="image/x-icon" href="https://s1.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48" />
<link rel="apple-touch-icon" href="https://s2.wp.com/i/webclip.png" />
<link rel='openid.server' href='https://johncarlosbaez.wordpress.com/?openidserver=1' />
<link rel='openid.delegate' href='https://johncarlosbaez.wordpress.com/' />
<link rel="search" type="application/opensearchdescription+xml" href="https://johncarlosbaez.wordpress.com/osd.xml" title="Azimuth" />
<link rel="search" type="application/opensearchdescription+xml" href="https://s1.wp.com/opensearch.xml" title="WordPress.com" />
<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>		<style type="text/css">
			.recentcomments a {
				display: inline !important;
				padding: 0 !important;
				margin: 0 !important;
			}

			table.recentcommentsavatartop img.avatar, table.recentcommentsavatarend img.avatar {
				border: 0px;
				margin: 0;
			}

			table.recentcommentsavatartop a, table.recentcommentsavatarend a {
				border: 0px !important;
				background-color: transparent !important;
			}

			td.recentcommentsavatarend, td.recentcommentsavatartop {
				padding: 0px 0px 1px 0px;
				margin: 0px;
			}

			td.recentcommentstextend {
				border: none !important;
				padding: 0px 0px 2px 10px;
			}

			.rtl td.recentcommentstextend {
				padding: 0px 10px 2px 0px;
			}

			td.recentcommentstexttop {
				border: none;
				padding: 0px 0px 0px 10px;
			}

			.rtl td.recentcommentstexttop {
				padding: 0px 10px 0px 0px;
			}
		</style>
		<meta name="application-name" content="Azimuth" /><meta name="msapplication-window" content="width=device-width;height=device-height" /><meta name="msapplication-task" content="name=Subscribe;action-uri=https://johncarlosbaez.wordpress.com/feed/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=Sign up for a free blog;action-uri=http://wordpress.com/signup/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=WordPress.com Support;action-uri=http://support.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=WordPress.com Forums;action-uri=http://forums.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="description" content="There&#039;s a formulation of the uncertainty principle that involves entropy!" />
<style type="text/css">
#headerimg{
	background: url(https://johncarlosbaez.files.wordpress.com/2010/08/azimuth_header.jpg) no-repeat;
}
#header h1 a, .description {
	color:#E5F2E9;
}
</style>
<link rel="amphtml" href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/amp/">		<link rel="stylesheet" id="custom-css-css" type="text/css" href="https://s0.wp.com/?custom-css=1&#038;csblog=RBZ9&#038;cscache=6&#038;csrev=7" />
		</head>
<body class="post-template-default single single-post postid-1308 single-format-standard customizer-styles-applied highlander-enabled highlander-light">

<div id="page">

<div id="header">
	<div id="headerimg" onclick="location.href='https://johncarlosbaez.wordpress.com';" style="cursor: pointer;">
		<h1><a href="https://johncarlosbaez.wordpress.com/">Azimuth</a></h1>
		<div class="description"></div>
	</div>
</div>

<ul id="pagebar" class="menu pagebar"><li ><a href="https://johncarlosbaez.wordpress.com/">Home</a></li><li class="page_item page-item-2"><a href="https://johncarlosbaez.wordpress.com/about/">About</a></li>
</ul>

<div id="grad" style="height: 65px; width: 100%; background: url(https://s2.wp.com/wp-content/themes/pub/contempt/images/blue_flower/topgrad.jpg);">&nbsp;</div>

	<div id="content" class="widecolumn">

  


		<div class="post-1308 post type-post status-publish format-standard hentry category-information-and-entropy category-mathematics category-physics category-quantum-technologies" id="post-1308">
			<h2>Entropy and Uncertainty</h2>

			<div class="entry">
				<p>I was going to write about a talk at the CQT, but I found a preprint lying on a table in the lecture hall, and it was so cool I&#8217;ll write about that instead:</p>
<p>&bull; Mario Berta, Matthias Christandl, Roger Colbeck, Joseph M. Renes, Renato Renner, <a href="http://arxiv.org/abs/0909.0950">The uncertainty principle in the presence of quantum memory</a>, <i>Nature Physics</i>, July 25, 2010.</p>
<p>Actually I won&#8217;t talk about the paper per se, since it&#8217;s better if I tell you a more basic result that I first learned from reading this paper: <i>the entropic uncertainty principle!</i></p>
<p>Everyone loves the concept of entropy, and everyone loves the uncertainty principle.  Even folks who don&#8217;t understand &#8217;em still love &#8217;em. They just sound so mysterious and spooky and <i>dark</i>.  I love &#8217;em too. So, it&#8217;s nice to see a mathematical relation between them.  </p>
<p>I explained entropy <a href="https://johncarlosbaez.wordpress.com/2010/10/12/algorithmic-thermodynamics/">back here</a>, so let me say a word about the uncertainty principle.  It&#8217;s a limitation on how accurately you can measure two things at once in quantum mechanics.  Sometimes you can only know a lot about one thing if you don&#8217;t know much about the other.  This happens when those two things &#8220;fail to commute&#8221;.  </p>
<p>Mathematically, the usual uncertainty principle says this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CDelta+A+%5Ccdot+%5CDelta+B+%5Cge+%5Cfrac%7B1%7D%7B2%7D+%7C%5Clangle+%5BA%2CB%5D+%5Crangle+%7C+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta A &#92;cdot &#92;Delta B &#92;ge &#92;frac{1}{2} |&#92;langle [A,B] &#92;rangle | " class="latex" /></p>
<p>In plain English: the uncertainty in <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> times the uncertainty in <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B" class="latex" /> is bigger than the absolute value of the expected value of their <b>commutator</b></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5BA%2CB%5D+%3D+A+B+-+B+A+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="[A,B] = A B - B A " class="latex" /></p>
<p>Whoops!   That started off as plain English, but it degenerated into plain gibberish near the end&#8230; which is probably why most people don&#8217;t understand the uncertainty principle.  I don&#8217;t think I&#8217;m gonna cure that today, but let me just nail down the math a bit.</p>
<p>Suppose <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B" class="latex" /> are observables &mdash; and to keep things really simple, by <b>observable</b> I&#8217;ll just mean a self-adjoint <img src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n &#92;times n" class="latex" /> matrix.  Suppose <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> is a <b>state</b>: that is, a unit vector in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BC%7D%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{C}^n" class="latex" />.   Then the <b>expected value</b> of <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> in the state <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> is the average answer you get when you measure that observable in that state.  Mathematically it&#8217;s equal to</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+A+%5Crangle+%3D+%5Clangle+%5Cpsi%2C+A+%5Cpsi+%5Crangle+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle A &#92;rangle = &#92;langle &#92;psi, A &#92;psi &#92;rangle " class="latex" /></p>
<p>Sorry, there are a lot of angle brackets running around here: the ones at right stand for the inner product in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BC%7D%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{C}^n" class="latex" />, which I&#8217;m assuming you understand, while the ones at left are being defined by this equation. They&#8217;re just a shorthand.</p>
<p>Once we can compute averages, we can compute standard deviations, so we define the <b>standard deviation</b> of an observable <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> in the state <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> to be <img src="https://s0.wp.com/latex.php?latex=%5CDelta+A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta A" class="latex" /> where</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5CDelta+A%29%5E2+%3D+%5Clangle+A%5E2+%5Crangle+-+%5Clangle+A+%5Crangle%5E2+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;Delta A)^2 = &#92;langle A^2 &#92;rangle - &#92;langle A &#92;rangle^2 " class="latex" /></p>
<p>Got it?  Just like in probability theory.  So now I hope you know what every symbol here means:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CDelta+A+%5Ccdot+%5CDelta+B+%5Cge+%5Cfrac%7B1%7D%7B2%7D+%7C%5Clangle+%5BA%2CB%5D+%5Crangle+%7C+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta A &#92;cdot &#92;Delta B &#92;ge &#92;frac{1}{2} |&#92;langle [A,B] &#92;rangle | " class="latex" /></p>
<p>and if you&#8217;re a certain sort of person you can have fun going home and proving this.  Hint: it takes an inequality to prove an inequality.  Other hint: what&#8217;s the <a href="http://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">most important inequality in the universe?</a></p>
<p>But now for the fun part: entropy!</p>
<p>Whenever you have an observable <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> and a state <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" />, you get a probability distribution: the distribution of outcomes when you measure that observable in that state.  And this probability distribution has an entropy!  Let&#8217;s call the entropy <img src="https://s0.wp.com/latex.php?latex=S%28A%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(A)" class="latex" />.  I&#8217;ll define it a bit more carefully later.</p>
<p>But the point is: this entropy is really a very nice way to think about our uncertainty, or ignorance, of the observable <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" />.  It&#8217;s better, in many ways, than the standard deviation.  For example, it doesn&#8217;t change if we multiply <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> by 2. The standard deviation  doubles, but we&#8217;re not twice as ignorant!  </p>
<p>Entropy is invariant under lots of transformations of our observables.   So we should want an uncertainty principle that only involves entropy.  And here it is, the <b>entropic uncertainty principle</b>:</p>
<p><img src="https://s0.wp.com/latex.php?latex=S%28A%29+%2B+S%28B%29+%5Cge+%5Cmathrm%7Blog%7D+%5C%2C+%5Cfrac%7B1%7D%7Bc%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(A) + S(B) &#92;ge &#92;mathrm{log} &#92;, &#92;frac{1}{c} " class="latex" /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c" class="latex" /> is defined as follows.  To keep things simple, suppose that <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> is <b>nondegenerate</b>, meaning that all its eigenvalues are distinct.  If it&#8217;s not, we can tweak it a tiny bit and it will be. Let its eigenvectors be called <img src="https://s0.wp.com/latex.php?latex=%5Cphi_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_i" class="latex" />.  Similarly, suppose <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B" class="latex" /> is nondegenerate and call its eigenvectors <img src="https://s0.wp.com/latex.php?latex=%5Cchi_j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;chi_j" class="latex" />.  Then we let</p>
<p><img src="https://s0.wp.com/latex.php?latex=c+%3D+%5Cmathrm%7Bmax%7D_%7Bi%2Cj%7D+%7C%5Clangle+%5Cphi_i%2C+%5Cchi_j+%5Crangle%7C%5E2+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c = &#92;mathrm{max}_{i,j} |&#92;langle &#92;phi_i, &#92;chi_j &#92;rangle|^2 " class="latex" /></p>
<p>Note this becomes 1 when there&#8217;s an eigenvector of <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> that&#8217;s also an eigenvector of <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B" class="latex" />. In this case its possible to find a state where we know both observables precisely, and in this case also </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Blog%7D%5C%2C+%5Cfrac%7B1%7D%7Bc%7D+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{log}&#92;, &#92;frac{1}{c} = 0" class="latex" />  </p>
<p>And that makes sense: in this case <img src="https://s0.wp.com/latex.php?latex=S%28A%29+%2B+S%28B%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(A) + S(B)" class="latex" />, which measures our ignorance of <i>both</i> observables, is indeed zero.</p>
<p>But if there&#8217;s no eigenvector of <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> that&#8217;s also an eigenvector of <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c" class="latex" /> is smaller than 1, so </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Blog%7D+%5C%2C+%5Cfrac%7B1%7D%7Bc%7D+%3E+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{log} &#92;, &#92;frac{1}{c} &gt; 0" class="latex" />  </p>
<p>so the entropic uncertainty principle says we really must have some ignorance about either <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B" class="latex" /> (or both).</p>
<p>So the entropic uncertainty principle makes intuitive sense.  But let me define the entropy <img src="https://s0.wp.com/latex.php?latex=S%28A%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(A)" class="latex" />, to make the principle precise.  If <img src="https://s0.wp.com/latex.php?latex=%5Cphi_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_i" class="latex" /> are the eigenvectors of <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" />, the probabilities of getting various outcomes when we measure <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> in the state <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> are</p>
<p><img src="https://s0.wp.com/latex.php?latex=p_i+%3D+%7C%5Clangle+%5Cphi_i%2C+%5Cpsi+%5Crangle%7C%5E2+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i = |&#92;langle &#92;phi_i, &#92;psi &#92;rangle|^2 " class="latex" /></p>
<p>So, we define the entropy by</p>
<p><img src="https://s0.wp.com/latex.php?latex=S%28A%29+%3D+-+%5Csum_i+p_i+%5C%3B+%5Cmathrm%7Blog%7D%5C%2C+p_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(A) = - &#92;sum_i p_i &#92;; &#92;mathrm{log}&#92;, p_i " class="latex" /></p>
<p>Here you can use any base for your logarithm, as long as you&#8217;re consistent.  Mathematicians and physicists use <i>e</i>, while computer scientists, who prefer integers, settle for the best known integer approximation: 2.   </p>
<p>Just kidding!  Darn &mdash; now I&#8217;ve insulted all the computer scientists.  I hope none of them reads this.  <img src="https://i2.wp.com/math.ucr.edu/home/baez/emoticons/uhh.gif" alt="" /></p>
<p>Who came up with this entropic uncertainty principle?  I&#8217;m not an expert on this, so I&#8217;ll probably get this wrong, but I gather it came from an idea of Deutsch:</p>
<p>&bull; David Deutsch, Uncertainty in quantum measurements, <i>Phys. Rev. Lett.</i> <b>50</b> (1983), 631-633.</p>
<p>Then it got improved and formulated as a conjecture by Kraus:</p>
<p>&bull; K. Kraus, Complementary observables and uncertainty relations, <i>Phys. Rev. D</i> <b>35</b> (1987), 3070-3075.</p>
<p>and then that conjecture was proved here:</p>
<p>&bull; H. Maassen and J. B. Uffink, Generalized entropic uncertainty relations, <i>Phys. Rev. Lett.</i> <b>60</b> (1988), 1103-1106.</p>
<p>The paper I found in the lecture hall proves a more refined version where the system being measured &mdash; let&#8217;s call it <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> &mdash; is entangled to the observer&#8217;s memory apparatus &mdash; let&#8217;s call it <img src="https://s0.wp.com/latex.php?latex=O&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="O" class="latex" />.  In this situation they show</p>
<p><img src="https://s0.wp.com/latex.php?latex=S%28A%7CO%29+%2B+S%28B%7CO%29+%5Cge+S%28X%7CO%29+%2B+%5Cmathrm%7Blog%7D+%5C%2C+%5Cfrac%7B1%7D%7Bc%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(A|O) + S(B|O) &#92;ge S(X|O) + &#92;mathrm{log} &#92;, &#92;frac{1}{c} " class="latex" /></p>
<p>where I&#8217;m using a concept of &#8220;conditional entropy&#8221;: the entropy of something <i>given</i> something else.  Here&#8217;s their abstract:</p>
<blockquote><p>
The uncertainty principle, originally formulated by Heisenberg, clearly illustrates the difference between classical and quantum mechanics. The principle bounds the uncertainties about the outcomes of two incompatible measurements, such as position and momentum, on a particle. It implies that one cannot predict the outcomes for both possible choices of measurement to arbitrary precision, even if information about the preparation of the particle is available in a classical memory. However, if the particle is prepared entangled with a quantum memory, a device that might be available in the not-too-distant future, it is possible to predict the outcomes for both measurement choices precisely. Here, we extend the uncertainty principle to incorporate this case, providing a lower bound on the uncertainties, which depends on the amount of entanglement between the particle and the quantum memory. We detail the application of our result to witnessing entanglement and to quantum key distribution.
</p></blockquote>
<p>By the way, on a really trivial note&#8230;</p>
<p>My wisecrack about 2 being the best known integer approximation to <i>e</i> made me wonder: since 3 is actually closer to <i>e</i>, are there some applications where ternary digits would theoretically be better than binary ones?  I&#8217;ve heard of &quot;<a href="http://en.wikipedia.org/wiki/Ternary_numeral_system">trits</a>&quot; but I don&#8217;t actually know any applications where they&#8217;re optimal.</p>
<p>Oh &mdash; <a href="http://en.wikipedia.org/wiki/Radix_economy">here&#8217;s one</a>.</p>
<div id="jp-post-flair" class="sharedaddy sd-sharing-enabled">
<div id='jp-relatedposts' class='jp-relatedposts' >
	<h3 class="jp-relatedposts-headline"><em>Related</em></h3>
</div></div>
				
				<p class="postmetadata alt">
					<small>
					This entry was posted  on Tuesday, October 19th, 2010 at 7:17 am and is filed under <a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/" rel="category tag">information and entropy</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>, <a href="https://johncarlosbaez.wordpress.com/category/quantum-technologies/" rel="category tag">quantum technologies</a>.					You can follow any responses to this entry through the <a href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/feed/'>RSS 2.0</a> feed.
											You can <a href="#respond">leave a response</a>, or <a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/trackback/" rel="trackback">trackback</a> from your own site.
					
					</small>
				</p>

				<nav id="nav-below">
					<h3 class="assistive-text">Post navigation</h3>
					<span class="nav-previous"><a href="https://johncarlosbaez.wordpress.com/2010/10/15/this-weeks-finds-week-304/" rel="prev">&laquo; Previous Post</a></span>
					<span class="nav-next"><a href="https://johncarlosbaez.wordpress.com/2010/10/22/the-art-of-math/" rel="next">Next Post &raquo;</a></span>
				</nav><!-- #nav-below -->

			</div>
		</div>

	<div id="comments">


<h3 id="comments-title">50 Responses to <em>Entropy and Uncertainty</em></h3>


<ol class="commentlist">
			<li class="comment even thread-even depth-1 parent highlander-comment" id="comment-2037">
				<div id="div-comment-2037" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/656e05d084448337fb49459225dc525e?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">DavidTweed</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2037">19 October, 2010 at 9:53 am</a>		</div>

		<p>About bits vs trits: in addition to issues about physical representation, computer scientists think in terms of bits because a lot of the computer stuff is based on boolean logic (even when the variables are &#8220;boolean values&#8221; which aren&#8217;t strictly represented as single bits).</p>
<p>There are some situations where one might want to use a tri-valued logic with &#8220;true&#8221;, &#8220;false&#8221; and &#8220;unknown&#8221;. You can, with a bit of thought about what you want to acheive, write down satisfactory truth tables for all the logical operations (and, or, etc) and generally extend this to a both a reasoning logic and something you might want to implement in programs. But I don&#8217;t think there&#8217;s ever been a big enough use to actually build a machine with physical trits rather than encoding the values into integers on a bit-based machine. For an example, see</p>
<p><a href="http://www.c2.com/cgi/wiki?ThreeValuedLogic" rel="nofollow ugc">http://www.c2.com/cgi/wiki?ThreeValuedLogic</a></p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2037#respond' data-commentid="2037" data-postid="1308" data-belowelement="div-comment-2037" data-respondelement="respond" data-replyto="Reply to DavidTweed" aria-label='Reply to DavidTweed'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment odd alt depth-2 highlander-comment" id="comment-2038">
				<div id="div-comment-2038" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/6b3fa8cd421b5fd2028e3c1e9c32aa7f?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Tim van Beek</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2038">19 October, 2010 at 10:16 am</a>		</div>

		<p>Of course all truly object oriented programming languages have trits instead of bits, because the variable</p>
<p>val myBoolean : Boolean</p>
<p>may be true, false or nil = null.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2038#respond' data-commentid="2038" data-postid="1308" data-belowelement="div-comment-2038" data-respondelement="respond" data-replyto="Reply to Tim van Beek" aria-label='Reply to Tim van Beek'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor even depth-2 parent highlander-comment" id="comment-2040">
				<div id="div-comment-2040" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2040">19 October, 2010 at 1:22 pm</a>		</div>

		<p>Interesting stuff!  </p>
<p>There&#8217;s a bit about multi-valued logic in electronic circuits on <a href="http://en.wikipedia.org/wiki/Trivalent_logic#Electronics" rel="nofollow">Wikipedia</a>.</p>
<p><a href="http://www.c2.com/cgi/wiki?ThreeValuedLogic" rel="nofollow">That page</a> David cites has some very interesting discussions but also a little wackiness, like this:</p>
<blockquote><p>
<a href="http://www.c2.com/cgi/wiki?BottomType" rel="nofollow">BottomType</a> did not originate in Category Theory, because I first ran into it in the 1970s in some theoretical CS books (the Anatomy of Lisp, 1979, and another one on something like Denotational Semantics from circa 1973-1975), and Category Theory was very new at that time.
</p></blockquote>
<p>Huh?  Category theory has been around since 1945, and what these folks are calling &#8220;Bottom Type&#8221; is what category theorists call an &#8220;initial object&#8221;.</p>
<p>Topos theory, a branch of category theory, can be seen as a very sophisticated and beautiful multi-valued logic.   But three-valued logic goes back a lot earlier, to <a href="http://en.wikipedia.org/wiki/Jan_%C5%81ukasiewicz" rel="nofollow">Łukasiewicz</a>, around 1917.  So he deserves a lot of credit in the subject of multi-valued logic.  (He also invented &#8220;Polish notation&#8221;, but for some reason people saw fit only to credit his country for that &mdash; maybe because they thought it was too hard to say &#8220;Łukasiewicz&#8221;.)</p>
<p>I&#8217;ve also heard that some work in the tradition of <a href="http://en.wikipedia.org/wiki/Buddhist_logic" rel="nofollow">Buddhist logic</a> investigated multivalued logics, but I don&#8217;t know much about that, and I kinda doubt Łukasiewicz was influenced by that.  (Dunno.)</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2040#respond' data-commentid="2040" data-postid="1308" data-belowelement="div-comment-2040" data-respondelement="respond" data-replyto="Reply to John Baez" aria-label='Reply to John Baez'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment odd alt depth-3 highlander-comment" id="comment-2042">
				<div id="div-comment-2042" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/6b3fa8cd421b5fd2028e3c1e9c32aa7f?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Tim van Beek</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2042">19 October, 2010 at 1:55 pm</a>		</div>

		<blockquote>
<p>Category theory has been around since 1945&#8230;</p>
</blockquote>
<p>Maybe the author intended to say that the notion of BottomType was invented without any knowledge of/reference to category theory, (although the relative clause beginning with &#8220;because&#8230;&#8221; may indicate that this is not so&#8230;).</p>
<blockquote>
<p>Bottom Type” is what category theorists call an “initial object”.</p>
</blockquote>
<p>What is an arrow in the category with types as objects? &#8220;a arrow b&#8221; = a extends b? (This would make the BottomType an initial object).</p>
<blockquote>
<p>&#8230;maybe because they thought it was too hard to say “Łukasiewicz”.</p>
</blockquote>
<p>Yes, definitely! Polish has several versions of &#8220;s&#8221; and &#8220;sh&#8221;, I&#8217;m not capable to distinguish those let alone pronouncing them.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2042#respond' data-commentid="2042" data-postid="1308" data-belowelement="div-comment-2042" data-respondelement="respond" data-replyto="Reply to Tim van Beek" aria-label='Reply to Tim van Beek'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment even depth-3 highlander-comment" id="comment-2043">
				<div id="div-comment-2043" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/656e05d084448337fb49459225dc525e?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">DavidTweed</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2043">19 October, 2010 at 2:12 pm</a>		</div>

		<p>Clearly the category theory remark is a misunderstanding of when category theory became widely known in CS as opposed to when it was created by mathematicians. I can believe that the notion of a bottom <em>value</em> (with a polymorphic type) was independently &#8220;invented&#8221; before those times.</p>
<p>But I wouldn&#8217;t defend that wiki much, it was the first reasonably explicit website on tri-valued logic that a web-search found.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2043#respond' data-commentid="2043" data-postid="1308" data-belowelement="div-comment-2043" data-respondelement="respond" data-replyto="Reply to DavidTweed" aria-label='Reply to DavidTweed'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt depth-3 highlander-comment" id="comment-2051">
				<div id="div-comment-2051" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/7bd56f321baeba6c04fa3b64944cc91b?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">C. McCann</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2051">19 October, 2010 at 10:21 pm</a>		</div>

		<blockquote><p>Category theory has been around since 1945, and what these folks are calling “Bottom Type” is what category theorists call an “initial object”.</p></blockquote>
<p>I&#8217;m pretty sure that this is not the case, if only on the grounds that what they&#8217;re calling &#8220;Bottom Type&#8221; there is at least two distinct concepts in the context of at least three possible categories. They all relate to bottom elements of <i>some</i> poset (though not necessarily one on types), except for the one concept of the lot that&#8217;s most relevant to multivalued logic&#8211;namely, nullable references to a boolean value, which are merely isomorphic to any other three-element enumerated type.</p>
<p>So there&#8217;s a lot of confusion and misuse of terminology in that discussion, but I think I should leave it at that because most people here are probably not interested in programming language theory, and it&#8217;s all veering off-topic for the post anyway.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2051#respond' data-commentid="2051" data-postid="1308" data-belowelement="div-comment-2051" data-respondelement="respond" data-replyto="Reply to C. McCann" aria-label='Reply to C. McCann'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor even depth-2 parent highlander-comment" id="comment-2055">
				<div id="div-comment-2055" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2055">20 October, 2010 at 2:37 am</a>		</div>

		<p>Tim wrote:</p>
<blockquote><p>
Maybe the author intended to say that the notion of BottomType was invented without any knowledge of/reference to category theory&#8230;
</p></blockquote>
<p>Yes.  I don&#8217;t actually know the early history of &#8216;types&#8217; in computer science.  By now it&#8217;s clear that it&#8217;s really good to formalize types using category theory, but I don&#8217;t know when this was realized, and which ideas on types were:</p>
<p>1) first invented by computer scientists and then independently reinvented by category theorists (in different language),</p>
<p>2) first invented by category theorists and then independently reinvented by computer scientists (in different language),</p>
<p>3) first invented by computer scientists and then consciously borrowed by category theorists,</p>
<p>4) first invented by category theorists and then consciously borrowed by computer scientists.</p>
<p>By now the two communities are communicating pretty well, so there&#8217;s a lot of 3) and 4).  But that was not always so.</p>
<p>It&#8217;s also quite possible that when the author wrote:</p>
<blockquote><p>
BottomType  did not originate in Category Theory, because I first ran into it in the 1970s in some theoretical CS books (the Anatomy of Lisp, 1979, and another one on something like Denotational Semantics from circa 1973-1975), Category Theory was very new at that time.
</p></blockquote>
<p>he was taking a very computer-science-centered point of view, and meant &#8220;category theory was very new to computer scientists at that time&#8221;.  </p>
<p>I just know a few dates.  McCarthy invented the programming language Lisp, based on the lambda calculus, 1958. In 1965, an infuential paper by Landin  pointed out an analogy between the lambda calculus and the language ALGOL.  And in 1980, the deep relation between the <i>typed</i> lambda calculus and cartesian closed categories was<br />
discovered by Lambek.</p>
<p>Tim writes:</p>
<blockquote><p>
What is an arrow in the category with types as objects?
</p></blockquote>
<p>You can imagine a category where objects are data types and a morphism f: A &rarr; B is an equivalence class of programs that takes data of type A as input and outputs data of type B.  For more details, try <a href="http://arxiv.org/PS_cache/arxiv/pdf/0903/0903.0340v3.pdf#page=50" rel="nofollow">the introduction Mike Stay and I wrote</a>.   </p>
<p>He was the computer scientist in this team; I was the category theorist, so don&#8217;t expect me to know anything about actual computer languages!  But you can imagine &#8216;extension&#8217; of types as a trivial sort of program: for example, a program where you input an integer and it outputs that integer <i>viewed as a floating-point</i>.  Often, of course, this and other forms of &#8216;type conversion&#8217; are built in, via &#8216;polymorphism&#8217;. But still, you can think of &#8216;extension&#8217; and other forms of &#8216;type conversion&#8217; as degenerate cases of programs, and all programs as all giving rise to morphisms in a category whose objects are types.</p>
<p>And then the <a href="http://en.wikipedia.org/wiki/Void_type" rel="nofollow">&#8216;void type&#8217;</a> or &#8216;bottom type&#8217; is the <a href="http://ncatlab.org/nlab/show/initial+object" rel="nofollow">initial object</a>.</p>
<p>C. McCann wrote:</p>
<blockquote><p>
I’m pretty sure that this is not the case, if only on the grounds that what they’re calling “Bottom Type” there is at least two distinct concepts in the context of at least three possible categories. They all relate to bottom elements of <i>some</i> poset (though not necessarily one on types), except for the one concept of the lot that’s most relevant to multivalued logic–namely, nullable references to a boolean value, which are merely isomorphic to any other three-element enumerated type.
</p></blockquote>
<p>As you probably know (but others may not), <a href="http://ncatlab.org/nlab/show/partial+order#as_a_category_with_extra_properties_5" rel="nofollow">any poset can be seen as a category</a>, and then a bottom element for this poset is the same as an initial object for that category.</p>
<p>Since I&#8217;m more of a category theorist, the only kind of &#8216;bottom type&#8217; that I understand is an initial object.  I don&#8217;t understand &#8216;nullable references to a boolean value&#8217;, and why they deserve the name &#8216;bottom type&#8217; too.  But I&#8217;d be glad to learn.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2055#respond' data-commentid="2055" data-postid="1308" data-belowelement="div-comment-2055" data-respondelement="respond" data-replyto="Reply to John Baez" aria-label='Reply to John Baez'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment odd alt depth-3 highlander-comment" id="comment-2061">
				<div id="div-comment-2061" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/918361a321e40a2d9b2ddcf5f2ff93d0?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Tim van Beek</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2061">20 October, 2010 at 5:42 am</a>		</div>

		<p>C. McCann wrote:</p>
<blockquote>
<p>&#8230;most people here are probably not interested in programming language theory&#8230;</p>
</blockquote>
<p>Maybe, but at least <i>some</i> people are.<br />
It would seem that JB is interested in the connection of category theory and programming languages, and I happen to be a software developer, so I&#8217;m interested in programming language from a very pragmatic POV.</p>
<p>JB asked:</p>
<blockquote>
<p>I don’t understand ‘nullable references to a boolean value’, and why they deserve the name ‘bottom type’ too. But I’d be glad to learn.</p>
</blockquote>
<p>I don&#8217;t want to preempt the answer of C. McCann, here is how I understand this statement, using Java nomenclature:</p>
<p>NULL is a special memory address that indicates that a reference to an object is not initialized. Java distinguishes classes and &#8220;primitive types&#8221;, the latter are not derived from &#8220;Object&#8221;. &#8220;Object&#8221; is the root class of the inheritance tree. </p>
<p>The primitive types include boolean. Primitive types in Java cannot be set to NULL, this is possible with references to objects only: A primitive type is always initialized with a default value.</p>
<p>Java also has &#8220;wrapper classes&#8221; for the primitive types, these have the same names but start with a capital letter, example:</p>
<p>boolean and Boolean.</p>
<p>So, boolean is not NULL-able, but Boolean is:</p>
<blockquote>
<p>// this results in a compiler error:<br />
boolean isPrimitive = null;</p>
<p>// this initializes the variable isPrimitive with the default value false:<br />
boolean isPrimitive;</p>
<p>Boolean isWrapperClass = null;</p>
</blockquote>
<p>Java also knows the &#8220;instanceof&#8221; operator, that compares a reference A and a class C and returns true if the class of A is derived from C. &#8220;instanceof&#8221; will always return true if A is NULL.</p>
<p>Example: </p>
<blockquote>
<p>Boolean isNull = null;</p>
<p>if(isNull instanceof String)<br />
{<br />
   // we&#8217;ll end up here as long as &#8220;isNull&#8221; is NULL.<br />
}</p>
</blockquote>
<p>The &#8220;primitive type inconsistency&#8221; of Java was introduced for performance considerations, I&#8217;d guess, and has often been critized. The successor languages C# and Scala don&#8217;t have &#8220;primitive types&#8221;, in these languages everything is an object :-)</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2061#respond' data-commentid="2061" data-postid="1308" data-belowelement="div-comment-2061" data-respondelement="respond" data-replyto="Reply to Tim van Beek" aria-label='Reply to Tim van Beek'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even depth-2 parent highlander-comment" id="comment-2056">
				<div id="div-comment-2056" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/7d62be404c89efbea1cd6b0dacfd0e3e?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Giampiero Campa</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2056">20 October, 2010 at 2:58 am</a>		</div>

		<p>On the other hand, considering high impedance as a possible state of a digital terminal (which it is), all digital circuits are actually based on 3 values, high, low and floating:</p>
<p><a href="http://en.wikipedia.org/wiki/Three-state_logic" rel="nofollow ugc">http://en.wikipedia.org/wiki/Three-state_logic</a></p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2056#respond' data-commentid="2056" data-postid="1308" data-belowelement="div-comment-2056" data-respondelement="respond" data-replyto="Reply to Giampiero Campa" aria-label='Reply to Giampiero Campa'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor odd alt depth-3 parent highlander-comment" id="comment-2057">
				<div id="div-comment-2057" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2057">20 October, 2010 at 3:10 am</a>		</div>

		<p>So what do you think about <a href="http://en.wikipedia.org/wiki/Trivalent_logic#Electronics" rel="nofollow">this Wikipedia page</a> that says digital logic supports <i>four</i> logical values&#8230; and then seemingly goes on to list six or ten?</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2057#respond' data-commentid="2057" data-postid="1308" data-belowelement="div-comment-2057" data-respondelement="respond" data-replyto="Reply to John Baez" aria-label='Reply to John Baez'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment even depth-4 highlander-comment" id="comment-2075">
				<div id="div-comment-2075" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/5850d628c599d7ac60d7f7889844995a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">John F</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2075">20 October, 2010 at 4:34 pm</a>		</div>

		<p>Multivalued digital logic is easy. Even with all non-negatives in a five volt pulse train system, using a 2.5 V level defines the typical unbalanced ternary.</p>
<p>The problem is transmission. Binary transmits well &#8211; e.g. &#8220;something or nothing&#8221;, or &#8220;either or&#8221; Morse dit dit dah &#8211; but multivalues do not because of shaping. The pulses aren&#8217;t perfectly timed rectangles.</p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt depth-4 highlander-comment" id="comment-2121">
				<div id="div-comment-2121" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/7d62be404c89efbea1cd6b0dacfd0e3e?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://www.mathworks.com/matlabcentral/fileexchange/authors/76178' rel='external nofollow ugc' class='url'>Giampiero Campa</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2121">23 October, 2010 at 7:25 pm</a>		</div>

		<p>I think that from either a conceptual or physical standpoint unknown states like U an X are neither states nor values, just a way or representing uncertainty, so i am not sure that they should be treated as equal to 0 or 1.</p>
<p>Similarly, the don&#8217;t care value, -, is a characteristic of a given function or truth table, so it definitely does not belong there.</p>
<p>Distinguishing Z from W is really a subtlety, while H and L might actually be useful, even if i still believe that grouping HiZ states under Z is fine for most purposes.</p>
<p>Anyway, Z is probably hard to detect, so it&#8217;s not practical to use Z to either store or transmit information, and therefore we are &#8220;stuck&#8221; with binary logic for practical purposes.</p>

		
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1 parent highlander-comment" id="comment-2039">
				<div id="div-comment-2039" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/a7fee90572f7316e52862ebabf8e3f39?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://complementaryslackness.wordpress.com/' rel='external nofollow ugc' class='url'>Joe</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2039">19 October, 2010 at 12:22 pm</a>		</div>

		<p>As a big fan of your book on gauge fields, knots, and gravity, I&#8217;m glad you liked our paper! In case you&#8217;re interested, I wrote up a short not-too-technical explanation <a href="http://complementaryslackness.wordpress.com/2010/08/03/entropic-uncertainty-principle/" rel="nofollow">here</a>.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2039#respond' data-commentid="2039" data-postid="1308" data-belowelement="div-comment-2039" data-respondelement="respond" data-replyto="Reply to Joe" aria-label='Reply to Joe'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor odd alt depth-2 highlander-comment" id="comment-2041">
				<div id="div-comment-2041" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2041">19 October, 2010 at 1:28 pm</a>		</div>

		<p>Great, thanks!  I&#8217;m sorry I didn&#8217;t get around to actually explaining your paper&#8230; but now people here can read <i>your</i> explanation.  It looks nice!</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2041#respond' data-commentid="2041" data-postid="1308" data-belowelement="div-comment-2041" data-respondelement="respond" data-replyto="Reply to John Baez" aria-label='Reply to John Baez'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1 parent highlander-comment" id="comment-2045">
				<div id="div-comment-2045" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/ef4a2fb0e47bee3226963fc8b5a353d8?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Justin Scheiner</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2045">19 October, 2010 at 4:38 pm</a>		</div>

		<p>Thanks! I&#8217;ve been lurking on your site(s) for a while and the topics are generally out my league. This article was right on target for me.</p>
<p>I&#8217;m a computer science guy and have found decimal ternary useful for understanding cantor sets. :D</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2045#respond' data-commentid="2045" data-postid="1308" data-belowelement="div-comment-2045" data-respondelement="respond" data-replyto="Reply to Justin Scheiner" aria-label='Reply to Justin Scheiner'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor odd alt depth-2 highlander-comment" id="comment-2059">
				<div id="div-comment-2059" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2059">20 October, 2010 at 3:46 am</a>		</div>

		<p>Glad you liked the article!  It&#8217;s always nice getting feedback, even feedback like &#8220;huh?&#8221;  I know what the folks who comment on this blog are like, but I have little sense for who is reading it and not commenting.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2059#respond' data-commentid="2059" data-postid="1308" data-belowelement="div-comment-2059" data-respondelement="respond" data-replyto="Reply to John Baez" aria-label='Reply to John Baez'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1 parent highlander-comment" id="comment-2046">
				<div id="div-comment-2046" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/151c18cc6cc3bd1bb7a0528c6ef88c77?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://reperiendi.wordpress.com' rel='external nofollow ugc' class='url'>Mike Stay</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2046">19 October, 2010 at 6:06 pm</a>		</div>

		<p>How does this relate to Fisher information?</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2046#respond' data-commentid="2046" data-postid="1308" data-belowelement="div-comment-2046" data-respondelement="respond" data-replyto="Reply to Mike Stay" aria-label='Reply to Mike Stay'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-reperiendi odd alt depth-2 highlander-comment" id="comment-2048">
				<div id="div-comment-2048" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/151c18cc6cc3bd1bb7a0528c6ef88c77?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://www.cs.auckland.ac.nz/~mike' rel='external nofollow ugc' class='url'>Mike Stay</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2048">19 October, 2010 at 9:17 pm</a>		</div>

		<p>OK, the Fisher information is the variance of the &#8220;score&#8221;; he introduced it in 1925.  Everett used it for talking about the uncertainty principle in his book on the many worlds interpretation in 1973.</p>
<p>The &#8220;score&#8221; of <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Ctheta%7D+%5Cmathrm%7Blog%7D%5C%2C+P%28X%7C%5Ctheta%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;frac{&#92;partial}{&#92;partial &#92;theta} &#92;mathrm{log}&#92;, P(X|&#92;theta)" class="latex" />.</p>
<p>The variance of a quantity <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%5Clangle+Y%5E2%5Crangle+-+%5Clangle+Y%5Crangle%5E2.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle Y^2&#92;rangle - &#92;langle Y&#92;rangle^2." class="latex" /></p>
<p>The Fisher information in a density matrix <img src="https://s0.wp.com/latex.php?latex=%5Crho&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho" class="latex" /> is<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+I_%5Crho+%3D+%5Cint+%5Crho%28%5Cvec%7Br%7D%29%5Cleft%5B%5Cvec%7B%5Cnabla%7D_D%5Cln+%5Crho%28%5Cvec%7Br%7D%29%5Cright%5D%5E2+d%5EDr&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle I_&#92;rho = &#92;int &#92;rho(&#92;vec{r})&#92;left[&#92;vec{&#92;nabla}_D&#92;ln &#92;rho(&#92;vec{r})&#92;right]^2 d^Dr" class="latex" /></p>
<p><a href="http://iopscience.iop.org/1367-2630/8/12/330/fulltext" rel="nofollow ugc">http://iopscience.iop.org/1367-2630/8/12/330/fulltext</a></p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2048#respond' data-commentid="2048" data-postid="1308" data-belowelement="div-comment-2048" data-respondelement="respond" data-replyto="Reply to Mike Stay" aria-label='Reply to Mike Stay'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor even depth-2 parent highlander-comment" id="comment-2060">
				<div id="div-comment-2060" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2060">20 October, 2010 at 4:22 am</a>		</div>

		<p>Mike wrote:</p>
<blockquote><p>
OK, the Fisher information is the variance of the “score”; Everett used it for talking about the uncertainty principle in his book on the many worlds interpretation in 1973.
</p></blockquote>
<p>The problem is, I don&#8217;t have any intuition for what&#8217;s going on in those formulas you wrote down &mdash; except the variance, which I learned back in high school.</p>
<p>I always have trouble understanding Fisher information.  I first tried understanding it back when Frieden started claiming that it was <a href="http://www.optics.arizona.edu/frieden/fisher_information.htm" rel="nofollow">earth-shatteringly important throughout all science</a>, but I failed miserably.  </p>
<p>Later I got some help from David Corfield.  </p>
<p>There&#8217;s a quantity you know well, called the &#8220;information gain&#8221; or &#8220;relative entropy&#8221; S(p,q): how much information you gain when your hypothesis about some system was given by the probability distribution q and someone tells you &#8220;no, it&#8217;s p&#8221;.  </p>
<p>For example, when I flip a coin and hide it from you, you hypothesize that it has a 50% chance of being heads and a 50% chance of being tails: that&#8217;s your p.  Then I lift my hand and you see it&#8217;s heads up.  So q is 100% heads, 0% tails.  The information gain works out to be one bit.  This example is too easy, but it conveys the flavor.</p>
<p>(Some obscurantists call information gain the <a href="http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" rel="nofollow">&#8220;Kullback-Leibler divergence&#8221;</a>.  No criticism of Kullback and Leibler intended, but that term completely obscures the meaning of the concept, whereas I could pretty much reinvent the math on my own starting from the phrase &#8220;relative entropy&#8221; or &#8220;information gain&#8221;.)</p>
<p>I learned about information gain when I studied Everett&#8217;s thesis in college, working with my friend Bruce Smith.  It made a lot of sense.  But I don&#8217;t remember Everett talking about Fisher information.</p>
<p>The information gain does not define a metric:</p>
<p>S(p,q) &ne; S(q,p)</p>
<p>but it does obey the triangle inequality, so you can symmetrize it and get a metric on probability measures!  That&#8217;s called the &#8220;information metric&#8221;.</p>
<p>And in science, you often have hypotheses parametrized by a bunch of numbers.  In this situation, what you really have is a function from some manifold to a space of probability measures.  So, the information metric on probability measures gives you a metric on that manifold!  And lots of times it&#8217;s a <a href="http://en.wikipedia.org/wiki/Riemannian_manifold" rel="nofollow">Riemannian metric</a>. </p>
<p>This makes a lot of intuitive sense: your manifold is a space of &#8220;hypotheses&#8221;, and there&#8217;s a distance between hypotheses, that says (in a symmetrized way) how much information you get if you started out believing one hypothesis and then learn the other is true.</p>
<p>There are people working on machine learning who think about hypotheses in this geometrical way, and think about geodesics in this manifold, and stuff like that.  The buzzword is <a href="http://en.wikipedia.org/wiki/Information_geometry" rel="nofollow">&#8220;information geometry&#8221;</a>.  David Corfield has been telling us about information geometry for years now, on <a href="http://math.ucr.edu/home/baez/corfield/2006/08/ruminating.html" rel="nofollow">various blogs</a>&#8230;</p>
<p>And then, if I remember right, the Fischer information is related in some simple way to the <a href="http://en.wikipedia.org/wiki/Riemann_curvature_tensor" rel="nofollow">Riemann curvature tensor</a> of this Riemannian metric!  </p>
<p>Unfortunately I forget the details.  Hmm, try <a href="http://biomet.oxfordjournals.org/content/47/1-2/203.abstract" rel="nofollow">this</a> and<br />
<a href="http://www.ece.rice.edu/~dhj/distance.pdf" rel="nofollow">this</a>.  </p>
<p>But unfortunately, I&#8217;m stuck on some more basic points.  </p>
<p>First of all, <i>why the heck should we care about the curvature of the information metric?</i>  What is its conceptual meaning?</p>
<p>Second, the Fischer information <i>itself</i> seems to define <a href="http://en.wikipedia.org/wiki/Fisher_information_metric" rel="nofollow">some sort of metric on probability distributions</a>!  So what&#8217;s going on? How could the curvature of one metric be another metric?  </p>
<p>I&#8217;m probably making some sort of terrible mistake here, right about the point where Fisher information raises its ugly head.  Maybe the Fischer information <i>is</i> the information metric, slightly repackaged &mdash; that would be more sensible than having it be the <i>curvature</i> of the information metric.</p>
<p>Yeah, I&#8217;m hoping that&#8217;s true.  That would make the world a simpler, better place.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2060#respond' data-commentid="2060" data-postid="1308" data-belowelement="div-comment-2060" data-respondelement="respond" data-replyto="Reply to John Baez" aria-label='Reply to John Baez'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment odd alt depth-3 parent highlander-comment" id="comment-2062">
				<div id="div-comment-2062" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/e12fed9193da121c6337ce250d548759?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://www.kent.ac.uk/secl/philosophy/staff/corfield.html' rel='external nofollow ugc' class='url'>David Corfield</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2062">20 October, 2010 at 8:22 am</a>		</div>

		<p>One thing is to get straight on how Riemannian manifold, metric, distance, divergence, and connection fit together &#8211; an exercise in differential geometry.</p>
<p>I may well have this wrong, but a Riemannian manifold is a manifold equipped with a Riemannian metric (one of those things that gives a real number when fed two tangent vectors). A Riemannian metric gives rise to a (symmetric) distance via geodesics.</p>
<p>It may be possible to define many connections on a Riemannian manifold which are compatible with the metric. Each of these connections gives rise to a type of geodesic. </p>
<p>One connection compatible with the Fisher information metric gives rise to a geodesic with the property that the associated (nonsymmetric) distance is relative entropy.</p>
<p>The Fisher information metric is the unique Riemannian metric invariant under reparameterization. Its curvature is studied in problems such as estimator accuracy.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2062#respond' data-commentid="2062" data-postid="1308" data-belowelement="div-comment-2062" data-respondelement="respond" data-replyto="Reply to David Corfield" aria-label='Reply to David Corfield'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment even depth-4 highlander-comment" id="comment-2063">
				<div id="div-comment-2063" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/6b3fa8cd421b5fd2028e3c1e9c32aa7f?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Tim van Beek</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2063">20 October, 2010 at 9:15 am</a>		</div>

		<p>We already mentioned Fisher information on this blog briefly<br />
<a href="https://johncarlosbaez.wordpress.com/2010/08/13/the-geometry-of-quantum-phase-transitions/" rel="nofollow">here</a>.</p>
<p>My simplistic view of Fisher information was this: We have a family of probability distributions (aka random variables) that can be parametrized by a finite set of parameters such that they form a manifold.</p>
<p>The Fisher metric is a Riemann metric on this manifold. It is unique in the following sense:</p>
<p>Definition: A stochastic map is a linear map on the algebra of random variables that preserves positivity and takes 1 to itself.</p>
<p>If a metric measures the ability to distinguish points, then the distance between two points should be reduced &#8211; at most &#8211; by any stochastic map, that is, a stochastic map should “muddy the waters” and reduce the ability to distinguish points.</p>
<p>It is possible to prove that the Fisher-Rao metric is the only one (up to multiples) that has this property:</p>
<p>Cencov, N. N. (1982). Statistical Decision Rules and Optimal Inference (Providence, RI, American Mathematical Society). </p>
<p>With regard to one interpretation of the metric distance, let me cite myself :-):</p>
<p>Let’s say we can obtain iid (independent identically distributed) samples from a fixed, but unkown, probability distribution (= point of our manifold), and would like to use these to estimate the parameters of this point.</p>
<p>What we would like to have is a uniformly minimum variance unbiased estimator T. Now, the Cramér-Rao lower bound gives a lower bound on the variance of all unbiased estimators, it is proportional to the inverse of the Fisher information matrix I.</p>
<p>In this sense, somewhat simplifying, the farther away a point is from the point where you get your samples from, the less samples you need, on the average, to find out that you are not there :-)</p>

		
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt depth-3 highlander-comment" id="comment-2064">
				<div id="div-comment-2064" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/ee67ce8f823fcad46c6cca7e12a71aef?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Chris Goddard</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2064">20 October, 2010 at 9:18 am</a>		</div>

		<p>Hi, John.</p>
<p>Interesting blog; I&#8217;m enjoying the variety of posts so far.  </p>
<blockquote><p>Unfortunately, I’m stuck on some more basic points.</p>
<p>First of all, why the heck should we care about the curvature of the information metric? What is its conceptual meaning?</p>
<p>Second, the Fischer information itself seems to define some sort of metric on probability distributions! So what’s going on? How could the curvature of one metric be another metric?&#8221;</p></blockquote>
<p>Now, I don&#8217;t know much about the standard approaches to information geometry through Machine Learning etc, but I&#8217;ll bite.</p>
<p>These two questions, according to my understanding, are related.  This is because it is possible to define the Fisher Information in the following fairly simple way &#8211;</p>
<p>Let  <img src="https://s0.wp.com/latex.php?latex=%5C%7B+TM+%5Ctimes+TM+%5Crightarrow+R+%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;{ TM &#92;times TM &#92;rightarrow R &#92;}" class="latex" />  be the class of metrics on a space  <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M" class="latex" />  with differentiable structure.  Choose a trivial basis for this space and extend over the manifold.  Say for  <img src="https://s0.wp.com/latex.php?latex=R%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="R^n" class="latex" />  this would be <img src="https://s0.wp.com/latex.php?latex=x_i+%5Cotimes+x_j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_i &#92;otimes x_j" class="latex" />, but of course this extends.  Broadly speaking, think of this as a basis for  <img src="https://s0.wp.com/latex.php?latex=GL%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="GL(n)" class="latex" />  &#8211; more interesting examples can then be constructed by merely considering the space locally as  <img src="https://s0.wp.com/latex.php?latex=GL%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="GL(n)" class="latex" />, e.g. bundles etc.</p>
<p>Then one can take a <i> section </i> of this space over the manifold  <img src="https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M" class="latex" /> , as  <img src="https://s0.wp.com/latex.php?latex=g+%3A+TM+%5Ctimes+TM+%5Crightarrow+R&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="g : TM &#92;times TM &#92;rightarrow R" class="latex" /> .  For clarity I will refer to this as the <i> information metric </i>, and assume that it is Riemannian.</p>
<p>Then the connection between this and the Fisher information is via the following rather beautiful observation.  View the information metric as a smooth sampling of the space of possibilities for the Riemannian metric at each point in the manifold.  Then we can interpret it probabilistically as a pdf</p>
<p><img src="https://s0.wp.com/latex.php?latex=f%28m%2C%5Calpha%29+%3D+%5Cdelta%28+g%28m%29+-+%5Calpha%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(m,&#92;alpha) = &#92;delta( g(m) - &#92;alpha)" class="latex" /></p>
<p>which indeed trivially has the property that if one integrates over the space of metrics for fixed m, we obtain 1.</p>
<p>From this the Fisher information functional can be constructed-</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cint_M+%5Cint_A+f%28m%2C%5Calpha%29+%5Cpartial+ln+f%28m%2C%5Calpha%29+%5Cpartial+ln+f%28m%2C%5Calpha%29+d%5Calpha+dm+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;int_M &#92;int_A f(m,&#92;alpha) &#92;partial ln f(m,&#92;alpha) &#92;partial ln f(m,&#92;alpha) d&#92;alpha dm " class="latex" /></p>
<p>and for this choice of geometric objects it can be demonstrated that the above reduces to</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cint_M+R%28g%29+dm%2C+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;int_M R(g) dm, " class="latex" /></p>
<p>nothing other than the integral of the scalar curvature over the original space.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2064#respond' data-commentid="2064" data-postid="1308" data-belowelement="div-comment-2064" data-respondelement="respond" data-replyto="Reply to Chris Goddard" aria-label='Reply to Chris Goddard'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment even depth-3 parent highlander-comment" id="comment-2066">
				<div id="div-comment-2066" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/6b3fa8cd421b5fd2028e3c1e9c32aa7f?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Tim van Beek</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2066">20 October, 2010 at 11:00 am</a>		</div>

		<p>JB asked:</p>
<blockquote>
<p>Second, the Fischer information itself seems to define some sort of metric on probability distributions! So what’s going on? How could the curvature of one metric be another metric? </p>
</blockquote>
<p>Sorry if I muddy the waters with my comment, but take a look a a simple example where our manifold is some <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}^n" class="latex" />, let the Kullback-Leibler divergence be <img src="https://s0.wp.com/latex.php?latex=S%28p%2C+q%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(p, q)" class="latex" /> and compute the Hessian of it, that is choose vectors <img src="https://s0.wp.com/latex.php?latex=u%2C+v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="u, v" class="latex" /> and parameters <img src="https://s0.wp.com/latex.php?latex=t%2C+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t, s" class="latex" />, differentiate <img src="https://s0.wp.com/latex.php?latex=S%28p+%2B+tu%2C+q+%2B+sv%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(p + tu, q + sv)" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=t%2C+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t, s" class="latex" />, at <img src="https://s0.wp.com/latex.php?latex=t%3Ds%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t=s=0" class="latex" /> and get the Fisher information <img src="https://s0.wp.com/latex.php?latex=F%28u%2C+v%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F(u, v)" class="latex" />.</p>
<p>(How do I use latex? Sorry, I already forgot&#8230;).</p>
<p>That is the Hessian of the real valued function <img src="https://s0.wp.com/latex.php?latex=S%28p%2C+q%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(p, q)" class="latex" /> is the Fisher information.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2066#respond' data-commentid="2066" data-postid="1308" data-belowelement="div-comment-2066" data-respondelement="respond" data-replyto="Reply to Tim van Beek" aria-label='Reply to Tim van Beek'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor odd alt depth-4 highlander-comment" id="comment-2067">
				<div id="div-comment-2067" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2067">20 October, 2010 at 12:22 pm</a>		</div>

		<p>Your comment didn&#8217;t muddy the waters.  It should help!</p>
<p>If we can understand the example of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}^n" class="latex" /> well enough, we should be able to understand any manifold, since they all look locally like <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}^n" class="latex" />.  </p>
<p>Two basic questions: </p>
<p>1) In this formulation, what&#8217;s the Fisher information a function of?  You wrote <img src="https://s0.wp.com/latex.php?latex=F%28u%2Cv%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F(u,v)" class="latex" /> but I guess it&#8217;s really a function of <img src="https://s0.wp.com/latex.php?latex=p%2Cq%2Cu%2Cv&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p,q,u,v" class="latex" />.  In other words, it&#8217;s a function on the tangent bundle of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5En+%5Ctimes+%5Cmathbb%7BR%7D%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}^n &#92;times &#92;mathbb{R}^n" class="latex" />.  Is that right? </p>
<p>For some reason I had been thinking that Fisher information showed up only when we took <img src="https://s0.wp.com/latex.php?latex=p+%3D+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p = q" class="latex" />.  Then it becomes a symmetric bilinear function of the two tangent vectors <img src="https://s0.wp.com/latex.php?latex=u%2C+v&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="u, v" class="latex" />, which is about what we expect for a Riemannian metric.</p>
<p>2) What&#8217;s the point?  I understand the conceptual meaning of &#8216;relative entropy&#8217; (or as you seem to insist on calling it, despite my already announced disgust, &#8216;Kullback-Leibler divergence&#8217;.)   But why should we take the Hessian of the relative entropy?  What good is that?  What does it mean?</p>
<p>I converted your comment into LaTeX.   To do LaTeX, use dollar signs as usual (single dollar signs only), but write &#8220;latex&#8221; directly after the first dollar sign, without a space.  Thus,</p>
<p>&#036;latex p \in \mathbb{R}^n &#036;</p>
<p>gives</p>
<p><img src="https://s0.wp.com/latex.php?latex=p+%5Cin+%5Cmathbb%7BR%7D%5En+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p &#92;in &#92;mathbb{R}^n " class="latex" /></p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment even depth-4 highlander-comment" id="comment-2069">
				<div id="div-comment-2069" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/6b3fa8cd421b5fd2028e3c1e9c32aa7f?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Tim van Beek</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2069">20 October, 2010 at 1:51 pm</a>		</div>

		<p>1) Yes, that&#8217;s right, I was lazy.</p>
<p>2) The relative entropy induces a topology on the space of probability distributions. I implicitly fixed a coordinate system, the Hessian with respect to this &#8211; arbitrary but fixed &#8211; coordinate system defines a Riemann metric that is compatible with this topology.</p>
<p>This metric is the Fisher metric, which is unique in the sense I described.</p>
<p>All of this is just an observation, I don&#8217;t know if there is any &#8220;point&#8221;&#8230;I don&#8217;t understand how the Fisher metric is supposed to be the &#8220;curvature&#8221; of a &#8220;metric&#8221; derived from the relative entropy, my educated guess is that this is just an unconventional phrasing of the connection I pointed out, but I don&#8217;t know&#8230;</p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt depth-4 highlander-comment" id="comment-2071">
				<div id="div-comment-2071" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/e12fed9193da121c6337ce250d548759?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://www.kent.ac.uk/secl/philosophy/staff/corfield.html' rel='external nofollow ugc' class='url'>David Corfield</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2071">20 October, 2010 at 3:22 pm</a>		</div>

		<p>Oh, it looks like what I said wasn&#8217;t quite right. There&#8217;s a unique connection associated with the Fisher information metric so that the inner product of vectors is invariant under transport by that connection. This is the Levi-Civita or Riemannian connection. But this connection gives rise to a distance which is not relative entropy (KL-divergence).</p>
<p>However, there is a whole one-parameter family of pairs of dual connections such that the inner product is preserved when the first vector is transported according to the first connection and the second vector by the second. (The Riemannian connection is the self-dual member of this family.)</p>
<p>One special member of this family has dual connections often denoted the e-connection and m-connection. It&#8217;s the e-connection which gives rise to the relative entropy divergence.</p>
<p>There&#8217;s then a bunch of clever stuff involving Legendre transformations between dual coordinate systems as in <a href="http://www.springerlink.com/content/x4ln74k5625r1467/fulltext.pdf" rel="nofollow">here</a>.</p>
<p>Tim&#8217;s returning us from the e-connection, or rather its form of divergence, to the Fisher information metric.</p>

		
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even depth-3 highlander-comment" id="comment-2073">
				<div id="div-comment-2073" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/5850d628c599d7ac60d7f7889844995a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">John F</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2073">20 October, 2010 at 4:00 pm</a>		</div>

		<p>The Jensen-Shannon metric is better.<br />
<a href="http://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence" rel="nofollow ugc">http://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence</a></p>
<p>BTW, Jensen&#8217;s work in this area was in the 1890s, predating whatever other dates mentioned above, published in 1904 I think.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2073#respond' data-commentid="2073" data-postid="1308" data-belowelement="div-comment-2073" data-respondelement="respond" data-replyto="Reply to John F" aria-label='Reply to John F'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt depth-3 parent highlander-comment" id="comment-2092">
				<div id="div-comment-2092" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/5850d628c599d7ac60d7f7889844995a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">John F</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2092">21 October, 2010 at 6:01 pm</a>		</div>

		<p>Crooks had a nice article &#8220;Measuring Thermodynamic Length&#8221;<br />
<a href="http://prl.aps.org/pdf/PRL/v99/i10/e100602" rel="nofollow ugc">http://prl.aps.org/pdf/PRL/v99/i10/e100602</a></p>
<p>Equation 6 therein may provide the aha you&#8217;re looking for.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2092#respond' data-commentid="2092" data-postid="1308" data-belowelement="div-comment-2092" data-respondelement="respond" data-replyto="Reply to John F" aria-label='Reply to John F'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor even depth-4 highlander-comment" id="comment-2094">
				<div id="div-comment-2094" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2094">22 October, 2010 at 12:53 am</a>		</div>

		<p>Aha!  </p>
<p>Very, very nice &mdash; thanks!  This helps immensely.</p>
<p>This article by Crooks should be readable to anyone who is comfortable with the usual statistical mechanics game of computing the means, variances, and higher moments of observables by repeatedly differentiating the logarithm of the partition function.  And you don&#8217;t need a subscription to Phys. Rev. Lett. to read it!  It&#8217;s free here:</p>
<p>&bull; Gavin E. Crooks, <a href="http://arxiv.org/abs/0706.0559" rel="nofollow">Measuring thermodynamic length</a>, <br /> arXiv:0706.0559.</p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt depth-4 parent highlander-comment" id="comment-2097">
				<div id="div-comment-2097" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/6b3fa8cd421b5fd2028e3c1e9c32aa7f?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Tim van Beek</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2097">22 October, 2010 at 7:52 am</a>		</div>

		<p>Aha!</p>
<p>(What&#8217;s &#8220;fractional distillation&#8221;?)</p>
<p>But I&#8217;m still getting confused by statements like this one:</p>
<blockquote>
<p>The square root of the<br />
Jensen-Shannon divergence is a metric between probability<br />
distributions [25]. However, unlike a Riemannian<br />
metric, the Jensen-Shannon metric space is not an intrinsic<br />
length space. There may not be a mid point b between<br />
points a and c such that d(a, b) + d(b, c) = d(a, c)<br />
and consequentially we cannot naturally measure path<br />
lengths. However, on any metric space we can define a<br />
new intrinsic metric by measuring the distance along continuous<br />
paths.</p>
</blockquote>
<p>How does the author define &#8220;divergence&#8221; and &#8220;square root of a divergence&#8221;?</p>
<p>And what do the last two sentences mean?</p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor even depth-4 highlander-comment" id="comment-2112">
				<div id="div-comment-2112" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2112">23 October, 2010 at 1:06 am</a>		</div>

		<p>As for the last two sentence in the text you quote: the author is apparently defining a metric space to be <b>intrinsic</b> if for any two points a and c there exists a <b>midpoint</b>, meaning a point b with</p>
<p> d(a, b) + d(b, c) = d(a, c).</p>
<p>And then he&#8217;s claiming that given any metric space with metric d, we can define a new metric d&#8217; that is intrinsic, by letting d'(a,b) be the infimum of the &#8220;arclengths&#8221; of continuous paths from a to b.  I&#8217;m not sure, but I think I see a reasonable way to define the &#8220;arclength&#8221; of a continuous path in any metric space (which could, of course, be infinite).  </p>
<p>And I think he&#8217;s also hinting that for an intrinsic metric space, the metric d&#8217; is the same as the metric d.</p>
<p>In other words: for an intrinsic metric space, the distance between two points equals the infimum of the arclengths of all continuous paths from one point to another.  This is pretty easy to see: just take your two points and repeatedly take choose midpoints to create, in the limit, a continuous path from one point to the other, whose arclength is the distance between these points!</p>
<p>He is saying all this a fairly concise way. <img src="https://i2.wp.com/math.ucr.edu/home/baez/emoticons/rolleyes.gif" alt="" /></p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt depth-4 highlander-comment" id="comment-2106">
				<div id="div-comment-2106" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/5850d628c599d7ac60d7f7889844995a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">John F</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2106">22 October, 2010 at 3:14 pm</a>		</div>

		<p>Tim,</p>
<p><i>numerically</i> a divergence is simply a monotonic nonnegative measure of (usually highly multidimensional) difference, and can&#8217;t necessarily be massaged into a norm or anything. Divergences are mostly commonly used as class separability indicators, for instance in hyperspectral geospatial imaging applications. The most useful divergence implemented in most GIS software is called Transform Divergence, which despite its vague name is fast to calculate. The square root is <i>numerically</i> the square root.</p>
<p>The Jensen-Shannon metric is a metric that doesn&#8217;t require coordinatizing to define. I think the last sentence is saying that it could be coordinatized if you wanted to.</p>

		
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1 highlander-comment" id="comment-2047">
				<div id="div-comment-2047" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/dd50e8b0462cc7fb7fa5bb0785e4f2a4?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://www.sunclipse.org' rel='external nofollow ugc' class='url'>Blake Stacey</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2047">19 October, 2010 at 8:31 pm</a>		</div>

		<p>If you like entropic uncertainty principles, you&#8217;d probably also like <a href="http://arxiv.org/abs/quant-ph/9608047" rel="nofollow">entropic Bell inequalities</a>.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2047#respond' data-commentid="2047" data-postid="1308" data-belowelement="div-comment-2047" data-respondelement="respond" data-replyto="Reply to Blake Stacey" aria-label='Reply to Blake Stacey'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1 highlander-comment" id="comment-2052">
				<div id="div-comment-2052" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/790504be0016c185f5f06f52954f3d49?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://epistle-null.blogspot.com' rel='external nofollow ugc' class='url'>some guy on the street</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2052">19 October, 2010 at 10:46 pm</a>		</div>

		<p>On trits, back in my undergrad, a friend got me to amuse myself with the &#8220;balanced base 3&#8221; representation of integers.  A familier sequence of integers might, in this notation, look like<br />
&#8220;&#8230; NN, N0, NP, 0N, 00, 0P, PN, P0, PP&#8230;&#8221;<br />
It&#8217;s a cute little thing, and it elucidates a conundrum of Meziriac &#8212; although it also makes some familiar digit-crunching algorithms somewhat messier &#8212; or I never thought enough about them, maybe.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2052#respond' data-commentid="2052" data-postid="1308" data-belowelement="div-comment-2052" data-respondelement="respond" data-replyto="Reply to some guy on the street" aria-label='Reply to some guy on the street'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1 highlander-comment" id="comment-2083">
				<div id="div-comment-2083" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/4151efe42f1bb60c6033191ea5ab6348?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">DavidTweed</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2083">20 October, 2010 at 12:31 am</a>		</div>

		<p>Going off topic, I&#8217;m starting to see a couple of user names from TheOilDrum show up here (such as WebHubTel), so I&#8217;ll point out that there&#8217;s currently a draft page on peak oil page under development on the Azimuth wiki.</p>
<p><a href="http://www.azimuthproject.org/azimuth/show/Peak+oil" rel="nofollow ugc">http://www.azimuthproject.org/azimuth/show/Peak+oil</a></p>
<p>I&#8217;m slowly adding to it, but any contributions (particularly corrections of errors) are very welcome to that or any other wiki page. It&#8217;s John Baez&#8217; project, but here&#8217;s my interpretation of a couple of points to bear in mind with respect to wiki articles:</p>
<p>1. Azimuth, with an intended audience of scientists, is trying to have its articles maintain the distinction between things like &#8220;observationally confirmed facts&#8221; (ideally with references as close to the source as possible), &#8220;model based projections&#8221; and &#8220;intuitive conjectures&#8221;, &#8220;speculations&#8221;, etc. It&#8217;s also preferred to be explicit about any uncertainty that exists. Part of why it&#8217;s gone slowly so far is me trying to figure out which stuff falls into each category (along with references).</p>
<p>2. Azimuth&#8217;s goal is providing an intro to all &#8220;environmental/sustainability&#8221; problems, not just energy.</p>
<p>3. Information about possible solutions are also very relevant, but advocacy should maintain the same sort of distinctions as 1.</p>
<p>(I&#8217;m not trying to scare anybody off from contributing, just trying to state what the goals for wiki articles are.) Information about how to get a wiki account can be found at</p>
<p><a href="http://www.azimuthproject.org/azimuth/show/HomePage" rel="nofollow ugc">http://www.azimuthproject.org/azimuth/show/HomePage</a></p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2083#respond' data-commentid="2083" data-postid="1308" data-belowelement="div-comment-2083" data-respondelement="respond" data-replyto="Reply to DavidTweed" aria-label='Reply to DavidTweed'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1 parent highlander-comment" id="comment-2053">
				<div id="div-comment-2053" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/f614294fdc866d8e2813c4eec0f231c6?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://www.ellerman.org' rel='external nofollow ugc' class='url'>David Ellerman</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2053">20 October, 2010 at 12:53 am</a>		</div>

		<p>The question of bits, trits, or nats is bypassed by using the base-free version, namely the antilog of Shannon&#8217;s entropy: </p>
<p><img src="https://s0.wp.com/latex.php?latex=H_%7Bm%7D%28p%29%3D2%5E%7BH%28p%29%7D%3D%5Cprod_%7Bi%7D%28%5Cfrac%7B1%7D%7Bp_%7Bi%7D%7D%29%5E%7Bp_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H_{m}(p)=2^{H(p)}=&#92;prod_{i}(&#92;frac{1}{p_{i}})^{p_{i}}" class="latex" />, </p>
<p>where the usual Shannon (additive) entropy is: </p>
<p><img src="https://s0.wp.com/latex.php?latex=H%28p%29%3D%5Csum_%7Bi%7Dp_%7Bi%7D%5Cmathrm%7Blog%7D_%7B2%7D%5C%2C%28%5Cfrac%7B1%7D%7Bp_%7Bi%7D%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H(p)=&#92;sum_{i}p_{i}&#92;mathrm{log}_{2}&#92;,(&#92;frac{1}{p_{i}})" class="latex" /> </p>
<p>for a finite probability distribution <img src="https://s0.wp.com/latex.php?latex=p+%3D+%5C%7Bp_%7B1%7D%2C%5Cldots%2Cp_%7Bn%7D%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p = &#92;{p_{1},&#92;ldots,p_{n}&#92;}" class="latex" />. Ironically, the basic property often used to justify Shannon&#8217;s additive entropy formula, namely the asymptotic equipartition property (see Cover and Thomas, chapter 3), actually develops the base-free multiplicative form given above, and then Shannon&#8217;s additive form is presented by choosing a base such as 2 and then writing <img src="https://s0.wp.com/latex.php?latex=H_%7Bm%7D%28p%29%3D2%5E%7BH%28p%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H_{m}(p)=2^{H(p)}" class="latex" />. Every math teacher has to get students to realize that the probabilities of independent events multiply rather than add, but Shannon &#8220;intuited&#8221; that &#8220;information&#8221; should then add so he developed his theory using the additive version, which involved choosing some base for the logs, rather than using the base-free multiplicative version of his entropy.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2053#respond' data-commentid="2053" data-postid="1308" data-belowelement="div-comment-2053" data-respondelement="respond" data-replyto="Reply to David Ellerman" aria-label='Reply to David Ellerman'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment even depth-2 parent highlander-comment" id="comment-2054">
				<div id="div-comment-2054" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/f614294fdc866d8e2813c4eec0f231c6?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://www.ellerman.org' rel='external nofollow ugc' class='url'>David Ellerman</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2054">20 October, 2010 at 12:58 am</a>		</div>

		<p>That&#8217;s Thomas Cover and Joy Thomas, <i>Elements of Information Theory</i>, Wiley, 1991.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2054#respond' data-commentid="2054" data-postid="1308" data-belowelement="div-comment-2054" data-respondelement="respond" data-replyto="Reply to David Ellerman" aria-label='Reply to David Ellerman'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment odd alt depth-3 parent highlander-comment" id="comment-2058">
				<div id="div-comment-2058" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/dc21eed3ebc499422d6c4a927c71ac4f?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://mobjectivist.blogspot.com' rel='external nofollow ugc' class='url'>WebHubTel</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2058">20 October, 2010 at 3:27 am</a>		</div>

		<p>I think that definition of entropy is also known a &#8220;perplexity&#8221;, which is a measure of surprise.</p>
<p>It might have a better intuitive notion behind it as you can lower the entropy by constraining a system and thus effectively reducing the state space and therefore the surprise. It has a more direct combinatorial feel to it, IMO.</p>
<p>I might have that interpretation wrong but it usually gets stated as the math relation and people leave it there. I always like to see an intuitive explanation for these things.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2058#respond' data-commentid="2058" data-postid="1308" data-belowelement="div-comment-2058" data-respondelement="respond" data-replyto="Reply to WebHubTel" aria-label='Reply to WebHubTel'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor even depth-4 highlander-comment" id="comment-2068">
				<div id="div-comment-2068" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2068">20 October, 2010 at 12:46 pm</a>		</div>

		<p>You can think of the entropy of a probability distribution to be the average value of the surprise you feel when, starting out knowing this probability distribution, you discover the actual value of the random variable it describes.</p>
<p>Here I&#8217;m doing not what David suggests, but the usual thing: treating surprise as <i>additive</i>.  Suppose I feel one tiny bit of surprise when you flip a fair coin and I discover it lands heads up.  Then if we treat surprise as additive, I&#8217;ll feel <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> bits of surprise if you flip the coin <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> times and it lands heads up every time.  So, this event, which has probability <img src="https://s0.wp.com/latex.php?latex=2%5E%7B-n%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="2^{-n}" class="latex" />, delivers <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> bits of surprise.  So, it seems sensible to define the surprise of an event of probability <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> to be</p>
<p><img src="https://s0.wp.com/latex.php?latex=-+%5Cmathrm%7Blog%7D_2+p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="- &#92;mathrm{log}_2 p" class="latex" /></p>
<p>Thus, if we are in a situation where there are a bunch of possible outcomes, with the <i>i</i>th outcome having probability <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" />, the <i>average</i> surprise I&#8217;ll feel is</p>
<p><img src="https://s0.wp.com/latex.php?latex=-+%5Csum_i+p_i+%5Cmathrm%7Blog%7D_2+p_i+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="- &#92;sum_i p_i &#92;mathrm{log}_2 p_i " class="latex" /></p>
<p>And this is the entropy!  </p>
<p>People usually say &#8220;expected value&#8221; where I&#8217;ve been saying &#8220;average&#8221; above, so we can summarize by saying <b>the entropy is the expected surprise</b>.   </p>
<p>This sounds a bit funny, because we think of a surprise as being <i>unexpected</i>.  &#8220;Expected surprise&#8221; sounds a bit paradoxical.  <img src="https://i1.wp.com/math.ucr.edu/home/baez/emoticons/tongue2.gif" alt="" /> But if we remember that &#8220;expected&#8221; means &#8220;average&#8221; here, and wrap our heads around the question &#8220;how surprised do you expect to be?&#8221;, we&#8217;ll see the answer is <i>entropy</i>.   The entropy of a probability distribution tells us how surprised we should expect to be.</p>
<p>David wisely suggests treating surprise as multiplicative rather than additive, to avoid the need for logarithms, and avoid the need to choose a specific base (like 2) for our logarithms. We could retell the whole story I just told using that system, if we wanted.</p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt depth-4 highlander-comment" id="comment-2072">
				<div id="div-comment-2072" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/656e05d084448337fb49459225dc525e?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">DavidTweed</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2072">20 October, 2010 at 3:47 pm</a>		</div>

		<p>Going off topic, I&#8217;m starting to see a couple of user names from TheOilDrum show up here (such as WebHubTel), so I&#8217;ll point out that there&#8217;s currently a draft page on peak oil page under development on the Azimuth wiki.</p>
<p><a href="http://www.azimuthproject.org/azimuth/show/Peak+oil" rel="nofollow ugc">http://www.azimuthproject.org/azimuth/show/Peak+oil</a></p>
<p>I&#8217;m slowly adding to it, but any contributions (particularly corrections of errors) are very welcome to that or any other wiki page. It&#8217;s John Baez&#8217; project, but here&#8217;s my interpretation of a couple of points to bear in mind with respect to wiki articles:</p>
<p>1. Azimuth, with an intended audience of scientists, is trying to have its articles maintain the distinction between things like &#8220;observationally confirmed facts&#8221; (ideally with references as close to the source as possible), &#8220;model based projections&#8221; and &#8220;intuitive conjectures&#8221;, &#8220;speculations&#8221;, etc. It&#8217;s also preferred to be explicit about any uncertainty that exists. Part of why it&#8217;s gone slowly so far is me trying to figure out which stuff falls into each category (along with references).</p>
<p>2. Azimuth&#8217;s goal is providing an intro to all &#8220;environmental/sustainability&#8221; problems, not just energy.</p>
<p>3. Information about possible solutions are also very relevant, but advocacy should maintain the same sort of distinctions as 1.</p>
<p>(I&#8217;m not trying to scare anybody off from contributing, just trying to state what the goals for wiki articles are.) Information about how to get a wiki account can be found at</p>
<p><a href="http://www.azimuthproject.org/azimuth/show/HomePage" rel="nofollow ugc">http://www.azimuthproject.org/azimuth/show/HomePage</a></p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment even depth-4 highlander-comment" id="comment-2074">
				<div id="div-comment-2074" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/656e05d084448337fb49459225dc525e?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">DavidTweed</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2074">20 October, 2010 at 4:14 pm</a>		</div>

		<p>Reading my comment back, it&#8217;s a little unclear in (1). It&#8217;s perfectly ok to have relevant speculations in an article, but the wording should make it clear that&#8217;s what they are (likewise with the other levels of evidence).</p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt depth-4 highlander-comment" id="comment-2079">
				<div id="div-comment-2079" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/dc21eed3ebc499422d6c4a927c71ac4f?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://mobjectivist.blogspot.com' rel='external nofollow ugc' class='url'>WebHubTel</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2079">20 October, 2010 at 11:55 pm</a>		</div>

		<p>Responding to DavidTweed, I would be happy to contribute to the Azimuth Wiki.  I infer what is different about the Azimuth Wiki versus something like Wikipedia, is that Azimuth is a bit more open to speculative approaches. In contrast, Wikipedia is really set up to go the accepted wisdom route.</p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor even depth-4 highlander-comment" id="comment-2080">
				<div id="div-comment-2080" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2080">21 October, 2010 at 12:19 am</a>		</div>

		<p>There are lot of differences between the <a href="http://www.azimuthproject.org/azimuth/show/HomePage" rel="nofollow">Azimuth Project</a> and Wikipedia.  About the only thing they have in common is that they&#8217;re wikis and they&#8217;re trying to provide reliable information!  The Azimuth Project is not an encyclopedia: it&#8217;s a focal point for scientists and engineers interested in saving the planet.  We&#8217;re trying to provide accurate, reliable information, so speculations should be clearly labelled as such, and attributed to whoever is doing the speculating.</p>
<p>For details, <a href="http://www.azimuthproject.org/azimuth/edit/Azimuth+Project" rel="nofollow">go here</a>.  And if you want to contribute, please <a href="http://www.azimuthproject.org/azimuth/show/Azimuth+Forum" rel="nofollow">join the Azimuth Forum</a>, so you can log your changes and discuss issues with the rest of us.  </p>

		
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent highlander-comment" id="comment-2076">
				<div id="div-comment-2076" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/f614294fdc866d8e2813c4eec0f231c6?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://www.ellerman.org' rel='external nofollow ugc' class='url'>David Ellerman</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2076">20 October, 2010 at 7:42 pm</a>		</div>

		<p>As John says, one could redo the whole theory using a multiplicative notion of surprise. Indeed, one common notion of surprise or unexpectedness is the reciprocal of probability, and as one information theorist put it: &#8220;[Shannon] defined a quantity which he called &#8216;amount-of-information&#8217;, which is essentially a logarithmic measure of the statistical unexpectedness (reciprocal of probability) of the message concerned.&#8221; [MacKay, Donald M. 1969. Information, Mechanism and Meaning. Cambridge: MIT Press, p. 79.] Using the reciprocal probability measure, the &#8220;average&#8221; of independent events is their geometric mean: <img src="https://s0.wp.com/latex.php?latex=H_%7Bm%7D%28p%29%3D%5Cprod_%7Bi%7D%28%5Cfrac%7B1%7D%7Bp_%7Bi%7D%7D%29%5E%7Bp_%7Bi%7D%7D%3D2%5E%7BH%28p%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H_{m}(p)=&#92;prod_{i}(&#92;frac{1}{p_{i}})^{p_{i}}=2^{H(p)}" class="latex" /> so the multiplicative base-free version of Shannon&#8217;s entropy is in that sense also the &#8220;average surprise.&#8221;</p>
<p>There is another way to approach this matter that avoids the &#8220;tarpit&#8221; of subjective notions like &#8220;surprise.&#8221; One commonly illustrates a probability 1/n as being a choice of one out of a set of n equiprobable alternatives. Thus a probability p is modeled as a choice out of 1/p equiprobabile options which is sometimes called the &#8220;number-equivalent&#8221; of the probability or of the proportion (in a nonprobabilistic context). Now <img src="https://s0.wp.com/latex.php?latex=p+%3D+%5C%7Bp_%7B1%7D%2C%5Cldots%2Cp_%7Bn%7D%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p = &#92;{p_{1},&#92;ldots,p_{n}&#92;}" class="latex" /> can be interpreted either as a probability distribution or a set of proportions with each <img src="https://s0.wp.com/latex.php?latex=p_%7Bi%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_{i}" class="latex" /> interpreted as a choice of  one among <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7Bp_%7Bi%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;frac{1}{p_{i}}" class="latex" /> equal alternatives. Then the multiplicative entropy is the (geometric) average number of equal alternatives.</p>
<p>This is relevant to the question of interpreting entropy raised by one commenter.  Shannon&#8217;s additive entropy is the average number of yes-or-no questions needed to single out a specific equal alternative, while the multiplicative version of his entropy is just the average number of equal alternatives.</p>
<p>One use of entropy in mathematical biology is to measure species diversity. The mathematical biologist Robert H. MacArthur noted that it is the multiplicative version of entropy that has the more intuitive interpretation as the average number of equally common species:</p>
<blockquote><p>
&#8220;Notice that if all N species are equally common, each is a proportion 1/N of the total. Thus the [Shannon entropy] measure &#8230; equals log N, so the [Shannon entropy] measure of equally common species is simply the logarithm of the number of equally common species, meaning that E equally common species would have the same diversity as the N unequally common species in our census. &#8221;</p>
<p>&#8220;Returning to the example of a census of 99 individuals of one species and 1 of a second, we calculate H = &#8230; =0.0560 [as the Shannon entropy using natural logs]. For a census of fifty individuals of each of the two species we would get H = &#8230; =0.693. To convert these back to &#8216;equally common species&#8217;, we take e^0.0560 = 1.057 for the first census and e^0.693 = 2.000 for the second. These numbers, 1.057 and 2, accord much more closely with our intuition of how diverse the areas actually are,&#8230; .&#8221;</p></blockquote>
<p> [MacArthur, Robert H. 1965. Patterns of Species Diversity. Biol. Rev. 40, p. 514.]</p>
<p>If the Shannon additive entropy using natural logs is <img src="https://s0.wp.com/latex.php?latex=H_%7Be%7D%28p%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H_{e}(p)" class="latex" />, then MacArthur is noting that the easier-to-interpret notion is: <img src="https://s0.wp.com/latex.php?latex=H_%7Bm%7D%28p%29%3D%5Cprod_%7Bi%7D%28%5Cfrac%7B1%7D%7Bp_%7Bi%7D%7D%29%5E%7Bp_%7Bi%7D%7D%3D2%5E%7BH%28p%29%7D%3De%5E%7BH_%7Be%7D%28p%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H_{m}(p)=&#92;prod_{i}(&#92;frac{1}{p_{i}})^{p_{i}}=2^{H(p)}=e^{H_{e}(p)}" class="latex" />.</p>
<p>The more common measure of species diversity is the Gini-Simpson index [see Rao, C. R. 1982. Diversity and Dissimilarity Coefficients: A Unified Approach. Theoretical Population Biology. 21: 24-43] which is just the previously mentioned logical entropy: <img src="https://s0.wp.com/latex.php?latex=h%28p%29%3D%5Csum_%7Bi%7Dp_%7Bi%7D%281-p_%7Bi%7D%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="h(p)=&#92;sum_{i}p_{i}(1-p_{i})" class="latex" /> and which is easily interpreted as the probability of getting distinct species or outcomes in two independent draws.</p>
<p>I have gone into this matter only to &#8216;loosen&#8217; the usual attachment to Shannon&#8217;s specific additive formula. There is no point to redo information theory routinely substituting the antilog for Shannon&#8217;s entropy since nothing mathematically new would be obtained [although it might be interesting to see what results could be rederived using logical entropy&#8211;see Ellerman, David 2009. Counting Distinctions: On the Conceptual Foundations of Shannon&#8217;s Information Theory. Synthese. 168 (1 (May)): 119-149, for a beginning].</p>
<p>Incidentally, the old comparison of Shannon&#8217;s additive entropy to the entropy formula derived in statistical mechanics is somewhat less than it seems since that derivation depends on using a specific version of Stirling&#8217;s approximation for n!. Add some higher-order terms to the approximation and a different formula emerges. This is not important numerically but it is precisely to the point if one is making a point about functional forms.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2076#respond' data-commentid="2076" data-postid="1308" data-belowelement="div-comment-2076" data-respondelement="respond" data-replyto="Reply to David Ellerman" aria-label='Reply to David Ellerman'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment even depth-2 highlander-comment" id="comment-2081">
				<div id="div-comment-2081" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/dc21eed3ebc499422d6c4a927c71ac4f?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://mobjectivist.blogspot.com' rel='external nofollow ugc' class='url'>WebHubTel</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2081">21 October, 2010 at 12:21 am</a>		</div>

		<p>One reciprocal probability measure is the odds function. This is defined as Odds = P/(1-P) where P is a cumulative probability. What is interesting about the idea of odds is that it has taken hold as an intuitive measure of probability for many people. </p>
<p>Interesting if you invert the odds function, then you get the power law function P = 1/(1+1/Odds), where Odds is just a relative measure against the median (in this case, the median is 1).  I think this function is the key to species diversity and lots of other behaviors. It comes up as a ratio distribution between two exponential distributions for one. Since species diversify by rate mechanisms (think mutations) may be Rate = dX/dTime you can see how this may naturally come about. Noth dX and dTime have natural distributions so that the rato may have something different.</p>
<p>I haven&#8217;t been able to deduce this yet but I think that the P=1/(1+1/Odds) distribution is the maximum entropy distribution for some unknown constraint. It definitely doesn&#8217;t have any finite moments.</p>
<p><a href="http://mobjectivist.blogspot.com/2010/04/entroplet-species-area-relationships.html" rel="nofollow ugc">http://mobjectivist.blogspot.com/2010/04/entroplet-species-area-relationships.html</a><br />
Plus some links in there. Fun messing around with this stuff.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2081#respond' data-commentid="2081" data-postid="1308" data-belowelement="div-comment-2081" data-respondelement="respond" data-replyto="Reply to WebHubTel" aria-label='Reply to WebHubTel'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-westy31 odd alt thread-odd thread-alt depth-1 highlander-comment" id="comment-2096">
				<div id="div-comment-2096" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/dd03c7797bb4dee936e1d551ee0eddce?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://www.xs4all.nl/~westy31/index.html' rel='external nofollow ugc' class='url'>westy31</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2096">22 October, 2010 at 7:39 am</a>		</div>

		<p>John wote:</p>
<blockquote>
<p>are there some applications where ternary digits would theoretically be better than binary ones?</p>
</blockquote>
<p>One is the most efficient way to weigh something with a balance.</p>
<p>If you put the object to be weighed on one side, and then weights on the other side, then binary weights (1,2,4,8&#8230;) are the most efficient, they use the least weights. But if you use both sides of the balance, subtracting the weights put together with the weighed objects, then ternary weights (1,3,9,27,&#8230;) are the most efficient. You can weigh anything upto 13 with just 3 weights:</p>
<p>    * 1=1<br />
    * 2=3-1<br />
    * 3=3<br />
    * 4=3+1<br />
    * 5=9-3-1<br />
    * 6=9-3<br />
    * 7=9-3+1<br />
    * 8 =9-1<br />
    * 9=9<br />
    * 10=9+1<br />
    * 11=9+3-1<br />
    * 12=9+3<br />
    * 13=9+3+1</p>
<p>Similarly, coins of 1,3,8,27,.. are the most efficient way of paying if you allow the seller to give change. (Binary is the best if you don&#8217;t allow change)</p>
<p>Gerard</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2096#respond' data-commentid="2096" data-postid="1308" data-belowelement="div-comment-2096" data-respondelement="respond" data-replyto="Reply to westy31" aria-label='Reply to westy31'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="pingback even thread-even depth-1 highlander-comment" id="comment-2099">
				<div id="div-comment-2099" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://johncarlosbaez.wordpress.com/2010/10/22/information-geometry/' rel='external nofollow ugc' class='url'>Information Geometry &laquo; Azimuth</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2099">22 October, 2010 at 10:37 am</a>		</div>

		<p>[&#8230;] was pointed out by John F in our discussion of entropy and [&#8230;]</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2099#respond' data-commentid="2099" data-postid="1308" data-belowelement="div-comment-2099" data-respondelement="respond" data-replyto="Reply to Information Geometry &laquo; Azimuth" aria-label='Reply to Information Geometry &laquo; Azimuth'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1 parent highlander-comment" id="comment-2102">
				<div id="div-comment-2102" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Sniffnoy</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2102">22 October, 2010 at 1:03 pm</a>		</div>

		<p>Regarding ternary: I&#8217;ve been doing some stuff with a kind of terrible sequence known as <a href="http://www.research.att.com/~njas/sequences/A005245" rel="nofollow">integer complexity</a> and the fact that 3 is closer to e than 2 comes up there.  I&#8217;ll use ||n|| to denote the complexity of n, the smallest number of 1s needed to write n using addition and multiplication &#8211; well, you can go see the Sloane entry for yourself.  This fact isn&#8217;t relevant for finding an upper bound &#8211; the upper bound based on binary representation is better than the one based on ternary.  But if you kind of invert the question and ask, I have k ones, what&#8217;s the largest number I can make with them using addition and multiplication?  Well ideally you&#8217;d group them into groups of e and multiply those together to get e^(k/e), but seeing as that doesn&#8217;t make a lot of sense, the actual maximum is 3^(k/3).  (If k is divisible by 3, anyway; otherwise you have a group of 2 or 4 left over.)  So you get ||n||&gt;=3log_3(n).  And this fact leads to 3 being nice in other ways with respect to this sequence, which results in you ending up looking at ternary representations after all for a bunch of things&#8230;</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2102#respond' data-commentid="2102" data-postid="1308" data-belowelement="div-comment-2102" data-respondelement="respond" data-replyto="Reply to Sniffnoy" aria-label='Reply to Sniffnoy'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment even depth-2 highlander-comment" id="comment-2104">
				<div id="div-comment-2104" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Sniffnoy</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2104">22 October, 2010 at 1:43 pm</a>		</div>

		<p>Oops, I missed the &#8220;radix economy&#8221; note.  Which has of course the same reason &#8211; 3 being the integer maximizing <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1%2Fn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n^{1/n}" class="latex" />, or minimizing n/(log n)&#8230;</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2104#respond' data-commentid="2104" data-postid="1308" data-belowelement="div-comment-2104" data-respondelement="respond" data-replyto="Reply to Sniffnoy" aria-label='Reply to Sniffnoy'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 highlander-comment" id="comment-2413">
				<div id="div-comment-2413" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/b2dbf62664997049475b4b6c0ff35c1c?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://none' rel='external nofollow ugc' class='url'>john e gray</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/#comment-2413">6 November, 2010 at 8:17 am</a>		</div>

		<p>This misses reference to pioneering work by Weinhold that I first read about when I started reading Physics Today, found in the introductory article in Physics Today: </p>
<p>&bull; F. Weinhold, Geometry and Thermodynamics, Physics Today 29(3), 23-30 (1976). </p>
<p>The pioneering insight was the usage of concavity found in the  property equations of state surface in a geometric fashion. Riemann was introduced by Gilmore (Drexel Univ) extended this to Reimannian geometry in the 80&#8217;s. A number of papers can be found on his website:</p>
<p><a href="http://www.physics.drexel.edu/~bob/Thermodynamics_pgm.html" rel="nofollow ugc">http://www.physics.drexel.edu/~bob/Thermodynamics_pgm.html</a></p>
<p>People interested in this subject can find much of interest on this webpage.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2413#respond' data-commentid="2413" data-postid="1308" data-belowelement="div-comment-2413" data-respondelement="respond" data-replyto="Reply to john e gray" aria-label='Reply to john e gray'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ol>



	<div id="respond" class="comment-respond">
		<h3 id="reply-title" class="comment-reply-title">Leave a Reply to <a href="#comment-2104">Sniffnoy</a> <small><a rel="nofollow" id="cancel-comment-reply-link" href="/2010/10/19/entropy-and-uncertainty/#respond">Cancel reply</a></small></h3><form action="https://johncarlosbaez.wordpress.com/wp-comments-post.php" method="post" id="commentform" class="comment-form"><input type="hidden" id="highlander_comment_nonce" name="highlander_comment_nonce" value="43cb85f550" /><input type="hidden" name="_wp_http_referer" value="/2010/10/19/entropy-and-uncertainty/?replytocom=2104" />
<input type="hidden" name="hc_post_as" id="hc_post_as" value="guest" />

<div class="comment-form-field comment-textarea">
	<label for="comment">Enter your comment here...</label>
	<div id="comment-form-comment"><textarea id="comment" name="comment" title="Enter your comment here..."></textarea></div>
</div>

<div id="comment-form-identity">
	<div id="comment-form-nascar">
		<p>Fill in your details below or click an icon to log in:</p>
		<ul>
			<li class="selected" style="display:none;">
				<a href="#comment-form-guest" id="postas-guest" class="nascar-signin-link"
                   title="Login via Guest">
									</a>
			</li>
			<li>
				<a href="#comment-form-load-service:WordPress.com" id="postas-wordpress" class="nascar-signin-link"
                   title="Login via WordPress.com">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"/></g></svg>				</a>
			</li>
			<li>
			<iframe id="googleplus-sign-in" name="googleplus-sign-in" src="https://public-api.wordpress.com/connect/?googleplus-sign-in=https%3A%2F%2Fjohncarlosbaez.wordpress.com&#038;color_scheme=light" width="24" height="24" scrolling="no" allowtransparency="true" seamless="seamless" frameborder="0"></iframe>
			</li>
			<li>
				<a href="#comment-form-load-service:Twitter" id="postas-twitter" class="nascar-signin-link"
                   title="Login via Twitter">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"/></g></svg>				</a>
			</li>
			<li>
				<a href="#comment-form-load-service:Facebook" id="postas-facebook" class="nascar-signin-link"
                   title="Login via Facebook">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"/></g></svg>				</a>
			</li>
		</ul>
	</div>

	<div id="comment-form-guest" class="comment-form-service selected">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
<a href="https://gravatar.com/site/signup/" target="_blank">				<img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Gravatar" width="25" class="no-grav" />
</a>			</div>

				<div class="comment-form-fields">
				<div class="comment-form-field comment-form-email">
					<label for="email">Email <span class="required">(required)</span> <span class="nopublish">(Address never made public)</span></label>
					<div class="comment-form-input"><input id="email" name="email" type="email" value="" /></div>
				</div>
				<div class="comment-form-field comment-form-author">
					<label for="author">Name <span class="required">(required)</span></label>
					<div class="comment-form-input"><input id="author" name="author" type="text" value="" /></div>
				</div>
				<div class="comment-form-field comment-form-url">
					<label for="url">Website</label>
					<div class="comment-form-input"><input id="url" name="url" type="url" value="" /></div>
				</div>
			</div>
			
		</div>
	</div>

	<div id="comment-form-wordpress" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="WordPress.com Logo" width="25" class="no-grav" />
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="wp_avatar" id="wordpress-avatar" class="comment-meta-wordpress" value="" />
				<input type="hidden" name="wp_user_id" id="wordpress-user_id" class="comment-meta-wordpress" value="" />
				<input type="hidden" name="wp_access_token" id="wordpress-access_token" class="comment-meta-wordpress" value="" />
						<p class="comment-form-posting-as pa-wordpress">
			<strong></strong>
			You are commenting using your WordPress.com account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( 'wordpress' );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"/></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-googleplus" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Google photo" width="25" class="no-grav" />
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="googleplus_avatar" id="googleplus-avatar" class="comment-meta-googleplus" value="" />
				<input type="hidden" name="googleplus_user_id" id="googleplus-user_id" class="comment-meta-googleplus" value="" />
				<input type="hidden" name="googleplus_access_token" id="googleplus-access_token" class="comment-meta-googleplus" value="" />
						<p class="comment-form-posting-as pa-googleplus">
			<strong></strong>
			You are commenting using your Google account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( 'googleplus' );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" x="0px" y="0px" viewBox="0 0 60 60" ><path fill="#519bf7" d="M56.3,30c0,-1.6 -0.2,-3.4 -0.6,-5h-3.1H42.2H30v10.6h14.8C44,39.3 42,42 39.1,43.9l8.8,6.8C53,46 56.3,39 56.3,30z" /><path fill="#3db366" d="M30,57.5c6.7,0 13.1,-2.4 17.9,-6.8l-8.8,-6.8c-2.5,1.6 -5.6,2.4 -9.1,2.4c-7.2,0 -13.3,-4.7 -15.4,-11.2l-9.3,7.1C9.8,51.3 19.1,57.5 30,57.5z" /><path fill="#fdc600" d="M5.3,42.2l9.3,-7.1c-0.5,-1.6 -0.8,-3.3 -0.8,-5.1s0.3,-3.5 0.8,-5.1l-9.3,-7.1C3.5,21.5 2.5,25.6 2.5,30S3.5,38.5 5.3,42.2z" /><path fill="#f15b44" d="M40.1,17.4l8,-8C43.3,5.1 37,2.5 30,2.5C19.1,2.5 9.8,8.7 5.3,17.8l9.3,7.1c2.1,-6.5 8.2,-11.1 15.4,-11.1C33.9,13.7 37.4,15.1 40.1,17.4z" /></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-twitter" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Twitter picture" width="25" class="no-grav" />
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="twitter_avatar" id="twitter-avatar" class="comment-meta-twitter" value="" />
				<input type="hidden" name="twitter_user_id" id="twitter-user_id" class="comment-meta-twitter" value="" />
				<input type="hidden" name="twitter_access_token" id="twitter-access_token" class="comment-meta-twitter" value="" />
						<p class="comment-form-posting-as pa-twitter">
			<strong></strong>
			You are commenting using your Twitter account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( 'twitter' );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"/></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-facebook" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="" alt="Facebook photo" width="25" class="no-grav" />
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="fb_avatar" id="facebook-avatar" class="comment-meta-facebook" value="" />
				<input type="hidden" name="fb_user_id" id="facebook-user_id" class="comment-meta-facebook" value="" />
				<input type="hidden" name="fb_access_token" id="facebook-access_token" class="comment-meta-facebook" value="" />
						<p class="comment-form-posting-as pa-facebook">
			<strong></strong>
			You are commenting using your Facebook account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( 'facebook' );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"/></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>


	<div id="comment-form-load-service" class="comment-form-service">
		<div class="comment-form-posting-as-cancel"><a href="javascript:HighlanderComments.cancelExternalWindow();">Cancel</a></div>
		<p>Connecting to %s</p>
	</div>

</div>

<script type="text/javascript">
var highlander_expando_javascript = function () {

	function hide( sel ) {
		var el = document.querySelector( sel );
		if ( el ) {
			el.style.setProperty( 'display', 'none' );
		}
	}

	function show( sel ) {
		var el = document.querySelector( sel );
		if ( el ) {
			el.style.removeProperty( 'display' );
		}
	}

	var input = document.createElement( 'input' );
	var comment = document.querySelector( '#comment' );

	if ( input && comment && 'placeholder' in input ) {
		var label = document.querySelector( '.comment-textarea label' );
		if ( label ) {
			var text = label.textContent;
			label.parentNode.removeChild( label );
			comment.setAttribute( 'placeholder', text );
		}
	}

	// Expando Mode: start small, then auto-resize on first click + text length
	hide( '#comment-form-identity' );
	hide( '#comment-form-subscribe' );
	hide( '#commentform .form-submit' );

	if ( comment ) {
		comment.style.height = '10px';

		var handler = function () {
			comment.style.height = HighlanderComments.initialHeight + 'px';
			show( '#comment-form-identity' );
			show( '#comment-form-subscribe' );
			show( '#commentform .form-submit' );
			HighlanderComments.resizeCallback();

			comment.removeEventListener( 'focus', handler );
		};

		comment.addEventListener( 'focus', handler );
	}
}

if ( document.readyState !== 'loading' ) {
	highlander_expando_javascript();
} else {
	if ( typeof window.jQuery === 'function' ) {
		// Use jQuery's `ready` if available.
		// This solves some scheduling issues between this script and the main highlander script.
		jQuery( document ).ready( highlander_expando_javascript );
	} else {
		// If not available, add a vanilla event listener.
		document.addEventListener( 'DOMContentLoaded', highlander_expando_javascript );
	}
}

</script>

<div id="comment-form-subscribe">
	<p class="comment-subscription-form"><input type="checkbox" name="subscribe" id="subscribe" value="subscribe" style="width: auto;"/> <label class="subscribe-label" id="subscribe-label" for="subscribe" style="display: inline;">Notify me of new comments via email.</label></p><p class="post-subscription-form"><input type="checkbox" name="subscribe_blog" id="subscribe_blog" value="subscribe" style="width: auto;"/> <label class="subscribe-label" id="subscribe-blog-label" for="subscribe_blog"  style="display: inline;">Notify me of new posts via email.</label></p></div>




<p class="form-submit wp-block-button"><input name="submit" type="submit" id="comment-submit" class="submit wp-block-button__link" value="Post Comment" /> <input type='hidden' name='comment_post_ID' value='1308' id='comment_post_ID' />
<input type='hidden' name='comment_parent' id='comment_parent' value='2104' />
</p><p style="display: none;"><input type="hidden" id="akismet_comment_nonce" name="akismet_comment_nonce" value="b87ff17cf9" /></p>
<input type="hidden" name="genseq" value="1632627422" />
<input type="hidden" id="ak_js" name="ak_js" value="43"/><textarea name="ak_hp_textarea" cols="45" rows="8" maxlength="100" style="display: none !important;"></textarea><script>document.getElementById( "ak_js" ).setAttribute( "value", ( new Date() ).getTime() );</script></form>	</div><!-- #respond -->
	<div style="clear: both"></div><p class="akismet_comment_form_privacy_notice">This site uses Akismet to reduce spam. <a href="https://akismet.com/privacy/" target="_blank" rel="nofollow noopener">Learn how your comment data is processed</a>.</p>
</div><!-- #comments -->
	
	</div>



	<div id="sidebar">
				<ul>

		
		<li id="recent-posts-3" class="widget widget_recent_entries">
		<h2 class="widgettitle">latest posts:</h2>

		<ul>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/">Classical Mechanics versus Thermodynamics (Part&nbsp;3)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/22/maxwells-relations-part-3/">Maxwell&#8217;s Relations (Part&nbsp;3)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/18/maxwells-relations-part-two/">Maxwell&#8217;s Relations (Part&nbsp;2)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/17/maxwells-relations-part-1/">Maxwell&#8217;s Relations (Part&nbsp;1)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/13/the-cyclic-identity-for-partial-derivatives/">The Cyclic Identity for Partial&nbsp;Derivatives</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/17/information-geometry-part-21/">Information Geometry (Part&nbsp;21)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/14/information-geometry-part-20/">Information Geometry (Part&nbsp;20)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/08/information-geometry-part-19/">Information Geometry (Part&nbsp;19)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/05/information-geometry-part-18/">Information Geometry (Part&nbsp;18)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/07/29/structured-vs-decorated-cospans-part-2/">Structured vs Decorated Cospans (Part&nbsp;2)</a>
									</li>
					</ul>

		</li>
<li id="recent-comments-2" class="widget widget_recent_comments"><h2 class="widgettitle">latest comments:</h2>
				<table class="recentcommentsavatar" cellspacing="0" cellpadding="0" border="0">
					<tr><td title="amarashiki" class="recentcommentsavatartop" style="height:32px; width:32px;"><a href="http://gravatar.com/amarashiki" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/62b2df0762257e75433ad6f161488c3a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstexttop" style=""><a href="http://gravatar.com/amarashiki" rel="nofollow">amarashiki</a> on <a href="https://johncarlosbaez.wordpress.com/2012/01/23/classical-mechanics-versus-thermodynamics-part-2/#comment-172566">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="John Baez" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://math.ucr.edu/home/baez/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://math.ucr.edu/home/baez/" rel="nofollow">John Baez</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172560">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="domenico" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://2.gravatar.com/avatar/ba06491deb8346d20356ac2ae05893ee?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">domenico on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172559">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="domenico" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://2.gravatar.com/avatar/ba06491deb8346d20356ac2ae05893ee?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">domenico on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172558">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="Maxwell Relations | Equivalent eXchange" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow"></a></td><td class="recentcommentstextend" style=""><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow">Maxwell Relations |&hellip;</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/22/maxwells-relations-part-3/#comment-172557">Maxwell&#8217;s Relations (Par&hellip;</a></td></tr><tr><td title="Maxwell Relations | Equivalent eXchange" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow"></a></td><td class="recentcommentstextend" style=""><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow">Maxwell Relations |&hellip;</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/18/maxwells-relations-part-two/#comment-172556">Maxwell&#8217;s Relations (Par&hellip;</a></td></tr><tr><td title="Maxwell Relations | Equivalent eXchange" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow"></a></td><td class="recentcommentstextend" style=""><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow">Maxwell Relations |&hellip;</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/17/maxwells-relations-part-1/#comment-172555">Maxwell&#8217;s Relations (Par&hellip;</a></td></tr><tr><td title="Robert A. Wilson" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="https://robwilson1.wordpress.com" rel="nofollow"><img alt='' src='https://2.gravatar.com/avatar/24dc7e2371491f36fd4538b3474920b5?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="https://robwilson1.wordpress.com" rel="nofollow">Robert A. Wilson</a> on <a href="https://johncarlosbaez.wordpress.com/2021/04/04/the-koide-formula/#comment-172553">The Koide Formula</a></td></tr><tr><td title="John Baez" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://math.ucr.edu/home/baez/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://math.ucr.edu/home/baez/" rel="nofollow">John Baez</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172545">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="Wolfgang" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://1.gravatar.com/avatar/d3c6d7ec8069e25c08a0a11263581925?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">Wolfgang on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172543">Classical Mechanics versus The&hellip;</a></td></tr>				</table>
				</li>
<li id="text-3" class="widget widget_text"><h2 class="widgettitle">How To Write Math Here:</h2>
			<div class="textwidget"><p>You can <a href="http://en.wikibooks.org/wiki/LaTeX/Mathematics">include math in your comments using LaTeX</a>,  but you need to do it this way:</p>
<p>&#036;latex  E = mc^2&#036;</p>
<p>You need the word 'latex' right after the first dollar sign, and it needs a space after it.  Double dollar signs don't work, and other limitations apply, some described <a href="http://en.support.wordpress.com/latex/">here</a>.  You can't preview comments here, but I'm happy to fix errors.</p>
</div>
		</li>
<li id="categories-2" class="widget widget_categories"><h2 class="widgettitle">Read Posts On:</h2>

			<ul>
					<li class="cat-item cat-item-177"><a href="https://johncarlosbaez.wordpress.com/category/art/">art</a> (3)
</li>
	<li class="cat-item cat-item-4003"><a href="https://johncarlosbaez.wordpress.com/category/astronomy/">astronomy</a> (29)
</li>
	<li class="cat-item cat-item-8262191"><a href="https://johncarlosbaez.wordpress.com/category/azimuth/">azimuth</a> (60)
</li>
	<li class="cat-item cat-item-86856"><a href="https://johncarlosbaez.wordpress.com/category/biodiversity/">biodiversity</a> (38)
</li>
	<li class="cat-item cat-item-4936"><a href="https://johncarlosbaez.wordpress.com/category/biology/">biology</a> (107)
</li>
	<li class="cat-item cat-item-355244"><a href="https://johncarlosbaez.wordpress.com/category/carbon-emissions/">carbon emissions</a> (78)
</li>
	<li class="cat-item cat-item-5936"><a href="https://johncarlosbaez.wordpress.com/category/chemistry/">chemistry</a> (74)
</li>
	<li class="cat-item cat-item-6108"><a href="https://johncarlosbaez.wordpress.com/category/climate/">climate</a> (155)
</li>
	<li class="cat-item cat-item-5043"><a href="https://johncarlosbaez.wordpress.com/category/computer-science/">computer science</a> (57)
</li>
	<li class="cat-item cat-item-9204"><a href="https://johncarlosbaez.wordpress.com/category/conferences/">conferences</a> (81)
</li>
	<li class="cat-item cat-item-1098"><a href="https://johncarlosbaez.wordpress.com/category/culture/">culture</a> (4)
</li>
	<li class="cat-item cat-item-657"><a href="https://johncarlosbaez.wordpress.com/category/economics/">economics</a> (32)
</li>
	<li class="cat-item cat-item-1212"><a href="https://johncarlosbaez.wordpress.com/category/energy/">energy</a> (50)
</li>
	<li class="cat-item cat-item-25393"><a href="https://johncarlosbaez.wordpress.com/category/engineering/">engineering</a> (11)
</li>
	<li class="cat-item cat-item-14852"><a href="https://johncarlosbaez.wordpress.com/category/mathematics/game-theory/">game theory</a> (29)
</li>
	<li class="cat-item cat-item-1215"><a href="https://johncarlosbaez.wordpress.com/category/geography/">geography</a> (4)
</li>
	<li class="cat-item cat-item-337"><a href="https://johncarlosbaez.wordpress.com/category/health/">health</a> (4)
</li>
	<li class="cat-item cat-item-678"><a href="https://johncarlosbaez.wordpress.com/category/history/">history</a> (2)
</li>
	<li class="cat-item cat-item-23375499"><a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/">information and entropy</a> (92)
</li>
	<li class="cat-item cat-item-3558"><a href="https://johncarlosbaez.wordpress.com/category/jobs/">jobs</a> (11)
</li>
	<li class="cat-item cat-item-5465"><a href="https://johncarlosbaez.wordpress.com/category/journals/">journals</a> (5)
</li>
	<li class="cat-item cat-item-3582"><a href="https://johncarlosbaez.wordpress.com/category/mathematics/">mathematics</a> (478)
</li>
	<li class="cat-item cat-item-18"><a href="https://johncarlosbaez.wordpress.com/category/music/">music</a> (3)
</li>
	<li class="cat-item cat-item-3968"><a href="https://johncarlosbaez.wordpress.com/category/networks/">networks</a> (185)
</li>
	<li class="cat-item cat-item-154934"><a href="https://johncarlosbaez.wordpress.com/category/oceans/">oceans</a> (13)
</li>
	<li class="cat-item cat-item-1211"><a href="https://johncarlosbaez.wordpress.com/category/physics/">physics</a> (204)
</li>
	<li class="cat-item cat-item-10451"><a href="https://johncarlosbaez.wordpress.com/category/probability/">probability</a> (92)
</li>
	<li class="cat-item cat-item-4909"><a href="https://johncarlosbaez.wordpress.com/category/psychology/">psychology</a> (6)
</li>
	<li class="cat-item cat-item-3330"><a href="https://johncarlosbaez.wordpress.com/category/publishing/">publishing</a> (19)
</li>
	<li class="cat-item cat-item-46615"><a href="https://johncarlosbaez.wordpress.com/category/puzzles/">puzzles</a> (14)
</li>
	<li class="cat-item cat-item-4140243"><a href="https://johncarlosbaez.wordpress.com/category/quantum-technologies/">quantum technologies</a> (28)
</li>
	<li class="cat-item cat-item-562"><a href="https://johncarlosbaez.wordpress.com/category/questions/">questions</a> (3)
</li>
	<li class="cat-item cat-item-93974"><a href="https://johncarlosbaez.wordpress.com/category/risks/">risks</a> (48)
</li>
	<li class="cat-item cat-item-37893"><a href="https://johncarlosbaez.wordpress.com/category/seminars/">seminars</a> (21)
</li>
	<li class="cat-item cat-item-581"><a href="https://johncarlosbaez.wordpress.com/category/software/">software</a> (19)
</li>
	<li class="cat-item cat-item-39438"><a href="https://johncarlosbaez.wordpress.com/category/strategies/">strategies</a> (36)
</li>
	<li class="cat-item cat-item-6877"><a href="https://johncarlosbaez.wordpress.com/category/sustainability/">sustainability</a> (71)
</li>
	<li class="cat-item cat-item-66608272"><a href="https://johncarlosbaez.wordpress.com/category/the-practice-of-science/">the practice of science</a> (27)
</li>
	<li class="cat-item cat-item-61590"><a href="https://johncarlosbaez.wordpress.com/category/this-weeks-finds/">this week&#039;s finds</a> (18)
</li>
			</ul>

			</li>
<li id="linkcat-20924250" class="widget widget_links"><h2 class="widgettitle">also visit these:</h2>

	<ul class='xoxo blogroll'>
<li><a href="http://www.azimuthproject.org/azimuth/show/Azimuth+Blog" title="Go here to see what’s on this blog, organized by topic or author!">Azimuth Blog Overview</a></li>
<li><a href="http://www.azimuthproject.org/azimuth/show/HomePage" title="for scientists and engineers who want to save the planet">Azimuth Project</a></li>
<li><a href="http://bittooth.blogspot.com/" title="David Summers on energy: oil, gas and more">Bit Tooth Energy</a></li>
<li><a href="http://bravenewclimate.com/" title="Barry Brooks on climate and energy policy">Brave New Climate</a></li>
<li><a href="http://physics.ucsd.edu/do-the-math/" title="UC San Diego prof uses physics and estimation to assess energy, growth, options">Do the Math</a></li>
<li><a href="http://dotearth.blogs.nytimes.com/" title="Andrew Revkin’s environmental blog on the New York Times">Dot Earth</a></li>
<li><a href="http://e360.yale.edu/" title="News from the Yale School of Forestry &amp; Environmental Studies">Environment 360</a></li>
<li><a href="http://planet3.org/" title="A metablog on sustainability">Planet3.0</a></li>
<li><a href="http://www.realclimate.org/" title="climate science from climate scientists">RealClimate</a></li>
<li><a href="http://www.easterbrook.ca/steve/" title="Steve Easterbrook&#8217;s blog on software engineering and climate modeling">Serendipity</a></li>
<li><a href="http://scienceofdoom.com/" title="climate science in perspective">The Science of Doom</a></li>
<li><a href="http://e360.yale.edu/" title="opinion, analysis, reporting and debate on environmental issues">Yale Environment 360</a></li>

	</ul>
</li>

<li id="rss_links-3" class="widget widget_rss_links"><h2 class="widgettitle">RSS feeds:</h2>
<p class="size-small"><a class="feed-image-link" href="https://johncarlosbaez.wordpress.com/feed/" title="Subscribe to Posts"><img src="https://johncarlosbaez.wordpress.com/i/rss/red-small.png?m=1391188133h" alt="RSS Feed" /></a>&nbsp;<a href="https://johncarlosbaez.wordpress.com/feed/" title="Subscribe to Posts">RSS - Posts</a></p><p class="size-small"><a class="feed-image-link" href="https://johncarlosbaez.wordpress.com/comments/feed/" title="Subscribe to Comments"><img src="https://johncarlosbaez.wordpress.com/i/rss/red-small.png?m=1391188133h" alt="RSS Feed" /></a>&nbsp;<a href="https://johncarlosbaez.wordpress.com/comments/feed/" title="Subscribe to Comments">RSS - Comments</a></p>
</li>
<li id="blog_subscription-3" class="widget widget_blog_subscription jetpack_subscription_widget"><h2 class="widgettitle"><label for="subscribe-field">Email Subscription:</label></h2>

			<form
				action="https://subscribe.wordpress.com"
				method="post"
				accept-charset="utf-8"
				id=""
			>
				<p>Enter your email address to subscribe to this blog and receive notifications of new posts by email.</p>
					<div class="jetpack-subscribe-count">
						<p>
						Join 5,227 other followers						</p>
					</div>
									<p id="subscribe-email">
					<label
						id="subscribe-field-label"
						for="subscribe-field"
						class="screen-reader-text"
					>
						Email Address:					</label>

					<input
							type="email"
							name="email"
							
							style="width: 95%; padding: 1px 10px"
							placeholder="Enter your email address"
							value=""
							id="subscribe-field"
						/>				</p>

				<p id="subscribe-submit"
									>
                    <input type="hidden" name="action" value="subscribe"/>
                    <input type="hidden" name="blog_id" value="12777403"/>
                    <input type="hidden" name="source" value="https://johncarlosbaez.wordpress.com/2010/10/19/entropy-and-uncertainty/?replytocom=2104"/>
                    <input type="hidden" name="sub-type" value="widget"/>
                    <input type="hidden" name="redirect_fragment" value="blog_subscription-3"/>
					<input type="hidden" id="_wpnonce" name="_wpnonce" value="8f1337fe87" />                    <button type="submit"
	                    	                        class="wp-block-button__link"
	                    		                	                >
	                    Sign me up!                    </button>
                </p>
            </form>
			
</li>
<li id="search-3" class="widget widget_search"><h2 class="widgettitle">SEARCH:</h2>
<form method="get" id="searchform" action="https://johncarlosbaez.wordpress.com/">
<div><label for="s" class="search-label">Search</label><input type="text" value="" name="s" id="s" />
<input type="submit" id="searchsubmit" value="Search" />
</div>
</form></li>
<li id="blog-stats-2" class="widget widget_blog-stats"><h2 class="widgettitle">Blog Stats:</h2>
		<ul>
			<li>4,177,046 hits</li>
		</ul>
		</li>
		</ul>
	</div>



<div id="footer">
	<p>
	<br />
	<a href="https://wordpress.com/?ref=footer_blog" rel="nofollow">Blog at WordPress.com.</a>
	</p>
</div>

</div>

		<!--  -->
<script src='//0.gravatar.com/js/gprofiles.js?ver=202138y' id='grofiles-cards-js'></script>
<script id='wpgroho-js-extra'>
var WPGroHo = {"my_hash":""};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s1.wp.com/wp-content/mu-plugins/gravatar-hovercards/wpgroho.js?m=1610363240h'></script>

	<script>
		// Initialize and attach hovercards to all gravatars
		( function() {
			function init() {
				if ( typeof Gravatar === 'undefined' ) {
					return;
				}

				if ( typeof Gravatar.init !== 'function' ) {
					return;
				}

				Gravatar.profile_cb = function ( hash, id ) {
					WPGroHo.syncProfileData( hash, id );
				};

				Gravatar.my_hash = WPGroHo.my_hash;
				Gravatar.init( 'body', '#wp-admin-bar-my-account' );
			}

			if ( document.readyState !== 'loading' ) {
				init();
			} else {
				document.addEventListener( 'DOMContentLoaded', init );
			}
		} )();
	</script>

		<div style="display:none">
	<div class="grofile-hash-map-656e05d084448337fb49459225dc525e">
	</div>
	<div class="grofile-hash-map-6b3fa8cd421b5fd2028e3c1e9c32aa7f">
	</div>
	<div class="grofile-hash-map-34784534843022b3541c8ddd693718cb">
	</div>
	<div class="grofile-hash-map-7bd56f321baeba6c04fa3b64944cc91b">
	</div>
	<div class="grofile-hash-map-918361a321e40a2d9b2ddcf5f2ff93d0">
	</div>
	<div class="grofile-hash-map-7d62be404c89efbea1cd6b0dacfd0e3e">
	</div>
	<div class="grofile-hash-map-5850d628c599d7ac60d7f7889844995a">
	</div>
	<div class="grofile-hash-map-a7fee90572f7316e52862ebabf8e3f39">
	</div>
	<div class="grofile-hash-map-ef4a2fb0e47bee3226963fc8b5a353d8">
	</div>
	<div class="grofile-hash-map-151c18cc6cc3bd1bb7a0528c6ef88c77">
	</div>
	<div class="grofile-hash-map-151c18cc6cc3bd1bb7a0528c6ef88c77">
	</div>
	<div class="grofile-hash-map-e12fed9193da121c6337ce250d548759">
	</div>
	<div class="grofile-hash-map-ee67ce8f823fcad46c6cca7e12a71aef">
	</div>
	<div class="grofile-hash-map-dd50e8b0462cc7fb7fa5bb0785e4f2a4">
	</div>
	<div class="grofile-hash-map-790504be0016c185f5f06f52954f3d49">
	</div>
	<div class="grofile-hash-map-4151efe42f1bb60c6033191ea5ab6348">
	</div>
	<div class="grofile-hash-map-f614294fdc866d8e2813c4eec0f231c6">
	</div>
	<div class="grofile-hash-map-dc21eed3ebc499422d6c4a927c71ac4f">
	</div>
	<div class="grofile-hash-map-dd03c7797bb4dee936e1d551ee0eddce">
	</div>
	<div class="grofile-hash-map-3d0837be44b824ac35cfa18a263d2a08">
	</div>
	<div class="grofile-hash-map-b2dbf62664997049475b4b6c0ff35c1c">
	</div>
	<div class="grofile-hash-map-62b2df0762257e75433ad6f161488c3a">
	</div>
	<div class="grofile-hash-map-ba06491deb8346d20356ac2ae05893ee">
	</div>
	<div class="grofile-hash-map-24dc7e2371491f36fd4538b3474920b5">
	</div>
	<div class="grofile-hash-map-d3c6d7ec8069e25c08a0a11263581925">
	</div>
	</div>
<script id='highlander-comments-js-extra'>
var HighlanderComments = {"loggingInText":"Logging In\u2026","submittingText":"Posting Comment\u2026","postCommentText":"Post Comment","connectingToText":"Connecting to %s","commentingAsText":"%1$s: You are commenting using your %2$s account.","logoutText":"Log Out","loginText":"Log In","connectURL":"https:\/\/johncarlosbaez.wordpress.com\/public.api\/connect\/?action=request","logoutURL":"https:\/\/johncarlosbaez.wordpress.com\/wp-login.php?action=logout&_wpnonce=598fb2ebe8","homeURL":"https:\/\/johncarlosbaez.wordpress.com\/","postID":"1308","gravDefault":"identicon","enterACommentError":"Please enter a comment","enterEmailError":"Please enter your email address here","invalidEmailError":"Invalid email address","enterAuthorError":"Please enter your name here","gravatarFromEmail":"This picture will show whenever you leave a comment. Click to customize it.","logInToExternalAccount":"Log in to use details from one of these accounts.","change":"Change","changeAccount":"Change Account","comment_registration":"","userIsLoggedIn":"","isJetpack":"","text_direction":"ltr"};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s1.wp.com/_static/??/wp-content/js/jquery/jquery.autoresize.js,/wp-content/mu-plugins/highlander-comments/script.js?m=1626677336j'></script>

<script>
window.addEventListener( "load", function( event ) {
	var link = document.createElement( "link" );
	link.href = "https://s0.wp.com/wp-content/mu-plugins/actionbar/actionbar.css?v=20210915";
	link.type = "text/css";
	link.rel = "stylesheet";
	document.head.appendChild( link );

	var script = document.createElement( "script" );
	script.src = "https://s0.wp.com/wp-content/mu-plugins/actionbar/actionbar.js?v=20210920";
	script.defer = true;
	document.body.appendChild( script );
} );
</script>

	<script crossorigin='anonymous' type='text/javascript' src='https://s2.wp.com/_static/??-eJyFTs0OgjAMfiHHAgcTDsZnGVtDNuk2207g7S2JXIyJp/58v3atxpcskMUmtgFe0UPdusQXq1DMfmkB+MB8QVSaIajL3mHMJ+nUYzN1aXPMbF1Q3EyOLDoWIN2MkPMP/hapcXo2oP0zurVqkKlUtl2j9Mfyq42egBOEP0XWGGYQttwm9hSrxJKPDne89ddhHPthuPbpDZCYYT4='></script>
<script type="text/javascript">
// <![CDATA[
(function() {
try{
  if ( window.external &&'msIsSiteMode' in window.external) {
    if (window.external.msIsSiteMode()) {
      var jl = document.createElement('script');
      jl.type='text/javascript';
      jl.async=true;
      jl.src='/wp-content/plugins/ie-sitemode/custom-jumplist.php';
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(jl, s);
    }
  }
}catch(e){}
})();
// ]]>
</script><script src="//stats.wp.com/w.js?62" defer></script> <script type="text/javascript">
_tkq = window._tkq || [];
_stq = window._stq || [];
_tkq.push(['storeContext', {'blog_id':'12777403','blog_tz':'0','user_lang':'en','blog_lang':'en','user_id':'0'}]);
_stq.push(['view', {'blog':'12777403','v':'wpcom','tz':'0','user_id':'0','post':'1308','subd':'johncarlosbaez'}]);
_stq.push(['extra', {'crypt':'UE40eW5QN0p8M2Y/RE1TaVhzUzFMbjdWNHpwZGhTayxPSUFCMGNrd29+Smw0TDhnZmRTK0hlRi9QSGh6bi9GXVhBJWIlZlR5U1JMLU8/MkNtblkvY1d6eVImTEouL2UleTBRZmlNdkp0aWJaNFJhPS0uTVpHa1hIc25EbVJyQmw/SkZ+Q3lLcjU/NDBvQTZVNVg1aEU1L0xnSXBRYkdYP2syVFJfblNQL0pKUHJxVEdLflpYZlR8d0ZWL2dTd0lPZ0JNcy5QX1JhdW1ZdkNRQVRMPTdFOHBRZVFFTXZ3TnImLXpafFJ5bysya1NOelBaRF9vWnZyaF8lLzl+LXhreEF6P2cuVjJSc1FBa21XSzN8cWxVdTl4Z0VyJSt8ai1abjRbN0s4VFFRYTBGTmpGUUZRWG9SbFdkaStZVlhGVzRfT2J8M3I5alpZeltlelBxLyxzSGNQfDNkYUtUYlZZLVR5OFJmLGlqZQ=='}]);
_stq.push([ 'clickTrackerInit', '12777403', '1308' ]);
	</script>
<noscript><img src="https://pixel.wp.com/b.gif?v=noscript" style="height:1px;width:1px;overflow:hidden;position:absolute;bottom:1px;" alt="" /></noscript>
<script>
if ( 'object' === typeof wpcom_mobile_user_agent_info ) {

	wpcom_mobile_user_agent_info.init();
	var mobileStatsQueryString = "";
	
	if( false !== wpcom_mobile_user_agent_info.matchedPlatformName )
		mobileStatsQueryString += "&x_" + 'mobile_platforms' + '=' + wpcom_mobile_user_agent_info.matchedPlatformName;
	
	if( false !== wpcom_mobile_user_agent_info.matchedUserAgentName )
		mobileStatsQueryString += "&x_" + 'mobile_devices' + '=' + wpcom_mobile_user_agent_info.matchedUserAgentName;
	
	if( wpcom_mobile_user_agent_info.isIPad() )
		mobileStatsQueryString += "&x_" + 'ipad_views' + '=' + 'views';

	if( "" != mobileStatsQueryString ) {
		new Image().src = document.location.protocol + '//pixel.wp.com/g.gif?v=wpcom-no-pv' + mobileStatsQueryString + '&baba=' + Math.random();
	}
	
}
</script>
</body>
</html>
<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Network Theory (Part 5)	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/</link>
	<description></description>
	<lastBuildDate>Tue, 23 Apr 2013 14:00:26 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: Arjun Jain		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-27805</link>

		<dc:creator><![CDATA[Arjun Jain]]></dc:creator>
		<pubDate>Tue, 23 Apr 2013 14:00:26 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=3059#comment-27805</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-27727&quot;&gt;John Baez&lt;/a&gt;.

Sorry for being so vague in my questions/statements- would not happen again. The paragraph is much clearer now.

Why do you say that  &#039;It is enough to assume t is very small&#039;, when discussing about the nature of H for exp(tH) to be stochastic for all $latex t\ge 0$? After that, how can we assume that the infinitesimal stochastic operator H will work to make exp(tH) stochastic for all times? Has it got something to do with these conditions on U:
U(t)U(s) = U(t+s) and $latex t_i \to t \quad \implies \quad U(t_i) \psi \to U(t)\psi$.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-27727">John Baez</a>.</p>
<p>Sorry for being so vague in my questions/statements- would not happen again. The paragraph is much clearer now.</p>
<p>Why do you say that  &#8216;It is enough to assume t is very small&#8217;, when discussing about the nature of H for exp(tH) to be stochastic for all <img src="https://s0.wp.com/latex.php?latex=t%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t&#92;ge 0" class="latex" />? After that, how can we assume that the infinitesimal stochastic operator H will work to make exp(tH) stochastic for all times? Has it got something to do with these conditions on U:<br />
U(t)U(s) = U(t+s) and <img src="https://s0.wp.com/latex.php?latex=t_i+%5Cto+t+%5Cquad+%5Cimplies+%5Cquad+U%28t_i%29+%5Cpsi+%5Cto+U%28t%29%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t_i &#92;to t &#92;quad &#92;implies &#92;quad U(t_i) &#92;psi &#92;to U(t)&#92;psi" class="latex" />.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-27727</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sat, 20 Apr 2013 13:41:20 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=3059#comment-27727</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-27722&quot;&gt;Arjun Jain&lt;/a&gt;.

&lt;blockquote&gt;
1. Why should the $latex U$ be linear operators?
&lt;/blockquote&gt;

I&#039;ll only talk about the case where $latex U$ is stochastic, because I don&#039;t want to explain why quantum mechanics is linear.  I&#039;ll just talk about why probability theory is linear.

Suppose we&#039;re playing a game like this.  If you give me $1, I&#039;ll give you $1 with probability 90%, and nothing with probability 10%.   If you give me nothing, I will give you nothing with probability 90%, and $1 with probability 10%.  

Suppose you give me $1 with probability $latex \psi_1$ and nothing with probability $latex \psi_2 = 1 - \psi_1.$   After you play this game, you will have $1 with probability $latex \phi_1$ and nothing with probability $latex \phi_2.$   

Calculate the vector $latex \phi = (\phi_1, \phi_2)$ as a function of $latex \psi = (\psi_1, \psi_2).$  In other words, write $latex \phi = U(\psi)$ and tell me what the function $latex U$ is.

If you do this example, it will help you see why we want $latex U$ to be linear.

&lt;blockquote&gt;
Can you help me understand this better?
&lt;/blockquote&gt;

You have to ask me a specific question for me to help you understand something better.  

&lt;blockquote&gt;
I did not understand the paragraphs before the moral paragraph...
&lt;/blockquote&gt;

Again, that&#039;s not a question.  It&#039;s a statement.
  
I hope you get the basic idea: if we have a bunch of linear operators $latex U(t) = \exp(t H)$ we call $latex H$ the &lt;b&gt;infinitesimal generator&lt;/b&gt; of those operators. I want to know which operators $latex H$ make $latex U(t) = \exp(t H)$  be stochastic for all $latex t \ge 0.$  I say a lot more about this in &lt;a href=&quot;http://math.ucr.edu/home/baez/networks/networks_12.html&quot; rel=&quot;nofollow&quot;&gt;Part 12&lt;/a&gt;.

&lt;blockquote&gt;
The whole paragraph on Infinitesimal stochastic versus self-adjoint operators is not very clear to me, though I have read it 6-7 times.
&lt;/blockquote&gt;

Again, that&#039;s not a question.  Have you tried doing some computations with examples?   There are some things we can only learn by doing.  We&#039;ll do lots of calculations with infinitesimal stochastic operators in this course; for self-adjoint operators you&#039;d do lots of calculations in a course on quantum mechanics.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-27722">Arjun Jain</a>.</p>
<blockquote><p>
1. Why should the <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="U" class="latex" /> be linear operators?
</p></blockquote>
<p>I&#8217;ll only talk about the case where <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="U" class="latex" /> is stochastic, because I don&#8217;t want to explain why quantum mechanics is linear.  I&#8217;ll just talk about why probability theory is linear.</p>
<p>Suppose we&#8217;re playing a game like this.  If you give me $1, I&#8217;ll give you $1 with probability 90%, and nothing with probability 10%.   If you give me nothing, I will give you nothing with probability 90%, and $1 with probability 10%.  </p>
<p>Suppose you give me $1 with probability <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi_1" class="latex" /> and nothing with probability <img src="https://s0.wp.com/latex.php?latex=%5Cpsi_2+%3D+1+-+%5Cpsi_1.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi_2 = 1 - &#92;psi_1." class="latex" />   After you play this game, you will have $1 with probability <img src="https://s0.wp.com/latex.php?latex=%5Cphi_1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_1" class="latex" /> and nothing with probability <img src="https://s0.wp.com/latex.php?latex=%5Cphi_2.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi_2." class="latex" />   </p>
<p>Calculate the vector <img src="https://s0.wp.com/latex.php?latex=%5Cphi+%3D+%28%5Cphi_1%2C+%5Cphi_2%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi = (&#92;phi_1, &#92;phi_2)" class="latex" /> as a function of <img src="https://s0.wp.com/latex.php?latex=%5Cpsi+%3D+%28%5Cpsi_1%2C+%5Cpsi_2%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi = (&#92;psi_1, &#92;psi_2)." class="latex" />  In other words, write <img src="https://s0.wp.com/latex.php?latex=%5Cphi+%3D+U%28%5Cpsi%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi = U(&#92;psi)" class="latex" /> and tell me what the function <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="U" class="latex" /> is.</p>
<p>If you do this example, it will help you see why we want <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="U" class="latex" /> to be linear.</p>
<blockquote><p>
Can you help me understand this better?
</p></blockquote>
<p>You have to ask me a specific question for me to help you understand something better.  </p>
<blockquote><p>
I did not understand the paragraphs before the moral paragraph&#8230;
</p></blockquote>
<p>Again, that&#8217;s not a question.  It&#8217;s a statement.</p>
<p>I hope you get the basic idea: if we have a bunch of linear operators <img src="https://s0.wp.com/latex.php?latex=U%28t%29+%3D+%5Cexp%28t+H%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="U(t) = &#92;exp(t H)" class="latex" /> we call <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> the <b>infinitesimal generator</b> of those operators. I want to know which operators <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> make <img src="https://s0.wp.com/latex.php?latex=U%28t%29+%3D+%5Cexp%28t+H%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="U(t) = &#92;exp(t H)" class="latex" />  be stochastic for all <img src="https://s0.wp.com/latex.php?latex=t+%5Cge+0.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t &#92;ge 0." class="latex" />  I say a lot more about this in <a href="http://math.ucr.edu/home/baez/networks/networks_12.html" rel="nofollow">Part 12</a>.</p>
<blockquote><p>
The whole paragraph on Infinitesimal stochastic versus self-adjoint operators is not very clear to me, though I have read it 6-7 times.
</p></blockquote>
<p>Again, that&#8217;s not a question.  Have you tried doing some computations with examples?   There are some things we can only learn by doing.  We&#8217;ll do lots of calculations with infinitesimal stochastic operators in this course; for self-adjoint operators you&#8217;d do lots of calculations in a course on quantum mechanics.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Arjun Jain		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-27722</link>

		<dc:creator><![CDATA[Arjun Jain]]></dc:creator>
		<pubDate>Sat, 20 Apr 2013 09:41:13 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=3059#comment-27722</guid>

					<description><![CDATA[1. Why should the Us be linear operators?

2. &quot; It seems easier to deal with this in the special case when integrals over X reduce to sums. So let’s suppose that happens… and let’s start by seeing what the first condition says in this case.

In this case, L^1(X) has a basis of ‘Kronecker delta functions’...&quot;

- Can you help me understand this better?

3. I did not understand the paragraphs before the moral paragraph:

&quot;...The idea behind my term is that any infintesimal stochastic operator should be the infinitesimal generator of a stochastic process.

In other words, when we get the details straightened out, any 1-parameter family of stochastic operators...

...Someone must have worked it out.&quot;

4. The whole paragraph on Infinitesimal stochastic versus self-adjoint operators is not very clear to me, though I have read it 6-7 times.]]></description>
			<content:encoded><![CDATA[<p>1. Why should the Us be linear operators?</p>
<p>2. &#8221; It seems easier to deal with this in the special case when integrals over X reduce to sums. So let’s suppose that happens… and let’s start by seeing what the first condition says in this case.</p>
<p>In this case, L^1(X) has a basis of ‘Kronecker delta functions’&#8230;&#8221;</p>
<p>&#8211; Can you help me understand this better?</p>
<p>3. I did not understand the paragraphs before the moral paragraph:</p>
<p>&#8220;&#8230;The idea behind my term is that any infintesimal stochastic operator should be the infinitesimal generator of a stochastic process.</p>
<p>In other words, when we get the details straightened out, any 1-parameter family of stochastic operators&#8230;</p>
<p>&#8230;Someone must have worked it out.&#8221;</p>
<p>4. The whole paragraph on Infinitesimal stochastic versus self-adjoint operators is not very clear to me, though I have read it 6-7 times.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-27659</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Wed, 17 Apr 2013 13:47:58 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=3059#comment-27659</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-27656&quot;&gt;Arjun Jain&lt;/a&gt;.

Arjun wrote:

&lt;blockquote&gt;
1. What is that way to make any set X into a measure space? 
&lt;/blockquote&gt;

Use &lt;a href=&quot;http://en.wikipedia.org/wiki/Counting_measure&quot; rel=&quot;nofollow&quot;&gt;counting measure&lt;/a&gt;.  

&lt;blockquote&gt;
Also, why do you say that integrals are more general than sums?
&lt;/blockquote&gt;

An integral with respect to counting measure is a sum.  It sounds like you want to learn a bit about &lt;a href=&quot;http://en.wikipedia.org/wiki/Measure_%28mathematics%29&quot; rel=&quot;nofollow&quot;&gt;measure theory&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/Lebesgue_integration&quot; rel=&quot;nofollow&quot;&gt;Lebesgue integration&lt;/a&gt;, which is the theory of integration on general measure spaces.

&lt;blockquote&gt;
2. What is the meaning of conjugate linear?
&lt;/blockquote&gt;

Like most math terms, this is defined &lt;a href=&quot;http://en.wikipedia.org/wiki/Antilinear_map&quot; rel=&quot;nofollow&quot;&gt;in Wikipedia&lt;/a&gt;.  When I want to learn the meaning of a math term, I type it into Google, and usually a Wikipedia article shows up near the very top of the choices.

&lt;blockquote&gt;
3. Is there any difference between &#039;maps&#039; and &#039;functions&#039;?
&lt;/blockquote&gt;

It depends on context.  A &#039;map&#039; is a function preserving whatever structure is on hand.  For example if we talked about a map between topological spaces, we&#039;d mean a continuous function.  If we talked about a map between manifolds, we&#039;d mean a smooth function.  But a map between sets means a function.

(To add to the confusion, in the French tradition &#039;function&#039; means a function taking values in the real or complex numbers, while a 
general function is called a &#039;map&#039;.)

&lt;blockquote&gt;
4. How do we know that $latex L^2$ is a vector space? --- $latex &#124;a+b&#124;^2\le (&#124;a&#124;^2+&#124;b&#124;^2+2&#124;ab&#124;)$ --- the first two terms are finite according to the definition of $latex L^2$, but how are we sure that the inner product will always be finite? Is there some other way to prove this?
&lt;/blockquote&gt;

The &lt;a href=&quot;http://en.wikipedia.org/wiki/Cauchy-Schwarz_inequality#Statement_of_the_inequality&quot; rel=&quot;nofollow&quot;&gt;Cauchy--Schwarz inequality&lt;/a&gt; holds for $latex L^2$ and it &lt;a href=&quot;http://en.wikipedia.org/wiki/Cauchy-Schwarz_inequality#Applications&quot; rel=&quot;nofollow&quot;&gt;implies the triangle inequality&lt;/a&gt;, which proves $latex L^2$ is a vector space.  

&lt;blockquote&gt;
5. The net-fish process in the beginning --- The corresponding rate equation will be d(Nfish)/dt=r as the only species is fish and that does not appear as an input, so its power will be 0 --- Right?
&lt;/blockquote&gt;

Right.  Earlier you were asking about transitions with no inputs.  I &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/04/03/network-theory-part-3/#comment-27556&quot; rel=&quot;nofollow&quot;&gt;pointed you to this example&lt;/a&gt;.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-27656">Arjun Jain</a>.</p>
<p>Arjun wrote:</p>
<blockquote><p>
1. What is that way to make any set X into a measure space?
</p></blockquote>
<p>Use <a href="http://en.wikipedia.org/wiki/Counting_measure" rel="nofollow">counting measure</a>.  </p>
<blockquote><p>
Also, why do you say that integrals are more general than sums?
</p></blockquote>
<p>An integral with respect to counting measure is a sum.  It sounds like you want to learn a bit about <a href="http://en.wikipedia.org/wiki/Measure_%28mathematics%29" rel="nofollow">measure theory</a> and <a href="http://en.wikipedia.org/wiki/Lebesgue_integration" rel="nofollow">Lebesgue integration</a>, which is the theory of integration on general measure spaces.</p>
<blockquote><p>
2. What is the meaning of conjugate linear?
</p></blockquote>
<p>Like most math terms, this is defined <a href="http://en.wikipedia.org/wiki/Antilinear_map" rel="nofollow">in Wikipedia</a>.  When I want to learn the meaning of a math term, I type it into Google, and usually a Wikipedia article shows up near the very top of the choices.</p>
<blockquote><p>
3. Is there any difference between &#8216;maps&#8217; and &#8216;functions&#8217;?
</p></blockquote>
<p>It depends on context.  A &#8216;map&#8217; is a function preserving whatever structure is on hand.  For example if we talked about a map between topological spaces, we&#8217;d mean a continuous function.  If we talked about a map between manifolds, we&#8217;d mean a smooth function.  But a map between sets means a function.</p>
<p>(To add to the confusion, in the French tradition &#8216;function&#8217; means a function taking values in the real or complex numbers, while a<br />
general function is called a &#8216;map&#8217;.)</p>
<blockquote><p>
4. How do we know that <img src="https://s0.wp.com/latex.php?latex=L%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L^2" class="latex" /> is a vector space? &#8212; <img src="https://s0.wp.com/latex.php?latex=%7Ca%2Bb%7C%5E2%5Cle+%28%7Ca%7C%5E2%2B%7Cb%7C%5E2%2B2%7Cab%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|a+b|^2&#92;le (|a|^2+|b|^2+2|ab|)" class="latex" /> &#8212; the first two terms are finite according to the definition of <img src="https://s0.wp.com/latex.php?latex=L%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L^2" class="latex" />, but how are we sure that the inner product will always be finite? Is there some other way to prove this?
</p></blockquote>
<p>The <a href="http://en.wikipedia.org/wiki/Cauchy-Schwarz_inequality#Statement_of_the_inequality" rel="nofollow">Cauchy&#8211;Schwarz inequality</a> holds for <img src="https://s0.wp.com/latex.php?latex=L%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L^2" class="latex" /> and it <a href="http://en.wikipedia.org/wiki/Cauchy-Schwarz_inequality#Applications" rel="nofollow">implies the triangle inequality</a>, which proves <img src="https://s0.wp.com/latex.php?latex=L%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L^2" class="latex" /> is a vector space.  </p>
<blockquote><p>
5. The net-fish process in the beginning &#8212; The corresponding rate equation will be d(Nfish)/dt=r as the only species is fish and that does not appear as an input, so its power will be 0 &#8212; Right?
</p></blockquote>
<p>Right.  Earlier you were asking about transitions with no inputs.  I <a href="https://johncarlosbaez.wordpress.com/2011/04/03/network-theory-part-3/#comment-27556" rel="nofollow">pointed you to this example</a>.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Arjun Jain		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-27656</link>

		<dc:creator><![CDATA[Arjun Jain]]></dc:creator>
		<pubDate>Wed, 17 Apr 2013 12:41:18 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=3059#comment-27656</guid>

					<description><![CDATA[Sir,

Sorry if these questions are too elementary:

1. What is that way to make any set X into a measure space? Also, why do you say that integrals are more general than sums?

2. What is the meaning of conjugate linear?

3. Is there any difference between &#039;maps&#039; and &#039;functions&#039;?

4. How do we know that $latex L^2$ is a vector space?
- $latex &#124;a+b&#124;^2\le (&#124;a&#124;^2+&#124;b&#124;^2+2&#124;ab&#124;)$- the first two terms are finite according to the definition of $L^2$, but how are we sure that the inner product will always be finite? Is there some other way to prove this?

5. The net-fish process in the beginning- The corresponding rate equation will be d(Nfish)/dt=r as the only species is fish and that does not appear as an input, so it&#039;s power will be 0- Right?]]></description>
			<content:encoded><![CDATA[<p>Sir,</p>
<p>Sorry if these questions are too elementary:</p>
<p>1. What is that way to make any set X into a measure space? Also, why do you say that integrals are more general than sums?</p>
<p>2. What is the meaning of conjugate linear?</p>
<p>3. Is there any difference between &#8216;maps&#8217; and &#8216;functions&#8217;?</p>
<p>4. How do we know that <img src="https://s0.wp.com/latex.php?latex=L%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L^2" class="latex" /> is a vector space?<br />
&#8211; <img src="https://s0.wp.com/latex.php?latex=%7Ca%2Bb%7C%5E2%5Cle+%28%7Ca%7C%5E2%2B%7Cb%7C%5E2%2B2%7Cab%7C%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|a+b|^2&#92;le (|a|^2+|b|^2+2|ab|)" class="latex" />&#8211; the first two terms are finite according to the definition of $L^2$, but how are we sure that the inner product will always be finite? Is there some other way to prove this?</p>
<p>5. The net-fish process in the beginning- The corresponding rate equation will be d(Nfish)/dt=r as the only species is fish and that does not appear as an input, so it&#8217;s power will be 0- Right?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Network Theory (Part 12) « Azimuth		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-8182</link>

		<dc:creator><![CDATA[Network Theory (Part 12) « Azimuth]]></dc:creator>
		<pubDate>Sun, 09 Oct 2011 08:06:26 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=3059#comment-8182</guid>

					<description><![CDATA[[...] We need to recall the analogy we began sketching in Part 5, and push it a bit further. The idea is that stochastic mechanics differs from quantum mechanics in two ways [...]]]></description>
			<content:encoded><![CDATA[<p>[&#8230;] We need to recall the analogy we began sketching in Part 5, and push it a bit further. The idea is that stochastic mechanics differs from quantum mechanics in two ways [&#8230;]</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-5347</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sun, 17 Apr 2011 00:40:34 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=3059#comment-5347</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-5344&quot;&gt;Giampiero Campa&lt;/a&gt;.

Thanks - fixed!  By the way, I &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/04/06/network-theory-part-4/#comment-5283&quot; rel=&quot;nofollow&quot;&gt;answered the puzzle&lt;/a&gt; in Part 4.  I hope the answer makes sense.  If not, please ask a question!]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-5344">Giampiero Campa</a>.</p>
<p>Thanks &#8211; fixed!  By the way, I <a href="https://johncarlosbaez.wordpress.com/2011/04/06/network-theory-part-4/#comment-5283" rel="nofollow">answered the puzzle</a> in Part 4.  I hope the answer makes sense.  If not, please ask a question!</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Giampiero Campa		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-5344</link>

		<dc:creator><![CDATA[Giampiero Campa]]></dc:creator>
		<pubDate>Sat, 16 Apr 2011 23:25:02 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=3059#comment-5344</guid>

					<description><![CDATA[I think you forgot the keyword &quot;latex&quot; in $a^\dagger$ in the text 3 formulas before the end of the article.]]></description>
			<content:encoded><![CDATA[<p>I think you forgot the keyword &#8220;latex&#8221; in $a^\dagger$ in the text 3 formulas before the end of the article.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Network Theory (Part 6) &#171; Azimuth		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-5326</link>

		<dc:creator><![CDATA[Network Theory (Part 6) &#171; Azimuth]]></dc:creator>
		<pubDate>Sat, 16 Apr 2011 06:19:54 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=3059#comment-5326</guid>

					<description><![CDATA[[...] Last time I told you what happens when we stand in a river and catch fish as they randomly swim past. Let me remind you of how that works. But today let&#8217;s use rabbits. [...]]]></description>
			<content:encoded><![CDATA[<p>[&#8230;] Last time I told you what happens when we stand in a river and catch fish as they randomly swim past. Let me remind you of how that works. But today let&#8217;s use rabbits. [&#8230;]</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-5282</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Thu, 14 Apr 2011 05:40:41 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=3059#comment-5282</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-5270&quot;&gt;John Baez&lt;/a&gt;.

Florifulgurator wrote:

&lt;blockquote&gt;
Oh yeah, I forgot about the symmetry question while happily browsing the old books again after a decade… – what is a “symmetric Petri net” … ?
&lt;/blockquote&gt;

Nice question!  I&#039;m not sure it&#039;s a standard term, but it has an obvious meaning:

A symmetric Petri net is one where every transition is reversible.

A bit more precisely: for each transition with a given list of inputs and a given list of outputs, there&#039;s a transition with those inputs as its &lt;i&gt;outputs&lt;/i&gt;, and those outputs as its &lt;i&gt;inputs&lt;/i&gt;.  We call this other transition the &lt;b&gt;reverse&lt;/b&gt; of the original transition.

More precisely still: a Petri net consists of a set $latex S$ of &lt;b&gt;states&lt;/b&gt;, a set $latex T$ of &lt;b&gt;transitions&lt;/b&gt;, and &lt;b&gt;input&lt;/b&gt; and &lt;b&gt;output&lt;/b&gt; functions

$latex i: S \times T \to \mathbb{N}$

$latex o: S \times T \to \mathbb{N}$

saying for each transition how many times each state appears as input or output.  Every Petri net has a &lt;b&gt;reversed&lt;/b&gt; Petri net where we switch the functions $latex i$ and $latex o$.  A Petri net is &lt;b&gt;symmetric&lt;/b&gt; if it&#039;s isomorphic to its reversed version.  Or, much better, if it&#039;s equipped with an isomorphism to its reversed version.  Then each transition has another transition called its &lt;b&gt;reverse&lt;/b&gt;. Then we can define what it means for a &lt;i&gt;stochastic&lt;/i&gt; Petri net to be symmetric: now the rate constant of each transition must equal that of its reverse.

Any stochastic Petri net gives rise to a &lt;a href=&quot;http://en.wikipedia.org/wiki/Markov_process&quot; rel=&quot;nofollow&quot;&gt;Markov process&lt;/a&gt;.  If the stochastic Petri net is symmetric, so is its Markov process.

&lt;blockquote&gt;
I’ve never cared about the nonsymmetric case. But others did:

&#8226; Ma Z.M. and Röckner M.: &lt;i&gt;Introduction to the Theory of (Non-Symmetric) Dirichlet Forms&lt;/i&gt;, Springer-Verlag, Berlin-Heidelberg-New York, 1992.
&lt;/blockquote&gt;

Great!  The wonderful thing about math is that there are tons of people working on tons of obscure-sounding subjects, so that when you get interested in something you usually find an entire book has been written about it already!  Books that seem completely boring suddenly become fascinating when you need to know what&#039;s in them.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/04/11/network-theory-part-5/#comment-5270">John Baez</a>.</p>
<p>Florifulgurator wrote:</p>
<blockquote><p>
Oh yeah, I forgot about the symmetry question while happily browsing the old books again after a decade… – what is a “symmetric Petri net” … ?
</p></blockquote>
<p>Nice question!  I&#8217;m not sure it&#8217;s a standard term, but it has an obvious meaning:</p>
<p>A symmetric Petri net is one where every transition is reversible.</p>
<p>A bit more precisely: for each transition with a given list of inputs and a given list of outputs, there&#8217;s a transition with those inputs as its <i>outputs</i>, and those outputs as its <i>inputs</i>.  We call this other transition the <b>reverse</b> of the original transition.</p>
<p>More precisely still: a Petri net consists of a set <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> of <b>states</b>, a set <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" /> of <b>transitions</b>, and <b>input</b> and <b>output</b> functions</p>
<p><img src="https://s0.wp.com/latex.php?latex=i%3A+S+%5Ctimes+T+%5Cto+%5Cmathbb%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i: S &#92;times T &#92;to &#92;mathbb{N}" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=o%3A+S+%5Ctimes+T+%5Cto+%5Cmathbb%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="o: S &#92;times T &#92;to &#92;mathbb{N}" class="latex" /></p>
<p>saying for each transition how many times each state appears as input or output.  Every Petri net has a <b>reversed</b> Petri net where we switch the functions <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=o&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="o" class="latex" />.  A Petri net is <b>symmetric</b> if it&#8217;s isomorphic to its reversed version.  Or, much better, if it&#8217;s equipped with an isomorphism to its reversed version.  Then each transition has another transition called its <b>reverse</b>. Then we can define what it means for a <i>stochastic</i> Petri net to be symmetric: now the rate constant of each transition must equal that of its reverse.</p>
<p>Any stochastic Petri net gives rise to a <a href="http://en.wikipedia.org/wiki/Markov_process" rel="nofollow">Markov process</a>.  If the stochastic Petri net is symmetric, so is its Markov process.</p>
<blockquote><p>
I’ve never cared about the nonsymmetric case. But others did:</p>
<p>&bull; Ma Z.M. and Röckner M.: <i>Introduction to the Theory of (Non-Symmetric) Dirichlet Forms</i>, Springer-Verlag, Berlin-Heidelberg-New York, 1992.
</p></blockquote>
<p>Great!  The wonderful thing about math is that there are tons of people working on tons of obscure-sounding subjects, so that when you get interested in something you usually find an entire book has been written about it already!  Books that seem completely boring suddenly become fascinating when you need to know what&#8217;s in them.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

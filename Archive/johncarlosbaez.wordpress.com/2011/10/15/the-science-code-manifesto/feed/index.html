<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: The Science Code Manifesto	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/</link>
	<description></description>
	<lastBuildDate>Wed, 19 Oct 2011 02:05:17 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: Weekly Picks &#171; Mathblogging.org &#8212; the Blog		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8488</link>

		<dc:creator><![CDATA[Weekly Picks &#171; Mathblogging.org &#8212; the Blog]]></dc:creator>
		<pubDate>Wed, 19 Oct 2011 02:05:17 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5603#comment-8488</guid>

					<description><![CDATA[[...] Azimuth points you to the Science Code Manifesto &#8212; if you code, go sign it! [...]]]></description>
			<content:encoded><![CDATA[<p>[&#8230;] Azimuth points you to the Science Code Manifesto &#8212; if you code, go sign it! [&#8230;]</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8425</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Tue, 18 Oct 2011 01:43:34 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5603#comment-8425</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8407&quot;&gt;David Corfield&lt;/a&gt;.

Yeah, we all tend to pick on the poor alchemists.  There &lt;i&gt;was&lt;/i&gt; a lot of secrecy in &lt;i&gt;some&lt;/i&gt; alchemical traditions, though.  Isaac Newton is a great example of that!]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8407">David Corfield</a>.</p>
<p>Yeah, we all tend to pick on the poor alchemists.  There <i>was</i> a lot of secrecy in <i>some</i> alchemical traditions, though.  Isaac Newton is a great example of that!</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: davidtweed		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8408</link>

		<dc:creator><![CDATA[davidtweed]]></dc:creator>
		<pubDate>Mon, 17 Oct 2011 12:03:12 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5603#comment-8408</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8402&quot;&gt;Nick Barnes&lt;/a&gt;.

I&#039;m very tempted to take the opposite view: being able to just read the code isn&#039;t much use, since what happens if I as an author and someone disagree about the correctness of some point: it&#039;ll almost certainly come down to a response I&#039;ve used myself on occasions &quot;It works on my machine, dunno what you think is wrong.&quot; In contrast if I can run the code, even if I can&#039;t understand it I can produce &quot;examples of misbehaviour&quot; that are more difficult to just brush under the carpet.

As you say, actually getting independently compilable code is incredibly difficult (and I&#039;m guilty of not cleaning up some code enough to put it on the Azimuth wiki, so I&#039;m a very black pot here) but I suspect it&#039;s the only thing that will be effective in spotting errors, some of which will have led to bigger &quot;overall picture interpretation&quot; mistakes.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8402">Nick Barnes</a>.</p>
<p>I&#8217;m very tempted to take the opposite view: being able to just read the code isn&#8217;t much use, since what happens if I as an author and someone disagree about the correctness of some point: it&#8217;ll almost certainly come down to a response I&#8217;ve used myself on occasions &#8220;It works on my machine, dunno what you think is wrong.&#8221; In contrast if I can run the code, even if I can&#8217;t understand it I can produce &#8220;examples of misbehaviour&#8221; that are more difficult to just brush under the carpet.</p>
<p>As you say, actually getting independently compilable code is incredibly difficult (and I&#8217;m guilty of not cleaning up some code enough to put it on the Azimuth wiki, so I&#8217;m a very black pot here) but I suspect it&#8217;s the only thing that will be effective in spotting errors, some of which will have led to bigger &#8220;overall picture interpretation&#8221; mistakes.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: David Corfield		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8407</link>

		<dc:creator><![CDATA[David Corfield]]></dc:creator>
		<pubDate>Mon, 17 Oct 2011 11:28:03 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5603#comment-8407</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8401&quot;&gt;Nick Barnes&lt;/a&gt;.

Yes, it&#039;s tricky to say what you wanted to say briefly. And as I said I&#039;m very sympathetic to what you are trying to achieve.

A good case of secrecy holding up progress is that of the Renaissance court mathematicians challenging each other to solve specific problems, while keeping their techniques to themselves.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8401">Nick Barnes</a>.</p>
<p>Yes, it&#8217;s tricky to say what you wanted to say briefly. And as I said I&#8217;m very sympathetic to what you are trying to achieve.</p>
<p>A good case of secrecy holding up progress is that of the Renaissance court mathematicians challenging each other to solve specific problems, while keeping their techniques to themselves.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Nick Barnes		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8402</link>

		<dc:creator><![CDATA[Nick Barnes]]></dc:creator>
		<pubDate>Mon, 17 Oct 2011 09:51:36 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5603#comment-8402</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8400&quot;&gt;Vasileios Anagnostopoulos&lt;/a&gt;.

The manifesto is principally concerned with publication: that readers should be able at least to *read* the code (because without this, an important aspect of method is not published).  Being able to *run* the code opens a subsidiary can of worms, and in particular is not going to be possible in many sciences at present. Many scientists, and some entire disciplines, rely on proprietary - and sometimes very expensive - third party software components.  I don&#039;t much like it, but I can&#039;t hope to change it, and as an outsider I can&#039;t even get traction towards changing it (although the discussion document does address this subject).

The manifesto is aimed at things which *can* be changed, today.

Finally, although I personally have a great deal of respect for RMS&#039;s work and achievements - and have been a satisfied user of GCC and emacs for more than 20 years - he&#039;s not any sort of authority in science. Why should scientists care what he thinks?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8400">Vasileios Anagnostopoulos</a>.</p>
<p>The manifesto is principally concerned with publication: that readers should be able at least to *read* the code (because without this, an important aspect of method is not published).  Being able to *run* the code opens a subsidiary can of worms, and in particular is not going to be possible in many sciences at present. Many scientists, and some entire disciplines, rely on proprietary &#8211; and sometimes very expensive &#8211; third party software components.  I don&#8217;t much like it, but I can&#8217;t hope to change it, and as an outsider I can&#8217;t even get traction towards changing it (although the discussion document does address this subject).</p>
<p>The manifesto is aimed at things which *can* be changed, today.</p>
<p>Finally, although I personally have a great deal of respect for RMS&#8217;s work and achievements &#8211; and have been a satisfied user of GCC and emacs for more than 20 years &#8211; he&#8217;s not any sort of authority in science. Why should scientists care what he thinks?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Nick Barnes		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8401</link>

		<dc:creator><![CDATA[Nick Barnes]]></dc:creator>
		<pubDate>Mon, 17 Oct 2011 09:36:20 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5603#comment-8401</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8383&quot;&gt;David Corfield&lt;/a&gt;.

As is often the case, precision was sacrificed in this simile, for the sake of brevity and rhetorical effect. &quot;Alchemy&quot; is standing in for the hermetic and esoteric traditions often followed in that discipline: a method might never be published, or if published might be enciphered, or described in metaphorical or allegorical ways, or steps might be omitted or misrepresented.  These obfuscations were used to prevent replication, or to restrict it to an elite circle of initiates.  The effect was that advances were slow and often lost.  Some of these traditions died hard in the 17th century, at the birth of modern science: scientists wanted to keep their discoveries to themselves.  Henry Oldenburg had to badger people into publication, and (as I recall) on occasion resorted to trickery to achieve it.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8383">David Corfield</a>.</p>
<p>As is often the case, precision was sacrificed in this simile, for the sake of brevity and rhetorical effect. &#8220;Alchemy&#8221; is standing in for the hermetic and esoteric traditions often followed in that discipline: a method might never be published, or if published might be enciphered, or described in metaphorical or allegorical ways, or steps might be omitted or misrepresented.  These obfuscations were used to prevent replication, or to restrict it to an elite circle of initiates.  The effect was that advances were slow and often lost.  Some of these traditions died hard in the 17th century, at the birth of modern science: scientists wanted to keep their discoveries to themselves.  Henry Oldenburg had to badger people into publication, and (as I recall) on occasion resorted to trickery to achieve it.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Vasileios Anagnostopoulos		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8400</link>

		<dc:creator><![CDATA[Vasileios Anagnostopoulos]]></dc:creator>
		<pubDate>Mon, 17 Oct 2011 09:02:42 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5603#comment-8400</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8384&quot;&gt;John Baez&lt;/a&gt;.

A notable omission of this manifesto  related to one of Stallman&#039;s view of software is the necessity of including a document for the procedure of compilation the source code in order to produce the excutable (imagine a 30000 LOC project without a makefile). Moreover equally important (in my view and Stallman&#039;s view) is the ability to run/interpret the code on at least a free (as in beer) environment. If someone has written the software in C++ calling HP/UX system calls is not useful to a researcher that does not have money to buy an HP/UX workstation. A notable example is Darwin&#039;s code that cannot be cross-compiled from another OS to produce a base system (it is not scientific example but It is an example of lack of executability).]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8384">John Baez</a>.</p>
<p>A notable omission of this manifesto  related to one of Stallman&#8217;s view of software is the necessity of including a document for the procedure of compilation the source code in order to produce the excutable (imagine a 30000 LOC project without a makefile). Moreover equally important (in my view and Stallman&#8217;s view) is the ability to run/interpret the code on at least a free (as in beer) environment. If someone has written the software in C++ calling HP/UX system calls is not useful to a researcher that does not have money to buy an HP/UX workstation. A notable example is Darwin&#8217;s code that cannot be cross-compiled from another OS to produce a base system (it is not scientific example but It is an example of lack of executability).</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8384</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sun, 16 Oct 2011 16:58:26 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5603#comment-8384</guid>

					<description><![CDATA[Here are some of the comments I got on my thread about this over on Google+.  

Toby Bartels wrote:

&lt;blockquote&gt;
I don&#039;t agree with this line in the &lt;a href=&quot;http://sciencecodemanifesto.org/discussion&quot; rel=&quot;nofollow&quot;&gt;supporting discussion&lt;/a&gt;:

&lt;blockquote&gt;Adapting someone else’s code without permission and citation is plagiarism.
&lt;/blockquote&gt;

The word ‘permission’ is incorrect here. The authors of the discussion appear to be conflating copyright and plagiarism; permission applies to copyright, while citation applies to plagiarism. (Also, ‘adapting’ is misleading but makes sense in context.)

For copyright, the possessive in ‘someone else&#039;s code’ refers to the legal owner of the copyright. Publishing someone else&#039;s code (whether adapted or not) without permission is a violation of laws that almost every jurisdiction has adopted, but citation as such is not required (although it&#039;s usually made a condition of permission). Abiding by the law is often wise; however, these laws have nothing to do with academic standards.

For plagiarism, the possessive in ‘someone else&#039;s code’ refers to the actual originator of the work. Using someone else&#039;s code (whether adapted or not) without citation is a violation of the academic standards that we normally adopt, but permission as such is not required (although it&#039;s usually obtained for legal reasons). Abiding by academic standards is a necessity for any decent researcher.

As I said, ‘adapting’ makes sense in context, so they should simply remove the text ‘permission and’.
&lt;/blockquote&gt;

Benjamin Ramage wrote:

&lt;blockquote&gt;
I like this idea, but I wonder about some of the finer points of what would be acceptable. Ecological data sets are often extremely messy (especially when they have been collected by dozens of different people over many years, e.g., long-term Forest Service inventory data), and thus code can be littered with notes about why particular plots/transects etc. have been excluded from analysis. Even in first-hand data sets, omissions and notes can be common; for instance, I have had to exclude plots with notes like &quot;field assistant appeared extremely hungover during data collection - data do not make any sense at all&quot;. In cases like this, would it be ethical to just delete the relevant parts of code before posting (assuming that the data set was not also provided)? If the raw data had to be provided, would it be ethical to delete the relevant parts of code AND delete the erroneous records from the data set? More generally, I guess I&#039;m wondering how much code cleaning would be accepted (or even expected)?
&lt;/blockquote&gt;

Carlos Scheiddeger wrote:

&lt;blockquote&gt;
Benjamin: these things you point out are directly analogous to the non-reasons people use to not publish their source code. There is a cultural component aspect: the community is expected to understand that all code starts messy. Open source writers have had to come to grips with this as well. Let&#039;s get the high-order bits right first!

Also, notice that the alternative (writing messy software but not publish) is much worse.

I would also like to add that this manifesto should include publishing data as well. So many papers are irreproducible (or incomparable) even with open source software, simply because the data on which the experiments are based cannot be acquired.
&lt;/blockquote&gt;

Jane Shevstov wrote:

&lt;blockquote&gt;
I&#039;m also an ecologist and I think what should be published are the core algorithms, not the stuff that&#039;s specific to processing your data. (Good programming means keeping the two as separate as possible anyway.) Of course, the data should be released, too, but that&#039;s a separate issue.

The question is which code is interesting or unique enough to publish. When I developed a new method for analyzing stock-flow networks, the code was published as an appendix to the paper. But does anyone really want to see R code for a bootstrap two-group comparison?
&lt;/blockquote&gt;

Benjamin Ramage wrote:

&lt;blockquote&gt;
+Jane Shevtsov, I agree that what is important to publish are the core algorithms and anything that makes an analysis unique or novel, but the proposed science code manifesto says &quot;All source code written specifically to process data for a published paper must be available to the reviewers and readers of the paper&quot;. 

+Carlos Scheidegger, I guess what I&#039;m asking for are guidelines about how much cleaning would be acceptable. In my opinion, there&#039;s a delicate balance between transparency and readability. Papers (and code) that acknowledge and explain every excluded data point (regardless of how trivial the reason or non-influential the outcome) can be nearly unreadable. At the other extreme, if a researcher excludes data points (as well as any reference to these data points) simply because they are outliers (i.e. without considering the potential mechanisms), questions can and should be raised about the legitimacy of the results. I know these are not new issues, but they are highly relevant to initiatives like The Science Code Manifesto. If clear guidelines are part of the manifesto, I think it might increase the chances of widespread adoption.
&lt;/blockquote&gt;

Carlos Scheidegger wrote:

&lt;blockquote&gt;
+Benjamin Ramage There should never be a penalty for publishing too much code. The culture should be that it&#039;s ok if your code is messy, as long as I can run it on my data.

There&#039;s two good side effects of this. First, it acknowledges that the current situation is terrible, and that an over-correction is sometimes necessary. Second, there&#039;s a long-term incentive to clean up code and create default standard libraries.
&lt;/blockquote&gt;

Miguel Angel wrote:

&lt;blockquote&gt;
+John Baez What are your thoughts about unit tests in science-related source code? I think unit tests would be great to ensure that the code does what is supposed to do and to provide certainty to other researchers who adapt the code that they&#039;re not breaking anything in the process of changing it.
&lt;/blockquote&gt;

John Baez wrote:

&lt;blockquote&gt;
+Miguel Angel I&#039;m not really the right person to answer that question; I&#039;m a mere mathematician. Someone else here could do better.

I&#039;ve just noticed, as I&#039;m trying to read papers about climate science, how often it&#039;s impossible to tell how the authors have processed their data. And it&#039;s not just climate science; it seems to be all science. Back when publishing meant &quot;printing words on paper&quot;, there was a good excuse for this.
&lt;/blockquote&gt;

Miguel Angel wrote:

&lt;blockquote&gt;
+John Baez It&#039;s alright. I just thought it would be a nice addition to the manifesto. Unit testing is used widely in software development, particularly useful when you have to deal with a lot of complexity in your code (Wikipedia does a better job at explaining it than me - http://en.wikipedia.org/wiki/Unit_testing).
&lt;/blockquote&gt;

Carlos Scheidegger wrote:

&lt;blockquote&gt;
+Miguel Angel In engineering and computational science there&#039;s a large research effort in &quot;verification and validation&quot; (&quot;V&#038;V&quot;). It&#039;s very related to unit testing. A quick search on google yielded this page on V&#038;V for computational fluid dynamics: http://www.grc.nasa.gov/WWW/wind/valid/tutorial/tutorial.html
&lt;/blockquote&gt;

Miguel Angel wrote:

&lt;blockquote&gt;
+Carlos Scheidegger Publicly available here: https://docs.google.com/viewer?a=v&#038;pid=explorer&#038;chrome=true&#038;srcid=0B_6AKCRES-6tNjUyNGM0YTUtOGE1OS00YzgxLTkxOTEtMGY2ODFiNjcxYWQy&#038;hl=en

It&#039;s a bit late here so I will read it tomorrow, but looks interesting.
&lt;/blockquote&gt;

F. Lengyel wrote:

&lt;blockquote&gt;
I was expecting an elaborated formal theory of validation and verification, as opposed to a catalog of recommended heuristics and methodological practice in plain English that researchers generally follow (or ought to follow) in the course of their work. IV&#038;V and V&#038;V seem to differ in who is doing the V&#038;V, so it is misleading to suggest that they are radically different. The extensive literature on formal methods familiar to a logician or computer scientist, e.g., formal logical and programming languages adapted to program verification, model checking, program transformation--receives passing mention. In any case, V&#038;V advocacy would require its own manifesto.
&lt;/blockquote&gt;

Tim van Beek wrote:

&lt;blockquote&gt;
I don&#039;t think there is any need to mention coding techniques in the manifesto. It is good and important as it is, to get people to recognize that their code should be part of their publication.

Of course most scientists aren&#039;t very good at programming, but most computer scientists aren&#039;t, too. Getting them to recognize that is an entirely different endeavor. Usually people think that they are good at programming when they succeeded to compile a small program and to get it to do what it was supposed to do. It&#039;s like thinking you know all about math because you can add and multiply natural numbers.

Unit-Tests are just one example of a tool in a large toolbox that helps you to design and code better programs and save a lot of time along the way. Software projects that develop big and highly critical software systems like the Windows operating system would have failed miserably decades ago if they hadn&#039;t developed these tools. Most scientists who develop software are at least 3 decades behind the state of the art in this sense. So there certainly is a lot of potential in a closer interaction of scientists who need to develop software, and professional programmers, but the former will have to understand this first.

Me, for example, I won&#039;t run after scientists to tell them about professional software development if they aren&#039;t interested. And I won&#039;t waste my time trying to explain to them why they should be interested.

BTW, I&#039;m the 418th &quot;endorser&quot; :-)
&lt;/blockquote&gt;]]></description>
			<content:encoded><![CDATA[<p>Here are some of the comments I got on my thread about this over on Google+.  </p>
<p>Toby Bartels wrote:</p>
<blockquote><p>
I don&#8217;t agree with this line in the <a href="http://sciencecodemanifesto.org/discussion" rel="nofollow">supporting discussion</a>:</p>
<blockquote><p>Adapting someone else’s code without permission and citation is plagiarism.
</p></blockquote>
<p>The word ‘permission’ is incorrect here. The authors of the discussion appear to be conflating copyright and plagiarism; permission applies to copyright, while citation applies to plagiarism. (Also, ‘adapting’ is misleading but makes sense in context.)</p>
<p>For copyright, the possessive in ‘someone else&#8217;s code’ refers to the legal owner of the copyright. Publishing someone else&#8217;s code (whether adapted or not) without permission is a violation of laws that almost every jurisdiction has adopted, but citation as such is not required (although it&#8217;s usually made a condition of permission). Abiding by the law is often wise; however, these laws have nothing to do with academic standards.</p>
<p>For plagiarism, the possessive in ‘someone else&#8217;s code’ refers to the actual originator of the work. Using someone else&#8217;s code (whether adapted or not) without citation is a violation of the academic standards that we normally adopt, but permission as such is not required (although it&#8217;s usually obtained for legal reasons). Abiding by academic standards is a necessity for any decent researcher.</p>
<p>As I said, ‘adapting’ makes sense in context, so they should simply remove the text ‘permission and’.
</p></blockquote>
<p>Benjamin Ramage wrote:</p>
<blockquote><p>
I like this idea, but I wonder about some of the finer points of what would be acceptable. Ecological data sets are often extremely messy (especially when they have been collected by dozens of different people over many years, e.g., long-term Forest Service inventory data), and thus code can be littered with notes about why particular plots/transects etc. have been excluded from analysis. Even in first-hand data sets, omissions and notes can be common; for instance, I have had to exclude plots with notes like &#8220;field assistant appeared extremely hungover during data collection &#8211; data do not make any sense at all&#8221;. In cases like this, would it be ethical to just delete the relevant parts of code before posting (assuming that the data set was not also provided)? If the raw data had to be provided, would it be ethical to delete the relevant parts of code AND delete the erroneous records from the data set? More generally, I guess I&#8217;m wondering how much code cleaning would be accepted (or even expected)?
</p></blockquote>
<p>Carlos Scheiddeger wrote:</p>
<blockquote><p>
Benjamin: these things you point out are directly analogous to the non-reasons people use to not publish their source code. There is a cultural component aspect: the community is expected to understand that all code starts messy. Open source writers have had to come to grips with this as well. Let&#8217;s get the high-order bits right first!</p>
<p>Also, notice that the alternative (writing messy software but not publish) is much worse.</p>
<p>I would also like to add that this manifesto should include publishing data as well. So many papers are irreproducible (or incomparable) even with open source software, simply because the data on which the experiments are based cannot be acquired.
</p></blockquote>
<p>Jane Shevstov wrote:</p>
<blockquote><p>
I&#8217;m also an ecologist and I think what should be published are the core algorithms, not the stuff that&#8217;s specific to processing your data. (Good programming means keeping the two as separate as possible anyway.) Of course, the data should be released, too, but that&#8217;s a separate issue.</p>
<p>The question is which code is interesting or unique enough to publish. When I developed a new method for analyzing stock-flow networks, the code was published as an appendix to the paper. But does anyone really want to see R code for a bootstrap two-group comparison?
</p></blockquote>
<p>Benjamin Ramage wrote:</p>
<blockquote><p>
+Jane Shevtsov, I agree that what is important to publish are the core algorithms and anything that makes an analysis unique or novel, but the proposed science code manifesto says &#8220;All source code written specifically to process data for a published paper must be available to the reviewers and readers of the paper&#8221;. </p>
<p>+Carlos Scheidegger, I guess what I&#8217;m asking for are guidelines about how much cleaning would be acceptable. In my opinion, there&#8217;s a delicate balance between transparency and readability. Papers (and code) that acknowledge and explain every excluded data point (regardless of how trivial the reason or non-influential the outcome) can be nearly unreadable. At the other extreme, if a researcher excludes data points (as well as any reference to these data points) simply because they are outliers (i.e. without considering the potential mechanisms), questions can and should be raised about the legitimacy of the results. I know these are not new issues, but they are highly relevant to initiatives like The Science Code Manifesto. If clear guidelines are part of the manifesto, I think it might increase the chances of widespread adoption.
</p></blockquote>
<p>Carlos Scheidegger wrote:</p>
<blockquote><p>
+Benjamin Ramage There should never be a penalty for publishing too much code. The culture should be that it&#8217;s ok if your code is messy, as long as I can run it on my data.</p>
<p>There&#8217;s two good side effects of this. First, it acknowledges that the current situation is terrible, and that an over-correction is sometimes necessary. Second, there&#8217;s a long-term incentive to clean up code and create default standard libraries.
</p></blockquote>
<p>Miguel Angel wrote:</p>
<blockquote><p>
+John Baez What are your thoughts about unit tests in science-related source code? I think unit tests would be great to ensure that the code does what is supposed to do and to provide certainty to other researchers who adapt the code that they&#8217;re not breaking anything in the process of changing it.
</p></blockquote>
<p>John Baez wrote:</p>
<blockquote><p>
+Miguel Angel I&#8217;m not really the right person to answer that question; I&#8217;m a mere mathematician. Someone else here could do better.</p>
<p>I&#8217;ve just noticed, as I&#8217;m trying to read papers about climate science, how often it&#8217;s impossible to tell how the authors have processed their data. And it&#8217;s not just climate science; it seems to be all science. Back when publishing meant &#8220;printing words on paper&#8221;, there was a good excuse for this.
</p></blockquote>
<p>Miguel Angel wrote:</p>
<blockquote><p>
+John Baez It&#8217;s alright. I just thought it would be a nice addition to the manifesto. Unit testing is used widely in software development, particularly useful when you have to deal with a lot of complexity in your code (Wikipedia does a better job at explaining it than me &#8211; <a href="http://en.wikipedia.org/wiki/Unit_testing" rel="nofollow ugc">http://en.wikipedia.org/wiki/Unit_testing</a>).
</p></blockquote>
<p>Carlos Scheidegger wrote:</p>
<blockquote><p>
+Miguel Angel In engineering and computational science there&#8217;s a large research effort in &#8220;verification and validation&#8221; (&#8220;V&amp;V&#8221;). It&#8217;s very related to unit testing. A quick search on google yielded this page on V&amp;V for computational fluid dynamics: <a href="http://www.grc.nasa.gov/WWW/wind/valid/tutorial/tutorial.html" rel="nofollow ugc">http://www.grc.nasa.gov/WWW/wind/valid/tutorial/tutorial.html</a>
</p></blockquote>
<p>Miguel Angel wrote:</p>
<blockquote><p>
+Carlos Scheidegger Publicly available here: <a href="https://docs.google.com/viewer?a=v&#038;pid=explorer&#038;chrome=true&#038;srcid=0B_6AKCRES-6tNjUyNGM0YTUtOGE1OS00YzgxLTkxOTEtMGY2ODFiNjcxYWQy&#038;hl=en" rel="nofollow ugc">https://docs.google.com/viewer?a=v&#038;pid=explorer&#038;chrome=true&#038;srcid=0B_6AKCRES-6tNjUyNGM0YTUtOGE1OS00YzgxLTkxOTEtMGY2ODFiNjcxYWQy&#038;hl=en</a></p>
<p>It&#8217;s a bit late here so I will read it tomorrow, but looks interesting.
</p></blockquote>
<p>F. Lengyel wrote:</p>
<blockquote><p>
I was expecting an elaborated formal theory of validation and verification, as opposed to a catalog of recommended heuristics and methodological practice in plain English that researchers generally follow (or ought to follow) in the course of their work. IV&amp;V and V&amp;V seem to differ in who is doing the V&amp;V, so it is misleading to suggest that they are radically different. The extensive literature on formal methods familiar to a logician or computer scientist, e.g., formal logical and programming languages adapted to program verification, model checking, program transformation&#8211;receives passing mention. In any case, V&amp;V advocacy would require its own manifesto.
</p></blockquote>
<p>Tim van Beek wrote:</p>
<blockquote><p>
I don&#8217;t think there is any need to mention coding techniques in the manifesto. It is good and important as it is, to get people to recognize that their code should be part of their publication.</p>
<p>Of course most scientists aren&#8217;t very good at programming, but most computer scientists aren&#8217;t, too. Getting them to recognize that is an entirely different endeavor. Usually people think that they are good at programming when they succeeded to compile a small program and to get it to do what it was supposed to do. It&#8217;s like thinking you know all about math because you can add and multiply natural numbers.</p>
<p>Unit-Tests are just one example of a tool in a large toolbox that helps you to design and code better programs and save a lot of time along the way. Software projects that develop big and highly critical software systems like the Windows operating system would have failed miserably decades ago if they hadn&#8217;t developed these tools. Most scientists who develop software are at least 3 decades behind the state of the art in this sense. So there certainly is a lot of potential in a closer interaction of scientists who need to develop software, and professional programmers, but the former will have to understand this first.</p>
<p>Me, for example, I won&#8217;t run after scientists to tell them about professional software development if they aren&#8217;t interested. And I won&#8217;t waste my time trying to explain to them why they should be interested.</p>
<p>BTW, I&#8217;m the 418th &#8220;endorser&#8221; :-)
</p></blockquote>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: David Corfield		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8383</link>

		<dc:creator><![CDATA[David Corfield]]></dc:creator>
		<pubDate>Sun, 16 Oct 2011 16:16:54 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5603#comment-8383</guid>

					<description><![CDATA[I&#039;m thoroughly in favour of code being published, not for its own sake but with a view to allowing replication and criticism. So

&lt;blockquote&gt;

...are simply extensions of the core principle of science: publication. Publication is what distinguishes science from alchemy, and is what has propelled science—and human society—so far and so fast in the last 300 years. The Manifesto is the natural application of this principle to the relatively new, and increasingly important, area of science software. 

&lt;/blockquote&gt;

I find a very odd thing to write. Weren&#039;t &lt;a href=&quot;http://en.wikipedia.org/wiki/Zosimos_of_Panopolis&quot; rel=&quot;nofollow&quot;&gt;Zosimos&lt;/a&gt; of Panopolis&#039;s books publications? I could just about understand the quotation with &#039;replication&#039; in place of &#039;publication&#039;.]]></description>
			<content:encoded><![CDATA[<p>I&#8217;m thoroughly in favour of code being published, not for its own sake but with a view to allowing replication and criticism. So</p>
<blockquote>
<p>&#8230;are simply extensions of the core principle of science: publication. Publication is what distinguishes science from alchemy, and is what has propelled science—and human society—so far and so fast in the last 300 years. The Manifesto is the natural application of this principle to the relatively new, and increasingly important, area of science software. </p>
</blockquote>
<p>I find a very odd thing to write. Weren&#8217;t <a href="http://en.wikipedia.org/wiki/Zosimos_of_Panopolis" rel="nofollow">Zosimos</a> of Panopolis&#8217;s books publications? I could just about understand the quotation with &#8216;replication&#8217; in place of &#8216;publication&#8217;.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: noodly		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/15/the-science-code-manifesto/#comment-8375</link>

		<dc:creator><![CDATA[noodly]]></dc:creator>
		<pubDate>Sun, 16 Oct 2011 09:51:45 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5603#comment-8375</guid>

					<description><![CDATA[There are two comments on HN, that I agree with (I&#039;m the author of the second):
http://news.ycombinator.com/item?id=3112705
http://news.ycombinator.com/item?id=3112984
(from thread http://news.ycombinator.com/item?id=3112274)

tl;dr - &quot;I didn&#039;t see any description of problems on this page, that this manifesto wants to solve&quot; (I see more problems that it creates)
&quot;The code is not as important as descriptions of algorithms, and the ideas behind code&quot;

I would also like to add:
Math will not go anywhere soon - programming languages are getting obsolete much faster - so it&#039;s more important that paper had as much detail as it&#039;s required to replicate the results without code than to have an easy access to code that can degrade quality of the papers e.g. when paper misses some important detail of algorithm, and the code is in some kind of assembly - code works, you can run it and get the same results - lazy researcher would use it, without understanding it - even if he couldn&#039;t code the same algorithm from the paper - raising the chance of replicating bugs. 
That&#039;s not how science should work.]]></description>
			<content:encoded><![CDATA[<p>There are two comments on HN, that I agree with (I&#8217;m the author of the second):<br />
<a href="http://news.ycombinator.com/item?id=3112705" rel="nofollow ugc">http://news.ycombinator.com/item?id=3112705</a><br />
<a href="http://news.ycombinator.com/item?id=3112984" rel="nofollow ugc">http://news.ycombinator.com/item?id=3112984</a><br />
(from thread <a href="http://news.ycombinator.com/item?id=3112274" rel="nofollow ugc">http://news.ycombinator.com/item?id=3112274</a>)</p>
<p>tl;dr &#8211; &#8220;I didn&#8217;t see any description of problems on this page, that this manifesto wants to solve&#8221; (I see more problems that it creates)<br />
&#8220;The code is not as important as descriptions of algorithms, and the ideas behind code&#8221;</p>
<p>I would also like to add:<br />
Math will not go anywhere soon &#8211; programming languages are getting obsolete much faster &#8211; so it&#8217;s more important that paper had as much detail as it&#8217;s required to replicate the results without code than to have an easy access to code that can degrade quality of the papers e.g. when paper misses some important detail of algorithm, and the code is in some kind of assembly &#8211; code works, you can run it and get the same results &#8211; lazy researcher would use it, without understanding it &#8211; even if he couldn&#8217;t code the same algorithm from the paper &#8211; raising the chance of replicating bugs.<br />
That&#8217;s not how science should work.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

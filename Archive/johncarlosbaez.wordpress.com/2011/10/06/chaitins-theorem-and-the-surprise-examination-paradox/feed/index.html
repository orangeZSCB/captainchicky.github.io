<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Chaitin&#8217;s Theorem and the Surprise Examination Paradox	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/</link>
	<description></description>
	<lastBuildDate>Tue, 17 Aug 2021 00:56:23 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: You are quite right, and my original response was wrong. I withdraw my claim by woopwoop - HackTech.news		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-171594</link>

		<dc:creator><![CDATA[You are quite right, and my original response was wrong. I withdraw my claim by woopwoop - HackTech.news]]></dc:creator>
		<pubDate>Tue, 17 Aug 2021 00:56:23 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5442#comment-171594</guid>

					<description><![CDATA[[&#8230;] John Baez, Chaitin&#8217;s theorem and the surprise examination paradox. [&#8230;]]]></description>
			<content:encoded><![CDATA[<p>[&#8230;] John Baez, Chaitin&rsquo;s theorem and the surprise examination paradox. [&#8230;]</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Yale Dikes		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-9815</link>

		<dc:creator><![CDATA[Yale Dikes]]></dc:creator>
		<pubDate>Thu, 10 Nov 2011 09:31:02 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5442#comment-9815</guid>

					<description><![CDATA[I think the reasoning has some interesting qualities which are time sensitive, language sensitive, but not paradoxical in the way it seems at first. To define terms, consider what it means to be surprised. There is clearly the issue of when something is a surprise. Let&#039;s say the professor offered the test on Friday week prior, it would be a surprise until the end of class on Thursday. But let&#039;s tighten up surprise -- there would be 24 hours where you knew for certain there would be a test on Thursday, assuming at least one day of the week will definitely have a test. The professor says he will stipulate that that is not &quot;really&quot; a surprise, even though from the point of view one has on Monday, it surely would be. It would only be after class on Wed, that you would be sure the only option would be Thursday, not to experience this 24 hour window of knowledge going from Thursday to the Friday of the test. But on Monday, you would know it could be Monday, Tues or Wed, without the 24 hour window, going forward. On Tues, you know it could be that day or Wed. On Wed, you would know it had to be that day, or there would be a potential 24 hour period of not being surprised. If there is a potential, disallowed by the professor of never being aware, even for a moment of the test before it occurs, then you know the next day is a no go if the test doesn&#039;t hit you that day, and we are back in the pickle. Tuesday must be the day, but we have the window. Uh oh. If the Professor lightens up and says on Monday you will not be able to guess when the test is, if the test hasn&#039;t been given by Thursday you will have a one day heads up, then there is no predicting the test, until and unless the end of class on Thursday, but not on Monday or earlier( there is a Monty Hall issue, but that&#039;s another story). Otherwise, the Professor is selling a bill of goods ( or he&#039;s buying into wily George&#039;s redefinition of surprise unwittingly), and can&#039;t promise the test will be given on one of 5 days, and will never allow for a twenty four hour window.

So the Professor relents, and sees that looking forward until Thursday he will be able to tally surprise people, but not on Thursday for Friday -- that like picking a marble out of jars, one marble, five jars, pick four empty jars you know that the fifth will have it. The paradox comes from a nutty stipulation of &quot;surprise&quot;, and the fallacy ignoratio elenchi , or redefinition thatGeorge introduces. It&#039;s logically impossible to avoid the 24 window, and if that standard is utilized, it generates a nutty result. Just as if I said the same thing about the jars: &quot;You will be surprised. You will never know which jar has the marble.&quot; So you pick till 4, and realize it must be five = fail. Translate: can&#039;t be 5, so 4 is the highest, number. So you get to three jars and know it must be 4 = fail. Translate: can&#039;t be 4 so three is the highest number. And so on. What is occurring is just a product of a defective definition of &quot;surprise&quot; lurking that can&#039;t be met given the other conditions. ( The contradiction argument is not a &quot;proof,&quot; but a disproof: A--&#062; P. not P ---&#062; Contra----&#062;invalid ----&#062;Plug in A, A is invalid). Change the def to what we normally mean as third dimensional creatures when we say surprise, meaning at the beginning of the sequence not foreclosing the possibility of this changing going forward. And we are back to being surprised, at least till Thursday. But on Monday, since we know it&#039;s not foreclosed by the potential 24 hour window, it would still be a surprise to us if the test were to occur on Friday.]]></description>
			<content:encoded><![CDATA[<p>I think the reasoning has some interesting qualities which are time sensitive, language sensitive, but not paradoxical in the way it seems at first. To define terms, consider what it means to be surprised. There is clearly the issue of when something is a surprise. Let&#8217;s say the professor offered the test on Friday week prior, it would be a surprise until the end of class on Thursday. But let&#8217;s tighten up surprise &#8212; there would be 24 hours where you knew for certain there would be a test on Thursday, assuming at least one day of the week will definitely have a test. The professor says he will stipulate that that is not &#8220;really&#8221; a surprise, even though from the point of view one has on Monday, it surely would be. It would only be after class on Wed, that you would be sure the only option would be Thursday, not to experience this 24 hour window of knowledge going from Thursday to the Friday of the test. But on Monday, you would know it could be Monday, Tues or Wed, without the 24 hour window, going forward. On Tues, you know it could be that day or Wed. On Wed, you would know it had to be that day, or there would be a potential 24 hour period of not being surprised. If there is a potential, disallowed by the professor of never being aware, even for a moment of the test before it occurs, then you know the next day is a no go if the test doesn&#8217;t hit you that day, and we are back in the pickle. Tuesday must be the day, but we have the window. Uh oh. If the Professor lightens up and says on Monday you will not be able to guess when the test is, if the test hasn&#8217;t been given by Thursday you will have a one day heads up, then there is no predicting the test, until and unless the end of class on Thursday, but not on Monday or earlier( there is a Monty Hall issue, but that&#8217;s another story). Otherwise, the Professor is selling a bill of goods ( or he&#8217;s buying into wily George&#8217;s redefinition of surprise unwittingly), and can&#8217;t promise the test will be given on one of 5 days, and will never allow for a twenty four hour window.</p>
<p>So the Professor relents, and sees that looking forward until Thursday he will be able to tally surprise people, but not on Thursday for Friday &#8212; that like picking a marble out of jars, one marble, five jars, pick four empty jars you know that the fifth will have it. The paradox comes from a nutty stipulation of &#8220;surprise&#8221;, and the fallacy ignoratio elenchi , or redefinition thatGeorge introduces. It&#8217;s logically impossible to avoid the 24 window, and if that standard is utilized, it generates a nutty result. Just as if I said the same thing about the jars: &#8220;You will be surprised. You will never know which jar has the marble.&#8221; So you pick till 4, and realize it must be five = fail. Translate: can&#8217;t be 5, so 4 is the highest, number. So you get to three jars and know it must be 4 = fail. Translate: can&#8217;t be 4 so three is the highest number. And so on. What is occurring is just a product of a defective definition of &#8220;surprise&#8221; lurking that can&#8217;t be met given the other conditions. ( The contradiction argument is not a &#8220;proof,&#8221; but a disproof: A&#8211;&gt; P. not P &#8212;&gt; Contra&#8212;-&gt;invalid &#8212;-&gt;Plug in A, A is invalid). Change the def to what we normally mean as third dimensional creatures when we say surprise, meaning at the beginning of the sequence not foreclosing the possibility of this changing going forward. And we are back to being surprised, at least till Thursday. But on Monday, since we know it&#8217;s not foreclosed by the potential 24 hour window, it would still be a surprise to us if the test were to occur on Friday.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: The Complexity Barrier « Azimuth		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8885</link>

		<dc:creator><![CDATA[The Complexity Barrier « Azimuth]]></dc:creator>
		<pubDate>Fri, 28 Oct 2011 03:58:28 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5442#comment-8885</guid>

					<description><![CDATA[More on Chaitin&#039;s incompleteness theorem.]]></description>
			<content:encoded><![CDATA[<p>More on Chaitin&#8217;s incompleteness theorem.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Bruce Smith		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8876</link>

		<dc:creator><![CDATA[Bruce Smith]]></dc:creator>
		<pubDate>Thu, 27 Oct 2011 20:35:12 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5442#comment-8876</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8164&quot;&gt;John Baez&lt;/a&gt;.

I don&#039;t think it can be done in C, since C semantics are not well-defined unless you specify a particular finite machine size. (Since C programs can do things like convert pointers to integers and back, tell you the size of any datatype, and convert data of any specified datatype to bytes and back.) On a finite machine of N bits, all programs either finish in time less than about 2**N or take forever.

But if you take &quot;C without size-specific operations&quot;, or a higher level language like Python, or for that matter a different sort of low-level language like a Turing machine, then that&#039;s not an issue -- you can define a precise semantics that allows it to run a program for an arbitrarily long time and allocate an arbitrary number of objects in memory which contain pointers to each other. (To stick with the spirit of the question, for whatever language you choose, you&#039;d want to disallow use of any large external batch of information like a &quot;standard library&quot;, except for whatever is so basic that you think of it as part of the native language. This is not a serious handicap for this problem.)

The main things that the program &#039;U&#039; (I&#039;d rather call the program itself &#039;U&#039; than call its length &#039;U&#039;) needs to do are:

- recognize a syntactically correct statement or proof;

- check the validity of a purported proof;

- recognize certain statements as saying or implying &quot;The Kolmogorov complexity of n is more than i&quot; for some n and i. (It&#039;s not necessary to recognize all such statements, just at least one for each n and i; so it can just recognize a statement that consists of some template with specific values of n and i inserted into it at certain places.)

Assuming that U expresses the proofs it wants to check in a practical proof language (which will be more like what a practical theorem-prover like Coq uses than like what a traditional logician would recognize as &quot;straight Peano arithmetic&quot;, but which will not be excessively powerful in the spirit of this question), I&#039;d estimate that the most complex part is checking proof validity, but that that can still be expressed in at most a few dozen syntactic rules, each expressible in a few lines of code. (The authors of a system like Coq, which includes code to actually do that, would know better, as long as they remember that the vast majority of their system&#039;s actual code is not needed for this problem.)

This makes me think that even without trying to compact it much, in a reasonable language we could write U in a few hundred lines of code, or (after a bit of simple compression) a few thousand bytes. (And perhaps much less if we tried hard to compact the whole program in clever ways.)

So L will also be &quot;a few thousand&quot; (bytes or digits), or perhaps less, rather than some number you can never possibly count to.

For comparison:

- Bill Gates&#039; first commercial success was an implementation of a useful version of BASIC in about 4000 bytes;

- 4k programs (4096 bytes or less) can produce graphical animations like this one http://www.youtube.com/watch?v=FWmv1ykGzis (to be fair, the complexity of some of the OS, graphics drivers, and hardware should be included, but this is a lot less than you might think if you imagine rewriting it purely for compactness rather than for speed, and only including what this sort of program needs to produce output);

- the complete genetic code of an organism can be as short as a few hundred thousand bytes, and that has to be encoded in a way that doesn&#039;t allow for highly clever compression schemes.

So this answers my question, as precisely as I cared about. (The key point I didn&#039;t know when I asked it was that it was basically just asking how complex a program like U needs to be.) In fact, given your description of Chaitin&#039;s book, I&#039;d be surprised if he doesn&#039;t include a concrete version of a program that could be U, and therefore directly come up with a specific legal value for L.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8164">John Baez</a>.</p>
<p>I don&#8217;t think it can be done in C, since C semantics are not well-defined unless you specify a particular finite machine size. (Since C programs can do things like convert pointers to integers and back, tell you the size of any datatype, and convert data of any specified datatype to bytes and back.) On a finite machine of N bits, all programs either finish in time less than about 2**N or take forever.</p>
<p>But if you take &#8220;C without size-specific operations&#8221;, or a higher level language like Python, or for that matter a different sort of low-level language like a Turing machine, then that&#8217;s not an issue &#8212; you can define a precise semantics that allows it to run a program for an arbitrarily long time and allocate an arbitrary number of objects in memory which contain pointers to each other. (To stick with the spirit of the question, for whatever language you choose, you&#8217;d want to disallow use of any large external batch of information like a &#8220;standard library&#8221;, except for whatever is so basic that you think of it as part of the native language. This is not a serious handicap for this problem.)</p>
<p>The main things that the program &#8216;U&#8217; (I&#8217;d rather call the program itself &#8216;U&#8217; than call its length &#8216;U&#8217;) needs to do are:</p>
<p>&#8211; recognize a syntactically correct statement or proof;</p>
<p>&#8211; check the validity of a purported proof;</p>
<p>&#8211; recognize certain statements as saying or implying &#8220;The Kolmogorov complexity of n is more than i&#8221; for some n and i. (It&#8217;s not necessary to recognize all such statements, just at least one for each n and i; so it can just recognize a statement that consists of some template with specific values of n and i inserted into it at certain places.)</p>
<p>Assuming that U expresses the proofs it wants to check in a practical proof language (which will be more like what a practical theorem-prover like Coq uses than like what a traditional logician would recognize as &#8220;straight Peano arithmetic&#8221;, but which will not be excessively powerful in the spirit of this question), I&#8217;d estimate that the most complex part is checking proof validity, but that that can still be expressed in at most a few dozen syntactic rules, each expressible in a few lines of code. (The authors of a system like Coq, which includes code to actually do that, would know better, as long as they remember that the vast majority of their system&#8217;s actual code is not needed for this problem.)</p>
<p>This makes me think that even without trying to compact it much, in a reasonable language we could write U in a few hundred lines of code, or (after a bit of simple compression) a few thousand bytes. (And perhaps much less if we tried hard to compact the whole program in clever ways.)</p>
<p>So L will also be &#8220;a few thousand&#8221; (bytes or digits), or perhaps less, rather than some number you can never possibly count to.</p>
<p>For comparison:</p>
<p>&#8211; Bill Gates&#8217; first commercial success was an implementation of a useful version of BASIC in about 4000 bytes;</p>
<p>&#8211; 4k programs (4096 bytes or less) can produce graphical animations like this one <a href="http://www.youtube.com/watch?v=FWmv1ykGzis" rel="nofollow ugc">http://www.youtube.com/watch?v=FWmv1ykGzis</a> (to be fair, the complexity of some of the OS, graphics drivers, and hardware should be included, but this is a lot less than you might think if you imagine rewriting it purely for compactness rather than for speed, and only including what this sort of program needs to produce output);</p>
<p>&#8211; the complete genetic code of an organism can be as short as a few hundred thousand bytes, and that has to be encoded in a way that doesn&#8217;t allow for highly clever compression schemes.</p>
<p>So this answers my question, as precisely as I cared about. (The key point I didn&#8217;t know when I asked it was that it was basically just asking how complex a program like U needs to be.) In fact, given your description of Chaitin&#8217;s book, I&#8217;d be surprised if he doesn&#8217;t include a concrete version of a program that could be U, and therefore directly come up with a specific legal value for L.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8172</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sun, 09 Oct 2011 01:40:56 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5442#comment-8172</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8169&quot;&gt;Roger Witte&lt;/a&gt;.

From my description &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8164&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;, I&#039;m sure that L = 10&lt;sup&gt;&lt;/sup&gt;&lt;sup&gt;9&lt;/sup&gt; works.  

But a good programmer who has studied some logic (like Bruce) could probably guess whether L = 10&lt;sup&gt;&lt;/sup&gt;&lt;sup&gt;6&lt;/sup&gt;, 10&lt;sup&gt;&lt;/sup&gt;&lt;sup&gt;5&lt;/sup&gt; or even some smaller value works!]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8169">Roger Witte</a>.</p>
<p>From my description <a href="https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8164" rel="nofollow">here</a>, I&#8217;m sure that L = 10<sup></sup><sup>9</sup> works.  </p>
<p>But a good programmer who has studied some logic (like Bruce) could probably guess whether L = 10<sup></sup><sup>6</sup>, 10<sup></sup><sup>5</sup> or even some smaller value works!</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8171</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sun, 09 Oct 2011 01:12:21 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5442#comment-8171</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8169&quot;&gt;Roger Witte&lt;/a&gt;.

As the Wikipedia article and I explained, you can explicitly compute a constant L such that Peano arithmetic can’t prove any natural number requires a C program more than L characters long to print it out.   

It may be impossible to compute the &lt;i&gt;smallest&lt;/i&gt; such constant L---that would be an interesting result which I haven&#039;t seen.  However, as &#039;some guy in the street&#039; &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8160&quot; rel=&quot;nofollow&quot;&gt;pointed out&lt;/a&gt;, if some constant does the job then so does any larger constant.  I&#039;m merely asserting that &lt;i&gt;some&lt;/i&gt; such constant does the job and can be explicitly computed.

The halting problem and the incomputability of Kolmogorov complexity are no obstacle here.  Indeed, they underlie everything we&#039;re discussing. 

Chaitin&#039;s theorem says that not only is Kolmogorov complexity uncomputable, there&#039;s no way to prove it takes any value bigger than L, even though it does so in all but finitely many cases.  This is an extremely strong form of uncomputability!]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8169">Roger Witte</a>.</p>
<p>As the Wikipedia article and I explained, you can explicitly compute a constant L such that Peano arithmetic can’t prove any natural number requires a C program more than L characters long to print it out.   </p>
<p>It may be impossible to compute the <i>smallest</i> such constant L&#8212;that would be an interesting result which I haven&#8217;t seen.  However, as &#8216;some guy in the street&#8217; <a href="https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8160" rel="nofollow">pointed out</a>, if some constant does the job then so does any larger constant.  I&#8217;m merely asserting that <i>some</i> such constant does the job and can be explicitly computed.</p>
<p>The halting problem and the incomputability of Kolmogorov complexity are no obstacle here.  Indeed, they underlie everything we&#8217;re discussing. </p>
<p>Chaitin&#8217;s theorem says that not only is Kolmogorov complexity uncomputable, there&#8217;s no way to prove it takes any value bigger than L, even though it does so in all but finitely many cases.  This is an extremely strong form of uncomputability!</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Roger Witte		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8169</link>

		<dc:creator><![CDATA[Roger Witte]]></dc:creator>
		<pubDate>Sun, 09 Oct 2011 00:51:55 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5442#comment-8169</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8164&quot;&gt;John Baez&lt;/a&gt;.

I don&#039;t think the program can be done.

There is a slight problem here.

The Kolmogrov Complexity is not a computable function:

&#8226; &lt;a href=&quot;http://en.wikipedia.org/wiki/Kolmogorov_complexity#Incomputability_of_Kolmogorov_complexity&quot; rel=&quot;nofollow&quot;&gt;3.1 Incomputability of Kolmogorov complexity&lt;/a&gt;, Wikipedia.

So will any particular such program run into issues such as halting problem?

So although I am convinced that for every n and s such that PA proves K(n)=s, s&#060;L I suspect that there may be some n for which PA cannot prove the values of K(n),

So rather than giving you an actual value L it only shows it would be contradictory for there not to be such a value (Since our reasoning is classical this is not a distinction ... isn&#039;t it weird that I now find this difficult to swallow when, 30 years ago during my BSc Mathematics course, I wouldn&#039;t have had difficulty percieving the distinction?).]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8164">John Baez</a>.</p>
<p>I don&#8217;t think the program can be done.</p>
<p>There is a slight problem here.</p>
<p>The Kolmogrov Complexity is not a computable function:</p>
<p>&bull; <a href="http://en.wikipedia.org/wiki/Kolmogorov_complexity#Incomputability_of_Kolmogorov_complexity" rel="nofollow">3.1 Incomputability of Kolmogorov complexity</a>, Wikipedia.</p>
<p>So will any particular such program run into issues such as halting problem?</p>
<p>So although I am convinced that for every n and s such that PA proves K(n)=s, s&lt;L I suspect that there may be some n for which PA cannot prove the values of K(n),</p>
<p>So rather than giving you an actual value L it only shows it would be contradictory for there not to be such a value (Since our reasoning is classical this is not a distinction &#8230; isn&#039;t it weird that I now find this difficult to swallow when, 30 years ago during my BSc Mathematics course, I wouldn&#039;t have had difficulty percieving the distinction?).</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8165</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sun, 09 Oct 2011 00:33:42 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5442#comment-8165</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8129&quot;&gt;Peter&lt;/a&gt;.

The &lt;a href=&quot;http://en.wikipedia.org/wiki/Halting_problem&quot; rel=&quot;nofollow&quot;&gt;uncomputability of the halting problem&lt;/a&gt; is crucial; it&#039;s the real reason for Chaitin&#039;s theorem and thus this spinoff.  We must constantly bear it in mind.  But it doesn&#039;t cause problems here.

At this stage in the proof we&#039;re assuming that only one number on our list is not printed out by a program of length ≤ L.  So, we can list all programs of length  ≤ L and do the following trick: 

let the 1st run one step, let the 2nd run one step,...  let the last run one step,

let the 1st run one step, let the 2nd run one step,...  let the last run one step,

and so on.  Some will never halt, and some will halt and print out numbers that aren&#039;t on our list.  But by our assumption, all but one of the numbers on our list will eventually get printed out... so then we know the &#039;culprit&#039;.

I didn&#039;t explain this very clearly before---thanks for pushing me to do so.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8129">Peter</a>.</p>
<p>The <a href="http://en.wikipedia.org/wiki/Halting_problem" rel="nofollow">uncomputability of the halting problem</a> is crucial; it&#8217;s the real reason for Chaitin&#8217;s theorem and thus this spinoff.  We must constantly bear it in mind.  But it doesn&#8217;t cause problems here.</p>
<p>At this stage in the proof we&#8217;re assuming that only one number on our list is not printed out by a program of length ≤ L.  So, we can list all programs of length  ≤ L and do the following trick: </p>
<p>let the 1st run one step, let the 2nd run one step,&#8230;  let the last run one step,</p>
<p>let the 1st run one step, let the 2nd run one step,&#8230;  let the last run one step,</p>
<p>and so on.  Some will never halt, and some will halt and print out numbers that aren&#8217;t on our list.  But by our assumption, all but one of the numbers on our list will eventually get printed out&#8230; so then we know the &#8216;culprit&#8217;.</p>
<p>I didn&#8217;t explain this very clearly before&#8212;thanks for pushing me to do so.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8164</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sun, 09 Oct 2011 00:18:12 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5442#comment-8164</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8118&quot;&gt;Bruce Smith&lt;/a&gt;.

Hi, Bruce!  I keep asking people to estimate $latex L$ for me, and nobody ever does.  It&#039;s possible Chaitin has, because he&#039;s written a book that works everything out very explicitly for a particular programming language. But I don&#039;t know.

To be precise: I want someone to give me a constant $latex L$ such that, say, Peano arithmetic can&#039;t prove any natural number requires a C program more than $latex L$ characters long to print it out.     

Since you&#039;re a programmer, maybe you can guess if I tell you this:

Any number $latex L$ with

$latex U + \log_n(L) + C &#060; L $

will do the job.  Here:

&#8226; $latex n$ is the base in which we write numbers in our programming language.  

&#8226; $latex U$ is the length of a program where you input a natural number $latex i$ and it tries to go through all proofs in Peano arithmetic until it finds one that proves some natural number has Kolmogorov complexity $latex \ge i$; then it outputs this number.  (Of course, for the value of $latex i$ we care about, it will not halt.)

&#8226; $latex C$ is a small overhead cost: the length of the extra &#039;glue&#039; to create a bigger program that takes the number $latex L$, written out in our chosen base, and feeds it into the program described above.  

This bigger program thus has length 

$latex U + \log_n(L) + C,$ 

and for the &lt;a href=&quot;http://en.wikipedia.org/wiki/Kolmogorov_complexity#Chaitin.27s_incompleteness_theorem&quot; rel=&quot;nofollow&quot;&gt;proof&lt;/a&gt; to work we need this to be smaller than $latex L.$

The bulk of the problem is getting an upper bound on $latex U.$  The number $latex L$ is just a bit bigger, surely smaller than $latex 2 U.$

Anyone want to take a crack at it?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8118">Bruce Smith</a>.</p>
<p>Hi, Bruce!  I keep asking people to estimate <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" /> for me, and nobody ever does.  It&#8217;s possible Chaitin has, because he&#8217;s written a book that works everything out very explicitly for a particular programming language. But I don&#8217;t know.</p>
<p>To be precise: I want someone to give me a constant <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" /> such that, say, Peano arithmetic can&#8217;t prove any natural number requires a C program more than <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" /> characters long to print it out.     </p>
<p>Since you&#8217;re a programmer, maybe you can guess if I tell you this:</p>
<p>Any number <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" /> with</p>
<p><img src="https://s0.wp.com/latex.php?latex=U+%2B+%5Clog_n%28L%29+%2B+C+%3C+L+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="U + &#92;log_n(L) + C &lt; L " class="latex" /></p>
<p>will do the job.  Here:</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> is the base in which we write numbers in our programming language.  </p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=U&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="U" class="latex" /> is the length of a program where you input a natural number <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> and it tries to go through all proofs in Peano arithmetic until it finds one that proves some natural number has Kolmogorov complexity <img src="https://s0.wp.com/latex.php?latex=%5Cge+i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;ge i" class="latex" />; then it outputs this number.  (Of course, for the value of <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> we care about, it will not halt.)</p>
<p>&bull; <img src="https://s0.wp.com/latex.php?latex=C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="C" class="latex" /> is a small overhead cost: the length of the extra &#039;glue&#039; to create a bigger program that takes the number <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" />, written out in our chosen base, and feeds it into the program described above.  </p>
<p>This bigger program thus has length </p>
<p><img src="https://s0.wp.com/latex.php?latex=U+%2B+%5Clog_n%28L%29+%2B+C%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="U + &#92;log_n(L) + C," class="latex" /> </p>
<p>and for the <a href="http://en.wikipedia.org/wiki/Kolmogorov_complexity#Chaitin.27s_incompleteness_theorem" rel="nofollow">proof</a> to work we need this to be smaller than <img src="https://s0.wp.com/latex.php?latex=L.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L." class="latex" /></p>
<p>The bulk of the problem is getting an upper bound on <img src="https://s0.wp.com/latex.php?latex=U.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="U." class="latex" />  The number <img src="https://s0.wp.com/latex.php?latex=L&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="L" class="latex" /> is just a bit bigger, surely smaller than <img src="https://s0.wp.com/latex.php?latex=2+U.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="2 U." class="latex" /></p>
<p>Anyone want to take a crack at it?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: some guy on the street		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8160</link>

		<dc:creator><![CDATA[some guy on the street]]></dc:creator>
		<pubDate>Sat, 08 Oct 2011 21:12:26 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=5442#comment-8160</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8118&quot;&gt;Bruce Smith&lt;/a&gt;.

Actually, any explicit upper bound for whatever you&#039;re calling L is itself a perfectly good explicit unprovable complexity: if for no x can T prove that K(x)&#062;L, then a fortiori for no x can it prove K(x) &#062; L+1.

That is, Chaitin&#039;s theorem doesn&#039;t need to find the minimal unprovable complexity to give explicit true non-theorems!]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/10/06/chaitins-theorem-and-the-surprise-examination-paradox/#comment-8118">Bruce Smith</a>.</p>
<p>Actually, any explicit upper bound for whatever you&#8217;re calling L is itself a perfectly good explicit unprovable complexity: if for no x can T prove that K(x)&gt;L, then a fortiori for no x can it prove K(x) &gt; L+1.</p>
<p>That is, Chaitin&#8217;s theorem doesn&#8217;t need to find the minimal unprovable complexity to give explicit true non-theorems!</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

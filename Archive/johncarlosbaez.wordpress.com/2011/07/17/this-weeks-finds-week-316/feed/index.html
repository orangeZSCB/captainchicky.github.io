<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: This Week&#8217;s Finds (Week 316)	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/</link>
	<description></description>
	<lastBuildDate>Mon, 10 Oct 2011 03:04:34 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: Terry Bollinger		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-8199</link>

		<dc:creator><![CDATA[Terry Bollinger]]></dc:creator>
		<pubDate>Mon, 10 Oct 2011 03:04:34 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=4415#comment-8199</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6906&quot;&gt;Graham&lt;/a&gt;.

@ George Church Oct 9, 2011:

George, thanks for the &lt;i&gt;Nature&lt;/i&gt; reference. I&#039;m involved in some re-assessment of simulated evolutionary methods, and some of the real-world techniques this article describes may have relevance. Also, while I&#039;m at it:

@ Graham July 21, 2011:

Optimization is always a mixed blessing, one that in general gains improved performance within a narrow range of problems at the expense of generality and/or adaptability for some larger range of problems. Think race horses, but the examples are far broader and go far deeper than that. I&#039;m convinced that one of the big tricks that we still don&#039;t understand well in genetics and biology in general is some sort of rather splendid balancing act that looks at performance, generality, and adaptability as an interrelated suite of optimizations that works well not just individually, but in the overall composition and competition of many, many organizations, each with its own particular balance. E.g. look at fast mutation in RNA viruses versus stability in DNA viruses. Which is right? Neither, I suspect, at least not on any absolute scale. The question is whether each one does well at accessing a niche created by that overall interaction of many, many factors, including in particular other forms of life.

There is a big opportunity in all of this for energy methods based on bio-modification, since as fast moving and sentient directors of molecular evolution we can access extreme optimizations that without special support would almost certainly be fatal competitively, and so do not occur naturally. That is something we should keep an eye out for when trying to use biology to solve the deeper problem of how to create a more virtuous energy capture and use cycle.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6906">Graham</a>.</p>
<p>@ George Church Oct 9, 2011:</p>
<p>George, thanks for the <i>Nature</i> reference. I&#8217;m involved in some re-assessment of simulated evolutionary methods, and some of the real-world techniques this article describes may have relevance. Also, while I&#8217;m at it:</p>
<p>@ Graham July 21, 2011:</p>
<p>Optimization is always a mixed blessing, one that in general gains improved performance within a narrow range of problems at the expense of generality and/or adaptability for some larger range of problems. Think race horses, but the examples are far broader and go far deeper than that. I&#8217;m convinced that one of the big tricks that we still don&#8217;t understand well in genetics and biology in general is some sort of rather splendid balancing act that looks at performance, generality, and adaptability as an interrelated suite of optimizations that works well not just individually, but in the overall composition and competition of many, many organizations, each with its own particular balance. E.g. look at fast mutation in RNA viruses versus stability in DNA viruses. Which is right? Neither, I suspect, at least not on any absolute scale. The question is whether each one does well at accessing a niche created by that overall interaction of many, many factors, including in particular other forms of life.</p>
<p>There is a big opportunity in all of this for energy methods based on bio-modification, since as fast moving and sentient directors of molecular evolution we can access extreme optimizations that without special support would almost certainly be fatal competitively, and so do not occur naturally. That is something we should keep an eye out for when trying to use biology to solve the deeper problem of how to create a more virtuous energy capture and use cycle.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: George Church		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-8189</link>

		<dc:creator><![CDATA[George Church]]></dc:creator>
		<pubDate>Sun, 09 Oct 2011 19:06:34 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=4415#comment-8189</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6906&quot;&gt;Graham&lt;/a&gt;.

Both MAGE and whole genome assembly (WGA) can (in principle) make whatever genome that you want. In practice, this is more like writing software in which considerable testing and debugging is required the further you get away from a working design.  So you need to make billions of combinations, check those that work, make some more, etc.  This is very inexpensive with MAGE -- 4.3 billion genomes per $1000 rather than $4 million per one genome.  http://www.nature.com/nature/journal/v460/n7257/full/nature08187.html]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6906">Graham</a>.</p>
<p>Both MAGE and whole genome assembly (WGA) can (in principle) make whatever genome that you want. In practice, this is more like writing software in which considerable testing and debugging is required the further you get away from a working design.  So you need to make billions of combinations, check those that work, make some more, etc.  This is very inexpensive with MAGE &#8212; 4.3 billion genomes per $1000 rather than $4 million per one genome.  <a href="http://www.nature.com/nature/journal/v460/n7257/full/nature08187.html" rel="nofollow ugc">http://www.nature.com/nature/journal/v460/n7257/full/nature08187.html</a></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: randform &#187; Blog Archive &#187; destructive sides of the power of science		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-7063</link>

		<dc:creator><![CDATA[randform &#187; Blog Archive &#187; destructive sides of the power of science]]></dc:creator>
		<pubDate>Sun, 07 Aug 2011 06:44:26 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=4415#comment-7063</guid>

					<description><![CDATA[[...] A second comment is related to the Manhattan project itself but also to the dangers of biotechnology. [...]]]></description>
			<content:encoded><![CDATA[<p>[&#8230;] A second comment is related to the Manhattan project itself but also to the dangers of biotechnology. [&#8230;]</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6911</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Fri, 22 Jul 2011 03:46:18 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=4415#comment-6911</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6904&quot;&gt;Bill&lt;/a&gt;.

Wow, what a great reply!  I&#039;m glad my pleas led you to delurk.

I have a few questions. At first this passage stumped me:

&lt;blockquote&gt;
The amber codon was discovered through its suppressor mutation, a change in the anticodon of a tRNA that allowed it to recognize the amber codon (UAG). 
&lt;/blockquote&gt;

But maybe now I get it.  The modified tRNA was able to recognize the amber codon and create an amino acid from it, thus &#039;suppressing&#039; its actual function as a stop codon?

(At first I didn&#039;t get how &#039;recognizing&#039; counted as &#039;suppressing&#039;.)

&lt;blockquote&gt;
For amber mutations, the efficiency of suppression is ~30% for the good suppressors.
&lt;/blockquote&gt;

So you&#039;re saying that at most 30% of the amber codons get &#039;read through&#039; and translated into an amino acid, while the rest still act as stop codons.  

&lt;blockquote&gt;
However, ~1/1000 incoming phage do survive (it’s a kinetic race between modification and digestion) and the progeny from that infection will have the new modification but not the old one. 
&lt;/blockquote&gt;

Does &quot;have the new modification&quot; mean &quot;have a methyl group attached to a base in the recognition site of the restriction enzyme&quot;?  I&#039;m a bit confused because I don&#039;t understand whether this modification in the phage&#039;s DNA is something a bacterium does to help kill the phage, or something a phage needs to have to keep from being killed.  Your passage above makes it sound like the progeny have this modification yet survive.

On a vastly lesser note, I was surprised to discover that &#039;phage&#039; is used as a plural noun as well as singular. It&#039;s also true for &#039;sheep&#039; and &#039;fish&#039;, but those are old Anglo-Saxon words for creatures that come in herds (or schools), so they function as mass nouns like `mud&#039; or &#039;water&#039;: we might say &quot;a lot of fish swimming in a lot of water&quot;.  I suppose there are so many phages that they deserve to be treated as a mass noun, but it must have taken someone bold (or uneducated) to be the first to try that with a Greek-derived word!  &lt;img src=&quot;http://math.ucr.edu/home/baez/emoticons/tongue2.gif&quot; alt=&quot;&quot; /&gt;

&lt;blockquote&gt;
I have been interested in what you have been talking about and have some ideas. But that will come later. 
&lt;/blockquote&gt;

Okay, great.  I&#039;m looking forward to it.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6904">Bill</a>.</p>
<p>Wow, what a great reply!  I&#8217;m glad my pleas led you to delurk.</p>
<p>I have a few questions. At first this passage stumped me:</p>
<blockquote><p>
The amber codon was discovered through its suppressor mutation, a change in the anticodon of a tRNA that allowed it to recognize the amber codon (UAG).
</p></blockquote>
<p>But maybe now I get it.  The modified tRNA was able to recognize the amber codon and create an amino acid from it, thus &#8216;suppressing&#8217; its actual function as a stop codon?</p>
<p>(At first I didn&#8217;t get how &#8216;recognizing&#8217; counted as &#8216;suppressing&#8217;.)</p>
<blockquote><p>
For amber mutations, the efficiency of suppression is ~30% for the good suppressors.
</p></blockquote>
<p>So you&#8217;re saying that at most 30% of the amber codons get &#8216;read through&#8217; and translated into an amino acid, while the rest still act as stop codons.  </p>
<blockquote><p>
However, ~1/1000 incoming phage do survive (it’s a kinetic race between modification and digestion) and the progeny from that infection will have the new modification but not the old one.
</p></blockquote>
<p>Does &#8220;have the new modification&#8221; mean &#8220;have a methyl group attached to a base in the recognition site of the restriction enzyme&#8221;?  I&#8217;m a bit confused because I don&#8217;t understand whether this modification in the phage&#8217;s DNA is something a bacterium does to help kill the phage, or something a phage needs to have to keep from being killed.  Your passage above makes it sound like the progeny have this modification yet survive.</p>
<p>On a vastly lesser note, I was surprised to discover that &#8216;phage&#8217; is used as a plural noun as well as singular. It&#8217;s also true for &#8216;sheep&#8217; and &#8216;fish&#8217;, but those are old Anglo-Saxon words for creatures that come in herds (or schools), so they function as mass nouns like `mud&#8217; or &#8216;water&#8217;: we might say &#8220;a lot of fish swimming in a lot of water&#8221;.  I suppose there are so many phages that they deserve to be treated as a mass noun, but it must have taken someone bold (or uneducated) to be the first to try that with a Greek-derived word!  <img src="https://i1.wp.com/math.ucr.edu/home/baez/emoticons/tongue2.gif" alt="" /></p>
<blockquote><p>
I have been interested in what you have been talking about and have some ideas. But that will come later.
</p></blockquote>
<p>Okay, great.  I&#8217;m looking forward to it.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Bill		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6904</link>

		<dc:creator><![CDATA[Bill]]></dc:creator>
		<pubDate>Thu, 21 Jul 2011 23:52:28 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=4415#comment-6904</guid>

					<description><![CDATA[As a mathematics major turned biologist, I have been lurking here for a while.  My topology is really rusty since it has been &#062;30 yrs since I took the course, along with basic algebra, as an undergraduate.  I have been interested in what you have been talking about and have some ideas.  But that will come later. First, some answers to your questions.

&lt;blockquote&gt;
• What did people actually do with that strain of E. coli that ‘reads through’ amber?
&lt;/blockquote&gt;

Nonsense mutations and suppressors.  Nonsense mutations have a change of a codon for an amino acid to a stop codon (TAA, TGA, TAG).  These were among the last codons to be described (mid 60&#039;s).  The amber codon was discovered through its suppressor mutation, a change in the anticodon of a tRNA that allowed it to recognize the amber codon (UAG).  These suppressor strains were an essential component of the microbial geneticist&#039;s tool kit for quite a while, especially for bacteriophage geneticists.  Isolating an amber mutation in a bacteriophage in your gene of interest allowed you to grow the phage and then infect a wild type strain.  Without the presence of the suppressor, the mutant phage would no longer express that gene and one could then do experiments to determine the gene&#039;s function.  Such a mutation is referred to as a conditional lethal.  Another widely used conditional lethal are temperature sensitive mutants (ts).

Many, many more conditional lethals have been developed for many different systems, and these have been invaluable to microbial geneticists (and here I include yeast genetics).  The basic game played is one that takes + --&#062; - and then - --&#062; +.  For example, say you have isolated a mutation that affects a certain process.  What other proteins are involved in the process?  One way of isolating mutations in other genes is to find extragenic suppressor mutations that restore function (- --&#062; +).  With new genes, the whole game can be played again to define the network of genes for a given process.  

When this sort of technology is combined with biochemistry, it provides a very powerful tool for studying fundamental biological processes.  It&#039;s no wonder that &lt;i&gt;E. coli&lt;/i&gt; (Gram negative), &lt;i&gt;B. subtilis&lt;/i&gt; (Gram positive), &lt;i&gt;S. cerevisiae&lt;/i&gt; (baker&#039;s/brewer&#039;s yeast) and &lt;i&gt;S. pombe&lt;/i&gt; (fission yeast) have been the model organisms of choice.

&lt;blockquote&gt;
• How could such a strain be viable, anyway?
&lt;/blockquote&gt;

For amber mutations, the efficiency of suppression is ~30 % for the good suppressors.  Also, there are only ~300 amber stop codons in &lt;i&gt;E. coli&lt;/i&gt;.  Thus, relatively few proteins will be affected.  Moreover, a second stop codon in the same reading frame will soon terminate translation leading to a normal protein with some length of junk on the end.  Their are several different fates.

First, the extra sequence could have no or little effect on protein function.  Indeed, this is often the case, and biologists have taken advantage of this to create genes encoding protein-protein hybrids.  One type of fusion has changed the face of cell biology: GFP fusion.  Here, the gene encoding GFP (green fluorescent protein) is placed in the same reading frame downstream of your gene of interest with its stop codon removed, creating a C-terminal fusion.  Similarly, GFP can be placed upstream, creating an N-terminal fusion.  When expressed in a cell, the location of the GFP (and presumably the fusion) can be followed in real time in live cells.  This is only one use of GFP (and the rainbow of color variants) and new uses are invented all the time.  

Second, the extra protein sequence could have a detrimental effect on the protein&#039;s function.  However, since 70% of the time translation is terminated normally, there is enough good protein to provide the needed function for the cell.  This is analogous to recessive mutations, but in this case the mutant protein and the wild type are expressed from the same gene.

Third, the extra sequence could prevent the protein from folding properly.  This is usually not a problem for E. coli, or any other organism, since it contains systems that deal with unfolded or improperly folded proteins.  First, chaperon proteins attach and try to refold the protein, but if this is unsuccessful, the protein will be taken to a conserved molecular machine that digests the protein back to amino acids, the molecular equivalent to a paper shredder.  Even if this system is overwhelmed by over production of a foreign protein, &lt;i&gt;E. coli&lt;/i&gt; effectively segregates the protein into what are called &#039;inclusion bodies&#039;.  We take advantage of this for protein purification purposes since inclusion bodies are easy to isolate.  The hard part is getting the protein back into solution and folded properly.

&lt;blockquote&gt;
• What are some of the coolest possible applications of this new MAGE/CAGE technology?
&lt;/blockquote&gt;

The goals of Farren Isaacs &#038; George Church and Jennifer Normanly &#038; Jeffrey Miller are related.  Normanly and Miller&#039;s goal was motivated back in the days when genetic engineering was complicated and tedious.  Essentially, their thought was that if one wanted to isolate mutations in a protein, you were always limited to those mutations that you could identify in your selection and screening procedure.  However, one could isolate a collection of amber mutants across the gene and then use different amber suppressor strains that substituted a different amino acid into the site.  The ideal situation would have been to be able to substitute each of the 19 other amino acids.  Unfortunately, nature provided several roadblocks.  One I know of is charging of amino acids to their cognate tRNAs by the synthetases.  Some of them use the anticodon to select the proper tRNA for charging; change the anticodon and you get mischarging or little charging at all.  When the project reached this point, the paper that you cite, PCR and other techniques essentially made mutagenesis easy, so the Normanly &#038; Miller  technique was not widely used.  Good idea at the time.

The goals of Isaacs &#038; Church are more far reaching.  Elimination of all of the amber stops will allow, as you surmised, the placement of that codon anywhere within a gene.  In other related work, using frame shifting tRNAs, people have started to develop amino acyl-tRNA synthetases that will charge non-native amino acids onto tRNAs.  It is hoped that this can expand the catalytic range of enzymes, plus a whole bunch of other applications (novel peptide drugs comes to mind).  The disadvantage of the frame shifting approach is that it is inefficient and if one made it efficient it would probably kill the cell.  In contrast, the Isaacs &#038; Church approach avoids this difficulty in two ways.  Once all of the used amber stop codons are eliminated, you can then safely remove the protein factor that recognizes UAG.  There are two translation termination factors in E. coli RF-1 and RF-2.  The these proteins that assume the shape of a tRNA and bind to the stop codon in the A-site of the translating ribosome.  One RF recognizes UAA and UGA and the other UAA and UAG.  Eliminating the latter will free up UAG for aa-tRNA binding and eliminate termination at UAG.  Thus, 100% efficiency of inserting the desired amino acid into a site is at least theoretically possible.  But as with everything in biology, who knows what can go wrong.

&lt;blockquote&gt;
• What could the effects be? For example, if the &lt;i&gt;E. coli&lt;/i&gt; in my gut became virus-resistant, would their populations grow enough to make me notice?
• If we released a strain of virus-resistant &lt;i&gt;E. coli&lt;/i&gt; into the wild, could it take over, thanks to this advantage?
&lt;/blockquote&gt;

It is unlikely that these sorts of modifications could make E. coli virus resistant.  It&#039;s analogous to the LHC creating a black hole that will gobble the earth up.  Bacteria and viruses have been around for 4 billion years, and thus far, no virus resistant bacteria have ever been discovered or have taken over an ecosystem.  Bacteria can become resistant to a particular strains of phage, but never to all phage.  

Bacteria do possess several defense mechanisms to inhibit incoming phage.  The best studied is the restriction/modification system.  This is a two gene system. One gene encodes a site specific DNAase that specifically cuts DNA.  Discovery of these enzymes led to the first wave of genetic engineering of the cut and paste variety.  The second gene encodes a DNA modifying enzyme that adds a methyl group to a base in the recognition site of the restriction enzyme.  Different strains of bacteria have different restriction/modification systems.  Thus, an incoming virus that grew on a cell with one system will not have the new host&#039;s modification and thus will be digested.  However, ~1/1000 incoming phage do survive (it&#039;s a kinetic race between modification and digestion) and the progeny from that infection will have the new modification but not the old one.  There is a plethora of defenses that phage have come up with to deal with this.

A second, defense mechanism is the CRSPR system.  It is really interesting but I have not read up on it, so I won&#039;t comment.

Finally, &lt;i&gt;E. coli&lt;/i&gt; is a wimp.  It is a minor member of the trillions of bacteria that live in your gut.  Mouse studies have shown that it inhabits the mucous lining the intestine near the cecum.  It normally grows there and nowhere else.  It uses mucous polysaccharides as an energy/carbon source and uses the Entner-Doudoroff pathway for glycolysis (not the Embden-Meyerhof-Parnas pathway that everyone learns in into-Bio).  Mutations in the ED pathway prevent &lt;i&gt;E. coli&lt;/i&gt; from colonizing a host, and once it is shed from the mucous layer, it no longer grows.  So even if you could get a virus resistant &lt;i&gt;E. coli&lt;/i&gt;, nothing much would happen.  

&lt;blockquote&gt;
• To what extent are &lt;i&gt;E. coli&lt;/i&gt; populations kept under control by phages, or perhaps somehow by other viruses [Nomeclature note: bacterial virus === bacteriophage === phage]?
&lt;/blockquote&gt;

The roles of phage in bacterial ecology are largely unknown.  It was only about 10 yrs ago that the number of phage present in the environment was first uncovered.  The numbers still addle my brain when I stop to think about it.  Take any surface water and you can find 10^5 - 10^7 phage/ml.  A popular estimate for the number of phage in the oceans is ~10^31.  For bacteria that are rapidly growing, I have seen estimates anywhere from 20 to 50% of the bacteria are killed off each day.  When a phage kills a bacterium, it causes the cell to burst and release the newly formed phage.  This also releases nutrients for other bacteria to consume, which are then eaten by the zooplanktonic grazers and on up the food chain.  

It&#039;s a no brainer to assume that bacteriophage are important players in carbon and other nutrient cycling.  For example, cyanobacteria blooms are measured by satellite and used in calculation of the uptake of CO&lt;sub&gt;2&lt;/sub&gt; into the ocean.  I haven&#039;t delved into the assumptions surrounding CO&lt;sub&gt;2&lt;/sub&gt; flux into and out of the ocean, and in one talk I heard, no one in the field has a good handle on it.  Experiments are just beginning.

A second role, is one of gene transfer.  While lytic phage just infect grow and kill their hosts, lysogenic phage, can grow in this manner but are also capable becoming quiescent, either integrating their DNA into the bacterial chromosome or by becoming a stable plasmid.  Lytic gene expression is turned off by a repressor protein that binds to the lytic gene promoter regions.  Some phage carry genes that are expressed in the lysogen. These can be beneficial, such as genes for photosynthesis and nitrogen fixation or harmful (from our perspective).  In many of the pathogenic &lt;i&gt;E. coli&lt;/i&gt;, the toxin genes were brought in by a lysogenic phage.  

There&#039;s a separate story on how the study of phage led to the development of MAGE/CAGE technology, but I have written too much.]]></description>
			<content:encoded><![CDATA[<p>As a mathematics major turned biologist, I have been lurking here for a while.  My topology is really rusty since it has been &gt;30 yrs since I took the course, along with basic algebra, as an undergraduate.  I have been interested in what you have been talking about and have some ideas.  But that will come later. First, some answers to your questions.</p>
<blockquote><p>
• What did people actually do with that strain of E. coli that ‘reads through’ amber?
</p></blockquote>
<p>Nonsense mutations and suppressors.  Nonsense mutations have a change of a codon for an amino acid to a stop codon (TAA, TGA, TAG).  These were among the last codons to be described (mid 60&#8217;s).  The amber codon was discovered through its suppressor mutation, a change in the anticodon of a tRNA that allowed it to recognize the amber codon (UAG).  These suppressor strains were an essential component of the microbial geneticist&#8217;s tool kit for quite a while, especially for bacteriophage geneticists.  Isolating an amber mutation in a bacteriophage in your gene of interest allowed you to grow the phage and then infect a wild type strain.  Without the presence of the suppressor, the mutant phage would no longer express that gene and one could then do experiments to determine the gene&#8217;s function.  Such a mutation is referred to as a conditional lethal.  Another widely used conditional lethal are temperature sensitive mutants (ts).</p>
<p>Many, many more conditional lethals have been developed for many different systems, and these have been invaluable to microbial geneticists (and here I include yeast genetics).  The basic game played is one that takes + &#8211;&gt; &#8211; and then &#8211; &#8211;&gt; +.  For example, say you have isolated a mutation that affects a certain process.  What other proteins are involved in the process?  One way of isolating mutations in other genes is to find extragenic suppressor mutations that restore function (- &#8211;&gt; +).  With new genes, the whole game can be played again to define the network of genes for a given process.  </p>
<p>When this sort of technology is combined with biochemistry, it provides a very powerful tool for studying fundamental biological processes.  It&#8217;s no wonder that <i>E. coli</i> (Gram negative), <i>B. subtilis</i> (Gram positive), <i>S. cerevisiae</i> (baker&#8217;s/brewer&#8217;s yeast) and <i>S. pombe</i> (fission yeast) have been the model organisms of choice.</p>
<blockquote><p>
• How could such a strain be viable, anyway?
</p></blockquote>
<p>For amber mutations, the efficiency of suppression is ~30 % for the good suppressors.  Also, there are only ~300 amber stop codons in <i>E. coli</i>.  Thus, relatively few proteins will be affected.  Moreover, a second stop codon in the same reading frame will soon terminate translation leading to a normal protein with some length of junk on the end.  Their are several different fates.</p>
<p>First, the extra sequence could have no or little effect on protein function.  Indeed, this is often the case, and biologists have taken advantage of this to create genes encoding protein-protein hybrids.  One type of fusion has changed the face of cell biology: GFP fusion.  Here, the gene encoding GFP (green fluorescent protein) is placed in the same reading frame downstream of your gene of interest with its stop codon removed, creating a C-terminal fusion.  Similarly, GFP can be placed upstream, creating an N-terminal fusion.  When expressed in a cell, the location of the GFP (and presumably the fusion) can be followed in real time in live cells.  This is only one use of GFP (and the rainbow of color variants) and new uses are invented all the time.  </p>
<p>Second, the extra protein sequence could have a detrimental effect on the protein&#8217;s function.  However, since 70% of the time translation is terminated normally, there is enough good protein to provide the needed function for the cell.  This is analogous to recessive mutations, but in this case the mutant protein and the wild type are expressed from the same gene.</p>
<p>Third, the extra sequence could prevent the protein from folding properly.  This is usually not a problem for E. coli, or any other organism, since it contains systems that deal with unfolded or improperly folded proteins.  First, chaperon proteins attach and try to refold the protein, but if this is unsuccessful, the protein will be taken to a conserved molecular machine that digests the protein back to amino acids, the molecular equivalent to a paper shredder.  Even if this system is overwhelmed by over production of a foreign protein, <i>E. coli</i> effectively segregates the protein into what are called &#8216;inclusion bodies&#8217;.  We take advantage of this for protein purification purposes since inclusion bodies are easy to isolate.  The hard part is getting the protein back into solution and folded properly.</p>
<blockquote><p>
• What are some of the coolest possible applications of this new MAGE/CAGE technology?
</p></blockquote>
<p>The goals of Farren Isaacs &amp; George Church and Jennifer Normanly &amp; Jeffrey Miller are related.  Normanly and Miller&#8217;s goal was motivated back in the days when genetic engineering was complicated and tedious.  Essentially, their thought was that if one wanted to isolate mutations in a protein, you were always limited to those mutations that you could identify in your selection and screening procedure.  However, one could isolate a collection of amber mutants across the gene and then use different amber suppressor strains that substituted a different amino acid into the site.  The ideal situation would have been to be able to substitute each of the 19 other amino acids.  Unfortunately, nature provided several roadblocks.  One I know of is charging of amino acids to their cognate tRNAs by the synthetases.  Some of them use the anticodon to select the proper tRNA for charging; change the anticodon and you get mischarging or little charging at all.  When the project reached this point, the paper that you cite, PCR and other techniques essentially made mutagenesis easy, so the Normanly &amp; Miller  technique was not widely used.  Good idea at the time.</p>
<p>The goals of Isaacs &amp; Church are more far reaching.  Elimination of all of the amber stops will allow, as you surmised, the placement of that codon anywhere within a gene.  In other related work, using frame shifting tRNAs, people have started to develop amino acyl-tRNA synthetases that will charge non-native amino acids onto tRNAs.  It is hoped that this can expand the catalytic range of enzymes, plus a whole bunch of other applications (novel peptide drugs comes to mind).  The disadvantage of the frame shifting approach is that it is inefficient and if one made it efficient it would probably kill the cell.  In contrast, the Isaacs &amp; Church approach avoids this difficulty in two ways.  Once all of the used amber stop codons are eliminated, you can then safely remove the protein factor that recognizes UAG.  There are two translation termination factors in E. coli RF-1 and RF-2.  The these proteins that assume the shape of a tRNA and bind to the stop codon in the A-site of the translating ribosome.  One RF recognizes UAA and UGA and the other UAA and UAG.  Eliminating the latter will free up UAG for aa-tRNA binding and eliminate termination at UAG.  Thus, 100% efficiency of inserting the desired amino acid into a site is at least theoretically possible.  But as with everything in biology, who knows what can go wrong.</p>
<blockquote><p>
• What could the effects be? For example, if the <i>E. coli</i> in my gut became virus-resistant, would their populations grow enough to make me notice?<br />
• If we released a strain of virus-resistant <i>E. coli</i> into the wild, could it take over, thanks to this advantage?
</p></blockquote>
<p>It is unlikely that these sorts of modifications could make E. coli virus resistant.  It&#8217;s analogous to the LHC creating a black hole that will gobble the earth up.  Bacteria and viruses have been around for 4 billion years, and thus far, no virus resistant bacteria have ever been discovered or have taken over an ecosystem.  Bacteria can become resistant to a particular strains of phage, but never to all phage.  </p>
<p>Bacteria do possess several defense mechanisms to inhibit incoming phage.  The best studied is the restriction/modification system.  This is a two gene system. One gene encodes a site specific DNAase that specifically cuts DNA.  Discovery of these enzymes led to the first wave of genetic engineering of the cut and paste variety.  The second gene encodes a DNA modifying enzyme that adds a methyl group to a base in the recognition site of the restriction enzyme.  Different strains of bacteria have different restriction/modification systems.  Thus, an incoming virus that grew on a cell with one system will not have the new host&#8217;s modification and thus will be digested.  However, ~1/1000 incoming phage do survive (it&#8217;s a kinetic race between modification and digestion) and the progeny from that infection will have the new modification but not the old one.  There is a plethora of defenses that phage have come up with to deal with this.</p>
<p>A second, defense mechanism is the CRSPR system.  It is really interesting but I have not read up on it, so I won&#8217;t comment.</p>
<p>Finally, <i>E. coli</i> is a wimp.  It is a minor member of the trillions of bacteria that live in your gut.  Mouse studies have shown that it inhabits the mucous lining the intestine near the cecum.  It normally grows there and nowhere else.  It uses mucous polysaccharides as an energy/carbon source and uses the Entner-Doudoroff pathway for glycolysis (not the Embden-Meyerhof-Parnas pathway that everyone learns in into-Bio).  Mutations in the ED pathway prevent <i>E. coli</i> from colonizing a host, and once it is shed from the mucous layer, it no longer grows.  So even if you could get a virus resistant <i>E. coli</i>, nothing much would happen.  </p>
<blockquote><p>
• To what extent are <i>E. coli</i> populations kept under control by phages, or perhaps somehow by other viruses [Nomeclature note: bacterial virus === bacteriophage === phage]?
</p></blockquote>
<p>The roles of phage in bacterial ecology are largely unknown.  It was only about 10 yrs ago that the number of phage present in the environment was first uncovered.  The numbers still addle my brain when I stop to think about it.  Take any surface water and you can find 10^5 &#8211; 10^7 phage/ml.  A popular estimate for the number of phage in the oceans is ~10^31.  For bacteria that are rapidly growing, I have seen estimates anywhere from 20 to 50% of the bacteria are killed off each day.  When a phage kills a bacterium, it causes the cell to burst and release the newly formed phage.  This also releases nutrients for other bacteria to consume, which are then eaten by the zooplanktonic grazers and on up the food chain.  </p>
<p>It&#8217;s a no brainer to assume that bacteriophage are important players in carbon and other nutrient cycling.  For example, cyanobacteria blooms are measured by satellite and used in calculation of the uptake of CO<sub>2</sub> into the ocean.  I haven&#8217;t delved into the assumptions surrounding CO<sub>2</sub> flux into and out of the ocean, and in one talk I heard, no one in the field has a good handle on it.  Experiments are just beginning.</p>
<p>A second role, is one of gene transfer.  While lytic phage just infect grow and kill their hosts, lysogenic phage, can grow in this manner but are also capable becoming quiescent, either integrating their DNA into the bacterial chromosome or by becoming a stable plasmid.  Lytic gene expression is turned off by a repressor protein that binds to the lytic gene promoter regions.  Some phage carry genes that are expressed in the lysogen. These can be beneficial, such as genes for photosynthesis and nitrogen fixation or harmful (from our perspective).  In many of the pathogenic <i>E. coli</i>, the toxin genes were brought in by a lysogenic phage.  </p>
<p>There&#8217;s a separate story on how the study of phage led to the development of MAGE/CAGE technology, but I have written too much.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Graham		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6907</link>

		<dc:creator><![CDATA[Graham]]></dc:creator>
		<pubDate>Thu, 21 Jul 2011 18:44:27 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=4415#comment-6907</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6871&quot;&gt;John Baez&lt;/a&gt;.

nad - I was thinking of modifying Brian Eno&#039;s quote like that. But who is Brei?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6871">John Baez</a>.</p>
<p>nad &#8211; I was thinking of modifying Brian Eno&#8217;s quote like that. But who is Brei?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Graham		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6906</link>

		<dc:creator><![CDATA[Graham]]></dc:creator>
		<pubDate>Thu, 21 Jul 2011 18:41:59 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=4415#comment-6906</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6896&quot;&gt;John Baez&lt;/a&gt;.

I am not an expert on this stuff, and worse, there doesn&#039;t seem to be anybody reading this blog who is. But as I understand it:

You could type any string of As,Cs,Gs,Ts, into your word processor and Venter&#039;s technology would make an organism with  that DNA. It is more complicated than printing your document, and I don&#039;t think it is guaranteed to be entirely WYSIWYG, but that is the principle. It might take a few years and cost a few million, and of course it wouldn&#039;t work unless you knew what to type, but it seems extremely flexible. As far as I can see the MAGE/CAGE stuff can only do limited edits. For example, one thing I think that could be done with Venter&#039;s technology would be to remove the &#039;junk&#039; DNA from a bacteria, making a more efficient version that could outcompete the naturally occurring version.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6896">John Baez</a>.</p>
<p>I am not an expert on this stuff, and worse, there doesn&#8217;t seem to be anybody reading this blog who is. But as I understand it:</p>
<p>You could type any string of As,Cs,Gs,Ts, into your word processor and Venter&#8217;s technology would make an organism with  that DNA. It is more complicated than printing your document, and I don&#8217;t think it is guaranteed to be entirely WYSIWYG, but that is the principle. It might take a few years and cost a few million, and of course it wouldn&#8217;t work unless you knew what to type, but it seems extremely flexible. As far as I can see the MAGE/CAGE stuff can only do limited edits. For example, one thing I think that could be done with Venter&#8217;s technology would be to remove the &#8216;junk&#8217; DNA from a bacteria, making a more efficient version that could outcompete the naturally occurring version.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6896</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Thu, 21 Jul 2011 08:58:38 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=4415#comment-6896</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6828&quot;&gt;Graham&lt;/a&gt;.

Graham wrote:

&lt;blockquote&gt;
You would certainly notice if a virus-resistant pathogenic strain took over. There are outbreaks of these pathogenic strains of course, like the recent one in Germany. As far as I know, the reason these kill tens rather than millions is that they are outcompeted by benign strains.
&lt;/blockquote&gt;

Thanks for all your comments.
  
So, here&#039;s a scenario that came to mind.  A biotech company like Genzyme develops a version of &lt;i&gt;E. coli&lt;/i&gt; with a modified genetic code, to make it virus-resistant.  As Marc notes:

&lt;blockquote&gt;
... engineering a permanent resistance to viral infection would be a monumental feat. 
&lt;/blockquote&gt;

But maybe as long as the &lt;i&gt;E. coli&lt;/i&gt; are kept safely contained in the laboratory, they&#039;ll meet rather few challenges from viruses, so new strains of viruses able to hijack their genetic code won&#039;t evolve.  

But then, a sophisticated terrorist group obtains a sample of these modified &lt;i&gt;E. coli&lt;/i&gt;, and manages to make it more virulent, perhaps borrowing a virulence factor from &lt;a href=&quot;http://en.wikipedia.org/wiki/Escherichia_coli_O157:H7&quot; rel=&quot;nofollow&quot;&gt;&lt;i&gt;E. coli&lt;/i&gt; O157:H7&lt;/a&gt;: the pathogenic strain that caused that &lt;a href=&quot;http://en.wikipedia.org/wiki/2011_E._coli_O104:H4_outbreak&quot; rel=&quot;nofollow&quot;&gt;outbreak in Germany&lt;/a&gt; (and elsewhere in Europe).  

So, this new strain of &lt;i&gt;E. coli&lt;/i&gt; outcompetes the benign strains, spreads around the world, and kills millions...

Of course it would take some sophistication to take an &lt;i&gt;E. coli&lt;/i&gt; with a modified genetic code and give it genes from ordinary virulent &lt;i&gt;E. coli&lt;/i&gt;: you might need to translate those genes into the new code.  But maybe that wouldn&#039;t be extremely hard, if the new code was public knowledge!  I&#039;m not sure, since I&#039;m no expert.

On the other hand, HR wrote:

&lt;blockquote&gt;
I don’t know the answer to how much bacteria are controlled by bacteriophages in the wild but laboratory strains of bacteria are already engineered with multiple metabolic mutations which are meant to make their persistence in the environment difficult.
&lt;/blockquote&gt;

So, maybe we&#039;re safe.

By the way, apparently &lt;i&gt;E. coli&lt;/i&gt; O157:H7 has genes that produce a &lt;a href=&quot;http://en.wikipedia.org/wiki/Shiga-like_toxin&quot; rel=&quot;nofollow&quot;&gt;Shiga-like toxin&lt;/a&gt;, which kills cells lining small blood vessels and produces bloody diarrhea.  According to Wikipedia,

&lt;blockquote&gt;
Shiga-like toxins are iron-regulated toxins that catalytically inactivate 60S ribosomal subunits of eukaryotic cells, blocking mRNA translation and causing cell death. Shiga-like toxins are functionally identical to toxins produced by virulent &lt;i&gt;Shigella&lt;/i&gt; species. Strains of E. coli that express shiga-like toxins gained this ability due to infection with a prophage containing the structural coding for the toxin, and nonproducing strains may become infected and produce shiga-like toxins after incubation with shiga toxin positive strains. The prophage responsible seems to have infected the strain&#039;s ancestors fairly recently, as viral particles have been observed to replicate in the host if it is stressed in some way (e.g. antibiotics). The periplasmic catalase is encoded on the pO157 plasmid, and is believed to be involved in virulence by providing additional oxidative protection when infecting the host.
&lt;/blockquote&gt;

I don&#039;t know what all this means, but a &#039;prophage&#039; is a virus that&#039;s been integrated into the DNA of a bacterium.

Graham wrote:

&lt;blockquote&gt;
John wrote:
&lt;blockquote&gt;
    What are some of the coolest possible applications of this new MAGE/CAGE technology? 
&lt;/blockquote&gt;
I think that is the wrong question because Craig Venter’s technology is so much more powerful.
&lt;/blockquote&gt;

Could you say a bit about that?  I know Venter is doing interesting things, but is it doing something similar to this MAGE/CAGE stuff and doing it better, or is it doing something really different that&#039;s just a whole lot more exciting? 
]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6828">Graham</a>.</p>
<p>Graham wrote:</p>
<blockquote><p>
You would certainly notice if a virus-resistant pathogenic strain took over. There are outbreaks of these pathogenic strains of course, like the recent one in Germany. As far as I know, the reason these kill tens rather than millions is that they are outcompeted by benign strains.
</p></blockquote>
<p>Thanks for all your comments.</p>
<p>So, here&#8217;s a scenario that came to mind.  A biotech company like Genzyme develops a version of <i>E. coli</i> with a modified genetic code, to make it virus-resistant.  As Marc notes:</p>
<blockquote><p>
&#8230; engineering a permanent resistance to viral infection would be a monumental feat.
</p></blockquote>
<p>But maybe as long as the <i>E. coli</i> are kept safely contained in the laboratory, they&#8217;ll meet rather few challenges from viruses, so new strains of viruses able to hijack their genetic code won&#8217;t evolve.  </p>
<p>But then, a sophisticated terrorist group obtains a sample of these modified <i>E. coli</i>, and manages to make it more virulent, perhaps borrowing a virulence factor from <a href="http://en.wikipedia.org/wiki/Escherichia_coli_O157:H7" rel="nofollow"><i>E. coli</i> O157:H7</a>: the pathogenic strain that caused that <a href="http://en.wikipedia.org/wiki/2011_E._coli_O104:H4_outbreak" rel="nofollow">outbreak in Germany</a> (and elsewhere in Europe).  </p>
<p>So, this new strain of <i>E. coli</i> outcompetes the benign strains, spreads around the world, and kills millions&#8230;</p>
<p>Of course it would take some sophistication to take an <i>E. coli</i> with a modified genetic code and give it genes from ordinary virulent <i>E. coli</i>: you might need to translate those genes into the new code.  But maybe that wouldn&#8217;t be extremely hard, if the new code was public knowledge!  I&#8217;m not sure, since I&#8217;m no expert.</p>
<p>On the other hand, HR wrote:</p>
<blockquote><p>
I don’t know the answer to how much bacteria are controlled by bacteriophages in the wild but laboratory strains of bacteria are already engineered with multiple metabolic mutations which are meant to make their persistence in the environment difficult.
</p></blockquote>
<p>So, maybe we&#8217;re safe.</p>
<p>By the way, apparently <i>E. coli</i> O157:H7 has genes that produce a <a href="http://en.wikipedia.org/wiki/Shiga-like_toxin" rel="nofollow">Shiga-like toxin</a>, which kills cells lining small blood vessels and produces bloody diarrhea.  According to Wikipedia,</p>
<blockquote><p>
Shiga-like toxins are iron-regulated toxins that catalytically inactivate 60S ribosomal subunits of eukaryotic cells, blocking mRNA translation and causing cell death. Shiga-like toxins are functionally identical to toxins produced by virulent <i>Shigella</i> species. Strains of E. coli that express shiga-like toxins gained this ability due to infection with a prophage containing the structural coding for the toxin, and nonproducing strains may become infected and produce shiga-like toxins after incubation with shiga toxin positive strains. The prophage responsible seems to have infected the strain&#8217;s ancestors fairly recently, as viral particles have been observed to replicate in the host if it is stressed in some way (e.g. antibiotics). The periplasmic catalase is encoded on the pO157 plasmid, and is believed to be involved in virulence by providing additional oxidative protection when infecting the host.
</p></blockquote>
<p>I don&#8217;t know what all this means, but a &#8216;prophage&#8217; is a virus that&#8217;s been integrated into the DNA of a bacterium.</p>
<p>Graham wrote:</p>
<blockquote><p>
John wrote:</p>
<blockquote><p>
    What are some of the coolest possible applications of this new MAGE/CAGE technology?
</p></blockquote>
<p>I think that is the wrong question because Craig Venter’s technology is so much more powerful.
</p></blockquote>
<p>Could you say a bit about that?  I know Venter is doing interesting things, but is it doing something similar to this MAGE/CAGE stuff and doing it better, or is it doing something really different that&#8217;s just a whole lot more exciting? </p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: nad		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6895</link>

		<dc:creator><![CDATA[nad]]></dc:creator>
		<pubDate>Thu, 21 Jul 2011 07:58:19 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=4415#comment-6895</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6871&quot;&gt;John Baez&lt;/a&gt;.

I also think that biotechnology will have a big impact. And it is indeed hard to tell, whether or how much  it will help in overcoming world problems. One problem is also that people will first pick the (comparatively) &quot;easy&quot; challenges. That is it is way easier to modify (e.g. via trial and error) given genetic code, than to design a new one. And it is easier to design a &quot;simple&quot; entity (like a virus) than a complex one. Reverse engineering for complex organisms is still very hard. This is not only due to the sheer number of genes in a complex organism but in particular also how the &lt;a href=&quot;http://en.wikipedia.org/wiki/Regulation_of_gene_expression&quot; rel=&quot;nofollow&quot;&gt;clocks of gene expression work &lt;/a&gt; a.s.o.

So for all sorts of reasons (e.g. alone for the reason that people in research may need to have a result for getting their next 3 month funding), there may be a lot of biotechological projects, where people tinker around without too much care for further implications. And tinkering around may be also detached from scientific contexts. In particular having such rather &quot;simple&quot; modifications at hand like the one linked to from &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/07/06/operads-and-the-tree-of-life/#comment-6686&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; this may also raise the danger of bio-terrorism and -warfare. (&lt;a href=&quot;http://www.youtube.com/watch?v=s8TLKDrKWug&#038;NR=1&quot; rel=&quot;nofollow&quot;&gt;Some people&lt;/a&gt; think that this could be worse than the threat from nuclear technologies and they may be right.) 

It is also a question in how far the patenting business etc. impairs the development of eventually useful technology. In particular high fees for licensing and &lt;a href=&quot;http://pubs.acs.org/doi/full/10.1021/nl100550k&quot; rel=&quot;nofollow&quot;&gt;information&lt;/a&gt; are a problem for developing countries and they are rather not a problem for terrorists.

&lt;blockquote&gt;Optimists should be reminded that part of their optimism is an inability to imagine the creative ideas of the future – Brei Eno&lt;/blockquote&gt;]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6871">John Baez</a>.</p>
<p>I also think that biotechnology will have a big impact. And it is indeed hard to tell, whether or how much  it will help in overcoming world problems. One problem is also that people will first pick the (comparatively) &#8220;easy&#8221; challenges. That is it is way easier to modify (e.g. via trial and error) given genetic code, than to design a new one. And it is easier to design a &#8220;simple&#8221; entity (like a virus) than a complex one. Reverse engineering for complex organisms is still very hard. This is not only due to the sheer number of genes in a complex organism but in particular also how the <a href="http://en.wikipedia.org/wiki/Regulation_of_gene_expression" rel="nofollow">clocks of gene expression work </a> a.s.o.</p>
<p>So for all sorts of reasons (e.g. alone for the reason that people in research may need to have a result for getting their next 3 month funding), there may be a lot of biotechological projects, where people tinker around without too much care for further implications. And tinkering around may be also detached from scientific contexts. In particular having such rather &#8220;simple&#8221; modifications at hand like the one linked to from <a href="https://johncarlosbaez.wordpress.com/2011/07/06/operads-and-the-tree-of-life/#comment-6686" rel="nofollow">here</a> this may also raise the danger of bio-terrorism and -warfare. (<a href="http://www.youtube.com/watch?v=s8TLKDrKWug&amp;NR=1" rel="nofollow">Some people</a> think that this could be worse than the threat from nuclear technologies and they may be right.) </p>
<p>It is also a question in how far the patenting business etc. impairs the development of eventually useful technology. In particular high fees for licensing and <a href="http://pubs.acs.org/doi/full/10.1021/nl100550k" rel="nofollow">information</a> are a problem for developing countries and they are rather not a problem for terrorists.</p>
<blockquote><p>Optimists should be reminded that part of their optimism is an inability to imagine the creative ideas of the future – Brei Eno</p></blockquote>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Terry Bollinger		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/07/17/this-weeks-finds-week-316/#comment-6886</link>

		<dc:creator><![CDATA[Terry Bollinger]]></dc:creator>
		<pubDate>Wed, 20 Jul 2011 13:41:10 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=4415#comment-6886</guid>

					<description><![CDATA[Tungsten! That&#039;s about as weird as uranium, and it&#039;s a biological element about which I&#039;ve never seen anything before. Surely this unexpected dependence makes Stephen Wolfram feel more needed, at least by European bacteria?

While not advocating it -- I&#039;m a big fan of sometimes just saying &quot;there is insufficient data to formulate a testable theory&quot; -- I would of note that close associations of odd elements are the meat of panspermia speculations.

The odd element combinations, if primordial, would from that perspective tend to indicate that the true origins of life were on planets very different indeed from those of our solar system. Such a point could in turn help explain why speculations about the origin of life on earth always seem to end up stretched to some statistical limit. If life originated in a very different setting, theories of how life might have originated on earth would be roughly like trying to explain the presence of diamonds in a creek bed by theorizing how room-temperature aqueous processes could lead to diamond formation in streams.

Conversely, perhaps on some very distant and very heavy planet, the chemical quirks and coincidences that baffle us about life might look far more mundane and commonplace.

It&#039;s worth noting also that such speculations could perhaps someday lead to computational testability of panspermia ideas.

More specifically: If one modeled in detail the surface chemistry of an energetic planet rich in tungsten, molybdenum, selenium, and other plausibly associated elements, would that model show a large increase in the likelihood of physicochemical processes that exhibit expandable memory, replication, and mutation?

As with computational astrophysics, such an approach might take panspermia from the realms of interesting but basically idle speculation into something for which non-trivial results might be derived about the type of extrasolar environment in which life most likely arose.

I must at the same time admit that I don&#039;t think any currently existing computational and modeling systems exist that could handle the massive simulations that would be needed.

----

Did I just say &quot;theories of aqueous diamond formation? Hmm!

What follows is a total tangent, something I worked on back in high school, which was... a while back!:

Why does life not create diamond for things such as teeth?

Before you laugh too quickly about the need for intense heat and pressure or vacuum vapor deposition, beware: Those are all sledge hammer approaches, methods that encourage a tiny and energetically minimal change in bonding direction by slamming carbon around in ways that give it little choice.

Life encourages tiny changes in bond directions all the time, and does so elegantly and with minimal fuss. The tools of course are called enzymes. As you read this page, said enzymes are constantly creating bonds whose statistical unlikelihood dwarfs by many orders of magnitude the difference between graphite and diamond.

So again the question, but a bit differently: Why does life not create the enzymes to create diamond for uses such as teeth?

Energy levels are not the issue. The difference between those of graphite and diamond are well within the limits that life can handle. (Please note however that I am going on the memory of calculations I made decades ago!)

Size? Maybe. Graphite and diamond bonds are very compact. It could simply be that the types of protein-based enzymes made by life simply can&#039;t handle the smaller bond sizes. I don&#039;t fully buy that argument, however, since life long ago learned the trick of using big tools to make smaller tools. Thus even if a first-order DNA-defined protein enzyme cannot do the trick, it and other enzymes could very likely create smaller chemical molecules -- catalysts -- with just the right bonding structures.

Ignorance? It&#039;s possible! It took life a couple of billion years to reach the specific set of higher-efficiency photosynthesis seen in grasses, so who&#039;s to say that life just hasn&#039;t been around long enough to figure out how to make diamond?

And with that &quot;hmm, what if...?&quot; thought, I&#039;ll end with my aqueous diamond synthesis model from back in the late 1970s.

First, cut a seed diamond to expose its cubic faces. Next, treat the surface with hydrogen to ensure termination of carbon surface bonds with hydrogen atoms.

What this gives you geometrically is a surface lined with alternating close pairs of hydrogen atoms that are first vertical (:) and then horizontal (..), like this: (: .. : .. : .. :), only with the horizontal dot pairs better centered. At high magnification the diamond surface would look a bit like one of those metal traction surfaces that use alternating vertical and horizontal short bars,  only with dot pairs replacing the bars.

Now immerse the surface treated in water and add your reactant and catalyst. The reactant is formaldehyde, and the catalyst binds to the formaldehyde so that the oxygen end sticks out.

The loaded catalyst has additional groups that bond selectively to the hydrogen-terminated cubic diamond surface. As a loaded catalyst molecule approaches the cubic diamond surface, it presents the oxygen to one of the hydrogen pairs at just the right angle to cause the production and discarding a water molecule:

    OCH2 [formaldehyde] -&#062; C [graphite or diamond] + H2O

Again from memory, I&#039;m pretty sure that this reaction is energetically favorable, so no additional energy should be needed. Even if an energy boost was required, though, it could be provided by a more complex catalyst system. That is after all what the ATP cycle in cells is all about.

The result: A new layer of diamond begins to form. The nice thing about using the cubic faces (versus the octahedral ones) is that geometry alone determines correct bonding. As long as the formaldehyde oxygen atoms bond only to the close pairs of hydrogen atoms, the resulting layer is geometrically guaranteed to have diamond bonding, versus graphite or other allotropes.

Layer-by-layer growth should be possible using only a single catalyst. However, adding a second edge-growth catalyst would likely speed up  the process. This second catalyst would cause the formaldehyde to bond in exactly the same fashion, but would attach itself at the growing edge of a new diamond layer.

The oddest thing about all of the above is that I&#039;ve never been able to come up with a powerful reason why it could not work.

The configuration is simple, the energy levels are not drastic, and real enzymes do much more complex things than this. Back when I first worked on this idea would have liked to model the detailed bonding behavior of the formaldehyde oxygen as it approaches the diamond cubic surface hydrogen pair. But alas, I didn&#039;t get my first four function hand calculator until my senior year in high school, and I don&#039;t think the quantum chemistry models of that time would have been up to the task anyway.

So: Could diamonds be grown in aqueous solutions?

Maybe; maybe not. I would at least suggest that it is a question that merits more careful examination. I don&#039;t think it can be fully dismissed based on analogies (pressure and vacuum methods) that don&#039;t directly address the question of enzymatic plausibility.]]></description>
			<content:encoded><![CDATA[<p>Tungsten! That&#8217;s about as weird as uranium, and it&#8217;s a biological element about which I&#8217;ve never seen anything before. Surely this unexpected dependence makes Stephen Wolfram feel more needed, at least by European bacteria?</p>
<p>While not advocating it &#8212; I&#8217;m a big fan of sometimes just saying &#8220;there is insufficient data to formulate a testable theory&#8221; &#8212; I would of note that close associations of odd elements are the meat of panspermia speculations.</p>
<p>The odd element combinations, if primordial, would from that perspective tend to indicate that the true origins of life were on planets very different indeed from those of our solar system. Such a point could in turn help explain why speculations about the origin of life on earth always seem to end up stretched to some statistical limit. If life originated in a very different setting, theories of how life might have originated on earth would be roughly like trying to explain the presence of diamonds in a creek bed by theorizing how room-temperature aqueous processes could lead to diamond formation in streams.</p>
<p>Conversely, perhaps on some very distant and very heavy planet, the chemical quirks and coincidences that baffle us about life might look far more mundane and commonplace.</p>
<p>It&#8217;s worth noting also that such speculations could perhaps someday lead to computational testability of panspermia ideas.</p>
<p>More specifically: If one modeled in detail the surface chemistry of an energetic planet rich in tungsten, molybdenum, selenium, and other plausibly associated elements, would that model show a large increase in the likelihood of physicochemical processes that exhibit expandable memory, replication, and mutation?</p>
<p>As with computational astrophysics, such an approach might take panspermia from the realms of interesting but basically idle speculation into something for which non-trivial results might be derived about the type of extrasolar environment in which life most likely arose.</p>
<p>I must at the same time admit that I don&#8217;t think any currently existing computational and modeling systems exist that could handle the massive simulations that would be needed.</p>
<p>&#8212;-</p>
<p>Did I just say &#8220;theories of aqueous diamond formation? Hmm!</p>
<p>What follows is a total tangent, something I worked on back in high school, which was&#8230; a while back!:</p>
<p>Why does life not create diamond for things such as teeth?</p>
<p>Before you laugh too quickly about the need for intense heat and pressure or vacuum vapor deposition, beware: Those are all sledge hammer approaches, methods that encourage a tiny and energetically minimal change in bonding direction by slamming carbon around in ways that give it little choice.</p>
<p>Life encourages tiny changes in bond directions all the time, and does so elegantly and with minimal fuss. The tools of course are called enzymes. As you read this page, said enzymes are constantly creating bonds whose statistical unlikelihood dwarfs by many orders of magnitude the difference between graphite and diamond.</p>
<p>So again the question, but a bit differently: Why does life not create the enzymes to create diamond for uses such as teeth?</p>
<p>Energy levels are not the issue. The difference between those of graphite and diamond are well within the limits that life can handle. (Please note however that I am going on the memory of calculations I made decades ago!)</p>
<p>Size? Maybe. Graphite and diamond bonds are very compact. It could simply be that the types of protein-based enzymes made by life simply can&#8217;t handle the smaller bond sizes. I don&#8217;t fully buy that argument, however, since life long ago learned the trick of using big tools to make smaller tools. Thus even if a first-order DNA-defined protein enzyme cannot do the trick, it and other enzymes could very likely create smaller chemical molecules &#8212; catalysts &#8212; with just the right bonding structures.</p>
<p>Ignorance? It&#8217;s possible! It took life a couple of billion years to reach the specific set of higher-efficiency photosynthesis seen in grasses, so who&#8217;s to say that life just hasn&#8217;t been around long enough to figure out how to make diamond?</p>
<p>And with that &#8220;hmm, what if&#8230;?&#8221; thought, I&#8217;ll end with my aqueous diamond synthesis model from back in the late 1970s.</p>
<p>First, cut a seed diamond to expose its cubic faces. Next, treat the surface with hydrogen to ensure termination of carbon surface bonds with hydrogen atoms.</p>
<p>What this gives you geometrically is a surface lined with alternating close pairs of hydrogen atoms that are first vertical (:) and then horizontal (..), like this: (: .. : .. : .. :), only with the horizontal dot pairs better centered. At high magnification the diamond surface would look a bit like one of those metal traction surfaces that use alternating vertical and horizontal short bars,  only with dot pairs replacing the bars.</p>
<p>Now immerse the surface treated in water and add your reactant and catalyst. The reactant is formaldehyde, and the catalyst binds to the formaldehyde so that the oxygen end sticks out.</p>
<p>The loaded catalyst has additional groups that bond selectively to the hydrogen-terminated cubic diamond surface. As a loaded catalyst molecule approaches the cubic diamond surface, it presents the oxygen to one of the hydrogen pairs at just the right angle to cause the production and discarding a water molecule:</p>
<p>    OCH2 [formaldehyde] -&gt; C [graphite or diamond] + H2O</p>
<p>Again from memory, I&#8217;m pretty sure that this reaction is energetically favorable, so no additional energy should be needed. Even if an energy boost was required, though, it could be provided by a more complex catalyst system. That is after all what the ATP cycle in cells is all about.</p>
<p>The result: A new layer of diamond begins to form. The nice thing about using the cubic faces (versus the octahedral ones) is that geometry alone determines correct bonding. As long as the formaldehyde oxygen atoms bond only to the close pairs of hydrogen atoms, the resulting layer is geometrically guaranteed to have diamond bonding, versus graphite or other allotropes.</p>
<p>Layer-by-layer growth should be possible using only a single catalyst. However, adding a second edge-growth catalyst would likely speed up  the process. This second catalyst would cause the formaldehyde to bond in exactly the same fashion, but would attach itself at the growing edge of a new diamond layer.</p>
<p>The oddest thing about all of the above is that I&#8217;ve never been able to come up with a powerful reason why it could not work.</p>
<p>The configuration is simple, the energy levels are not drastic, and real enzymes do much more complex things than this. Back when I first worked on this idea would have liked to model the detailed bonding behavior of the formaldehyde oxygen as it approaches the diamond cubic surface hydrogen pair. But alas, I didn&#8217;t get my first four function hand calculator until my senior year in high school, and I don&#8217;t think the quantum chemistry models of that time would have been up to the task anyway.</p>
<p>So: Could diamonds be grown in aqueous solutions?</p>
<p>Maybe; maybe not. I would at least suggest that it is a question that merits more careful examination. I don&#8217;t think it can be fully dismissed based on analogies (pressure and vacuum methods) that don&#8217;t directly address the question of enzymatic plausibility.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

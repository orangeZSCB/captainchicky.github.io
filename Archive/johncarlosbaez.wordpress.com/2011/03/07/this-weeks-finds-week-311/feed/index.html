<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: This Week&#8217;s Finds (Week 311)	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/</link>
	<description></description>
	<lastBuildDate>Thu, 26 Dec 2013 22:46:55 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: Logic, Probability and Reflection &#124; Azimuth		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-34839</link>

		<dc:creator><![CDATA[Logic, Probability and Reflection &#124; Azimuth]]></dc:creator>
		<pubDate>Thu, 26 Dec 2013 22:46:55 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=2704#comment-34839</guid>

					<description><![CDATA[[...] Last week I attended the &lt;a href=&quot;http://intelligence.org/&quot; rel=&quot;nofollow&quot;&gt;Machine Intelligence Research Institute&#039;s&lt;/a&gt; sixth &lt;a href=&quot;http://intelligence.org/2013/07/24/miris-december-2013-workshop/&quot; rel=&quot;nofollow&quot;&gt;Workshop on Logic, Probability, and Reflection&lt;/a&gt;.  You may know this institute under their previous name: the Singularity Institute.  It seems to be the brainchild of Eliezer Yudkowsky, a well-known advocate of &#039;friendly artificial intelligence&#039;, whom I interviewed in &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/&quot; rel=&quot;nofollow&quot;&gt;week311&lt;/a&gt;, &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/&quot; rel=&quot;nofollow&quot;&gt;week312&lt;/a&gt; and &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/03/25/this-weeks-finds-week-313/&quot; rel=&quot;nofollow&quot;&gt;week313&lt;/a&gt; of &lt;i&gt;This Week&#039;s Finds&lt;/i&gt;. [...]]]></description>
			<content:encoded><![CDATA[<p>[&#8230;] Last week I attended the <a href="http://intelligence.org/" rel="nofollow">Machine Intelligence Research Institute&#8217;s</a> sixth <a href="http://intelligence.org/2013/07/24/miris-december-2013-workshop/" rel="nofollow">Workshop on Logic, Probability, and Reflection</a>.  You may know this institute under their previous name: the Singularity Institute.  It seems to be the brainchild of Eliezer Yudkowsky, a well-known advocate of &#8216;friendly artificial intelligence&#8217;, whom I interviewed in <a href="https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/" rel="nofollow">week311</a>, <a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/" rel="nofollow">week312</a> and <a href="https://johncarlosbaez.wordpress.com/2011/03/25/this-weeks-finds-week-313/" rel="nofollow">week313</a> of <i>This Week&#8217;s Finds</i>. [&#8230;]</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-34275</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Fri, 06 Dec 2013 23:41:14 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=2704#comment-34275</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-34265&quot;&gt;Bryan Thomas&lt;/a&gt;.

Thanks!]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-34265">Bryan Thomas</a>.</p>
<p>Thanks!</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Bryan Thomas		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-34265</link>

		<dc:creator><![CDATA[Bryan Thomas]]></dc:creator>
		<pubDate>Fri, 06 Dec 2013 17:09:34 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=2704#comment-34265</guid>

					<description><![CDATA[For those interested in the 1983 Omni piece by Vinge, it is now available through the Internet Archive.  https://archive.org/details/omni-magazine-1983-01]]></description>
			<content:encoded><![CDATA[<p>For those interested in the 1983 Omni piece by Vinge, it is now available through the Internet Archive.  <a href="https://archive.org/details/omni-magazine-1983-01" rel="nofollow ugc">https://archive.org/details/omni-magazine-1983-01</a></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Alexander Kruel &#183; Why you should be wary of the Singularity Institute		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-23797</link>

		<dc:creator><![CDATA[Alexander Kruel &#183; Why you should be wary of the Singularity Institute]]></dc:creator>
		<pubDate>Mon, 07 Jan 2013 12:29:07 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=2704#comment-23797</guid>

					<description><![CDATA[[...] Eliezer Yudkowsky in an interview with John [...]]]></description>
			<content:encoded><![CDATA[<p>[&#8230;] Eliezer Yudkowsky in an interview with John [&#8230;]</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Alexander Kruel · Is criticism of the Singularity Institute a result of hostility?		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-23652</link>

		<dc:creator><![CDATA[Alexander Kruel · Is criticism of the Singularity Institute a result of hostility?]]></dc:creator>
		<pubDate>Fri, 04 Jan 2013 11:35:41 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=2704#comment-23652</guid>

					<description><![CDATA[&quot;[...] and run the AI, at which point, if all goes well, we Win.)” — Eliezer Yudkowsky in an interview with John Baez]]></description>
			<content:encoded><![CDATA[<p>&#8220;[&#8230;] and run the AI, at which point, if all goes well, we Win.)” — Eliezer Yudkowsky in an interview with John Baez</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Thomas Too		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-21174</link>

		<dc:creator><![CDATA[Thomas Too]]></dc:creator>
		<pubDate>Fri, 26 Oct 2012 02:21:30 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=2704#comment-21174</guid>

					<description><![CDATA[Hey, you&#039;re right.  I assumed attendee were donors.  Well, I&#039;ve got to go now, I just found a list of people to whom I wish to sell my absolutely effective perpetual motion machines.]]></description>
			<content:encoded><![CDATA[<p>Hey, you&#8217;re right.  I assumed attendee were donors.  Well, I&#8217;ve got to go now, I just found a list of people to whom I wish to sell my absolutely effective perpetual motion machines.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-21173</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Fri, 26 Oct 2012 02:10:40 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=2704#comment-21173</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-21172&quot;&gt;Thomas Too&lt;/a&gt;.

Thomas Too wrote:

&lt;blockquote&gt;
Look at the lists of attendees of singularity conferences. There are many people from universities and defense contractors.
&lt;/blockquote&gt;

Okay, those people are &lt;i&gt;attending the conferences&lt;/i&gt;---but now you&#039;ve got me curious to know which kinds of people are &lt;i&gt;donating money&lt;/i&gt; to the Singularity Institute.  It&#039;s not too hard to find out: just &lt;a href=&quot;http://singularity.org/topdonors/&quot; rel=&quot;nofollow&quot;&gt;look at the list of top donors&lt;/a&gt; and use Google to find out what they do. 

I only had time now to look at the top five donors, and they are &lt;i&gt;not&lt;/i&gt; people who work at universities.  They&#039;re a foundation, an &quot;Estonian programmer who participated in the development of Skype and FastTrack/Kazaa&quot;, a person who works on &quot;Proximiant building technology to beam receipts straight to your phone&quot;, an investment group, and a millionaire who &quot;retired seven years ago after a successful career in Silicon Valley&quot;.   This matches what I expected.  Perhaps you could go through the list and see what the typical contributor is like.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-21172">Thomas Too</a>.</p>
<p>Thomas Too wrote:</p>
<blockquote><p>
Look at the lists of attendees of singularity conferences. There are many people from universities and defense contractors.
</p></blockquote>
<p>Okay, those people are <i>attending the conferences</i>&#8212;but now you&#8217;ve got me curious to know which kinds of people are <i>donating money</i> to the Singularity Institute.  It&#8217;s not too hard to find out: just <a href="http://singularity.org/topdonors/" rel="nofollow">look at the list of top donors</a> and use Google to find out what they do. </p>
<p>I only had time now to look at the top five donors, and they are <i>not</i> people who work at universities.  They&#8217;re a foundation, an &#8220;Estonian programmer who participated in the development of Skype and FastTrack/Kazaa&#8221;, a person who works on &#8220;Proximiant building technology to beam receipts straight to your phone&#8221;, an investment group, and a millionaire who &#8220;retired seven years ago after a successful career in Silicon Valley&#8221;.   This matches what I expected.  Perhaps you could go through the list and see what the typical contributor is like.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Thomas Too		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-21172</link>

		<dc:creator><![CDATA[Thomas Too]]></dc:creator>
		<pubDate>Fri, 26 Oct 2012 01:52:19 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=2704#comment-21172</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-21170&quot;&gt;John Baez&lt;/a&gt;.

Look at the lists of attendees of singularity conferences.  There are many people from universities and defense contractors.  I have read the self deluded ramblings of the risks of AI.

The risks of AI supposes that it might exist.  There is no evidence that it will.  A symposium on the risks of discovering the philosphers stone would have been as useful. The emperor has no clothes, but people who want to get money from the emperor stand in line to say how spendid is his raiment.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-21170">John Baez</a>.</p>
<p>Look at the lists of attendees of singularity conferences.  There are many people from universities and defense contractors.  I have read the self deluded ramblings of the risks of AI.</p>
<p>The risks of AI supposes that it might exist.  There is no evidence that it will.  A symposium on the risks of discovering the philosphers stone would have been as useful. The emperor has no clothes, but people who want to get money from the emperor stand in line to say how spendid is his raiment.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-21170</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Fri, 26 Oct 2012 01:16:07 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=2704#comment-21170</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-21169&quot;&gt;Thomas Too&lt;/a&gt;.

I never made any claims of rapid progress toward intelligent machines, so I have no position to defend and don&#039;t feel like discussing this question now.  But Alexander Kruel has been interviewing researchers about this, and you might be interested in what they say:

&#8226; Alexander Kruel, &lt;a href=&quot;http://wiki.lesswrong.com/wiki/Interview_series_on_risks_from_AI&quot; rel=&quot;nofollow&quot;&gt;Interview series on risks from AI&lt;/a&gt;.

By the way, you write:

&lt;blockquote&gt;
Oh, I don’t doubt that if a person is naive enough to persuaded by the singularity arguments, that they are naive enough to give money, but a substantial portion of their money is coming from institutions like universities...
&lt;/blockquote&gt;

What&#039;s the evidence for this claim, please?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-21169">Thomas Too</a>.</p>
<p>I never made any claims of rapid progress toward intelligent machines, so I have no position to defend and don&#8217;t feel like discussing this question now.  But Alexander Kruel has been interviewing researchers about this, and you might be interested in what they say:</p>
<p>&bull; Alexander Kruel, <a href="http://wiki.lesswrong.com/wiki/Interview_series_on_risks_from_AI" rel="nofollow">Interview series on risks from AI</a>.</p>
<p>By the way, you write:</p>
<blockquote><p>
Oh, I don’t doubt that if a person is naive enough to persuaded by the singularity arguments, that they are naive enough to give money, but a substantial portion of their money is coming from institutions like universities&#8230;
</p></blockquote>
<p>What&#8217;s the evidence for this claim, please?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Thomas Too		</title>
		<link>https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/#comment-21169</link>

		<dc:creator><![CDATA[Thomas Too]]></dc:creator>
		<pubDate>Fri, 26 Oct 2012 00:29:16 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=2704#comment-21169</guid>

					<description><![CDATA[Oh, I don&#039;t doubt that if a person is naive enough to persuaded by the singularity arguments, that they are naive enough to give money, but a substantial portion of their money is coming from institutions like universities, so, I guess you could say it is in large part, state money, but a  major portion of state education funding comes from federal state grants, or work at companies that get federal funding, because the most gullible are federal employees. 
 Singularity &quot;research&quot; has some similarities to a multi level marketing scheme.  Get in at the beginning, donate money for seminars to get a credential as an expert, then teach a similar course to other people who want to scam the next greedy sucker behind them.
Singularity has little in common with either science or philosoply.  Science only occurs if you can do an experiment with a control, which has never happened in singularity research. Philosophy is a search for basic understanding that is open to all who are prepared to advance and defend their concepts, but for singularity, unless you have accepted the basic premise that it is coming, you are excluded as &quot;naive.&quot;
Singularity has more in common with the self help and actualization movement, homeopathy, and alchemy.    I If you don&#039;t agree with the premise, then you &quot;just don&#039;t get it.&quot;  You &quot;just don&#039;t get it,&quot; is an example of the special pleading logical fallacy, such as described by Carl Sagan.  
As I have written before, the singularity is the new philosphoer&#039;s stone. 
So , While you have only responded to half my post, I respond in 4 parts to yours.
It is not all private money.
Singularity donations are like a ponzi scheme.
Singularity is not science or philosphy.
The singularity is the new philosophers stone. 
I was expecting a dismissive &quot;just dont get it response,&quot; so am a little surprised you made a fact argument.  But as you dismiss my 4 parts in your response, please also address (to dismiss) the second part of my prior post, that there is no progress , real or expected, in intelligent machines.  I will be counting how many times I &quot;just dont get it.&quot;]]></description>
			<content:encoded><![CDATA[<p>Oh, I don&#8217;t doubt that if a person is naive enough to persuaded by the singularity arguments, that they are naive enough to give money, but a substantial portion of their money is coming from institutions like universities, so, I guess you could say it is in large part, state money, but a  major portion of state education funding comes from federal state grants, or work at companies that get federal funding, because the most gullible are federal employees.<br />
 Singularity &#8220;research&#8221; has some similarities to a multi level marketing scheme.  Get in at the beginning, donate money for seminars to get a credential as an expert, then teach a similar course to other people who want to scam the next greedy sucker behind them.<br />
Singularity has little in common with either science or philosoply.  Science only occurs if you can do an experiment with a control, which has never happened in singularity research. Philosophy is a search for basic understanding that is open to all who are prepared to advance and defend their concepts, but for singularity, unless you have accepted the basic premise that it is coming, you are excluded as &#8220;naive.&#8221;<br />
Singularity has more in common with the self help and actualization movement, homeopathy, and alchemy.    I If you don&#8217;t agree with the premise, then you &#8220;just don&#8217;t get it.&#8221;  You &#8220;just don&#8217;t get it,&#8221; is an example of the special pleading logical fallacy, such as described by Carl Sagan.<br />
As I have written before, the singularity is the new philosphoer&#8217;s stone.<br />
So , While you have only responded to half my post, I respond in 4 parts to yours.<br />
It is not all private money.<br />
Singularity donations are like a ponzi scheme.<br />
Singularity is not science or philosphy.<br />
The singularity is the new philosophers stone.<br />
I was expecting a dismissive &#8220;just dont get it response,&#8221; so am a little surprised you made a fact argument.  But as you dismiss my 4 parts in your response, please also address (to dismiss) the second part of my prior post, that there is no progress , real or expected, in intelligent machines.  I will be counting how many times I &#8220;just dont get it.&#8221;</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

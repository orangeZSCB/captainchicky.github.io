<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>This Week&#8217;s Finds (Week 312) | Azimuth</title>
<link rel="profile" href="http://gmpg.org/xfn/11" />
<link rel="pingback" href="https://johncarlosbaez.wordpress.com/xmlrpc.php" />
<meta name='robots' content='max-image-preview:large, noindex, follow' />
<link rel='dns-prefetch' href='//s2.wp.com' />
<link rel='dns-prefetch' href='//s0.wp.com' />
<link rel='dns-prefetch' href='//s.wordpress.com' />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Feed" href="https://johncarlosbaez.wordpress.com/feed/" />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Comments Feed" href="https://johncarlosbaez.wordpress.com/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; This Week&#8217;s Finds (Week&nbsp;312) Comments Feed" href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/feed/" />
	<script type="text/javascript">
		/* <![CDATA[ */
		function addLoadEvent(func) {
			var oldonload = window.onload;
			if (typeof window.onload != 'function') {
				window.onload = func;
			} else {
				window.onload = function () {
					oldonload();
					func();
				}
			}
		}
		/* ]]> */
	</script>
			<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/72x72\/","ext":".png","svgUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/s1.wp.com\/wp-includes\/js\/wp-emoji-release.min.js?m=1625065786h&ver=5.8.1"}};
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([10084,65039,8205,55357,56613],[10084,65039,8203,55357,56613])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='all-css-0-1' href='https://s0.wp.com/_static/??-eJyNkdtSAyEMhl9INkWnOl44PguHiKnAMhCsvL3Zepi1tdUbhj/Jl/yTwL4oN2fGzJC6KrEHyg0qRsPoVZkbH6nJtXYFv2OUnygTD+BnTNigdAuHslT4hPuCQhdpsQbJVIRXraftpMF2ih5snN2LimSrqQMaj4jfjSi72L2M2TVI6MlglKmLo5Uo0QysKmIwbkyJ8t+45Nb6B3Te/MGpNEMuZrFsxtxZhUr+yPa/W1TDlEM7g6/WvuxN4qmYU/MXsD35gHJeKfn8K8a3y0iRMcraUrE1JW+intTHtRfuMT3o2xt9d7/dbK5375l75CE=?cssminify=yes' type='text/css' media='all' />
<style id='wp-block-library-inline-css'>
.has-text-align-justify {
	text-align:justify;
}
</style>
<style id='global-styles-inline-css'>
body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--normal: 16px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--huge: 42px;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-normal-font-size{font-size: var(--wp--preset--font-size--normal) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-huge-font-size{font-size: var(--wp--preset--font-size--huge) !important;}
</style>
<link rel='stylesheet' id='all-css-2-1' href='https://s0.wp.com/_static/??-eJx9i0EKgCAQAD+ULYJRHaK3qJhY666o0fezW126zcAMGNR09LaUDq4kLFN1VCGeIuHpAxXwjgWy1TUwfURsqEP+W7MzyL6hh1a99JnWuEg1zEpNo1T7DZLtMYQ=?cssminify=yes' type='text/css' media='all' />
<link rel='stylesheet' id='print-css-3-1' href='https://s2.wp.com/wp-content/mu-plugins/global-print/global-print.css?m=1465851035h&cssminify=yes' type='text/css' media='print' />
<style id='jetpack-global-styles-frontend-style-inline-css'>
:root { --font-headings: unset; --font-base: unset; --font-headings-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif; --font-base-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif;}
</style>
<link rel='stylesheet' id='all-css-6-1' href='https://s0.wp.com/wp-content/themes/h4/global.css?m=1420737423h&cssminify=yes' type='text/css' media='all' />
<script id='jetpack_related-posts-js-extra'>
var related_posts_js_options = {"post_heading":"h4"};
</script>
<script id='wpcom-actionbar-placeholder-js-extra'>
var actionbardata = {"siteID":"12777403","siteName":"Azimuth","siteURL":"http:\/\/johncarlosbaez.wordpress.com","siteHost":"johncarlosbaez.wordpress.com","icon":"<img alt='' src='https:\/\/s2.wp.com\/i\/logo\/wpcom-gray-white.png' class='avatar avatar-50' height='50' width='50' \/>","canManageOptions":"","canCustomizeSite":"","isFollowing":"","themeSlug":"pub\/contempt","signupURL":"https:\/\/wordpress.com\/start\/","loginURL":"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2011%2F03%2F14%2Fthis-weeks-finds-week-312%2F&signup_flow=account","themeURL":"","xhrURL":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/admin-ajax.php","nonce":"c031e776ae","isSingular":"1","isFolded":"","isLoggedIn":"","isMobile":"","subscribeNonce":"<input type=\"hidden\" id=\"_wpnonce\" name=\"_wpnonce\" value=\"8f1337fe87\" \/>","referer":"https:\/\/johncarlosbaez.wordpress.com\/2011\/03\/14\/this-weeks-finds-week-312\/?replytocom=4578","canFollow":"1","feedID":"62242","statusMessage":"","subsEmailDefault":"instantly","customizeLink":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/customize.php?url=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2011%2F03%2F14%2Fthis-weeks-finds-week-312%2F%3Freplytocom%3D4578","postID":"2735","shortlink":"https:\/\/wp.me\/pRBZ9-I7","canEditPost":"","editLink":"https:\/\/wordpress.com\/post\/johncarlosbaez.wordpress.com\/2735","statsLink":"https:\/\/wordpress.com\/stats\/post\/2735\/johncarlosbaez.wordpress.com","i18n":{"view":"View site","follow":"Follow","following":"Following","edit":"Edit","login":"Log in","signup":"Sign up","customize":"Customize","report":"Report this content","themeInfo":"Get theme: Contempt","shortlink":"Copy shortlink","copied":"Copied","followedText":"New posts from this site will now appear in your <a href=\"https:\/\/wordpress.com\/read\">Reader<\/a>","foldBar":"Collapse this bar","unfoldBar":"Expand this bar","editSubs":"Manage subscriptions","viewReader":"View site in Reader","viewReadPost":"View post in Reader","subscribe":"Sign me up","enterEmail":"Enter your email address","followers":"Join 5,227 other followers","alreadyUser":"Already have a WordPress.com account? <a href=\"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2011%2F03%2F14%2Fthis-weeks-finds-week-312%2F&signup_flow=account\">Log in now.<\/a>","stats":"Stats","notifyNewPosts":"Notify me of new posts","notifyNewPostsDetails":"Receive web and mobile notifications for new posts from this site.","emailNewPosts":"Email me new posts","emailNewPostsDetails":"You can customize your notification settings further <a href=\"https:\/\/wordpress.com\/following\/manage?s=johncarlosbaez.wordpress.com\">here<\/a>.","emailNewComments":"Email me new comments","instantly":"Instantly","daily":"Daily","weekly":"Weekly"}};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s0.wp.com/_static/??-eJyFjcEKwjAQRH/IbQxSPYnfUtu1bMhuYnZD7d/bQj1YBE/D8B4zbsrQJzEUc0FdTmqMqt2ITdCD+6ac7hQRqmJZBDEgeaS9xxVyrCOJuoKxMxxgXd21H+slGuSSXvOHkfSxDqgrDM+KZd6iYZK/EjCNZTnc5Btf/fnkL8fW+za8ASssW38='></script>
<script type='text/javascript'>
	window.addEventListener( 'DOMContentLoaded', function() {
		rltInitialize( {"token":null,"iframeOrigins":["https:\/\/widgets.wp.com"]} );
	} );
</script>
<link rel='stylesheet' id='all-css-0-2' href='https://s0.wp.com/wp-content/mu-plugins/highlander-comments/style.css?m=1625210320h&cssminify=yes' type='text/css' media='all' />
<!--[if lt IE 8]>
<link rel='stylesheet' id='highlander-comments-ie7-css'  href='https://s2.wp.com/wp-content/mu-plugins/highlander-comments/style-ie7.css?m=1351637563h&#038;ver=20110606' media='all' />
<![endif]-->
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://johncarlosbaez.wordpress.com/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://s1.wp.com/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress.com" />
<link rel="canonical" href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/" />
<link rel='shortlink' href='https://wp.me/pRBZ9-I7' />
<link rel="alternate" type="application/json+oembed" href="https://public-api.wordpress.com/oembed/?format=json&amp;url=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2011%2F03%2F14%2Fthis-weeks-finds-week-312%2F&amp;for=wpcom-auto-discovery" /><link rel="alternate" type="application/xml+oembed" href="https://public-api.wordpress.com/oembed/?format=xml&amp;url=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2011%2F03%2F14%2Fthis-weeks-finds-week-312%2F&amp;for=wpcom-auto-discovery" />
<!-- Jetpack Open Graph Tags -->
<meta property="og:type" content="article" />
<meta property="og:title" content="This Week&#8217;s Finds (Week 312)" />
<meta property="og:url" content="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/" />
<meta property="og:description" content="The second part of an interview with Eliezer Yudkowsky." />
<meta property="article:published_time" content="2011-03-14T08:48:54+00:00" />
<meta property="article:modified_time" content="2011-03-15T02:32:46+00:00" />
<meta property="og:site_name" content="Azimuth" />
<meta property="og:image" content="https://s0.wp.com/i/blank.jpg" />
<meta property="og:locale" content="en_US" />
<meta name="twitter:site" content="@wordpressdotcom" />
<meta name="twitter:text:title" content="This Week&#8217;s Finds (Week&nbsp;312)" />
<meta name="twitter:card" content="summary" />
<meta property="fb:app_id" content="249643311490" />
<meta property="article:publisher" content="https://www.facebook.com/WordPresscom" />

<!-- End Jetpack Open Graph Tags -->
<link rel="shortcut icon" type="image/x-icon" href="https://s1.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48" />
<link rel="icon" type="image/x-icon" href="https://s1.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48" />
<link rel="apple-touch-icon" href="https://s2.wp.com/i/webclip.png" />
<link rel='openid.server' href='https://johncarlosbaez.wordpress.com/?openidserver=1' />
<link rel='openid.delegate' href='https://johncarlosbaez.wordpress.com/' />
<link rel="search" type="application/opensearchdescription+xml" href="https://johncarlosbaez.wordpress.com/osd.xml" title="Azimuth" />
<link rel="search" type="application/opensearchdescription+xml" href="https://s1.wp.com/opensearch.xml" title="WordPress.com" />
<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>		<style type="text/css">
			.recentcomments a {
				display: inline !important;
				padding: 0 !important;
				margin: 0 !important;
			}

			table.recentcommentsavatartop img.avatar, table.recentcommentsavatarend img.avatar {
				border: 0px;
				margin: 0;
			}

			table.recentcommentsavatartop a, table.recentcommentsavatarend a {
				border: 0px !important;
				background-color: transparent !important;
			}

			td.recentcommentsavatarend, td.recentcommentsavatartop {
				padding: 0px 0px 1px 0px;
				margin: 0px;
			}

			td.recentcommentstextend {
				border: none !important;
				padding: 0px 0px 2px 10px;
			}

			.rtl td.recentcommentstextend {
				padding: 0px 10px 2px 0px;
			}

			td.recentcommentstexttop {
				border: none;
				padding: 0px 0px 0px 10px;
			}

			.rtl td.recentcommentstexttop {
				padding: 0px 10px 0px 0px;
			}
		</style>
		<meta name="application-name" content="Azimuth" /><meta name="msapplication-window" content="width=device-width;height=device-height" /><meta name="msapplication-task" content="name=Subscribe;action-uri=https://johncarlosbaez.wordpress.com/feed/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=Sign up for a free blog;action-uri=http://wordpress.com/signup/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=WordPress.com Support;action-uri=http://support.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=WordPress.com Forums;action-uri=http://forums.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="description" content="The second part of an interview with Eliezer Yudkowsky." />
<style type="text/css">
#headerimg{
	background: url(https://johncarlosbaez.files.wordpress.com/2010/08/azimuth_header.jpg) no-repeat;
}
#header h1 a, .description {
	color:#E5F2E9;
}
</style>
<link rel="amphtml" href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/amp/">		<link rel="stylesheet" id="custom-css-css" type="text/css" href="https://s0.wp.com/?custom-css=1&#038;csblog=RBZ9&#038;cscache=6&#038;csrev=7" />
		</head>
<body class="post-template-default single single-post postid-2735 single-format-standard customizer-styles-applied highlander-enabled highlander-light">

<div id="page">

<div id="header">
	<div id="headerimg" onclick="location.href='https://johncarlosbaez.wordpress.com';" style="cursor: pointer;">
		<h1><a href="https://johncarlosbaez.wordpress.com/">Azimuth</a></h1>
		<div class="description"></div>
	</div>
</div>

<ul id="pagebar" class="menu pagebar"><li ><a href="https://johncarlosbaez.wordpress.com/">Home</a></li><li class="page_item page-item-2"><a href="https://johncarlosbaez.wordpress.com/about/">About</a></li>
</ul>

<div id="grad" style="height: 65px; width: 100%; background: url(https://s2.wp.com/wp-content/themes/pub/contempt/images/blue_flower/topgrad.jpg);">&nbsp;</div>

	<div id="content" class="widecolumn">

  


		<div class="post-2735 post type-post status-publish format-standard hentry category-this-weeks-finds" id="post-2735">
			<h2>This Week&#8217;s Finds (Week&nbsp;312)</h2>

			<div class="entry">
				<p>This is the second part of my interview with <a href="http://yudkowsky.net/">Eliezer Yudkowsky</a>.  If you click on some technical terms here, you&#8217;ll go down to a section where I explain them.  </p>
<p>
<b>JB</b>: You&#8217;ve made a great case for working on artificial intelligence&mdash;and more generally, understanding how intelligence works, to figure out how we can improve it.  It&#8217;s especially hard to argue against studying rationality.  Even most people who doubt computers will ever get smarter will admit the possibility that people can improve.  And it seems clear that the almost every problem we face could benefit from better thinking.</p>
<p>
I&#8217;m intrigued by the title <i>The Art of Rationality</i> because it suggests that there&#8217;s a kind of art to it.  We don&#8217;t know how to teach someone to be a great artist, but maybe we can teach them to be a better artist.  So, what are some of the key principles when it comes to thinking better?</p>
<p>
<b>EY</b>: Stars above, what an open-ended question.  The idea behind the book is to explain all the drop-dead basic fundamentals that almost no one seems to know about, like what is evidence, what is simplicity, what is truth, the importance of actually changing your mind now and then, the major known <a href="#Cognitive Bias">cognitive biases</a> that stop people from changing their minds, what it means to live in a universe where things are made of parts, and so on.  This is going to be a book primarily aimed at people who are not completely frightened away by complex mathematical concepts such as addition, multiplication, and division (i.e., all you need to understand <a href="#Bayes' Theorem">Bayes&#8217; Theorem</a> if it&#8217;s explained properly), albeit with the whole middle of the book being just practical advice based on cognitive biases for the benefit of people who don&#8217;t want to deal with multiplication and division.   Each chapter is going to address a different aspect of rationality, not in full textbook detail, just enough to convey the sense of a concept, with each chapter being around 5-10,000 words broken into 4-10 bite-size sections of 500-2000 words each.  Which of the 27 currently planned book chapters did you want me to summarize?</p>
<p>
But if I had to pick just one thing, just one concept that&#8217;s most important, I think it would be the difference between rationality and rationalization.</p>
<p>
Suppose there&#8217;s two boxes, only one of which contains a diamond.  And on the two boxes there are various signs and portents which distinguish, imperfectly and probabilistically, between boxes which contain diamonds, and boxes which don&#8217;t.  I could take a sheet of paper, and I could write down all the signs and portents that I understand, and do my best to add up the evidence, and then on the bottom line I could write, &quot;And therefore, there is a 37% probability that Box A contains the diamond.&quot;  That&#8217;s rationality.  Alternatively, I could be the owner of Box A, and I could hire a clever salesman to sell Box A for the highest price he can get; and the clever salesman starts by writing on the bottom line of his sheet of paper, &quot;And therefore, Box A contains the diamond&quot;, and then he writes down all the arguments he can think of on the lines above.</p>
<p>
But consider:  At the moment the salesman wrote down the bottom line on that sheet of paper, the truth or falsity of the statement was fixed.  It&#8217;s already right or already wrong, and writing down arguments on the lines above isn&#8217;t going to change that.  Or if you imagine a spread of probable worlds, some of which have different boxes containing the diamond, the <i>correlation</i> between the ink on paper and the diamond&#8217;s location became fixed at the moment the ink was written down, and nothing which doesn&#8217;t change the ink or the box is going to change that correlation.</p>
<p>
That&#8217;s &quot;rationalization&quot;, which should really be given a name that better distinguishes it from rationality, like &quot;anti-rationality&quot; or something.  It&#8217;s like calling lying &quot;truthization&quot;.  You can&#8217;t make rational what isn&#8217;t rational to start with.</p>
<p>
Whatever process your brain uses, in reality, to decide what you&#8217;re going to argue for, that&#8217;s what determines your real-world effectiveness.  Rationality isn&#8217;t something you can use to argue for a side you already picked.  Your only chance to be rational is while you&#8217;re still choosing sides, before you write anything down on the bottom line.  If I had to pick one concept to convey, it would be that one.</p>
<p>
<b>JB</b>: Okay.  I wasn&#8217;t really trying to get you to summarize a whole book.  I&#8217;ve seen you explain a whole lot of heuristics designed to help us be more rational.  So I was secretly wondering if the &quot;art of rationality&quot; is mainly a long list of heuristics, or whether you&#8217;ve been able to find a few key principles that somehow spawn all those heuristics.</p>
<p>
Either way, it could be a tremendously useful book.  And even if you could distill the basic ideas down to something quite terse, in practice people are going to need all those heuristics&mdash;especially since many of them take the form &quot;here&#8217;s something you tend to do without noticing you&#8217;re doing it&mdash;so watch out!&quot;  If we&#8217;re saddled with dozens of <a href="#Cognitive Bias">cognitive biases</a> that we can only overcome through strenuous effort, then your book has to be long.  You can&#8217;t just say &quot;apply Bayes&#8217; rule and all will be well.&quot;</p>
<p>
I can see why you&#8217;d single out the principle that &quot;rationality only comes into play before you&#8217;ve made up your mind&quot;, because so much seemingly rational argument is really just a way of bolstering support for pre-existing positions.  But what is rationality? Is it something with a simple essential core, like &quot;updating probability estimates according to Bayes&#8217; rule&quot;, or is its very definition inherently long and complicated?</p>
<p>
<b>EY</b>:  I&#8217;d say that there are parts of rationality that we do understand very well in principle.  <a href="#Bayes' Theorem">Bayes&#8217; Theorem</a>, the <a href="#Expected Utility">expected utility formula</a>, and <a href="#Solomonoff Induction">Solomonoff induction</a> between them will get you quite a long way.  Bayes&#8217; Theorem says how to update based on the evidence, Solomonoff induction tells you how to assign your priors (in principle, it should go as the <a href="#Kolmogorov Complexity">Kolmogorov complexity</a> aka algorithmic complexity of the hypothesis), and then once you have a function which predicts what will probably happen as the result of different actions, the expected utility formula says how to choose between them.</p>
<p>
Marcus Hutter has a formalism called <a href="#AIXI">AIXI</a> which combines all three to write out an AI as a <a href="http://www.hutter1.net/ai/uaibook.htm#oneline">single equation</a> which requires infinite computing power plus a <a href="#Halting Oracle">halting oracle</a> to run.  And Hutter and I have been debating back and forth for quite a while on which AI problems are or aren&#8217;t solved by AIXI.  For example, I look at the equation as written and I see that AIXI will try the experiment of dropping an anvil on itself to resolve its uncertainty about what happens next, because the formalism as written invokes a sort of Cartesian dualism with AIXI on one side of an impermeable screen and the universe on the other; the equation for AIXI says how to predict sequences of percepts using Solomonoff induction, but it&#8217;s too simple to encompass anything as reflective as &quot;dropping an anvil on myself will destroy that which is processing these sequences of percepts&quot;.  At least that&#8217;s what I claim; I can&#8217;t actually remember whether Hutter was agreeing with me about that as of our last conversation.  Hutter sees AIXI as important because he thinks it&#8217;s a theoretical solution to almost all of the important problems; I see AIXI as important because it demarcates the line between things that we understand in a fundamental sense and a whole lot of other things we don&#8217;t.</p>
<p>
So there are parts of rationality&mdash;big, important parts too&mdash;which we know how to derive from simple, compact principles in the sense that we could write very simple pieces of code which would behave rationally along that dimension given unlimited computing power.</p>
<p>
But as soon as you start asking &quot;How can <i>human beings</i> be more rational?&quot; then things become hugely more complicated because human beings make much more complicated errors that need to be patched on an individual basis, and asking &quot;How can I be rational?&quot; is only one or two orders of magnitude simpler than asking &quot;How does the brain work?&quot;, i.e., you <i>can</i> hope to write a single book that will cover many of the major topics, but not quite answer it in an interview question&#8230;</p>
<p>
On the other hand, the question &quot;What is it that I am <i>trying to do</i>, when I try to be rational?&quot; is a question for which big, important chunks can be answered by saying &quot;Bayes&#8217; Theorem&quot;, &quot;expected utility formula&quot; and &quot;simplicity prior&quot; (where Solomonoff induction is the canonical if uncomputable simplicity prior).</p>
<p>
At least from a mathematical perspective.  From a human perspective, if you asked &quot;What am I trying to do, when I try to be rational?&quot; then the fundamental answers would run more along the lines of &quot;Find the truth without flinching from it and without flushing all the arguments you disagree with out the window&quot;, &quot;When you don&#8217;t know, try to avoid just making stuff up&quot;, &quot;Figure out whether the strength of evidence is great enough to support the weight of every individual detail&quot;, &quot;Do what should lead to the best consequences, but not just what looks on the immediate surface like it should lead to the best consequences, you may need to follow extra rules that compensate for known failure modes like shortsightedness and moral rationalizing&quot;&#8230;</p>
<p>
<b>JB</b>:  Fascinating stuff!</p>
<p>
Yes, I can see that trying to improve humans is vastly more complicated than designing a system from scratch&#8230; but also very exciting, because you can tell a human a high-level principle like &quot; &quot;When you don&#8217;t know, try to avoid just making stuff up&quot; and have some slight hope that they&#8217;ll understand it without it being explained in a mathematically precise way.</p>
<p>
I guess AIXI dropping an anvil on itself is a bit like some of the self-destructive experiments that parents fear their children will try, like sticking a pin into an electrical outlet.  And it seems impossible to avoid doing such experiments without having a base of knowledge that was either &quot;built in&quot; or acquired by means of previous experiments.</p>
<p>
In the latter case, it seems just a matter of luck that none of these previous experiments were fatal.  Luckily, people also have &quot;built in&quot; knowledge.  More precisely, we have access to our ancestor&#8217;s knowledge and habits, which get transmitted to us genetically and culturally.  But still, a fair amount of random blundering, suffering, and even death was required to build up that knowledge base.</p>
<p>
So when you imagine &quot;seed AIs&quot; that keep on improving themselves and eventually become smarter than us, how can you reasonably hope that they&#8217;ll avoid making truly spectacular mistakes?   How can they learn really new stuff without a lot of risk?</p>
<p>
<b>EY</b>:  The best answer I can offer is that they can be conservative externally and deterministic internally.</p>
<p>
Human minds are constantly operating on the ragged edge of error, because we have evolved to compete with other humans.  If you&#8217;re a bit more conservative, if you double-check your calculations, someone else will grab the banana and that conservative gene will not be passed on to descendants.  Now this does not mean we couldn&#8217;t end up in a bad situation with AI companies competing with each other, but there&#8217;s at least the <i>opportunity</i> to do better.  </p>
<p>
If I recall correctly, the Titanic sank from managerial hubris and cutthroat cost competition, not engineering hubris.  The original liners were designed far more conservatively, with triple-redundant compartmentalized modules and soon.  But that was before cost competition took off, when the engineers could just add on safety features whenever they wanted.  The part about the Titanic being extremely safe was pure marketing literature. </p>
<p>
There is also no good reason why any machine mind should be overconfident the way that humans are.  There are studies showing that, yes, managers prefer subordinates who make overconfident promises to subordinates who make accurate promises&mdash;sometimes I still wonder that people are this silly, but given that people are this silly, the social pressures and evolutionary pressures follow.  And we have <i>lots</i> of studies showing that, for whatever reason, humans are hugely overconfident; less than half of students finish their papers by the time they think it 99% probable they&#8217;ll get done, etcetera.</p>
<p>
And this is a form of stupidity an AI can simply do without.  Rationality is not omnipotent; a <a href="#Bounded rationality">bounded rationalist</a> cannot do all things.  But there is no reason why a bounded rationalist should ever have to <i>overpromise</i>, be systematically overconfident, systematically tend to claim it can do what it can&#8217;t.  It does not have to systematically underestimate the value of getting more information, or overlook the possibility of unspecified <a href="#Black Swan">Black Swans</a> and what sort of general behavior helps to compensate.  (A bounded rationalist <i>does</i> end up overlooking specific Black Swans because it doesn&#8217;t have enough computing power to think of all <i>specific</i> possible catastrophes.)</p>
<p>
And contrary to how it works in say Hollywood, even if an AI does manage to accidentally kill a human being, that doesn&#8217;t mean it&#8217;s going to go &#8220;I HAVE KILLED&#8221; and dress up in black and start shooting nuns from rooftops.  What it ought to do&mdash;what you&#8217;d want to see happen&mdash;would be for the utility function to go on undisturbed, and for the probability distribution to update based on whatever unexpected thing just happened and contradicted its old hypotheses about what does and does not kill humans.  In other words, keep the same goals and say &#8220;oops&#8221; on the world-model; keep the same terminal values and revise its instrumental policies.  These sorts of external-world errors are not catastrophic unless they can actually wipe out the planet in one shot, somehow.</p>
<p>
The catastrophic sort of error, the sort you can&#8217;t recover from, is an error in modifying your own source code.  If you accidentally change your utility function you will no longer <i>want</i> to change it back.  And in this case you might indeed ask, &quot;How will an AI make millions or billions of code changes to itself without making a mistake like that?&quot;  But there are in fact methods powerful enough to do a billion error-free operations.  A friend of mine once said something along the lines of &quot;a CPU does a mole of transistor operations, error-free, in a day&quot; though I haven&#8217;t checked the numbers.  When chip manufacturers are building a machine with hundreds of millions of interlocking pieces and they don&#8217;t want to have to change it after it leaves the factory, they may go so far as to prove the machine correct, using human engineers to navigate the proof space and suggest lemmas to prove (which AIs can&#8217;t do, they&#8217;re defeated by the exponential explosion) and complex theorem-provers to prove the lemmas (which humans would find boring) and simple verifiers to check the generated proof.  It takes a combination of human and machine abilities and it&#8217;s extremely expensive.  But I strongly suspect that an Artificial General Intelligence with a good design would be able to treat <i>all</i> its code that way&mdash;that it would combine all those abilities in a single mind, and find it easy and natural to prove theorems about its code changes.  It could not, of course, prove theorems about the external world (at least not without highly questionable assumptions).  It could not prove external actions correct.  The only thing it could write proofs about would be events inside the highly deterministic environment of a CPU&mdash;that is, its own thought processes.  But it could prove that it was processing probabilities about those actions in a Bayesian way, and prove that it was assessing the probable consequences using a particular utility function.  It could prove that it was sanely trying to achieve the same goals.</p>
<p>
A self-improving AI that&#8217;s unsure about whether to do something ought to just wait and do it later after self-improving some more.  It doesn&#8217;t have to be overconfident.  It doesn&#8217;t have to operate on the ragged edge of failure.  It doesn&#8217;t have to stop gathering information too early, if more information can be productively gathered before acting.  It doesn&#8217;t have to fail to understand the concept of a Black Swan.  It doesn&#8217;t have to do all this using a broken error-prone brain like a human one.  It doesn&#8217;t have to be stupid in the ways like overconfidence that humans seem to have specifically evolved to be stupid.  It doesn&#8217;t have to be poorly calibrated (assign 99% probabilities that come true less that 99 out of 100 times), because bounded rationalists can&#8217;t do everything but they don&#8217;t have to claim what they can&#8217;t do.  It can <i>prove</i> that its self-modifications aren&#8217;t making itself crazy or changing its goals, at least if the transistors work as specified, or make no more than any possible combination of 2 errors, etc.  And if the worst does happen, so long as there&#8217;s still a world left afterward, it will say &quot;Oops&quot; and not do it again.  This sounds to me like essentially the optimal scenario given any sort of bounded rationalist whatsoever.</p>
<p>
And finally, if I was building a self-improving AI, I wouldn&#8217;t ask it to operate heavy machinery until after it had grown up.  Why should it?</p>
<p>
<b>JB</b>: Indeed!  </p>
<p>Okay&mdash;I&#8217;d like to take a break here, explain some terms you used, and pick up next week with some less technical questions, like <i>what&#8217;s a better use of time: tackling environmental problems, or trying to prepare for a technological singularity?</i><br />
<br />&nbsp;<br />&nbsp;</p>
<h4>Some explanations</h4>
<p>Here are some quick explanations.  If you click on the links here you&#8217;ll get more details:</p>
<p><a name="Cognitive Bias"><br /></a></p>
<p>&bull; <b>Cognitive Bias</b>.  A <a href="http://en.wikipedia.org/wiki/Cognitive_bias">cognitive bias</a> is a way in which people&#8217;s judgements systematically deviate from some norm&mdash;for example, from ideal rational behavior.  You can see a <a href="http://en.wikipedia.org/wiki/List_of_cognitive_biases">long list of cognitive biases</a> on Wikipedia.  It&#8217;s good to know a lot of these and learn how to spot them in yourself and your friends.  </p>
<p>
For example, <a href="http://en.wikipedia.org/wiki/Confirmation_bias">confirmation bias</a> is the tendency to pay more attention to information that confirms our existing beliefs.  Another great example is the <a href="http://en.wikipedia.org/wiki/Bias_blind_spot">bias blind spot</a>: the tendency for people to think of themselves as less cognitively biased than average!  I&#8217;m sure glad I don&#8217;t suffer from <i>that</i>.
</p>
<p><a name="Bayes' Theorem"><br /></a> </p>
<p>&bull; <b>Bayes&#8217; Theorem</b>.  This is a rule for updating our opinions about probabilities when we get new information.  Suppose you start out thinking the probability of some event A is P(A), and the probability of some event B is P(B).  Suppose P(A|B) is the probability of event A <i>given</i> that B happens.  Likewise, suppose P(B|A) is the probability of B given that A happens.  Then the probability that both A and B happen is
</p>
<p>
P(A|B) P(B)
</p>
<p>
but by the same token it&#8217;s also
</p>
<p>
P(B|A) P(A)
</p>
<p>
so these are equal.  A little algebra gives <a href="http://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes&#8217; Theorem</a>:
</p>
<p>
P(A|B) = P(B|A) P(A) / P(B)
</p>
<p>
If for some reason we know everything on the right-hand side, we can this equation to work out P(A|B), and thus update our probability for event A when we see event B happen.
</p>
<p>
For a longer explanation with examples, see:
</p>
<p>&bull; Eliezer Yudkowsky, <a href="http://yudkowsky.net/rational/bayes">An intuitive explanation of Bayes&#8217; Theorem</a>.</p>
<p>Some handy jargon: we call P(A) the <b>prior</b> probability of A, and P(A|B) the <b>posterior</b> probability.   </p>
<p><a name="Solomonoff Induction"><br /></a> </p>
<p>&bull;<b>Solomonoff Induction</b>.  Bayes&#8217; Theorem helps us compute posterior probabilities, but where do we get the prior probabilities from?  How can we guess probabilities before we&#8217;ve observed anything? </p>
<p>This famous puzzle led Ray Solomonoff to invent <a href="http://en.wikipedia.org/wiki/Inductive_inference">Solomonoff induction</a>.  The key new idea is <a href="http://www.scholarpedia.org/article/Algorithmic_probability">algorithmic probability theory</a>.  This is a way to define a probability for any string of letters in some alphabet, where a string counts as more probable if it&#8217;s less complicated.  If we think of a string as a &quot;hypothesis&quot;&mdash;it could be a sentence in English, or an equation&mdash;this becomes a way to formalize <a href="http://en.wikipedia.org/wiki/Occam%27s_razor">Occam&#8217;s razor</a>: the idea that given two competing hypotheses, the simpler one is more likely to be true.</p>
<p>
So, algorithmic probability lets us define a prior probability distribution on hypotheses, the so-called &#8220;simplicity prior&#8221;, that implements Occam&#8217;s razor.</p>
<p>
More precisely, suppose we have a special programming language where:</p>
<ol>
<li> Computer programs are written as strings of bits.
</p>
</li>
<li>They contain a special bit string meaning &#8220;END&#8221; at the end, and nowhere else.
</p>
</li>
<li>
They don&#8217;t take an input: they just run and either halt and print out a string of letters, or never halt.</p>
</li>
</ol>
<p>Then to get the algorithmic probability of a string of letters, we take all programs that print out that string and add up</p>
<p><div align="center">
2<sup>-length of program</sup></p>
</div>
<p>So, you can see that a string counts as more probable if it has more short programs that print it out.</p>
<p><a name="Kolmogorov Complexity"><br /></a></p>
<p> &bull;<b>Kolmogorov complexity</b>.  The <a href="http://en.wikipedia.org/wiki/Kolmogorov_complexity">Kolmologorov complexity</a> of a string of letters is the length of the shortest program that prints it out, where programs are written in a special language as described above.   This is a way of measuring how complicated a string is.  It&#8217;s closely related to the algorithmic entropy: the difference between the Kolmogorov complexity of a string and minus the logarithm of its algorithmic probability is bounded by a constant, if we take logarithms using base 2.  For more on all this stuff, see:</p>
<p>&bull; M. Li and P. Vit&aacute;nyi, <i>An Introduction to Kolmogorov Complexity Theory and its Applications</i>, Springer, Berlin, 2008.</p>
<p><a name="Halting Oracle"><br /></a> </p>
<p> &bull; <b>Halting Oracle</b>.  Alas, the algorithmic probability of a string is not <a href="http://en.wikipedia.org/wiki/Computability_theory">computable</a>.   Why?  Because to compute it, you&#8217;d need to go through all the programs in your special language that print out that string and add up a contribution from each one.   But to do that, you&#8217;d need to know which programs halt&mdash;and there&#8217;s no systematic way to answer that question, which is called the <a href="http://en.wikipedia.org/wiki/Halting_problem">halting problem</a>.
</p>
<p>
But, we can pretend!  We can pretend we have a magic box that will tell us whether any program in our special language halts.  Computer scientists call any sort of magic box that answers questions an <a href="http://en.wikipedia.org/wiki/Oracle_machine">oracle</a>.  So, our particular magic box called a <a href="http://www.xamuel.com/the-halting-problem/">halting oracle</a>.</p>
<p><a name="AIXI"><br /></a> </p>
<p> &bull; <b>AIXI</b>.  AIXI is <a href="http://www.hutter1.net/">Marcus Hutter&#8217;s</a> attempt to define an agent that &quot;behaves optimally in any computable environment&quot;.  Since AIXI relies on the idea of algorithmic probability, you can&#8217;t run AIXI on a computer unless it has infinite computer power and&mdash;the really hard part&mdash;access to a halting oracle.  However, Hutter has also defined computable approximations to AIXI.  For a quick intro, see this:</p>
<p>&bull; Marcus Hutter, <a href="http://www.hutter1.net/ai/aixigentle.pdf">Universal intelligence: a mathematical top-down approach</a>.</p>
<p>
For more, try this:
</p>
<p>&bull; Marcus Hutter, <i>Universal Artificial Intelligence: Sequential Decisions Based on Algorithmic Probability</i>, Springer, Berlin, 2005.</p>
<p><a name="Expected Utility"><br /></a> </p>
<p> &bull; <b>Utility</b>.  <a href="http://en.wikipedia.org/wiki/Utility">Utility</a> is a hypothetical numerical measure of satisfaction.  If you know the probabilities of various outcomes, and you know what your utility will be in each case, you can compute your &quot;expected utility&quot;  by taking the probabilities of the different outcomes, multiplying them by the corresponding utilities, and adding them up.  In simple terms, this is how happy you&#8217;ll be <i>on average</i>.  The <a href="http://en.wikipedia.org/wiki/Expected_utility_hypothesis">expected utility hypothesis</a> says that a rational decision-maker has a utility function and will try to maximize its expected utility.  </p>
<p><a name="Bounded Rationality"><br /></a> </p>
<p> &bull;<b>Bounded Rationality</b>.  In the real world, any decision-maker has limits on its computational power and the time it has to make a decision.  The idea that rational decision-makers &quot;maximize expected utility&quot; is oversimplified unless it takes this into account somehow.  Theories of <a href="http://en.wikipedia.org/wiki/Bounded_rationality">bounded rationality</a> try to take these limitations into account.  One approach is to think of decision-making as yet another activity whose costs and benefits must be taken into account when making decisions.  Roughly: you must decide how much time you want to spend deciding.  Of course, there&#8217;s an interesting circularity here.</p>
<p><a name="Black Swan"><br /></a> </p>
<p> &bull; <b>Black Swan</b>.  According to <a href="http://en.wikipedia.org/wiki/Nassim_Nicholas_Taleb">Nassim Taleb</a>, human history is dominated by <a href="http://en.wikipedia.org/wiki/Black_swan_theory">black swans</a>: important events that were unpredicted and indeed unpredictable, but rationalized by hindsight and thus made to seem as if they <i>could</i> have been predicted.  He believes that rather than trying to predict such events (which he considers largely futile), we should try to get good at adapting to them.  For more see:</p>
<p>&bull; Nassim Taleb, <i><a href="http://en.wikipedia.org/wiki/The_Black_Swan_%28Taleb_book%29">The Black Swan: The Impact of the Highly Improbable</a></i>, Random House, New York, 2007.</p>
<hr />
<p>
<em>The first principle is that you must not fool yourself&mdash;and you are the easiest person to fool.</em> &#8211; Richard Feynman</p>
<div id="jp-post-flair" class="sharedaddy sd-sharing-enabled">
<div id='jp-relatedposts' class='jp-relatedposts' >
	<h3 class="jp-relatedposts-headline"><em>Related</em></h3>
</div></div>
				
				<p class="postmetadata alt">
					<small>
					This entry was posted  on Monday, March 14th, 2011 at 8:48 am and is filed under <a href="https://johncarlosbaez.wordpress.com/category/this-weeks-finds/" rel="category tag">this week's finds</a>.					You can follow any responses to this entry through the <a href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/feed/'>RSS 2.0</a> feed.
											You can <a href="#respond">leave a response</a>, or <a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/trackback/" rel="trackback">trackback</a> from your own site.
					
					</small>
				</p>

				<nav id="nav-below">
					<h3 class="assistive-text">Post navigation</h3>
					<span class="nav-previous"><a href="https://johncarlosbaez.wordpress.com/2011/03/12/tsunami/" rel="prev">&laquo; Previous Post</a></span>
					<span class="nav-next"><a href="https://johncarlosbaez.wordpress.com/2011/03/18/energy-the-environment-and-what-mathematicians-can-do-part-1/" rel="next">Next Post &raquo;</a></span>
				</nav><!-- #nav-below -->

			</div>
		</div>

	<div id="comments">


<h3 id="comments-title">30 Responses to <em>This Week&#8217;s Finds (Week&nbsp;312)</em></h3>


<ol class="commentlist">
			<li class="comment even thread-even depth-1 highlander-comment" id="comment-4577">
				<div id="div-comment-4577" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/5850d628c599d7ac60d7f7889844995a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">John F</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4577">14 March, 2011 at 10:45 am</a>		</div>

		<p>So, an &#8220;oops&#8221; moment may be a better signal of AI self-discovery than an &#8220;aha&#8221; moment? Aha! Wait, &#8211; oops.</p>
<p>Although some of its priors will have to be inductively inferred, especially for new hypotheses, most ab initio priors can be spoon fed on bootup. It would be interesting to see if there is a maximal set of priors that doesn&#8217;t incorporate many biases.</p>
<p>I think most self-destructive behavior can be avoided by hard coding, as a bias. It doesn&#8217;t have to be quite as explicit as &#8220;avoid self destruction&#8221;; maybe &#8220;it is always probably a bad idea to diminish the ability to compute probabilities&#8221;.</p>
<p>The HAL problem in 2001 stemmed from the overconfidence bias &#8211; which was empirically derived: &#8220;We are all, by any practical definition of the words, foolproof and incapable of error.&#8221; So then when it made an error, it flawlessly inferred that it should be paranoid, since it was therefore the humans&#8217; fault.</p>
<p>An unsure AI doesn&#8217;t have to do nothing. For example, suppose it is in a large vehicle, and it encounters a sodden bundle on the highway. It is prudent to stop, but the choices are never just &#8220;keep going and run it over&#8221; or &#8220;stop and wait&#8221;. There is always also &#8220;poke it with a stick&#8221;.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4577#respond' data-commentid="4577" data-postid="2735" data-belowelement="div-comment-4577" data-respondelement="respond" data-replyto="Reply to John F" aria-label='Reply to John F'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1 parent highlander-comment" id="comment-4578">
				<div id="div-comment-4578" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/83c16232570c763f8e0821a98c18e087?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">streamfortyseven</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4578">14 March, 2011 at 10:48 am</a>		</div>

		<p>I&#8217;ll let the experts in algorithmics argue about whether the modified AIXI approach is feasible in finite time. It still looks like a rule-based AI which changes its rules in a predetermined manner and thus has neither intentionality nor volition of its own. </p>
<p>As to the Titanic, the statement that &#8220;the Titanic sank from managerial hubris and cutthroat cost competition, not engineering hubris&#8230;. The part about the Titanic being extremely safe was pure marketing literature&#8221; is counterfactual. </p>
<p>On the contrary, an engineering study done in 1998 stated that &#8220;[t]he Titanic was also equipped with the ultimate in turn-of-the-century design and technology, including sixteen major watertight compartments in her lower section that could easily be sealed off in the event of a punctured hull.&#8221; This study found, by means of testing a piece of the steel recovered from the wreckage, that the steel used in the hull plating had high sulfur content and was prone to brittle fracture and not ductile deformation at the low temperatures that could be expected to exist in an ice field: </p>
<p>&#8220;The failure of the hull steel resulted from brittle fractures caused by the high sulphur content of the steel, the low temperature water on the night of the disaster, and the high impact loading of the collision with the iceberg. When the Titanic hit the iceberg, the hull plates split open and continued cracking as the water flooded the ship. Low water temperatures and high impact loading also caused the brittle failure of the rivets used to fasten the hull plates to the ship&#8217;s main structure. On impact, the rivets were either sheared off or the heads popped off because of excessive loading, which opened up riveted seams.&#8221; (see <a href="http://www.writing.engr.psu.edu/uer/bassett.html" rel="nofollow ugc">http://www.writing.engr.psu.edu/uer/bassett.html</a>)</p>
<p>Given the technology of the time, this failure mode could not have been easily foreseen. From an extensive analysis done by another group, &#8220;[t]he steel used in constructing the RMS Titanic was probably the best plain carbon ship plate available in the period of 1909 to 1911 &#8230; If the Titanic had not collided with the iceberg, it could have had a career of more than 20 years as the Olympic had. It was built of similar steel, in the same shipyard, and from the same design. The only difference was a big iceberg.&#8221; (see <a href="http://www.tms.org/pubs/journals/jom/9801/felkins-9801.html" rel="nofollow ugc">http://www.tms.org/pubs/journals/jom/9801/felkins-9801.html</a>)</p>
<p>The fact of the matter is that it was neither managerial nor engineering hubris that caused the collision and the sinking, nor cost-cutting on the part of the White Star Line. The safety features were the best known <b>at the time</b>, and the materials used were the best available <b>at the time</b>.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4578#respond' data-commentid="4578" data-postid="2735" data-belowelement="div-comment-4578" data-respondelement="respond" data-replyto="Reply to streamfortyseven" aria-label='Reply to streamfortyseven'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor even depth-2 parent highlander-comment" id="comment-4583">
				<div id="div-comment-4583" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4583">14 March, 2011 at 1:02 pm</a>		</div>

		<p>Fascinating, streamfortyseven! </p>
<p>Are these points universally accepted, or controversial?  I can easily imagine people using the Titanic as a kind of football to push different philosophies of risk management, engineering, etcetera&#8230; sort of like how other people continue to re-argue the case of <a href="http://en.wikipedia.org/wiki/Alger_Hiss" rel="nofollow">Alger Hiss</a>.  But I have no idea if they actually do.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4583#respond' data-commentid="4583" data-postid="2735" data-belowelement="div-comment-4583" data-respondelement="respond" data-replyto="Reply to John Baez" aria-label='Reply to John Baez'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment odd alt depth-3 highlander-comment" id="comment-4597">
				<div id="div-comment-4597" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/83c16232570c763f8e0821a98c18e087?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">streamfortyseven</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4597">14 March, 2011 at 8:23 pm</a>		</div>

		<p>The best steel made at that time tended to be high-sulfur steel, which was also easier to machine, i.e. drill rivet holes in. There were 3 million rivets in the Titanic, roughly, and the technology for bending 3/4 inch sheet steel was relatively crude as well. This kind of steel has been shown by engineering studies done in the 1990s, more than 80 years after the sinking, to fracture and break in cold water, rather than bend. The studies showing this are not controversial, and this is the most accepted reason for the failure of Titanic&#8217;s hull. Titanic&#8217;s sister ship, the Olympic, built on very close to the same plan by the same shipyard and using the same steel, was in service for at least 20 years, the sole difference between the two is that the Olympic did not ever hit an iceberg.</p>
<p>Double hulls with this kind of steel may not have saved the day; any collision with this kind of steel would result in fracturing, not ductile deformation. That&#8217;s a matter for speculation, but the industry from then on made double hulls a requirement, amongst many other safety improvements.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4597#respond' data-commentid="4597" data-postid="2735" data-belowelement="div-comment-4597" data-respondelement="respond" data-replyto="Reply to streamfortyseven" aria-label='Reply to streamfortyseven'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment even depth-3 highlander-comment" id="comment-4600">
				<div id="div-comment-4600" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/83c16232570c763f8e0821a98c18e087?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">streamfortyseven</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4600">14 March, 2011 at 9:33 pm</a>		</div>

		<p>The other trouble is that people tend to make analyses of historical events based on information that they have available at present, and do not take into consideration that the information available at the time of the event was much more limited, of a different character, was inaccurate or incomplete, or just plain wrong.</p>
<p>It&#8217;s true, no one would build a ship like Titanic today, using high-sulfur steel, a single hull, and bulkheads that barely topped the waterline. However, given the state of engineering knowledge of 1909 to 1911, it was state-of-the-art technology. They didn&#8217;t have the testing ability to find out otherwise and they had no clue that such a catastrophic failure could occur, that the steel of the hull plating would break like a porcelain teacup on a glancing blow from an iceberg. The fact that more than 80 years had to pass before the true cause of the structural failure was found should give some idea of the difficulty of the problem &#8211; which wasn&#8217;t directly solved by postmortem examination, but by adoption of an entirely different way of making steel, and the use of high-carbon, low-sulfur steel for hull plating.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4600#respond' data-commentid="4600" data-postid="2735" data-belowelement="div-comment-4600" data-respondelement="respond" data-replyto="Reply to streamfortyseven" aria-label='Reply to streamfortyseven'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt depth-2 parent highlander-comment" id="comment-4589">
				<div id="div-comment-4589" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/04e8217661e5e48b523b8ebcb194a8a7?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://cscheid.net' rel='external nofollow ugc' class='url'>Carlos</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4589">14 March, 2011 at 2:33 pm</a>		</div>

		<p>&#8220;has neither intentionality nor volition of its own&#8221;</p>
<p>Can you define intentionality or volition in a way that doesn&#8217;t prescribe, prima facie, that silicon-based intelligence, theoretical however they might be, could have intentionality or volition? From your message, it would seem not, since by definition anything we could possibly program could be seen as constrained to obeying rules. </p>
<p>As a result, the complaint about intentionality or volition feels very much like meat chauvinism.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4589#respond' data-commentid="4589" data-postid="2735" data-belowelement="div-comment-4589" data-respondelement="respond" data-replyto="Reply to Carlos" aria-label='Reply to Carlos'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment even depth-3 parent highlander-comment" id="comment-4599">
				<div id="div-comment-4599" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/83c16232570c763f8e0821a98c18e087?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">streamfortyseven</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4599">14 March, 2011 at 9:10 pm</a>		</div>

		<p>&#8220;meat chauvinism&#8221;? Is this the beginning of a civil rights complaint from the Association for Computing Machinery? ;-)</p>
<p>I&#8217;m not sure how to parse your question, but these might provide some answers:</p>
<p>1. <a href="http://www.c4ads.org/files/cads_report_inmodels_060206.pdf" rel="nofollow ugc">http://www.c4ads.org/files/cads_report_inmodels_060206.pdf</a></p>
<p>2. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.8441&#038;rep=rep1&#038;type=pdf" rel="nofollow ugc">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.8441&#038;rep=rep1&#038;type=pdf</a></p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4599#respond' data-commentid="4599" data-postid="2735" data-belowelement="div-comment-4599" data-respondelement="respond" data-replyto="Reply to streamfortyseven" aria-label='Reply to streamfortyseven'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment odd alt depth-4 highlander-comment" id="comment-4601">
				<div id="div-comment-4601" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/5850d628c599d7ac60d7f7889844995a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">John Furey</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4601">14 March, 2011 at 10:13 pm</a>		</div>

		<p>Previously I said it seemed to me that mere diligence met the externally observable definitions of volition you proffered. I added that irrational preference seemed to be the missing ingredient. Any thoughts? How would one externally observe a lack of &#8220;predetermined manner&#8221;, if such lack is required.</p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment even depth-4 highlander-comment" id="comment-4602">
				<div id="div-comment-4602" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/83c16232570c763f8e0821a98c18e087?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">streamfortyseven</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4602">14 March, 2011 at 11:29 pm</a>		</div>

		<p>Who decides what is &#8220;rational&#8221;? If we say that &#8220;rational&#8221; preferences maximize the probability of positive reinforcement, then we&#8217;ve got to wait until the end of the first iteration of the game, so to speak, before we can begin to collect information on this, and we&#8217;ve got to run the game numerous times to figure out the probablilities of positive reinforcement &#8211; but before any of this happens, we have to know what &#8220;positive reinforcement&#8221; means.</p>
<p>Mere diligence is the act of doing the same thing over and over; irrational preference is (1) that condition which exists until there is sufficient information to provide some indication of the probability of positive reinforcement given a particular input set or (2) that condition which exists when the probability of positive reinforcement given a particular input set is known and is not taken into account; ignorance is an example of (1) and bluffing or creativity may be an example of (2).</p>
<p>Diligence (or perseverance), the repeating of a certain set of actions may be an indicator of volition if there is a probability greater than 50% (say) that the end result is positive reinforcement, but may not be an indicator of anything if the end result is not positive reinforcement. The first case might be a learned behavior conditioned by positive reinforcement, the second case might be that of unconscious repetitive movements as seen in epileptic seizures or tardive dyskinesia.</p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt depth-4 highlander-comment" id="comment-4617">
				<div id="div-comment-4617" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/5850d628c599d7ac60d7f7889844995a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">John Furey</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4617">15 March, 2011 at 1:07 pm</a>		</div>

		<p>No, diligence is not mindless repetition. It is perseverence in accomplishing.<br />
<a href="http://dictionary.reference.com/browse/diligence" rel="nofollow ugc">http://dictionary.reference.com/browse/diligence</a><br />
To be diligent one must know what to accomplish, and know whether you are accomplishing it. The notion is like a journey.</p>
<p>Anyway a robot can be diligent without volition. For instance a Roomba with ordinary sensors can diligent about patroling a certain room, and with additional sensors can be diligent about many things.</p>

		
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1 parent highlander-comment" id="comment-4581">
				<div id="div-comment-4581" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/653623c8ab2aa94f882be46111bb3ae4?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://xwww.uni-math.gwdg.de/graboluk/' rel='external nofollow ugc' class='url'>Lukasz Grabowski</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4581">14 March, 2011 at 12:54 pm</a>		</div>

		<p>Only a tangential comment: It&#8217;s interesting how current nuclear crisis in Japan has its impact in Germany&#8217;s public debate on nuclear power. I tend to have an opinion along the lines &#8220;I can&#8217;t possibly imagine what kind of accident could happen here that would cause radioactive leakage&#8221;, whereas many people say something like &#8220;We don&#8217;t care you can&#8217;t imagine. We also can&#8217;t imagine such a thing, but we want the nuclear plants shut just to be sure.&#8221; After reading the interview, and steamfortyseven&#8217;s comment on Titanic, I&#8217;m pondering whether this isn&#8217;t actually a sensible approach of &#8220;avoiding black swans&#8221;.</p>
<p>But as a matter of fact, I&#8217;m still waiting for the final assessment of the Japanese nuclear crisis, hoping that it won&#8217;t cause any substantial permanent damage.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4581#respond' data-commentid="4581" data-postid="2735" data-belowelement="div-comment-4581" data-respondelement="respond" data-replyto="Reply to Lukasz Grabowski" aria-label='Reply to Lukasz Grabowski'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor odd alt depth-2 highlander-comment" id="comment-4584">
				<div id="div-comment-4584" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4584">14 March, 2011 at 1:07 pm</a>		</div>

		<p>I&#8217;m very interested in the debate about nuclear power, and how the Japanese tsunami will affect this debate.  The issue of &#8220;black swans&#8221; is very relevant!   But I hope people to discuss tsunami-related issues <a href="https://johncarlosbaez.wordpress.com/2011/03/12/tsunami/" rel="nofollow">here</a>, where I&#8217;ve summarized some news about the tsunami, the problems with the Fukushima reactors, and the many deaths that people in the West seem much less interested in.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4584#respond' data-commentid="4584" data-postid="2735" data-belowelement="div-comment-4584" data-respondelement="respond" data-replyto="Reply to John Baez" aria-label='Reply to John Baez'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="pingback even thread-odd thread-alt depth-1 highlander-comment" id="comment-4590">
				<div id="div-comment-4590" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://qchu.wordpress.com/2011/03/09/john-baez-interviews-eliezer-yudkowsky/' rel='external nofollow ugc' class='url'>John Baez interviews Eliezer Yudkowsky &laquo; Annoying Precision</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4590">14 March, 2011 at 3:23 pm</a>		</div>

		<p>[&#8230;] 3/14/11: Part two of the interview is [&#8230;]</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4590#respond' data-commentid="4590" data-postid="2735" data-belowelement="div-comment-4590" data-respondelement="respond" data-replyto="Reply to John Baez interviews Eliezer Yudkowsky &laquo; Annoying Precision" aria-label='Reply to John Baez interviews Eliezer Yudkowsky &laquo; Annoying Precision'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent highlander-comment" id="comment-4603">
				<div id="div-comment-4603" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/83c16232570c763f8e0821a98c18e087?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">streamfortyseven</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4603">14 March, 2011 at 11:57 pm</a>		</div>

		<p>EY writes that “Marcus Hutter has a formalism called AIXI which combines all three to write out an AI as a single equation which requires infinite computing power plus a halting oracle to run. … Hutter sees AIXI as important because he thinks it’s a theoretical solution to almost all of the important problems; I see AIXI as important because it demarcates the line between things that we understand in a fundamental sense and a whole lot of other things we don’t.”</p>
<p>Hutter presents AIXI as a sort of “chronological Turing machine” which uses reinforcement learning to modify itself to enhance the probability of getting a positive result. The math which he uses, to the limited extent I can understand it, looks quite similar to that used in connectionist learning machines, and specifically, to that used in backpropagation neural networks (see <a href="http://en.wikipedia.org/wiki/Backpropagation" rel="nofollow ugc">http://en.wikipedia.org/wiki/Backpropagation</a> and <a href="http://www.speech.sri.com/people/anand/771/html/node37.html" rel="nofollow ugc">http://www.speech.sri.com/people/anand/771/html/node37.html</a>) The trouble with this is that backprop networks are well-specified only for “toy” problems and are nearly impossible, if not wholly impossible, to scale up to real problems, which Hutter states is a problem for his more limited version of AIXI as well (see <a href="http://www.hutter1.net/ai/aixigentle.pdf" rel="nofollow ugc">http://www.hutter1.net/ai/aixigentle.pdf</a> at p57, “A direct implementation of the AIXItl model is, at best, possible for small-scale (toy) environments due to the large factor 2l in computation time.”)</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4603#respond' data-commentid="4603" data-postid="2735" data-belowelement="div-comment-4603" data-respondelement="respond" data-replyto="Reply to streamfortyseven" aria-label='Reply to streamfortyseven'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor even depth-2 parent highlander-comment" id="comment-4606">
				<div id="div-comment-4606" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4606">15 March, 2011 at 2:20 am</a>		</div>

		<p>Right, I don&#8217;t see AIXI and its computable variants as <i>practical</i> systems, but rather as tools to investigate certain conceptual points.  </p>
<p>Any human or animal has a vast supply of built-in tendencies at birth which are adapted to the environment it finds itself in: to take a random example, the part of our brain called the <a href="http://en.wikipedia.org/wiki/Fusiform_face_area" rel="nofollow">fusiform face area</a> seems dedicated to recognizing faces and perhaps categorizing other types of visual stimuli.  AIXI is much closer to the <a href="http://en.wikipedia.org/wiki/Tabula_rasa" rel="nofollow"><i>tabula rasa</i></a> of Locke&#8217;s naive epistemology: in plain English, a blank slate.</p>
<p>This is why the whole question of prior probabilities is so important for AIXI: <i>how can you assign probabilities to hypotheses before you have any experience of the world?</i>   And that&#8217;s where <a href="http://en.wikipedia.org/wiki/Inductive_inference" rel="nofollow">Solomonoff induction</a> comes into play: you can assign probabilities by saying that simpler hypotheses count as more probable.</p>
<p>So, AIXI would start life as a radically unspecialized being, much more of a blank slate than a human baby or a baby fruit fly.  Only after long exposure to some particular &#8216;environment&#8217; would it have a chance to start seeming &#8216;intelligent&#8217; in the ordinary sense.  </p>
<p>Since I haven&#8217;t read Hutter&#8217;s book, I don&#8217;t know if he&#8217;s done any experiments with AIXI&#8217;s computable variants in interesting &#8216;environments&#8217;.  Given the very slow run-time you mention, it might be impractical.  Someone should try versions that cut even more corners and does things worse  but faster. </p>
<p>Yudkowsky said:</p>
<blockquote><p>
Hutter sees AIXI as important because he thinks it’s a theoretical solution to almost all of the important problems; I see AIXI as important because it demarcates the line between things that we understand in a fundamental sense and a whole lot of other things we don’t.
</p></blockquote>
<p>I&#8217;m on Yudkowsky&#8217;s side here.  Personally I&#8217;d emphasize that we understand a few things quite well and a whole lot of things not very well at all.  And to me, this makes the task of constructing really interesting AI seem like a very large task that will take a long time.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4606#respond' data-commentid="4606" data-postid="2735" data-belowelement="div-comment-4606" data-respondelement="respond" data-replyto="Reply to John Baez" aria-label='Reply to John Baez'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment odd alt depth-3 highlander-comment" id="comment-4631">
				<div id="div-comment-4631" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/1c5a8a88aadcdcb7a4b24b8913a0993f?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://lesswrong.com/lw/qk/that_alien_message/' rel='external nofollow ugc' class='url'>Eliezer Yudkowsky</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4631">16 March, 2011 at 7:40 am</a>		</div>

		<p>Actually, I would expect the true infinite-computing-power version of AIXI to learn <i><b>extremely</b></i> fast.  See <a href="http://lesswrong.com/lw/qk/that_alien_message/" rel="nofollow">That Alien Message</a> for details.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4631#respond' data-commentid="4631" data-postid="2735" data-belowelement="div-comment-4631" data-respondelement="respond" data-replyto="Reply to Eliezer Yudkowsky" aria-label='Reply to Eliezer Yudkowsky'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment even depth-3 highlander-comment" id="comment-4648">
				<div id="div-comment-4648" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/656e05d084448337fb49459225dc525e?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">DavidTweed</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4648">16 March, 2011 at 4:11 pm</a>		</div>

		<p>As I mentioned last week, it&#8217;s far from clear that the first &#8220;semi-independent&#8221; AI&#8217;s will be logical machines that have been constructed, simply because it&#8217;s unclear that the number of (unaugmented) human beings devoted to the task will be able to keep all of the details in their &#8220;collective&#8221; heads. As a datapoint, one of the recent areas of work in language compilation technology is applying pattern recognition techniques to choosing optimatisations (selected from a set which are known to preserve correctness), because the complexity of the relatively low-power (compared to something that could host a true AI) chips+memory is exceeding human ability to design/test suitable optimisation strategies.</p>
<p>It might, as pointed out, have the issue that we won&#8217;t know what kind of attitudes the AI might have if they are produced from incremental advances of pattern based systems, but I find it difficult to believe the &#8220;designed logic&#8221; approach will get there even close to the timescale of that approach.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4648#respond' data-commentid="4648" data-postid="2735" data-belowelement="div-comment-4648" data-respondelement="respond" data-replyto="Reply to DavidTweed" aria-label='Reply to DavidTweed'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt depth-3 parent highlander-comment" id="comment-4652">
				<div id="div-comment-4652" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/83c16232570c763f8e0821a98c18e087?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">streamfortyseven</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4652">16 March, 2011 at 7:36 pm</a>		</div>

		<p>From what I can gather from this paper, On the Existence and Convergence of Computable Universal Priors∗. Marcus Hutter. IDSIA, Galleria 2, CH-6928 Manno-Lugano, Switzerland <a href="mailto:marcus@idsia.ch">marcus@idsia.ch</a>, available at <a href="http://www.hutter1.net/ai/unipriors.pdf" rel="nofollow ugc">http://www.hutter1.net/ai/unipriors.pdf</a>, Table 5 on page 8 seems to suggest that the task of constructing really interesting AI will take a <b>really long</b> time&#8230;</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4652#respond' data-commentid="4652" data-postid="2735" data-belowelement="div-comment-4652" data-respondelement="respond" data-replyto="Reply to streamfortyseven" aria-label='Reply to streamfortyseven'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment even depth-4 highlander-comment" id="comment-4653">
				<div id="div-comment-4653" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/c06be7d387ad838e57f6f420ad0b7f92?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Thomas</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4653">16 March, 2011 at 9:28 pm</a>		</div>

		<p>&#8220;really interesting AI will take a really long time…&#8221; Not only that: Nahm <a href="http://www.itp.uni-hannover.de/~flohr/lectures/cft/nahm.cft.pdf" rel="nofollow"><i>estimates</i></a> 150 years until &#8220;we really understand what is going on at the basic scale&#8221; in physics.</p>

		
				</div>
				</li><!-- #comment-## -->
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor odd alt depth-4 highlander-comment" id="comment-4654">
				<div id="div-comment-4654" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4654">17 March, 2011 at 2:10 am</a>		</div>

		<p>Thomas wrote:</p>
<blockquote>
<p>Not only that: Nahm estimates 150 years until “we really understand what is going on at the basic scale” in physics.</p>
</blockquote>
<p>Of course, that&#8217;s not particularly relevant to the question of AI: we don&#8217;t need to understand fundamental physics to develop AI.</p>
<p>But I essentially agree with Nahm.  Though I&#8217;d be loath to put a date on how long it&#8217;ll take to figure out the true laws of physics, there are lots of very basic important things that we&#8217;re completely clueless about.  Why do elementary particles have mass at all, let alone the specific masses they have?  What is most of the universe made of?  (Not, apparently, the kinds of matter we understand.)  Why does space have 3 dimensions?  Etcetera.  </p>
<p>For a more complete list of puzzles, see:</p>
<p>&bull; <a href="http://math.ucr.edu/home/baez/physics/General/open_questions.html" rel="nofollow">Open questions in physics</a>, The Physics FAQ.</p>
<p>(This needs to be updated a bit!)</p>

		
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1 highlander-comment" id="comment-4628">
				<div id="div-comment-4628" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/790504be0016c185f5f06f52954f3d49?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://epistle-null.blogspot.com' rel='external nofollow ugc' class='url'>some guy on the street</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4628">16 March, 2011 at 5:52 am</a>		</div>

		<p>Oh, the thing called &#8220;rationalization&#8221; above has variously been called &#8220;rhetoric&#8221; and &#8220;sophistry&#8221; in the past, and is well known to historians.</p>
<p>If I may interject one small caution, I suspect that the <i>rarity</i>  of trained rationality is significant of the nature of human thinking: it <i>isn&#8217;t</i> rational, and for good reason: careful reason can easily take too much time!  This is why, for instance, Aristotle and Thomas (that&#8217;s Aquinas&#8230;) argue in favour of <i>virtue</i>; the habit of acting ethically formed through long deliberate practice.</p>
<p>It seems to me &#8212; and I may be wrong &#8212; that this art of rationality is essentially the ideal object of a classical Liberal Arts education &#8212; whether with a platonic academy or under Aristotle&#8217;s tutelage or in the University of Paris (the old one, that doesn&#8217;t exist anymore).</p>
<p>In this recent period of apparently universal literacy it seems to me appalling that rational thought isn&#8217;t given formal attention in grade school curricula.  You can tell this has been a problem for a while, when (for instance) music faculties at <i>BIG</i> modern universities stop teaching Gregorian chant on the grounds that &#8220;the students don&#8217;t find it accessible&#8221;.  I have heard tell of such horrors near here, and can only wonder &#8220;since when is it fitting in a University to meet students where they are?&#8221; (A course has to, by nature, start where the students are, but the aim of a course has to be somewhere ELSE). Anyways. &lt;/rant&gt;</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4628#respond' data-commentid="4628" data-postid="2735" data-belowelement="div-comment-4628" data-respondelement="respond" data-replyto="Reply to some guy on the street" aria-label='Reply to some guy on the street'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent highlander-comment" id="comment-4659">
				<div id="div-comment-4659" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/763cc4f73f88dbac2b1a828e929a81f5?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://www.last.fm/user/rwitte' rel='external nofollow ugc' class='url'>Roger Witte</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4659">17 March, 2011 at 1:52 pm</a>		</div>

		<p>I have often though that there is a reasonable possibility that the first AI might not arise from people trying to build an AI at all.  As both cloud computing and computer viruses advance, we may get virus style processes wandering around trying to steal the resources they need (processor time, storage space) from the cloud without being detected and deleted&#8230;Once we have the ingredients of competition, imperfect reproduction and natural selection, Darwinian evolution starts.  If intelligence helps such a program or process prosper secretively (which it might) then it could happen without us noticing.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4659#respond' data-commentid="4659" data-postid="2735" data-belowelement="div-comment-4659" data-respondelement="respond" data-replyto="Reply to Roger Witte" aria-label='Reply to Roger Witte'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment even depth-2 parent highlander-comment" id="comment-4662">
				<div id="div-comment-4662" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/83c16232570c763f8e0821a98c18e087?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">streamfortyseven</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4662">17 March, 2011 at 4:18 pm</a>		</div>

		<p>Yeah, but will it stop the human operator from kill -9&#8217;ing the processes? Will it negotiate? &#8220;Dave, why are you doing this?&#8221;</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4662#respond' data-commentid="4662" data-postid="2735" data-belowelement="div-comment-4662" data-respondelement="respond" data-replyto="Reply to streamfortyseven" aria-label='Reply to streamfortyseven'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment odd alt depth-3 highlander-comment" id="comment-4677">
				<div id="div-comment-4677" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://1.gravatar.com/avatar/7d62be404c89efbea1cd6b0dacfd0e3e?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">Giampiero Campa</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4677">18 March, 2011 at 6:07 am</a>		</div>

		<p>Maybe they will perform ritual kill -9&#8217;ing of carefully selected and freshly spawned nice processes in an effort to please the gods.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4677#respond' data-commentid="4677" data-postid="2735" data-belowelement="div-comment-4677" data-respondelement="respond" data-replyto="Reply to Giampiero Campa" aria-label='Reply to Giampiero Campa'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-johncarlosbaez bypostauthor even depth-2 parent highlander-comment" id="comment-4676">
				<div id="div-comment-4676" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn"><a href='http://math.ucr.edu/home/baez/' rel='external nofollow ugc' class='url'>John Baez</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4676">18 March, 2011 at 3:10 am</a>		</div>

		<p>This sort of Darwinian evolution may not quickly lead to &#8216;intelligence&#8217; of the sort we humans pride ourselves on, but it could lead to prerequisites that are quite significant, like: the ability to distinguish between &#8216;self&#8217; and &#8216;non-self&#8217;, the ability to sense and react to a wide variety of threats, the ability to cooperate, and so on.</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4676#respond' data-commentid="4676" data-postid="2735" data-belowelement="div-comment-4676" data-respondelement="respond" data-replyto="Reply to John Baez" aria-label='Reply to John Baez'>Reply</a></div>
				</div>
				<ul class="children">
		<li class="comment odd alt depth-3 highlander-comment" id="comment-4680">
				<div id="div-comment-4680" class="comment-body">
				<div class="comment-author vcard">
			<img alt='' src='https://2.gravatar.com/avatar/83c16232570c763f8e0821a98c18e087?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' />			<cite class="fn">streamfortyseven</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4680">18 March, 2011 at 7:42 am</a>		</div>

		<p>already there: Core Wars&#8230;</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4680#respond' data-commentid="4680" data-postid="2735" data-belowelement="div-comment-4680" data-respondelement="respond" data-replyto="Reply to streamfortyseven" aria-label='Reply to streamfortyseven'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="pingback even thread-odd thread-alt depth-1 highlander-comment" id="comment-4782">
				<div id="div-comment-4782" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://www.acceleratingfuture.com/michael/blog/2011/03/3370/' rel='external nofollow ugc' class='url'>Accelerating Future</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-4782">20 March, 2011 at 9:01 pm</a>		</div>

		<p>[&#8230;] EY: I’d say that there are parts of rationality that we do understand [&#8230;]</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4782#respond' data-commentid="4782" data-postid="2735" data-belowelement="div-comment-4782" data-respondelement="respond" data-replyto="Reply to Accelerating Future" aria-label='Reply to Accelerating Future'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="pingback odd alt thread-even depth-1 highlander-comment" id="comment-16089">
				<div id="div-comment-16089" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://kruel.co/2012/06/23/technically-correct-and-yet-wrong/' rel='external nofollow ugc' class='url'>Alexander Kruel &middot; Technically correct and yet wrong.</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-16089">23 June, 2012 at 7:15 pm</a>		</div>

		<p>[&#8230;]   I’d say that there are parts of rationality that we do understand very well in principle. Bayes’ Theorem, the expected utility formula, and Solomonoff induction between them will get you quite a long [&#8230;]</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=16089#respond' data-commentid="16089" data-postid="2735" data-belowelement="div-comment-16089" data-respondelement="respond" data-replyto="Reply to Alexander Kruel &middot; Technically correct and yet wrong." aria-label='Reply to Alexander Kruel &middot; Technically correct and yet wrong.'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="pingback even thread-odd thread-alt depth-1 highlander-comment" id="comment-21452">
				<div id="div-comment-21452" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://kruel.co/2012/11/02/rationality-come-on-this-is-serious/' rel='external nofollow ugc' class='url'>Alexander Kruel &middot; Rationality? Come on, this is serious!</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-21452">2 November, 2012 at 2:29 pm</a>		</div>

		<p>[&#8230;] say that there are parts of rationality that we do understand very well in principle. Bayes’ Theorem, the expected utility formula, and Solomonoff induction between them will get you quite a long [&#8230;]</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=21452#respond' data-commentid="21452" data-postid="2735" data-belowelement="div-comment-21452" data-respondelement="respond" data-replyto="Reply to Alexander Kruel &middot; Rationality? Come on, this is serious!" aria-label='Reply to Alexander Kruel &middot; Rationality? Come on, this is serious!'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
		<li class="pingback odd alt thread-even depth-1 highlander-comment" id="comment-34840">
				<div id="div-comment-34840" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://johncarlosbaez.wordpress.com/2013/12/26/logic-probability-and-reflection/' rel='external nofollow ugc' class='url'>Logic, Probability and Reflection | Azimuth</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata">
			<a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/#comment-34840">26 December, 2013 at 10:46 pm</a>		</div>

		<p>[&#8230;] Last week I attended the <a href="http://intelligence.org/" rel="nofollow">Machine Intelligence Research Institute&#8217;s</a> sixth <a href="http://intelligence.org/2013/07/24/miris-december-2013-workshop/" rel="nofollow">Workshop on Logic, Probability, and Reflection</a>.  You may know this institute under their previous name: the Singularity Institute.  It seems to be the brainchild of Eliezer Yudkowsky, a well-known advocate of &#8216;friendly artificial intelligence&#8217;, whom I interviewed in <a href="https://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/" rel="nofollow">week311</a>, <a href="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/" rel="nofollow">week312</a> and <a href="https://johncarlosbaez.wordpress.com/2011/03/25/this-weeks-finds-week-313/" rel="nofollow">week313</a> of <i>This Week&#8217;s Finds</i>. [&#8230;]</p>

		<div class="reply"><a rel='nofollow' class='comment-reply-link' href='https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=34840#respond' data-commentid="34840" data-postid="2735" data-belowelement="div-comment-34840" data-respondelement="respond" data-replyto="Reply to Logic, Probability and Reflection | Azimuth" aria-label='Reply to Logic, Probability and Reflection | Azimuth'>Reply</a></div>
				</div>
				</li><!-- #comment-## -->
</ol>



	<div id="respond" class="comment-respond">
		<h3 id="reply-title" class="comment-reply-title">Leave a Reply to <a href="#comment-4578">streamfortyseven</a> <small><a rel="nofollow" id="cancel-comment-reply-link" href="/2011/03/14/this-weeks-finds-week-312/#respond">Cancel reply</a></small></h3><form action="https://johncarlosbaez.wordpress.com/wp-comments-post.php" method="post" id="commentform" class="comment-form"><input type="hidden" id="highlander_comment_nonce" name="highlander_comment_nonce" value="43cb85f550" /><input type="hidden" name="_wp_http_referer" value="/2011/03/14/this-weeks-finds-week-312/?replytocom=4578" />
<input type="hidden" name="hc_post_as" id="hc_post_as" value="guest" />

<div class="comment-form-field comment-textarea">
	<label for="comment">Enter your comment here...</label>
	<div id="comment-form-comment"><textarea id="comment" name="comment" title="Enter your comment here..."></textarea></div>
</div>

<div id="comment-form-identity">
	<div id="comment-form-nascar">
		<p>Fill in your details below or click an icon to log in:</p>
		<ul>
			<li class="selected" style="display:none;">
				<a href="#comment-form-guest" id="postas-guest" class="nascar-signin-link"
                   title="Login via Guest">
									</a>
			</li>
			<li>
				<a href="#comment-form-load-service:WordPress.com" id="postas-wordpress" class="nascar-signin-link"
                   title="Login via WordPress.com">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"/></g></svg>				</a>
			</li>
			<li>
			<iframe id="googleplus-sign-in" name="googleplus-sign-in" src="https://public-api.wordpress.com/connect/?googleplus-sign-in=https%3A%2F%2Fjohncarlosbaez.wordpress.com&#038;color_scheme=light" width="24" height="24" scrolling="no" allowtransparency="true" seamless="seamless" frameborder="0"></iframe>
			</li>
			<li>
				<a href="#comment-form-load-service:Twitter" id="postas-twitter" class="nascar-signin-link"
                   title="Login via Twitter">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"/></g></svg>				</a>
			</li>
			<li>
				<a href="#comment-form-load-service:Facebook" id="postas-facebook" class="nascar-signin-link"
                   title="Login via Facebook">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"/></g></svg>				</a>
			</li>
		</ul>
	</div>

	<div id="comment-form-guest" class="comment-form-service selected">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
<a href="https://gravatar.com/site/signup/" target="_blank">				<img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Gravatar" width="25" class="no-grav" />
</a>			</div>

				<div class="comment-form-fields">
				<div class="comment-form-field comment-form-email">
					<label for="email">Email <span class="required">(required)</span> <span class="nopublish">(Address never made public)</span></label>
					<div class="comment-form-input"><input id="email" name="email" type="email" value="" /></div>
				</div>
				<div class="comment-form-field comment-form-author">
					<label for="author">Name <span class="required">(required)</span></label>
					<div class="comment-form-input"><input id="author" name="author" type="text" value="" /></div>
				</div>
				<div class="comment-form-field comment-form-url">
					<label for="url">Website</label>
					<div class="comment-form-input"><input id="url" name="url" type="url" value="" /></div>
				</div>
			</div>
			
		</div>
	</div>

	<div id="comment-form-wordpress" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="WordPress.com Logo" width="25" class="no-grav" />
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="wp_avatar" id="wordpress-avatar" class="comment-meta-wordpress" value="" />
				<input type="hidden" name="wp_user_id" id="wordpress-user_id" class="comment-meta-wordpress" value="" />
				<input type="hidden" name="wp_access_token" id="wordpress-access_token" class="comment-meta-wordpress" value="" />
						<p class="comment-form-posting-as pa-wordpress">
			<strong></strong>
			You are commenting using your WordPress.com account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( 'wordpress' );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"/></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-googleplus" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Google photo" width="25" class="no-grav" />
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="googleplus_avatar" id="googleplus-avatar" class="comment-meta-googleplus" value="" />
				<input type="hidden" name="googleplus_user_id" id="googleplus-user_id" class="comment-meta-googleplus" value="" />
				<input type="hidden" name="googleplus_access_token" id="googleplus-access_token" class="comment-meta-googleplus" value="" />
						<p class="comment-form-posting-as pa-googleplus">
			<strong></strong>
			You are commenting using your Google account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( 'googleplus' );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" x="0px" y="0px" viewBox="0 0 60 60" ><path fill="#519bf7" d="M56.3,30c0,-1.6 -0.2,-3.4 -0.6,-5h-3.1H42.2H30v10.6h14.8C44,39.3 42,42 39.1,43.9l8.8,6.8C53,46 56.3,39 56.3,30z" /><path fill="#3db366" d="M30,57.5c6.7,0 13.1,-2.4 17.9,-6.8l-8.8,-6.8c-2.5,1.6 -5.6,2.4 -9.1,2.4c-7.2,0 -13.3,-4.7 -15.4,-11.2l-9.3,7.1C9.8,51.3 19.1,57.5 30,57.5z" /><path fill="#fdc600" d="M5.3,42.2l9.3,-7.1c-0.5,-1.6 -0.8,-3.3 -0.8,-5.1s0.3,-3.5 0.8,-5.1l-9.3,-7.1C3.5,21.5 2.5,25.6 2.5,30S3.5,38.5 5.3,42.2z" /><path fill="#f15b44" d="M40.1,17.4l8,-8C43.3,5.1 37,2.5 30,2.5C19.1,2.5 9.8,8.7 5.3,17.8l9.3,7.1c2.1,-6.5 8.2,-11.1 15.4,-11.1C33.9,13.7 37.4,15.1 40.1,17.4z" /></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-twitter" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Twitter picture" width="25" class="no-grav" />
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="twitter_avatar" id="twitter-avatar" class="comment-meta-twitter" value="" />
				<input type="hidden" name="twitter_user_id" id="twitter-user_id" class="comment-meta-twitter" value="" />
				<input type="hidden" name="twitter_access_token" id="twitter-access_token" class="comment-meta-twitter" value="" />
						<p class="comment-form-posting-as pa-twitter">
			<strong></strong>
			You are commenting using your Twitter account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( 'twitter' );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"/></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-facebook" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="" alt="Facebook photo" width="25" class="no-grav" />
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="fb_avatar" id="facebook-avatar" class="comment-meta-facebook" value="" />
				<input type="hidden" name="fb_user_id" id="facebook-user_id" class="comment-meta-facebook" value="" />
				<input type="hidden" name="fb_access_token" id="facebook-access_token" class="comment-meta-facebook" value="" />
						<p class="comment-form-posting-as pa-facebook">
			<strong></strong>
			You are commenting using your Facebook account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( 'facebook' );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24" ><rect x="0" fill="none" width="24" height="24"/><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"/></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>


	<div id="comment-form-load-service" class="comment-form-service">
		<div class="comment-form-posting-as-cancel"><a href="javascript:HighlanderComments.cancelExternalWindow();">Cancel</a></div>
		<p>Connecting to %s</p>
	</div>

</div>

<script type="text/javascript">
var highlander_expando_javascript = function () {

	function hide( sel ) {
		var el = document.querySelector( sel );
		if ( el ) {
			el.style.setProperty( 'display', 'none' );
		}
	}

	function show( sel ) {
		var el = document.querySelector( sel );
		if ( el ) {
			el.style.removeProperty( 'display' );
		}
	}

	var input = document.createElement( 'input' );
	var comment = document.querySelector( '#comment' );

	if ( input && comment && 'placeholder' in input ) {
		var label = document.querySelector( '.comment-textarea label' );
		if ( label ) {
			var text = label.textContent;
			label.parentNode.removeChild( label );
			comment.setAttribute( 'placeholder', text );
		}
	}

	// Expando Mode: start small, then auto-resize on first click + text length
	hide( '#comment-form-identity' );
	hide( '#comment-form-subscribe' );
	hide( '#commentform .form-submit' );

	if ( comment ) {
		comment.style.height = '10px';

		var handler = function () {
			comment.style.height = HighlanderComments.initialHeight + 'px';
			show( '#comment-form-identity' );
			show( '#comment-form-subscribe' );
			show( '#commentform .form-submit' );
			HighlanderComments.resizeCallback();

			comment.removeEventListener( 'focus', handler );
		};

		comment.addEventListener( 'focus', handler );
	}
}

if ( document.readyState !== 'loading' ) {
	highlander_expando_javascript();
} else {
	if ( typeof window.jQuery === 'function' ) {
		// Use jQuery's `ready` if available.
		// This solves some scheduling issues between this script and the main highlander script.
		jQuery( document ).ready( highlander_expando_javascript );
	} else {
		// If not available, add a vanilla event listener.
		document.addEventListener( 'DOMContentLoaded', highlander_expando_javascript );
	}
}

</script>

<div id="comment-form-subscribe">
	<p class="comment-subscription-form"><input type="checkbox" name="subscribe" id="subscribe" value="subscribe" style="width: auto;"/> <label class="subscribe-label" id="subscribe-label" for="subscribe" style="display: inline;">Notify me of new comments via email.</label></p><p class="post-subscription-form"><input type="checkbox" name="subscribe_blog" id="subscribe_blog" value="subscribe" style="width: auto;"/> <label class="subscribe-label" id="subscribe-blog-label" for="subscribe_blog"  style="display: inline;">Notify me of new posts via email.</label></p></div>




<p class="form-submit wp-block-button"><input name="submit" type="submit" id="comment-submit" class="submit wp-block-button__link" value="Post Comment" /> <input type='hidden' name='comment_post_ID' value='2735' id='comment_post_ID' />
<input type='hidden' name='comment_parent' id='comment_parent' value='4578' />
</p><p style="display: none;"><input type="hidden" id="akismet_comment_nonce" name="akismet_comment_nonce" value="307db48846" /></p>
<input type="hidden" name="genseq" value="1632614521" />
<input type="hidden" id="ak_js" name="ak_js" value="229"/><textarea name="ak_hp_textarea" cols="45" rows="8" maxlength="100" style="display: none !important;"></textarea><script>document.getElementById( "ak_js" ).setAttribute( "value", ( new Date() ).getTime() );</script></form>	</div><!-- #respond -->
	<div style="clear: both"></div><p class="akismet_comment_form_privacy_notice">This site uses Akismet to reduce spam. <a href="https://akismet.com/privacy/" target="_blank" rel="nofollow noopener">Learn how your comment data is processed</a>.</p>
</div><!-- #comments -->
	
	</div>



	<div id="sidebar">
				<ul>

		
		<li id="recent-posts-3" class="widget widget_recent_entries">
		<h2 class="widgettitle">latest posts:</h2>

		<ul>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/">Classical Mechanics versus Thermodynamics (Part&nbsp;3)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/22/maxwells-relations-part-3/">Maxwell&#8217;s Relations (Part&nbsp;3)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/18/maxwells-relations-part-two/">Maxwell&#8217;s Relations (Part&nbsp;2)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/17/maxwells-relations-part-1/">Maxwell&#8217;s Relations (Part&nbsp;1)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/13/the-cyclic-identity-for-partial-derivatives/">The Cyclic Identity for Partial&nbsp;Derivatives</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/17/information-geometry-part-21/">Information Geometry (Part&nbsp;21)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/14/information-geometry-part-20/">Information Geometry (Part&nbsp;20)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/08/information-geometry-part-19/">Information Geometry (Part&nbsp;19)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/05/information-geometry-part-18/">Information Geometry (Part&nbsp;18)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/07/29/structured-vs-decorated-cospans-part-2/">Structured vs Decorated Cospans (Part&nbsp;2)</a>
									</li>
					</ul>

		</li>
<li id="recent-comments-2" class="widget widget_recent_comments"><h2 class="widgettitle">latest comments:</h2>
				<table class="recentcommentsavatar" cellspacing="0" cellpadding="0" border="0">
					<tr><td title="amarashiki" class="recentcommentsavatartop" style="height:32px; width:32px;"><a href="http://gravatar.com/amarashiki" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/62b2df0762257e75433ad6f161488c3a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstexttop" style=""><a href="http://gravatar.com/amarashiki" rel="nofollow">amarashiki</a> on <a href="https://johncarlosbaez.wordpress.com/2012/01/23/classical-mechanics-versus-thermodynamics-part-2/#comment-172566">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="John Baez" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://math.ucr.edu/home/baez/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://math.ucr.edu/home/baez/" rel="nofollow">John Baez</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172560">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="domenico" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://2.gravatar.com/avatar/ba06491deb8346d20356ac2ae05893ee?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">domenico on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172559">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="domenico" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://2.gravatar.com/avatar/ba06491deb8346d20356ac2ae05893ee?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">domenico on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172558">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="Maxwell Relations | Equivalent eXchange" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow"></a></td><td class="recentcommentstextend" style=""><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow">Maxwell Relations |&hellip;</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/22/maxwells-relations-part-3/#comment-172557">Maxwell&#8217;s Relations (Par&hellip;</a></td></tr><tr><td title="Maxwell Relations | Equivalent eXchange" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow"></a></td><td class="recentcommentstextend" style=""><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow">Maxwell Relations |&hellip;</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/18/maxwells-relations-part-two/#comment-172556">Maxwell&#8217;s Relations (Par&hellip;</a></td></tr><tr><td title="Maxwell Relations | Equivalent eXchange" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow"></a></td><td class="recentcommentstextend" style=""><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow">Maxwell Relations |&hellip;</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/17/maxwells-relations-part-1/#comment-172555">Maxwell&#8217;s Relations (Par&hellip;</a></td></tr><tr><td title="Robert A. Wilson" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="https://robwilson1.wordpress.com" rel="nofollow"><img alt='' src='https://2.gravatar.com/avatar/24dc7e2371491f36fd4538b3474920b5?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="https://robwilson1.wordpress.com" rel="nofollow">Robert A. Wilson</a> on <a href="https://johncarlosbaez.wordpress.com/2021/04/04/the-koide-formula/#comment-172553">The Koide Formula</a></td></tr><tr><td title="John Baez" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://math.ucr.edu/home/baez/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://math.ucr.edu/home/baez/" rel="nofollow">John Baez</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172545">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="Wolfgang" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://1.gravatar.com/avatar/d3c6d7ec8069e25c08a0a11263581925?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">Wolfgang on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172543">Classical Mechanics versus The&hellip;</a></td></tr>				</table>
				</li>
<li id="text-3" class="widget widget_text"><h2 class="widgettitle">How To Write Math Here:</h2>
			<div class="textwidget"><p>You can <a href="http://en.wikibooks.org/wiki/LaTeX/Mathematics">include math in your comments using LaTeX</a>,  but you need to do it this way:</p>
<p>&#036;latex  E = mc^2&#036;</p>
<p>You need the word 'latex' right after the first dollar sign, and it needs a space after it.  Double dollar signs don't work, and other limitations apply, some described <a href="http://en.support.wordpress.com/latex/">here</a>.  You can't preview comments here, but I'm happy to fix errors.</p>
</div>
		</li>
<li id="categories-2" class="widget widget_categories"><h2 class="widgettitle">Read Posts On:</h2>

			<ul>
					<li class="cat-item cat-item-177"><a href="https://johncarlosbaez.wordpress.com/category/art/">art</a> (3)
</li>
	<li class="cat-item cat-item-4003"><a href="https://johncarlosbaez.wordpress.com/category/astronomy/">astronomy</a> (29)
</li>
	<li class="cat-item cat-item-8262191"><a href="https://johncarlosbaez.wordpress.com/category/azimuth/">azimuth</a> (60)
</li>
	<li class="cat-item cat-item-86856"><a href="https://johncarlosbaez.wordpress.com/category/biodiversity/">biodiversity</a> (38)
</li>
	<li class="cat-item cat-item-4936"><a href="https://johncarlosbaez.wordpress.com/category/biology/">biology</a> (107)
</li>
	<li class="cat-item cat-item-355244"><a href="https://johncarlosbaez.wordpress.com/category/carbon-emissions/">carbon emissions</a> (78)
</li>
	<li class="cat-item cat-item-5936"><a href="https://johncarlosbaez.wordpress.com/category/chemistry/">chemistry</a> (74)
</li>
	<li class="cat-item cat-item-6108"><a href="https://johncarlosbaez.wordpress.com/category/climate/">climate</a> (155)
</li>
	<li class="cat-item cat-item-5043"><a href="https://johncarlosbaez.wordpress.com/category/computer-science/">computer science</a> (57)
</li>
	<li class="cat-item cat-item-9204"><a href="https://johncarlosbaez.wordpress.com/category/conferences/">conferences</a> (81)
</li>
	<li class="cat-item cat-item-1098"><a href="https://johncarlosbaez.wordpress.com/category/culture/">culture</a> (4)
</li>
	<li class="cat-item cat-item-657"><a href="https://johncarlosbaez.wordpress.com/category/economics/">economics</a> (32)
</li>
	<li class="cat-item cat-item-1212"><a href="https://johncarlosbaez.wordpress.com/category/energy/">energy</a> (50)
</li>
	<li class="cat-item cat-item-25393"><a href="https://johncarlosbaez.wordpress.com/category/engineering/">engineering</a> (11)
</li>
	<li class="cat-item cat-item-14852"><a href="https://johncarlosbaez.wordpress.com/category/mathematics/game-theory/">game theory</a> (29)
</li>
	<li class="cat-item cat-item-1215"><a href="https://johncarlosbaez.wordpress.com/category/geography/">geography</a> (4)
</li>
	<li class="cat-item cat-item-337"><a href="https://johncarlosbaez.wordpress.com/category/health/">health</a> (4)
</li>
	<li class="cat-item cat-item-678"><a href="https://johncarlosbaez.wordpress.com/category/history/">history</a> (2)
</li>
	<li class="cat-item cat-item-23375499"><a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/">information and entropy</a> (92)
</li>
	<li class="cat-item cat-item-3558"><a href="https://johncarlosbaez.wordpress.com/category/jobs/">jobs</a> (11)
</li>
	<li class="cat-item cat-item-5465"><a href="https://johncarlosbaez.wordpress.com/category/journals/">journals</a> (5)
</li>
	<li class="cat-item cat-item-3582"><a href="https://johncarlosbaez.wordpress.com/category/mathematics/">mathematics</a> (478)
</li>
	<li class="cat-item cat-item-18"><a href="https://johncarlosbaez.wordpress.com/category/music/">music</a> (3)
</li>
	<li class="cat-item cat-item-3968"><a href="https://johncarlosbaez.wordpress.com/category/networks/">networks</a> (185)
</li>
	<li class="cat-item cat-item-154934"><a href="https://johncarlosbaez.wordpress.com/category/oceans/">oceans</a> (13)
</li>
	<li class="cat-item cat-item-1211"><a href="https://johncarlosbaez.wordpress.com/category/physics/">physics</a> (204)
</li>
	<li class="cat-item cat-item-10451"><a href="https://johncarlosbaez.wordpress.com/category/probability/">probability</a> (92)
</li>
	<li class="cat-item cat-item-4909"><a href="https://johncarlosbaez.wordpress.com/category/psychology/">psychology</a> (6)
</li>
	<li class="cat-item cat-item-3330"><a href="https://johncarlosbaez.wordpress.com/category/publishing/">publishing</a> (19)
</li>
	<li class="cat-item cat-item-46615"><a href="https://johncarlosbaez.wordpress.com/category/puzzles/">puzzles</a> (14)
</li>
	<li class="cat-item cat-item-4140243"><a href="https://johncarlosbaez.wordpress.com/category/quantum-technologies/">quantum technologies</a> (28)
</li>
	<li class="cat-item cat-item-562"><a href="https://johncarlosbaez.wordpress.com/category/questions/">questions</a> (3)
</li>
	<li class="cat-item cat-item-93974"><a href="https://johncarlosbaez.wordpress.com/category/risks/">risks</a> (48)
</li>
	<li class="cat-item cat-item-37893"><a href="https://johncarlosbaez.wordpress.com/category/seminars/">seminars</a> (21)
</li>
	<li class="cat-item cat-item-581"><a href="https://johncarlosbaez.wordpress.com/category/software/">software</a> (19)
</li>
	<li class="cat-item cat-item-39438"><a href="https://johncarlosbaez.wordpress.com/category/strategies/">strategies</a> (36)
</li>
	<li class="cat-item cat-item-6877"><a href="https://johncarlosbaez.wordpress.com/category/sustainability/">sustainability</a> (71)
</li>
	<li class="cat-item cat-item-66608272"><a href="https://johncarlosbaez.wordpress.com/category/the-practice-of-science/">the practice of science</a> (27)
</li>
	<li class="cat-item cat-item-61590"><a href="https://johncarlosbaez.wordpress.com/category/this-weeks-finds/">this week&#039;s finds</a> (18)
</li>
			</ul>

			</li>
<li id="linkcat-20924250" class="widget widget_links"><h2 class="widgettitle">also visit these:</h2>

	<ul class='xoxo blogroll'>
<li><a href="http://www.azimuthproject.org/azimuth/show/Azimuth+Blog" title="Go here to see what’s on this blog, organized by topic or author!">Azimuth Blog Overview</a></li>
<li><a href="http://www.azimuthproject.org/azimuth/show/HomePage" title="for scientists and engineers who want to save the planet">Azimuth Project</a></li>
<li><a href="http://bittooth.blogspot.com/" title="David Summers on energy: oil, gas and more">Bit Tooth Energy</a></li>
<li><a href="http://bravenewclimate.com/" title="Barry Brooks on climate and energy policy">Brave New Climate</a></li>
<li><a href="http://physics.ucsd.edu/do-the-math/" title="UC San Diego prof uses physics and estimation to assess energy, growth, options">Do the Math</a></li>
<li><a href="http://dotearth.blogs.nytimes.com/" title="Andrew Revkin’s environmental blog on the New York Times">Dot Earth</a></li>
<li><a href="http://e360.yale.edu/" title="News from the Yale School of Forestry &amp; Environmental Studies">Environment 360</a></li>
<li><a href="http://planet3.org/" title="A metablog on sustainability">Planet3.0</a></li>
<li><a href="http://www.realclimate.org/" title="climate science from climate scientists">RealClimate</a></li>
<li><a href="http://www.easterbrook.ca/steve/" title="Steve Easterbrook&#8217;s blog on software engineering and climate modeling">Serendipity</a></li>
<li><a href="http://scienceofdoom.com/" title="climate science in perspective">The Science of Doom</a></li>
<li><a href="http://e360.yale.edu/" title="opinion, analysis, reporting and debate on environmental issues">Yale Environment 360</a></li>

	</ul>
</li>

<li id="rss_links-3" class="widget widget_rss_links"><h2 class="widgettitle">RSS feeds:</h2>
<p class="size-small"><a class="feed-image-link" href="https://johncarlosbaez.wordpress.com/feed/" title="Subscribe to Posts"><img src="https://johncarlosbaez.wordpress.com/i/rss/red-small.png?m=1391188133h" alt="RSS Feed" /></a>&nbsp;<a href="https://johncarlosbaez.wordpress.com/feed/" title="Subscribe to Posts">RSS - Posts</a></p><p class="size-small"><a class="feed-image-link" href="https://johncarlosbaez.wordpress.com/comments/feed/" title="Subscribe to Comments"><img src="https://johncarlosbaez.wordpress.com/i/rss/red-small.png?m=1391188133h" alt="RSS Feed" /></a>&nbsp;<a href="https://johncarlosbaez.wordpress.com/comments/feed/" title="Subscribe to Comments">RSS - Comments</a></p>
</li>
<li id="blog_subscription-3" class="widget widget_blog_subscription jetpack_subscription_widget"><h2 class="widgettitle"><label for="subscribe-field">Email Subscription:</label></h2>

			<form
				action="https://subscribe.wordpress.com"
				method="post"
				accept-charset="utf-8"
				id=""
			>
				<p>Enter your email address to subscribe to this blog and receive notifications of new posts by email.</p>
					<div class="jetpack-subscribe-count">
						<p>
						Join 5,227 other followers						</p>
					</div>
									<p id="subscribe-email">
					<label
						id="subscribe-field-label"
						for="subscribe-field"
						class="screen-reader-text"
					>
						Email Address:					</label>

					<input
							type="email"
							name="email"
							
							style="width: 95%; padding: 1px 10px"
							placeholder="Enter your email address"
							value=""
							id="subscribe-field"
						/>				</p>

				<p id="subscribe-submit"
									>
                    <input type="hidden" name="action" value="subscribe"/>
                    <input type="hidden" name="blog_id" value="12777403"/>
                    <input type="hidden" name="source" value="https://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/?replytocom=4578"/>
                    <input type="hidden" name="sub-type" value="widget"/>
                    <input type="hidden" name="redirect_fragment" value="blog_subscription-3"/>
					<input type="hidden" id="_wpnonce" name="_wpnonce" value="8f1337fe87" />                    <button type="submit"
	                    	                        class="wp-block-button__link"
	                    		                	                >
	                    Sign me up!                    </button>
                </p>
            </form>
			
</li>
<li id="search-3" class="widget widget_search"><h2 class="widgettitle">SEARCH:</h2>
<form method="get" id="searchform" action="https://johncarlosbaez.wordpress.com/">
<div><label for="s" class="search-label">Search</label><input type="text" value="" name="s" id="s" />
<input type="submit" id="searchsubmit" value="Search" />
</div>
</form></li>
<li id="blog-stats-2" class="widget widget_blog-stats"><h2 class="widgettitle">Blog Stats:</h2>
		<ul>
			<li>4,176,961 hits</li>
		</ul>
		</li>
		</ul>
	</div>



<div id="footer">
	<p>
	<br />
	<a href="https://wordpress.com/?ref=footer_blog" rel="nofollow">Blog at WordPress.com.</a>
	</p>
</div>

</div>

		<!--  -->
<script src='//0.gravatar.com/js/gprofiles.js?ver=202138y' id='grofiles-cards-js'></script>
<script id='wpgroho-js-extra'>
var WPGroHo = {"my_hash":""};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s1.wp.com/wp-content/mu-plugins/gravatar-hovercards/wpgroho.js?m=1610363240h'></script>

	<script>
		// Initialize and attach hovercards to all gravatars
		( function() {
			function init() {
				if ( typeof Gravatar === 'undefined' ) {
					return;
				}

				if ( typeof Gravatar.init !== 'function' ) {
					return;
				}

				Gravatar.profile_cb = function ( hash, id ) {
					WPGroHo.syncProfileData( hash, id );
				};

				Gravatar.my_hash = WPGroHo.my_hash;
				Gravatar.init( 'body', '#wp-admin-bar-my-account' );
			}

			if ( document.readyState !== 'loading' ) {
				init();
			} else {
				document.addEventListener( 'DOMContentLoaded', init );
			}
		} )();
	</script>

		<div style="display:none">
	<div class="grofile-hash-map-5850d628c599d7ac60d7f7889844995a">
	</div>
	<div class="grofile-hash-map-83c16232570c763f8e0821a98c18e087">
	</div>
	<div class="grofile-hash-map-34784534843022b3541c8ddd693718cb">
	</div>
	<div class="grofile-hash-map-04e8217661e5e48b523b8ebcb194a8a7">
	</div>
	<div class="grofile-hash-map-5850d628c599d7ac60d7f7889844995a">
	</div>
	<div class="grofile-hash-map-653623c8ab2aa94f882be46111bb3ae4">
	</div>
	<div class="grofile-hash-map-1c5a8a88aadcdcb7a4b24b8913a0993f">
	</div>
	<div class="grofile-hash-map-656e05d084448337fb49459225dc525e">
	</div>
	<div class="grofile-hash-map-c06be7d387ad838e57f6f420ad0b7f92">
	</div>
	<div class="grofile-hash-map-790504be0016c185f5f06f52954f3d49">
	</div>
	<div class="grofile-hash-map-763cc4f73f88dbac2b1a828e929a81f5">
	</div>
	<div class="grofile-hash-map-7d62be404c89efbea1cd6b0dacfd0e3e">
	</div>
	<div class="grofile-hash-map-62b2df0762257e75433ad6f161488c3a">
	</div>
	<div class="grofile-hash-map-ba06491deb8346d20356ac2ae05893ee">
	</div>
	<div class="grofile-hash-map-24dc7e2371491f36fd4538b3474920b5">
	</div>
	<div class="grofile-hash-map-d3c6d7ec8069e25c08a0a11263581925">
	</div>
	</div>
<script id='highlander-comments-js-extra'>
var HighlanderComments = {"loggingInText":"Logging In\u2026","submittingText":"Posting Comment\u2026","postCommentText":"Post Comment","connectingToText":"Connecting to %s","commentingAsText":"%1$s: You are commenting using your %2$s account.","logoutText":"Log Out","loginText":"Log In","connectURL":"https:\/\/johncarlosbaez.wordpress.com\/public.api\/connect\/?action=request","logoutURL":"https:\/\/johncarlosbaez.wordpress.com\/wp-login.php?action=logout&_wpnonce=598fb2ebe8","homeURL":"https:\/\/johncarlosbaez.wordpress.com\/","postID":"2735","gravDefault":"identicon","enterACommentError":"Please enter a comment","enterEmailError":"Please enter your email address here","invalidEmailError":"Invalid email address","enterAuthorError":"Please enter your name here","gravatarFromEmail":"This picture will show whenever you leave a comment. Click to customize it.","logInToExternalAccount":"Log in to use details from one of these accounts.","change":"Change","changeAccount":"Change Account","comment_registration":"","userIsLoggedIn":"","isJetpack":"","text_direction":"ltr"};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s1.wp.com/_static/??/wp-content/js/jquery/jquery.autoresize.js,/wp-content/mu-plugins/highlander-comments/script.js?m=1626677336j'></script>

<script>
window.addEventListener( "load", function( event ) {
	var link = document.createElement( "link" );
	link.href = "https://s0.wp.com/wp-content/mu-plugins/actionbar/actionbar.css?v=20210915";
	link.type = "text/css";
	link.rel = "stylesheet";
	document.head.appendChild( link );

	var script = document.createElement( "script" );
	script.src = "https://s0.wp.com/wp-content/mu-plugins/actionbar/actionbar.js?v=20210920";
	script.defer = true;
	document.body.appendChild( script );
} );
</script>

	<script crossorigin='anonymous' type='text/javascript' src='https://s2.wp.com/_static/??-eJyFTs0OgjAMfiHHAgcTDsZnGVtDNuk2207g7S2JXIyJp/58v3atxpcskMUmtgFe0UPdusQXq1DMfmkB+MB8QVSaIajL3mHMJ+nUYzN1aXPMbF1Q3EyOLDoWIN2MkPMP/hapcXo2oP0zurVqkKlUtl2j9Mfyq42egBOEP0XWGGYQttwm9hSrxJKPDne89ddhHPthuPbpDZCYYT4='></script>
<script type="text/javascript">
// <![CDATA[
(function() {
try{
  if ( window.external &&'msIsSiteMode' in window.external) {
    if (window.external.msIsSiteMode()) {
      var jl = document.createElement('script');
      jl.type='text/javascript';
      jl.async=true;
      jl.src='/wp-content/plugins/ie-sitemode/custom-jumplist.php';
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(jl, s);
    }
  }
}catch(e){}
})();
// ]]>
</script><script src="//stats.wp.com/w.js?62" defer></script> <script type="text/javascript">
_tkq = window._tkq || [];
_stq = window._stq || [];
_tkq.push(['storeContext', {'blog_id':'12777403','blog_tz':'0','user_lang':'en','blog_lang':'en','user_id':'0'}]);
_stq.push(['view', {'blog':'12777403','v':'wpcom','tz':'0','user_id':'0','post':'2735','subd':'johncarlosbaez'}]);
_stq.push(['extra', {'crypt':'UE40eW5QN0p8M2Y/RE1TaVhzUzFMbjdWNHpwZGhTayxPSUFCMGNrd29+Smw0TDhnZmRTK0hlRi9QSGh6bi9GXVhBJWIlZlR5U1JMLU8/MkNtblkvY1d6eVImTEouL2UleTBRZmlNdkp0aWJaNFJhPS0uTVpHa1hIc25EbVJyQmw/SkZ+Q3lLcjU/NDBvQTY5YkZ+c0h1XTBjcWE3elh6QzRrREN8Z11GXWpnRXhHLVgmeE1sNDdDaC5NXWUvNlg1bk1WUUguZENGSlEuTWxdck02W2lPd1k5Vy9KUSszWDZSdiYvP0d8XVprOERHYllRL0laLS93d2xMRDd3WnJmZnhYbGVQbzMxaW00NkJFVTJDMV9OYy00cFl3aHZLLjlvTzMldmI9K0RdVzJhJjVQU0U5cWlLVU9JWjd0b0thUCxSalhJLGtEdG0uUjhZeWpHVDBUV2UuTjJOamJzSVN0dk00MnNfZG1bUw=='}]);
_stq.push([ 'clickTrackerInit', '12777403', '2735' ]);
	</script>
<noscript><img src="https://pixel.wp.com/b.gif?v=noscript" style="height:1px;width:1px;overflow:hidden;position:absolute;bottom:1px;" alt="" /></noscript>
<script>
if ( 'object' === typeof wpcom_mobile_user_agent_info ) {

	wpcom_mobile_user_agent_info.init();
	var mobileStatsQueryString = "";
	
	if( false !== wpcom_mobile_user_agent_info.matchedPlatformName )
		mobileStatsQueryString += "&x_" + 'mobile_platforms' + '=' + wpcom_mobile_user_agent_info.matchedPlatformName;
	
	if( false !== wpcom_mobile_user_agent_info.matchedUserAgentName )
		mobileStatsQueryString += "&x_" + 'mobile_devices' + '=' + wpcom_mobile_user_agent_info.matchedUserAgentName;
	
	if( wpcom_mobile_user_agent_info.isIPad() )
		mobileStatsQueryString += "&x_" + 'ipad_views' + '=' + 'views';

	if( "" != mobileStatsQueryString ) {
		new Image().src = document.location.protocol + '//pixel.wp.com/g.gif?v=wpcom-no-pv' + mobileStatsQueryString + '&baba=' + Math.random();
	}
	
}
</script>
</body>
</html>
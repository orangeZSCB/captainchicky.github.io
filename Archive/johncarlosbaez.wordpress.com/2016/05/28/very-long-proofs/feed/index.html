<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Very Long Proofs	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/</link>
	<description></description>
	<lastBuildDate>Mon, 13 Apr 2020 01:56:49 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: magnushiie		</title>
		<link>https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-82025</link>

		<dc:creator><![CDATA[magnushiie]]></dc:creator>
		<pubDate>Fri, 22 Jul 2016 08:25:12 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=21965#comment-82025</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-82012&quot;&gt;John Baez&lt;/a&gt;.

No, I just once solved some Project Euler problems, and a few of them were about Pythagorean triples. I spent a few minutes on writing a script to generate all the triples and their multiples using Euclid&#039;s formula and generate the graph (list of connected components really) from these. That&#039;s a sub-second computation.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-82012">John Baez</a>.</p>
<p>No, I just once solved some Project Euler problems, and a few of them were about Pythagorean triples. I spent a few minutes on writing a script to generate all the triples and their multiples using Euclid&#8217;s formula and generate the graph (list of connected components really) from these. That&#8217;s a sub-second computation.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-82012</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Fri, 22 Jul 2016 00:50:12 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=21965#comment-82012</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-82009&quot;&gt;magnushiie&lt;/a&gt;.

Wow, are you doing a lot of calculations in this topic?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-82009">magnushiie</a>.</p>
<p>Wow, are you doing a lot of calculations in this topic?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: magnushiie		</title>
		<link>https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-82009</link>

		<dc:creator><![CDATA[magnushiie]]></dc:creator>
		<pubDate>Thu, 21 Jul 2016 22:20:49 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=21965#comment-82009</guid>

					<description><![CDATA[FWIW, according to my calculations the largest connected component of the graph (where vertices are members of Pythagorean triples and edges indicate they belong to the same triple) up to 7825 has 5482 vertices (including 7825 itself of course). I&#039;m surprised this was not mentioned in the paper.]]></description>
			<content:encoded><![CDATA[<p>FWIW, according to my calculations the largest connected component of the graph (where vertices are members of Pythagorean triples and edges indicate they belong to the same triple) up to 7825 has 5482 vertices (including 7825 itself of course). I&#8217;m surprised this was not mentioned in the paper.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-81986</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Thu, 21 Jul 2016 00:47:17 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=21965#comment-81986</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-81981&quot;&gt;Ted&lt;/a&gt;.

Ted wrote:

&lt;blockquote&gt;
  What confidence do we have that long and complex proofs are valid?
&lt;/blockquote&gt;

What confidence do we have that a complicated machine like a modern airplane, with thousands of parts, won&#039;t malfunction and send us crashing to our deaths?  It&#039;s pretty much the same kind of question.  Sometimes airplanes &lt;em&gt;do&lt;/em&gt; malfunction and crash, yet I routinely use them and rarely worry about it, because the chance is high that I&#039;ll safely reach my destination, because lots of people work very hard to make them safe.

It&#039;s also worth noting that most mistakes in proofs can be easily fixed or sidestepped.  This is a difference between proofs and programs.  Something as trivial as a typo can prevent a program from working the way it should.  But human mathematicians can easily bounce back from typos or even more significant mistakes as long as the &lt;em&gt;overall idea&lt;/em&gt; of a proof is sound.   So we don&#039;t need &#039;zero mistakes&#039;.  We just need zero mistakes that are hard to fix.

Finally, about Wiles&#039; proof.  Around 1982--1986, Gerhard Frey and Ken Ribet showed that Fermat&#039;s Last Theorem would follow from the &#039;modularity conjecture&#039;.  This was a statement about geometry that a bunch of famous mathematicians were already interested in: it&#039;s vastly more important than whether some goofy equation has integer solutions.  Wiles proved a special case of the modularity conjecture, just enough to get Fermat&#039;s Last Theorem.   His first proof had a mistake; then his grad student Richard helped him fix it, and they published it in 1995.  Then a bunch of people streamlined his argument and proved the full-fledged version of what is now called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Modularity_theorem&quot; rel=&quot;nofollow&quot;&gt;Modularity Theorem&lt;/a&gt;.   There have been conferences on this topic, and some textbooks as well.   So by now many more than a handful of people have checked through this stuff.

Not me personally, but then I&#039;m not a number theorist!]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-81981">Ted</a>.</p>
<p>Ted wrote:</p>
<blockquote><p>
  What confidence do we have that long and complex proofs are valid?
</p></blockquote>
<p>What confidence do we have that a complicated machine like a modern airplane, with thousands of parts, won&#8217;t malfunction and send us crashing to our deaths?  It&#8217;s pretty much the same kind of question.  Sometimes airplanes <em>do</em> malfunction and crash, yet I routinely use them and rarely worry about it, because the chance is high that I&#8217;ll safely reach my destination, because lots of people work very hard to make them safe.</p>
<p>It&#8217;s also worth noting that most mistakes in proofs can be easily fixed or sidestepped.  This is a difference between proofs and programs.  Something as trivial as a typo can prevent a program from working the way it should.  But human mathematicians can easily bounce back from typos or even more significant mistakes as long as the <em>overall idea</em> of a proof is sound.   So we don&#8217;t need &#8216;zero mistakes&#8217;.  We just need zero mistakes that are hard to fix.</p>
<p>Finally, about Wiles&#8217; proof.  Around 1982&#8211;1986, Gerhard Frey and Ken Ribet showed that Fermat&#8217;s Last Theorem would follow from the &#8216;modularity conjecture&#8217;.  This was a statement about geometry that a bunch of famous mathematicians were already interested in: it&#8217;s vastly more important than whether some goofy equation has integer solutions.  Wiles proved a special case of the modularity conjecture, just enough to get Fermat&#8217;s Last Theorem.   His first proof had a mistake; then his grad student Richard helped him fix it, and they published it in 1995.  Then a bunch of people streamlined his argument and proved the full-fledged version of what is now called the <a href="https://en.wikipedia.org/wiki/Modularity_theorem" rel="nofollow">Modularity Theorem</a>.   There have been conferences on this topic, and some textbooks as well.   So by now many more than a handful of people have checked through this stuff.</p>
<p>Not me personally, but then I&#8217;m not a number theorist!</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Ted		</title>
		<link>https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-81981</link>

		<dc:creator><![CDATA[Ted]]></dc:creator>
		<pubDate>Wed, 20 Jul 2016 21:37:10 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=21965#comment-81981</guid>

					<description><![CDATA[I have no problem with proofs that are &quot;large&quot; in this way.  Presumably their program is not very big, and easy to verify.  Likewise for their clever work to cut down the problem space to just a trillion cases to check.

The more problematic &quot;large proofs&quot;, to me, are those like Wiles&#039; proof of Fermat -- 150 pages long, and so complex that only a handful of people in the world can understand it all.  Mistakes were found in it before.  I&#039;m a programmer, and I certainly cannot write 150 pages of material in my field with zero mistakes.  Can anyone?

Even Knuth, so methodical that he sends money to people who find mistakes in his work, has mailed over 100 checks for mistakes in his 2000-page seminal work.  Despite taking literally decades to write and edit, he can&#039;t go 20 pages without a minor blooper slipping through, in material that he already understands.

What confidence do we have that long and complex proofs are valid?]]></description>
			<content:encoded><![CDATA[<p>I have no problem with proofs that are &#8220;large&#8221; in this way.  Presumably their program is not very big, and easy to verify.  Likewise for their clever work to cut down the problem space to just a trillion cases to check.</p>
<p>The more problematic &#8220;large proofs&#8221;, to me, are those like Wiles&#8217; proof of Fermat &#8212; 150 pages long, and so complex that only a handful of people in the world can understand it all.  Mistakes were found in it before.  I&#8217;m a programmer, and I certainly cannot write 150 pages of material in my field with zero mistakes.  Can anyone?</p>
<p>Even Knuth, so methodical that he sends money to people who find mistakes in his work, has mailed over 100 checks for mistakes in his 2000-page seminal work.  Despite taking literally decades to write and edit, he can&#8217;t go 20 pages without a minor blooper slipping through, in material that he already understands.</p>
<p>What confidence do we have that long and complex proofs are valid?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-81011</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sun, 26 Jun 2016 16:10:00 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=21965#comment-81011</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-81003&quot;&gt;Stefan O&#039;Rear&lt;/a&gt;.

I see.  Thanks!]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-81003">Stefan O&#8217;Rear</a>.</p>
<p>I see.  Thanks!</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Stefan O'Rear		</title>
		<link>https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-81003</link>

		<dc:creator><![CDATA[Stefan O'Rear]]></dc:creator>
		<pubDate>Sun, 26 Jun 2016 11:14:45 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=21965#comment-81003</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-80968&quot;&gt;John Baez&lt;/a&gt;.

I am referring to https://rjlipton.wordpress.com/2010/10/23/galactic-algorithms/ , which apparently isn&#039;t standard terminology, whoops.

SNARKs can be generically constructed from probabilistically checkable proofs and Merkle trees, but I&#039;ve heard that early versions of the PCP theorem had O(Bekenstein entropy of the galaxy) constant factors.  Having trouble finding a citation for that right now though.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-80968">John Baez</a>.</p>
<p>I am referring to <a href="https://rjlipton.wordpress.com/2010/10/23/galactic-algorithms/" rel="nofollow ugc">https://rjlipton.wordpress.com/2010/10/23/galactic-algorithms/</a> , which apparently isn&#8217;t standard terminology, whoops.</p>
<p>SNARKs can be generically constructed from probabilistically checkable proofs and Merkle trees, but I&#8217;ve heard that early versions of the PCP theorem had O(Bekenstein entropy of the galaxy) constant factors.  Having trouble finding a citation for that right now though.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-80968</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sat, 25 Jun 2016 23:06:53 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=21965#comment-80968</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-80348&quot;&gt;Stefan O&#039;Rear&lt;/a&gt;.

What is a &quot;non-galactic&quot; SNARK?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-80348">Stefan O&#8217;Rear</a>.</p>
<p>What is a &#8220;non-galactic&#8221; SNARK?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Stefan O'Rear		</title>
		<link>https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-80967</link>

		<dc:creator><![CDATA[Stefan O'Rear]]></dc:creator>
		<pubDate>Sat, 25 Jun 2016 22:51:56 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=21965#comment-80967</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-80348&quot;&gt;Stefan O&#039;Rear&lt;/a&gt;.

Looks like we now have non-galactic SNARKs under Minicrypt-level assumptions, if anyone is still reading: http://ia.cr/2016/646]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-80348">Stefan O&#8217;Rear</a>.</p>
<p>Looks like we now have non-galactic SNARKs under Minicrypt-level assumptions, if anyone is still reading: <a href="http://ia.cr/2016/646" rel="nofollow ugc">http://ia.cr/2016/646</a></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: arch1		</title>
		<link>https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-80414</link>

		<dc:creator><![CDATA[arch1]]></dc:creator>
		<pubDate>Thu, 02 Jun 2016 20:44:16 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=21965#comment-80414</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-80381&quot;&gt;John Baez&lt;/a&gt;.

FWIW rough-estimating the number of white squares in the illustrated solution config seems to imply over 10^800 solutions at level 7824.  And I gather from section 3.6 in the paper that there are more level-7824 solution configs than that, possibly many more.

Which counted for little, as these teeming multitudes were laid low by just five numbers:  5180 &#038; 5865, 625 &#038; 7800, and 7825.  That’s because, by level 7824 (and I guess by earlier than that, as a just-in-time one-two punch* seems too coincidental), the first pair of the five had been forced to a different color than the second pair in any solution configuration; and since each pair makes a Pythagorean triple with 7825, and 7825 can’t avoid both colors at once, that was all she wrote, billy goat.

*ok, 7824-7825 punch (so picky:-)]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2016/05/28/very-long-proofs/#comment-80381">John Baez</a>.</p>
<p>FWIW rough-estimating the number of white squares in the illustrated solution config seems to imply over 10^800 solutions at level 7824.  And I gather from section 3.6 in the paper that there are more level-7824 solution configs than that, possibly many more.</p>
<p>Which counted for little, as these teeming multitudes were laid low by just five numbers:  5180 &amp; 5865, 625 &amp; 7800, and 7825.  That’s because, by level 7824 (and I guess by earlier than that, as a just-in-time one-two punch* seems too coincidental), the first pair of the five had been forced to a different color than the second pair in any solution configuration; and since each pair makes a Pythagorean triple with 7825, and 7825 can’t avoid both colors at once, that was all she wrote, billy goat.</p>
<p>*ok, 7824-7825 punch (so picky:-)</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

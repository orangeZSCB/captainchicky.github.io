<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title> information and entropy | Search Results  | Azimuth | Page 7</title>
<link rel="profile" href="http://gmpg.org/xfn/11" />
<link rel="pingback" href="https://johncarlosbaez.wordpress.com/xmlrpc.php" />
<meta name='robots' content='noindex, follow, max-image-preview:large' />
<link rel='dns-prefetch' href='//s2.wp.com' />
<link rel='dns-prefetch' href='//s0.wp.com' />
<link rel='dns-prefetch' href='//s1.wp.com' />
<link rel='dns-prefetch' href='//s.wordpress.com' />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Feed" href="https://johncarlosbaez.wordpress.com/feed/" />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Comments Feed" href="https://johncarlosbaez.wordpress.com/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Azimuth &raquo; Search Results for &#8220;information and entropy&#8221; Feed" href="https://johncarlosbaez.wordpress.com/search/information+and+entropy/feed/rss2/" />
	<script type="text/javascript">
		/* <![CDATA[ */
		function addLoadEvent(func) {
			var oldonload = window.onload;
			if (typeof window.onload != 'function') {
				window.onload = func;
			} else {
				window.onload = function () {
					oldonload();
					func();
				}
			}
		}
		/* ]]> */
	</script>
			<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/72x72\/","ext":".png","svgUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/s1.wp.com\/wp-includes\/js\/wp-emoji-release.min.js?m=1625065786h&ver=5.8.1"}};
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([10084,65039,8205,55357,56613],[10084,65039,8203,55357,56613])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='all-css-0-1' href='https://s2.wp.com/_static/??-eJyNkttSAyEMhl9IyFKnOl44PguHiKnAMhBaeXvZajvrqfWGIQnfn58AHLKwc2JMDLGJHJqnVIHSMyXiDvyCESvkZuB4LGaWttYbWHEnyLcRGix+VArCXim5lQpMo+DAhNm+ikCm6NKhcg94FqJkQ3Ojza5CREcaw+i6OFoFOeiORQT02nYZKV3HR20df4H+Nn90OsSQs14s6z43Fr6Q+2b73xJFMyVfr+B2/sQ2Uk1jbo4qn5Pid3b1ZMvMRz5m/fPiF7ADOY888HraC8a3y0gebYQxuWCtYqyRWhQfP2XhnuKjurtV9w/badrs3gHJreS0?cssminify=yes' type='text/css' media='all' />
<style id='wp-block-library-inline-css'>
.has-text-align-justify {
	text-align:justify;
}
</style>
<style id='global-styles-inline-css'>
body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--normal: 16px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--huge: 42px;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-normal-font-size{font-size: var(--wp--preset--font-size--normal) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-huge-font-size{font-size: var(--wp--preset--font-size--huge) !important;}
</style>
<link rel='stylesheet' id='all-css-2-1' href='https://s0.wp.com/_static/??-eJx9i0EKgCAQAD+ULYJRHaK3qJhY666o0fezW126zcAMGNR09LaUDq4kLFN1VCGeIuHpAxXwjgWy1TUwfURsqEP+W7MzyL6hh1a99JnWuEg1zEpNo1T7DZLtMYQ=?cssminify=yes' type='text/css' media='all' />
<link rel='stylesheet' id='print-css-3-1' href='https://s2.wp.com/wp-content/mu-plugins/global-print/global-print.css?m=1465851035h&cssminify=yes' type='text/css' media='print' />
<style id='jetpack-global-styles-frontend-style-inline-css'>
:root { --font-headings: unset; --font-base: unset; --font-headings-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif; --font-base-default: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen-Sans,Ubuntu,Cantarell,"Helvetica Neue",sans-serif;}
</style>
<link rel='stylesheet' id='all-css-6-1' href='https://s0.wp.com/wp-content/themes/h4/global.css?m=1420737423h&cssminify=yes' type='text/css' media='all' />
<script id='wpcom-actionbar-placeholder-js-extra'>
var actionbardata = {"siteID":"12777403","siteName":"Azimuth","siteURL":"http:\/\/johncarlosbaez.wordpress.com","siteHost":"johncarlosbaez.wordpress.com","icon":"<img alt='' src='https:\/\/s2.wp.com\/i\/logo\/wpcom-gray-white.png' class='avatar avatar-50' height='50' width='50' \/>","canManageOptions":"","canCustomizeSite":"","isFollowing":"","themeSlug":"pub\/contempt","signupURL":"https:\/\/wordpress.com\/start\/","loginURL":"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2017%2F09%2F12%2Fact-2018%2F&signup_flow=account","themeURL":"","xhrURL":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/admin-ajax.php","nonce":"e6f6fdfb46","isSingular":"","isFolded":"","isLoggedIn":"","isMobile":"","subscribeNonce":"<input type=\"hidden\" id=\"_wpnonce\" name=\"_wpnonce\" value=\"ffcb185558\" \/>","referer":"https:\/\/johncarlosbaez.wordpress.com\/page\/7\/?s=information+and+entropy","canFollow":"1","feedID":"62242","statusMessage":"","subsEmailDefault":"instantly","customizeLink":"https:\/\/johncarlosbaez.wordpress.com\/wp-admin\/customize.php?url=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2Fpage%2F7%2F%3Fs%3Dinformation%2Band%2Bentropy","i18n":{"view":"View site","follow":"Follow","following":"Following","edit":"Edit","login":"Log in","signup":"Sign up","customize":"Customize","report":"Report this content","themeInfo":"Get theme: Contempt","shortlink":"Copy shortlink","copied":"Copied","followedText":"New posts from this site will now appear in your <a href=\"https:\/\/wordpress.com\/read\">Reader<\/a>","foldBar":"Collapse this bar","unfoldBar":"Expand this bar","editSubs":"Manage subscriptions","viewReader":"View site in Reader","viewReadPost":"View post in Reader","subscribe":"Sign me up","enterEmail":"Enter your email address","followers":"Join 5,228 other followers","alreadyUser":"Already have a WordPress.com account? <a href=\"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjohncarlosbaez.wordpress.com%2F2017%2F09%2F12%2Fact-2018%2F&signup_flow=account\">Log in now.<\/a>","stats":"Stats","notifyNewPosts":"Notify me of new posts","notifyNewPostsDetails":"Receive web and mobile notifications for new posts from this site.","emailNewPosts":"Email me new posts","emailNewPostsDetails":"You can customize your notification settings further <a href=\"https:\/\/wordpress.com\/following\/manage?s=johncarlosbaez.wordpress.com\">here<\/a>.","emailNewComments":"Email me new comments","instantly":"Instantly","daily":"Daily","weekly":"Weekly"}};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s2.wp.com/_static/??-eJyFykEKwkAMQNELmQ4qtboQz1LbWDJMknGSQXt7K9SFILj6i//CI8Og4igeooWs5oxm/YRNtE34vqxXSgjVsCxAHEhu+sOV5JCLPufPIxlSHdHeM94rlnlNwyR/ETBNpXdc8YXP28OuOx3brt3HF3swRvU='></script>
<script type='text/javascript'>
	window.addEventListener( 'DOMContentLoaded', function() {
		rltInitialize( {"token":null,"iframeOrigins":["https:\/\/widgets.wp.com"]} );
	} );
</script>
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://johncarlosbaez.wordpress.com/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://s1.wp.com/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress.com" />

<!-- Jetpack Open Graph Tags -->
<meta property="og:title" content="Search Results for &#8220;information and entropy&#8221; &#8211; Page 7 &#8211; Azimuth" />
<meta property="og:site_name" content="Azimuth" />
<meta property="og:image" content="https://s0.wp.com/i/blank.jpg" />
<meta property="og:locale" content="en_US" />
<meta name="twitter:site" content="@wordpressdotcom" />
<meta property="fb:app_id" content="249643311490" />

<!-- End Jetpack Open Graph Tags -->
<link rel="shortcut icon" type="image/x-icon" href="https://s1.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48" />
<link rel="icon" type="image/x-icon" href="https://s1.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48" />
<link rel="apple-touch-icon" href="https://s2.wp.com/i/webclip.png" />
<link rel='openid.server' href='https://johncarlosbaez.wordpress.com/?openidserver=1' />
<link rel='openid.delegate' href='https://johncarlosbaez.wordpress.com/' />
<link rel="search" type="application/opensearchdescription+xml" href="https://johncarlosbaez.wordpress.com/osd.xml" title="Azimuth" />
<link rel="search" type="application/opensearchdescription+xml" href="https://s1.wp.com/opensearch.xml" title="WordPress.com" />
<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>		<style type="text/css">
			.recentcomments a {
				display: inline !important;
				padding: 0 !important;
				margin: 0 !important;
			}

			table.recentcommentsavatartop img.avatar, table.recentcommentsavatarend img.avatar {
				border: 0px;
				margin: 0;
			}

			table.recentcommentsavatartop a, table.recentcommentsavatarend a {
				border: 0px !important;
				background-color: transparent !important;
			}

			td.recentcommentsavatarend, td.recentcommentsavatartop {
				padding: 0px 0px 1px 0px;
				margin: 0px;
			}

			td.recentcommentstextend {
				border: none !important;
				padding: 0px 0px 2px 10px;
			}

			.rtl td.recentcommentstextend {
				padding: 0px 10px 2px 0px;
			}

			td.recentcommentstexttop {
				border: none;
				padding: 0px 0px 0px 10px;
			}

			.rtl td.recentcommentstexttop {
				padding: 0px 10px 0px 0px;
			}
		</style>
		<meta name="application-name" content="Azimuth" /><meta name="msapplication-window" content="width=device-width;height=device-height" /><meta name="msapplication-task" content="name=Subscribe;action-uri=https://johncarlosbaez.wordpress.com/feed/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=Sign up for a free blog;action-uri=http://wordpress.com/signup/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=WordPress.com Support;action-uri=http://support.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico" /><meta name="msapplication-task" content="name=WordPress.com Forums;action-uri=http://forums.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico" /><style type="text/css">
#headerimg{
	background: url(https://johncarlosbaez.files.wordpress.com/2010/08/azimuth_header.jpg) no-repeat;
}
#header h1 a, .description {
	color:#E5F2E9;
}
</style>
<!-- There is no amphtml version available for this URL. -->		<link rel="stylesheet" id="custom-css-css" type="text/css" href="https://s0.wp.com/?custom-css=1&#038;csblog=RBZ9&#038;cscache=6&#038;csrev=7" />
		</head>
<body class="search search-results paged paged-7 search-paged-7 customizer-styles-applied highlander-enabled highlander-light">

<div id="page">

<div id="header">
	<div id="headerimg" onclick="location.href='https://johncarlosbaez.wordpress.com';" style="cursor: pointer;">
		<h1><a href="https://johncarlosbaez.wordpress.com/">Azimuth</a></h1>
		<div class="description"></div>
	</div>
</div>

<ul id="pagebar" class="menu pagebar"><li ><a href="https://johncarlosbaez.wordpress.com/">Home</a></li><li class="page_item page-item-2"><a href="https://johncarlosbaez.wordpress.com/about/">About</a></li>
</ul>

<div id="grad" style="height: 65px; width: 100%; background: url(https://s2.wp.com/wp-content/themes/pub/contempt/images/blue_flower/topgrad.jpg);">&nbsp;</div>

	<div id="content">

	
		
			<div class="post-23902 post type-post status-publish format-standard hentry category-conferences category-mathematics category-networks" id="post-23902">
				<h2><a href="https://johncarlosbaez.wordpress.com/2017/09/12/act-2018/" rel="bookmark">Applied Category Theory&nbsp;2018</a></h2>
				<small>12 September, 2017</small><br />


				<div class="entry">
					<div align="center">
<img src="https://i0.wp.com/math.ucr.edu/home/baez/networks/network_theory.gif" />
</div>
<p>There will be a workshop on applied category theory!</p>
<p>• <a href="https://www.lorentzcenter.nl/lc/web/2018/969/info.php3?wsid=969&amp;venue=Oort">Applied Category Theory (ACT 2018)</a>.  <a href="https://johncarlosbaez.wordpress.com/2017/10/22/applied-category-theory-2018-adjoint-school/">School</a> 23&#8211;27 April 2018 and workshop 30 April&#8211;4 May 2018 at the <a href="https://www.lorentzcenter.nl/">Lorentz Center</a> in Leiden, the Netherlands.  Organized by <a href="http://www.cs.ox.ac.uk/bob.coecke/">Bob Coecke</a> (Oxford), <a href="http://www.brendanfong.com/">Brendan Fong</a> (MIT), <a href="http://www.cs.ru.nl/A.Kissinger/">Aleks Kissinger</a> (Nijmegen), <a href="https://www.cs.ox.ac.uk/people/martha.lewis/">Martha Lewis</a> (Amsterdam), and <a href="http://joshuatan.com/research">Joshua Tan</a> (Oxford).</p>
<p>The plenary speakers will be:</p>
<p>• Samson Abramsky (Oxford)<br />
• John Baez (UC Riverside)<br />
• Kathryn Hess (EPFL)<br />
• Mehrnoosh Sadrzadeh (Queen Mary)<br />
• David Spivak (MIT)</p>
<p>One week before the workshop there will be a &#8216;school&#8217; for students: the <a href="https://johncarlosbaez.wordpress.com/2017/10/22/applied-category-theory-2018-adjoint-school/">ACT 2018 Adjoint School</a>.</p>
<p>There will be a lot more to say as this progresses, but for now let me just quote from the conference website:</p>
<blockquote>
<p>Applied Category Theory (ACT 2018) is a five-day workshop on <a href="http://www.appliedcategorytheory.org/workshops/">applied category theory</a> running from April 30 to May 4 at the <a href="https://www.lorentzcenter.nl/">Lorentz Center in Leiden, the Netherlands</a>.</p>
<p><i>Towards an Integrative Science</i>: in this workshop, we want to instigate a multi-disciplinary research program in which concepts, structures, and methods from one scientific discipline can be reused in another. The aim of the workshop is to (1) explore the use of category theory within and across different disciplines, (2) create a more cohesive and collaborative ACT community, especially among early-stage researchers, and (3) accelerate research by outlining common goals and open problems for the field.</p>
<p>While the workshop will host discussions on a wide range of applications of category theory, there will be four special tracks on exciting new developments in the field:</p>
<p>1. Dynamical systems and networks<br />
2. Systems biology<br />
3. Cognition and AI<br />
4. Causality</p>
<p>Accompanying the workshop will be an <a href="http://www.appliedcategorytheory.org/?page_id=274">Adjoint Research School</a> for early-career researchers. This will comprise a 16 week online seminar, followed by a 4 day research meeting at the Lorentz Center in the week prior to ACT 2018.  Applications to the school will open prior to October 1, and are due November 1.   Admissions will be notified by November 15.</p>
<p>Sincerely,<br />
The organizers</p>
<p><a href="http://www.cs.ox.ac.uk/bob.coecke/">Bob Coecke</a> (Oxford), <a href="http://www.brendanfong.com/">Brendan Fong</a> (MIT), <a href="http://www.cs.ru.nl/A.Kissinger/">Aleks Kissinger</a> (Nijmegen), <a href="https://www.cs.ox.ac.uk/people/martha.lewis/">Martha Lewis</a> (Amsterdam), and <a href="http://joshuatan.com/research">Joshua Tan</a> (Oxford)</p>
<p>We welcome any feedback!  Please send comments to <a href="mailto:joshua.tan@magd.ox.ac.uk">this link</a>.</p>
<h3> About Applied Category Theory </h3>
<p>Category theory is a branch of mathematics originally developed to transport ideas from one branch of mathematics to another, e.g. from topology to algebra. Applied category theory refers to efforts to transport the ideas of category theory from mathematics to other disciplines in science, engineering, and industry.</p>
<p>This site originated from discussions at the Computational Category Theory Workshop at <a href="http://nist.gov/">NIST</a> on Sept. 28-29, 2015. It serves to collect and disseminate research, resources, and tools for the development of applied category theory, and hosts a blog for those involved in its study.
</p></blockquote>
<blockquote>
<h3> The proposal: <i>Towards an Integrative Science</i> </h3>
<p>Category theory was developed in the 1940s to translate ideas from one field of mathematics, e.g. topology, to another field of mathematics, e.g. algebra. More recently, category theory has become an unexpectedly useful and economical tool for modeling a range of different disciplines, including programming language theory [10], quantum mechanics [2], systems biology [12], complex networks [5], database theory [7], and dynamical systems [14].</p>
<p>A category consists of a collection of objects together with a collection of maps between those objects, satisfying certain rules. Topologists and geometers use category theory to describe the passage from one mathematical structure to another, while category theorists are also interested in categories for their own sake. In computer science and physics, many types of categories (e.g. topoi or monoidal categories) are used to give a formal semantics of domain-specific phenomena (e.g. automata [3], or regular languages [11], or quantum protocols [2]). In the applied category theory community, a long-articulated vision understands categories as mathematical workspaces for the experimental sciences, similar to how they are used in topology and geometry [13]. This has proved true in certain fields, including computer science and mathematical physics, and we believe that these results can be extended in an exciting direction: we believe that category theory has the potential to bridge specific different fields, and moreover that developments in such fields (e.g. automata) can be transferred successfully into other fields (e.g. systems biology) through category theory. Already, for example, the categorical modeling of quantum processes has helped solve an important open problem in natural language processing [9].</p>
<p>In this workshop, we want to instigate a multi-disciplinary research program in which concepts, structures, and methods from one discipline can be reused in another. Tangibly and in the short-term, we will bring together people from different disciplines in order to write an expository survey paper that grounds the varied research in applied category theory and lays out the parameters of the research program.</p>
<p>In formulating this research program, we are motivated by recent successes where category theory was used to model a wide range of phenomena across many disciplines, e.g. open dynamical systems (including open Markov processes and open chemical reaction networks), entropy and relative entropy [6], and descriptions of computer hardware [8]. Several talks will address some of these new developments. But we are also motivated by an open problem in applied category theory, one which was observed at the most recent workshop in applied category theory (Dagstuhl, Germany, in 2015): “a weakness of semantics/CT is that the definitions play a key role. Having the right definitions makes the theorems trivial, which is the opposite of hard subjects where they have combinatorial proofs of theorems (and simple definitions). […] In general, the audience agrees that people see category theorists only as reconstructing the things they knew already, and that is a disadvantage, because we do not give them a good reason to care enough” [1, pg. 61].</p>
<p>In this workshop, we wish to articulate a natural response to the above: instead of treating the reconstruction as a weakness, we should treat the use of categorical concepts as a natural part of transferring and integrating knowledge across disciplines. The restructuring employed in applied category theory cuts through jargon, helping to elucidate common themes across disciplines. Indeed, the drive for a common language and comparison of similar structures in algebra and topology is what led to the development category theory in the first place, and recent hints show that this approach is not only useful between mathematical disciplines, but between scientific ones as well. For example, the ‘Rosetta Stone’ of Baez and Stay demonstrates how symmetric monoidal closed categories capture the common structure between logic, computation, and physics [4].</p>
<p></p>
<p>[1] Samson Abramsky, John C. Baez, Fabio Gadducci, and Viktor Winschel. Categorical methods at the crossroads. Report from Dagstuhl Perspectives Workshop 14182, 2014.</p>
<p>[2]  Samson Abramsky and Bob Coecke. A categorical semantics of quantum protocols. In Handbook of Quantum Logic and Quantum Structures. Elsevier, Amsterdam, 2009.</p>
<p>[3] Michael A. Arbib and Ernest G. Manes. A categorist’s view of automata and systems. In Ernest G. Manes, editor, Category Theory Applied to Computation and Control. Springer, Berlin, 2005.</p>
<p>[4]  John C. Baez and Mike STay. Physics, topology, logic and computation: a Rosetta stone.  In Bob Coecke, editor, New Structures for Physics.  Springer, Berlin, 2011.</p>
<p>[5]  John C. Baez and Brendan Fong. A compositional framework for passive linear networks. arXiv e-prints, 2015.</p>
<p>[6]  John C. Baez, Tobias Fritz, and Tom Leinster. A characterization of entropy in terms of information loss. Entropy, 13(11):1945–1957, 2011.</p>
<p>[7]  Michael Fleming, Ryan Gunther, and Robert Rosebrugh. A database of categories. Journal of Symbolic Computing, 35(2):127–135, 2003.</p>
<p>[8]  Dan R. Ghica and Achim Jung. Categorical semantics of digital circuits. In Ruzica Piskac and Muralidhar Talupur, editors, Proceedings of the 16th Conference on Formal Methods in Computer-Aided Design.  Springer, Berlin, 2016.</p>
<p>[9]  Dimitri Kartsaklis, Mehrnoosh Sadrzadeh, Stephen Pulman, and Bob Coecke. Reasoning about meaning in natural language with compact closed categories and Frobenius algebras. In Logic and Algebraic Structures in Quantum Computing and Information. Cambridge University Press, Cambridge, 2013.</p>
<p>[10]  Eugenio Moggi. Notions of computation and monads. Information and Computation, 93(1):55–92, 1991.</p>
<p>[11]  Nicholas Pippenger. Regular languages and Stone duality.   Theory of Computing Systems 30(2):121–134, 1997.</p>
<p>[12]  Robert Rosen. The representation of biological systems from the standpoint of the theory of categories. Bulletin of Mathematical Biophysics, 20(4):317–341, 1958.</p>
<p>[13]  David I. Spivak. Category Theory for Scientists. MIT Press, Cambridge MA, 2014.</p>
<p>[14]  David I. Spivak, Christina Vasilakopoulou, and Patrick Schultz. Dynamical systems and sheaves. arXiv e-prints, 2016.</p>
</blockquote>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2017/09/12/act-2018/#comments">4 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/conferences/" rel="category tag">conferences</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/networks/" rel="category tag">networks</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2017/09/12/act-2018/" rel="bookmark" title="Permanent Link to Applied Category Theory&nbsp;2018">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-22763 post type-post status-publish format-standard hentry category-computer-science category-information-and-entropy" id="post-22763">
				<h2><a href="https://johncarlosbaez.wordpress.com/2016/11/15/algorithmic-thermodynamics-part-3/" rel="bookmark">Algorithmic Thermodynamics (Part&nbsp;3)</a></h2>
				<small>15 November, 2016</small><br />


				<div class="entry">
					<p> </p>
<div align="center"><a href="http://math.ucr.edu/home/baez/thermo/"><img width="450" src="https://i0.wp.com/math.ucr.edu/home/baez/thermo/thermo.jpg" /></a></div>
<p>This is my talk for the Santa Fe Institute workshop on <a href="https://johncarlosbaez.wordpress.com/2016/11/07/information-processing-and-biology/">Statistical Mechanics, Information Processing and Biology</a>:</p>
<p>• <a href="http://math.ucr.edu/home/baez/thermo/thermo.pdf">Computation and thermodynamics.</a></p>
<p>It&#8217;s about the link between computation and entropy.  I take the idea of a Turing machine for granted, but starting with that I explain recursive functions, the Church-Turing thesis, Kolomogorov complexity, the relation between Kolmogorov complexity and Shannon entropy, the uncomputability of Kolmogorov complexity, the &#8216;complexity barrier&#8217;, Levin&#8217;s computable version of complexity, and finally my work with Mike Stay on algorithmic thermodynamics.</p>
<p>In my talk slides I mention the &#8216;complexity barrier&#8217;, and state this theorem:</p>
<p><b>Theorem</b>.  Choose your favorite set of axioms for math.  If it&#8217;s finite and consistent, there exists <i>C</i> ≥ 0, the <b>complexity barrier</b>, such that for no natural number <i>n</i> can you prove the Kolmogorov complexity of <i>n</i> exceeds <i>C</i>.</p>
<p>For a sketch of the proof of this result, go here:</p>
<p>• <a href="http://math.ucr.edu/home/baez/surprises.html#chaitin">Chaitin&#8217;s incompleteness theorem</a>.</p>
<p>In my talk I showed a movie related to this: an animated video <a>created in 2009</a> using a program less than 4 kilobytes long that runs on a Windows XP machine:</p>
<div align="center">
<span class="embed-youtube" style="text-align:center; display: block;"><iframe class="youtube-player" width="560" height="315" src="https://www.youtube.com/embed/I5CTFMuFvb0?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</div>
<h3> For more </h3>
<p>For more details, read our paper:</p>
<p>• John Baez and Mike Stay, <a href="http://arxiv.org/abs/1010.2067">Algorithmic thermodynamics</a>, <i>Math. Struct. Comp. Sci.</i> <b>22</b> (2012), 771-787.</p>
<p>or these blog articles:</p>
<p>•  <a href="https://johncarlosbaez.wordpress.com/2010/10/12/algorithmic-thermodynamics/">Algorithmic thermodynamics (part 1)</a>.</p>
<p>• <a href="https://johncarlosbaez.wordpress.com/2011/01/06/algorithmic-thermodynamics-part-2/">Algorithmic thermodynamics (part 2)</a>.</p>
<p>They all emphasize slightly different aspects!</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2016/11/15/algorithmic-thermodynamics-part-3/#comments">4 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/computer-science/" rel="category tag">computer science</a>, <a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/" rel="category tag">information and entropy</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2016/11/15/algorithmic-thermodynamics-part-3/" rel="bookmark" title="Permanent Link to Algorithmic Thermodynamics (Part&nbsp;3)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-21793 post type-post status-publish format-standard hentry category-biology category-mathematics category-probability" id="post-21793">
				<h2><a href="https://johncarlosbaez.wordpress.com/2016/04/18/statistical-laws-of-darwinian-evolution/" rel="bookmark">Statistical Laws of Darwinian&nbsp;Evolution</a></h2>
				<small>18 April, 2016</small><br />


				<div class="entry">
					<p><i>guest post by <b><a href="http://www.azimuthproject.org/azimuth/show/Matteo+Smerlak">Matteo Smerlak</a></b></i></p>
<p>Biologists like Steven J. Gould like to emphasize that evolution is unpredictable. They have a point: there is absolutely no way an alien visiting the Earth 400 million years ago could have said:</p>
<blockquote><p>
  Hey, I know what&#8217;s gonna happen here. Some descendants of those ugly fish will grow wings and start flying in the air. Others will walk the surface of the Earth for a few million years, but they&#8217;ll get bored and they&#8217;ll eventually go back to the oceans; when they do, they&#8217;ll be able to chat across thousands of kilometers using ultrasound. Yet others will grow arms, legs, fur, they&#8217;ll climb trees and invent BBQ, and, sooner or later, they&#8217;ll start wondering &#8220;why all this?&#8221;.
</p></blockquote>
<p>Nor can we tell if, a week from now, the flu virus will mutate, become highly pathogenic and forever remove the furry creatures from the surface of the Earth.</p>
<p>Evolution isn&#8217;t gravity—we can&#8217;t tell in which directions things will fall down.</p>
<p>One reason we can&#8217;t predict the outcomes of evolution is that genomes evolve in a super-high dimensional combinatorial space, which a ginormous number of possible turns at every step. Another is that living organisms interact with one another in a massively non-linear way, with, feedback loops, tipping points and all that jazz.</p>
<p>Life&#8217;s a mess, if you want my physicist&#8217;s opinion.</p>
<p>But that doesn&#8217;t mean that <em>nothing</em> can be predicted. Think of statistics. Nobody can predict who I&#8217;ll vote for in the next election, but it&#8217;s easy to tell what the <em>distribution</em> of votes in the country will be like. Thus, for continuous variables which arise as sums of large numbers of independent components, the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem</a> tells us that the distribution will always be approximately normal. Or take extreme events: the max of <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> independent random variables is distributed according to a member of a one-parameter family of so-called &#8220;extreme value distributions&#8221;: this is the content of the famous <a href="https://en.wikipedia.org/wiki/Fisher–Tippett–Gnedenko_theorem">Fisher–Tippett–Gnedenko theorem</a>.</p>
<p>So this is the problem I want to think about in this blog post: is evolution ruled by <em>statistical laws</em>? Or, in physics terms: does it exhibit some form of <em>universality</em>?</p>
<h3> Fitness distributions are the thing </h3>
<p>One lesson from statistical physics is that, to uncover universality, you need to focus on <em>relevant</em> variables. In the case of evolution, it was Darwin&#8217;s main contribution to figure out the main relevant variable: the average number of viable offspring, aka <em>fitness</em>, of an organism. Other features—physical strength, metabolic efficiency, you name it—matter only insofar as they are correlated with fitness. If we further assume that fitness is (approximately) heritable, meaning that descendants have the same fitness as their ancestors, we get a simple yet powerful dynamical principle called <em>natural selection</em>: in a given population, the lineage with the highest fitness eventually dominates, i.e. its fraction goes to one over time. This principle is very general: it applies to genes and species, but also to non-living entities such as algorithms, firms or language. The general relevance of natural selection as a evolutionary force is sometimes referred to as <a href="https://en.wikipedia.org/wiki/Universal_Darwinism">&#8220;Universal Darwinism&#8221;</a>.</p>
<p>The general idea of natural selection is pictured below (reproduced from <a href="http://www.pnas.org/content/108/7/2633.full">this paper</a>):</p>
<div align="center">
<img width="450" src="https://i1.wp.com/math.ucr.edu/home/baez/mathematical/smerlak/fitnessdist.jpg" alt="" />
</div>
<p>It&#8217;s not hard to write down an equation which expresses natural selection in general terms. Consider an infinite population in which each lineage grows with some rate <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" />. (This rate is called the log-fitness or Malthusian fitness to contrast it with the number of viable offspring <img src="https://s0.wp.com/latex.php?latex=w%3De%5E%7Bx%5CDelta+t%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="w=e^{x&#92;Delta t}" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%5CDelta+t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta t" class="latex" /> the lifetime of a generation. It&#8217;s more convenient to use <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> than <img src="https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="w" class="latex" /> in what follows, so we&#8217;ll just call <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> &#8220;fitness&#8221;). Then the distribution of fitness at time <img src="https://s0.wp.com/latex.php?latex=t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t" class="latex" /> satisfies the equation</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7B%5Cpartial+p_t%28x%29%7D%7B%5Cpartial+t%7D+%3D%5Cleft%28x-%5Cint+d+y%5C%2C+y%5C%2C+p_t%28y%29%5Cright%29p_t%28x%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{&#92;partial p_t(x)}{&#92;partial t} =&#92;left(x-&#92;int d y&#92;, y&#92;, p_t(y)&#92;right)p_t(x) } " class="latex" />
</div>
<p>whose explicit solution in terms of the initial fitness distribution <img src="https://s0.wp.com/latex.php?latex=p_0%28x%29%3A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_0(x):" class="latex" /></p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_t%28x%29%3D%5Cfrac%7Be%5E%7Bx+t%7Dp_0%28x%29%7D%7B%5Cint+d+y%5C%2C+e%5E%7By+t%7Dp_0%28y%29%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_t(x)=&#92;frac{e^{x t}p_0(x)}{&#92;int d y&#92;, e^{y t}p_0(y)} } " class="latex" />
</div>
<p>is called the <b>Cramér transform</b> of <img src="https://s0.wp.com/latex.php?latex=p_0%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_0(x)" class="latex" /> in large deviations theory. That is, viewed as a flow in the space of probability distributions, natural selection is nothing but a time-dependent exponential tilt.  (These equations and the results below can be generalized to include the effect of mutations, which are critical to maintain variation in the population, but we&#8217;ll skip this here to focus on pure natural selection. See my paper referenced below for more information.)</p>
<p>An immediate consequence of these equations is that the mean fitness <img src="https://s0.wp.com/latex.php?latex=%5Cmu_t%3D%5Cint+dx%5C%2C+x%5C%2C+p_t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mu_t=&#92;int dx&#92;, x&#92;, p_t(x)" class="latex" /> grows monotonically in time, with a rate of growth given by the variance <img src="https://s0.wp.com/latex.php?latex=%5Csigma_t%5E2%3D%5Cint+dx%5C%2C+%28x-%5Cmu_t%29%5E2%5C%2C+p_t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sigma_t^2=&#92;int dx&#92;, (x-&#92;mu_t)^2&#92;, p_t(x)" class="latex" />:</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd%5Cmu_t%7D%7Bdt%7D%3D%5Csigma_t%5E2%5Cgeq+0+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d&#92;mu_t}{dt}=&#92;sigma_t^2&#92;geq 0 } " class="latex" />
</div>
<p>The great geneticist Ronald Fisher (yes, the one in the extreme value theorem!) was very impressed with this relationship. He thought it amounted to an biological version of the second law of thermodynamics, writing in his 1930 monograph</p>
<blockquote><p>
  Professor Eddington has recently remarked that &#8220;The law that entropy always increases&#8212;the second law of thermodynamics&#8212;holds, I think, the supreme position among the laws of nature&#8221;. It is not a little instructive that so similar a law should hold the supreme position among the biological sciences.
</p></blockquote>
<p>Unfortunately, this excitement hasn&#8217;t been shared by the biological community, notably because this Fisher <a href="https://en.wikipedia.org/wiki/Fisher%27s_fundamental_theorem_of_natural_selection">&#8220;fundamental theorem of natural selection&#8221;</a> isn&#8217;t predictive: the mean fitness <img src="https://s0.wp.com/latex.php?latex=%5Cmu_t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mu_t" class="latex" /> grows according to the fitness variance <img src="https://s0.wp.com/latex.php?latex=%5Csigma_t%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sigma_t^2" class="latex" />, but what determines the evolution of <img src="https://s0.wp.com/latex.php?latex=%5Csigma_t%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sigma_t^2" class="latex" />? I can&#8217;t use the identity above to predict the speed of evolution in any sense. Geneticists say it&#8217;s &#8220;dynamically insufficient&#8221;.</p>
<h3> Two limit theorems </h3>
<p>But the situation isn&#8217;t as bad as it looks. The evolution of <img src="https://s0.wp.com/latex.php?latex=p_t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_t(x)" class="latex" /> may be decomposed into the evolution of its mean <img src="https://s0.wp.com/latex.php?latex=%5Cmu_t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mu_t" class="latex" />, of its variance <img src="https://s0.wp.com/latex.php?latex=%5Csigma_t%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sigma_t^2" class="latex" />, and of its <b>shape</b> or <b>type</b></p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Coverline%7Bp%7D_t%28x%29%3D%5Csigma_t+p_t%28%5Csigma_t+x%2B%5Cmu_t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;overline{p}_t(x)=&#92;sigma_t p_t(&#92;sigma_t x+&#92;mu_t)" class="latex" />.
</div>
<p>(We also call <img src="https://s0.wp.com/latex.php?latex=%5Coverline%7Bp%7D_t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;overline{p}_t(x)" class="latex" /> the &#8220;standardized fitness distribution&#8221;.) With Ahmed Youssef we showed that:</p>
<p>&bull; If <img src="https://s0.wp.com/latex.php?latex=p_0%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_0(x)" class="latex" /> is supported on the whole real line and decays at infinity as</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=-%5Cln%5Cint_x%5E%7B%5Cinfty%7Dp_0%28y%29d+y%5Cunderset%7Bx%5Cto%5Cinfty%7D%7B%5Csim%7D+x%5E%7B%5Calpha%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="-&#92;ln&#92;int_x^{&#92;infty}p_0(y)d y&#92;underset{x&#92;to&#92;infty}{&#92;sim} x^{&#92;alpha} " class="latex" />
</div>
<p>for some <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3E+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &gt; 1" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=%5Cmu_t%5Csim+t%5E%7B%5Coverline%7B%5Calpha%7D-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mu_t&#92;sim t^{&#92;overline{&#92;alpha}-1}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%5Csigma_t%5E2%5Csim+t%5E%7B%5Coverline%7B%5Calpha%7D-2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sigma_t^2&#92;sim t^{&#92;overline{&#92;alpha}-2}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Coverline%7Bp%7D_t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;overline{p}_t(x)" class="latex" /> converges to the standard normal distribution as <img src="https://s0.wp.com/latex.php?latex=t%5Cto%5Cinfty&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="t&#92;to&#92;infty" class="latex" />. Here <img src="https://s0.wp.com/latex.php?latex=%5Coverline%7B%5Calpha%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;overline{&#92;alpha}" class="latex" /> is the conjugate exponent to <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha" class="latex" />, i.e. <img src="https://s0.wp.com/latex.php?latex=1%2F%5Coverline%7B%5Calpha%7D%2B1%2F%5Calpha%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/&#92;overline{&#92;alpha}+1/&#92;alpha=1" class="latex" />.</p>
<p>&bull; If <img src="https://s0.wp.com/latex.php?latex=p_0%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_0(x)" class="latex" /> has a finite right-end point <img src="https://s0.wp.com/latex.php?latex=x_%2B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_+" class="latex" />  with</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=p%28x%29%5Cunderset%7Bx%5Cto+x_%2B%7D%7B%5Csim%7D+%28x_%2B-x%29%5E%5Cbeta+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(x)&#92;underset{x&#92;to x_+}{&#92;sim} (x_+-x)^&#92;beta " class="latex" />
</div>
<p>for some <img src="https://s0.wp.com/latex.php?latex=%5Cbeta%5Cgeq0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta&#92;geq0" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=x_%2B-%5Cmu_t%5Csim+t%5E%7B-1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_+-&#92;mu_t&#92;sim t^{-1}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%5Csigma_t%5E2%5Csim+t%5E%7B-2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sigma_t^2&#92;sim t^{-2}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Coverline%7Bp%7D_t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;overline{p}_t(x)" class="latex" /> converges to the flipped gamma distribution</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p%5E%2A_%5Cbeta%28x%29%3D+%5Cfrac%7B%281%2B%5Cbeta%29%5E%7B%281%2B%5Cbeta%29%2F2%7D%7D%7B%5CGamma%281%2B%5Cbeta%29%7D+%5CTheta%5Bx-%281%2B%5Cbeta%29%5E%7B1%2F2%7D%5D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p^*_&#92;beta(x)= &#92;frac{(1+&#92;beta)^{(1+&#92;beta)/2}}{&#92;Gamma(1+&#92;beta)} &#92;Theta[x-(1+&#92;beta)^{1/2}] }" class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7B+e%5E%7B-%281%2B%5Cbeta%29%5E%7B1%2F2%7D%5B%281%2B%5Cbeta%29%5E%7B1%2F2%7D-x%5D%7D%5CBig%5B%281%2B%5Cbeta%29%5E%7B1%2F2%7D-x%5CBig%5D%5E%5Cbeta+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle { e^{-(1+&#92;beta)^{1/2}[(1+&#92;beta)^{1/2}-x]}&#92;Big[(1+&#92;beta)^{1/2}-x&#92;Big]^&#92;beta } " class="latex" />
</div>
<p>Here and below the symbol <img src="https://s0.wp.com/latex.php?latex=%5Csim&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sim" class="latex" /> means &#8220;asymptotically equivalent up to a positive multiplicative constant&#8221;; <img src="https://s0.wp.com/latex.php?latex=%5CTheta%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Theta(x)" class="latex" /> is the Heaviside step function. Note that <img src="https://s0.wp.com/latex.php?latex=p%5E%2A_%5Cbeta%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p^*_&#92;beta(x)" class="latex" /> becomes Gaussian in the limit <img src="https://s0.wp.com/latex.php?latex=%5Cbeta%5Cto%5Cinfty&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta&#92;to&#92;infty" class="latex" />, i.e. the attractors of cases 1 and 2 form a continuous line in the space of probability distributions; the other extreme case, <img src="https://s0.wp.com/latex.php?latex=%5Cbeta%5Cto0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta&#92;to0" class="latex" />, corresponds to a flipped exponential distribution.</p>
<p>The one-parameter family of attractors <img src="https://s0.wp.com/latex.php?latex=p_%5Cbeta%5E%2A%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_&#92;beta^*(x)" class="latex" /> is plotted below:</p>
<div align="center">
<img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/smerlak/attractors.jpg" alt="" /></div>
<p>These results achieve two things. First, they resolve the dynamical insufficiency of Fisher&#8217;s fundamental theorem by giving estimates of the speed of evolution in terms of the tail behavior of the initial fitness distribution. Second, they show that natural selection is indeed subject to a form of universality, whereby the relevant statistical structure turns out to be finite dimensional, with only a handful of &#8220;conserved quantities&#8221; (the <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> exponents) controlling the late-time behavior of natural selection. This amounts to a large reduction in complexity and, concomitantly, an enhancement of predictive power.</p>
<p>(For the mathematically-oriented reader, the proof of the theorems above involves two steps: first, translate the selection equation into a equation for (cumulant) generating functions; second, use a suitable Tauberian theorem&#8212;the Kasahara theorem&#8212;to relate the behavior of generating functions at large values of their arguments to the tail behavior of <img src="https://s0.wp.com/latex.php?latex=p_0%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_0(x)" class="latex" />. Details in our paper.)</p>
<p>It&#8217;s useful to consider the convergence of fitness distributions to the attractors <img src="https://s0.wp.com/latex.php?latex=p_%5Cbeta%5E%2A%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_&#92;beta^*(x)" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=0%5Cleq%5Cbeta%5Cleq+%5Cinfty&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="0&#92;leq&#92;beta&#92;leq &#92;infty" class="latex" /> in the skewness-kurtosis plane, i.e. in terms of the third and fourth cumulants of <img src="https://s0.wp.com/latex.php?latex=p_t%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_t(x)" class="latex" />.</p>
<div align="center">
<img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/smerlak/sksims.jpg" alt="" />
</div>
<p>The red curve is the family of attractors, with the normal at the bottom right and the flipped exponential at the top left, and the dots correspond to numerical simulations performed with the classical Wright&#8211;Fisher model and with a simple genetic algorithm solving a linear programming problem. The attractors attract!</p>
<h3> Conclusion and a question </h3>
<p>Statistics is useful because limit theorems (the central limit theorem, the extreme value theorem) exist. Without them, we wouldn&#8217;t be able to make any population-level prediction. Same with statistical physics: it only because matter consists of large numbers of atoms, and limit theorems hold (the H-theorem, the second law), that macroscopic physics is possible in the first place. I believe the same perspective is useful in evolutionary dynamics: it&#8217;s true that we can&#8217;t predict how many wings birds will have in ten million years, but we <em>can</em> tell what shape fitness distributions should have if natural selection is true.</p>
<p>I&#8217;ll close with an open question for you, the reader. In the central limit theorem as well as in the second law of thermodynamics, convergence is driven by a Lyapunov function, namely <em>entropy</em>. (In the case of the central limit theorem, it&#8217;s a relatively recent result by Arstein et al.: the entropy of the normalized sum of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> i.i.d. random variables, when it&#8217;s finite, is a monotonically increasing function of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" />.) In the case of natural selection for unbounded fitness, it&#8217;s clear that entropy will also be eventually monotonically increasing—the normal is the distribution with largest entropy at fixed variance and mean.</p>
<p>Yet it turns out that, in our case, entropy isn&#8217;t monotonic at all times; in fact, the closer the initial distribution <img src="https://s0.wp.com/latex.php?latex=p_0%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_0(x)" class="latex" /> is to the normal distribution, the later the entropy of the standardized fitness distribution starts to increase. Or, equivalently, the closer the initial distribution <img src="https://s0.wp.com/latex.php?latex=p_0%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_0(x)" class="latex" /> to the normal, the later its relative entropy with respect to the normal. Why is this? And what&#8217;s the actual Lyapunov function for this process (i.e., what functional of the standardized fitness distribution is monotonic at all times under natural selection)?</p>
<div align="center">
<img width="450" src="https://i1.wp.com/math.ucr.edu/home/baez/mathematical/smerlak/relativeentropy.jpg" alt="" /></div>
<div align="center">
<img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/smerlak/l1distance.jpg" alt="" />
</div>
<p>In the plots above the blue, orange and green lines correspond respectively to</p>
<div align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_0%28x%29%5Cpropto+e%5E%7B-x%5E2%2F2-x%5E4%7D%2C+%5Cquad+p_0%28x%29%5Cpropto+e%5E%7B-x%5E2%2F2-.01x%5E4%7D%2C+%5Cquad+p_0%28x%29%5Cpropto+e%5E%7B-x%5E2%2F2-.001x%5E4%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_0(x)&#92;propto e^{-x^2/2-x^4}, &#92;quad p_0(x)&#92;propto e^{-x^2/2-.01x^4}, &#92;quad p_0(x)&#92;propto e^{-x^2/2-.001x^4} } " class="latex" />
</div>
<h3> References </h3>
<p>&bull; S. J. Gould, <i>Wonderful Life: The Burgess Shale and the Nature of History</i>, W. W. Norton &amp; Co., New York, 1989.</p>
<p>&bull; M. Smerlak and A. Youssef, <a href="http://arxiv.org/pdf/1511.00296">Limiting fitness distributions in evolutionary dynamics</a>, 2015.</p>
<p>&bull; R. A. Fisher, <i>The Genetical Theory of Natural Selection</i>, Oxford University Press, Oxford, 1930.</p>
<p>&bull; S. Artstein, K. Ball, F. Barthe and A. Naor, <a href="http://www.ams.org/journals/jams/2004-17-04/S0894-0347-04-00459-X/S0894-0347-04-00459-X.pdf">Solution of Shannon&#8217;s problem on the monotonicity of entropy</a>, <i>J. Am. Math. Soc.</i> <b>17</b> (2004), 975&ndash;982.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2016/04/18/statistical-laws-of-darwinian-evolution/#comments">34 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/biology/" rel="category tag">biology</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/probability/" rel="category tag">probability</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2016/04/18/statistical-laws-of-darwinian-evolution/" rel="bookmark" title="Permanent Link to Statistical Laws of Darwinian&nbsp;Evolution">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-20665 post type-post status-publish format-standard hentry category-biology category-chemistry" id="post-20665">
				<h2><a href="https://johncarlosbaez.wordpress.com/2016/01/08/glycolysis/" rel="bookmark">Glycolysis (Part 1)</a></h2>
				<small>8 January, 2016</small><br />


				<div class="entry">
					<p>I&#8217;m trying to understand some biology.  Being a mathematician I&#8217;m less interested in all the complicated details of life on this particular planet than in something a bit more abstract.  I want to know &#8216;the language of life&#8217;: the right way to talk about living systems.</p>
<p>Of course, there&#8217;s no way to reach this goal without learning a lot of the complicated details.  But I might as well be honest and state my goal, since it&#8217;s bound to put a strange spin on how I learn and talk about biology.</p>
<p>For example, when I heard people were <a href="https://johncarlosbaez.wordpress.com/2016/01/02/biology-and-the-pi-calculus/">using the pi-calculus to model a very simple bacterium</a>, I wasn&#8217;t eager to know how close their model is to the Last Universal Ancestor, the primordial bug from which we all descend.   Even though it&#8217;s a fascinating question, it&#8217;s not one I can help solve.  Instead,  I wanted to know if the pi-calculus is really the best language for this kind of model.</p>
<p>I also wanted to know what <i>types</i> of chemical reactions are needed for a cell to survive.  I&#8217;ll never remember all the details of those reactions: I don&#8217;t have the right kind of mind for that.  But I might manage to think about these reactions in abstract ways that biologists haven&#8217;t tried.</p>
<p>So, when I read this:</p>
<blockquote><p>
The minimal gene set prokaryote has been exhaustively described in the enhanced π-calculus. We represented the 237 genes, their relative products, and the metabolic pathways expressed and regulated by the genes, as the corresponding processes and channels. In particular: the <a href="https://en.wikipedia.org/wiki/Glycolysis">glycolytic pathway</a>, the <a href="https://en.wikipedia.org/wiki/Pentose_phosphate_pathway">pentose phosphate pathway</a>, the pathways involved in nucleotide, aminoacids, coenzyme, lipids, and glycerol metabolism.
</p></blockquote>
<p>I instantly wanted to get an <em>overall view</em> of these reactions, without immersing myself in all the details.</p>
<p>Unfortunately I don&#8217;t know how to do this.  Do you?</p>
<p>It might be like trying to learn grammar without learning vocabulary: not very easy, and perhaps unwise.</p>
<p>But I bet there&#8217;s a biochemistry textbook that would help me: one that focuses on the forest before getting into the names of all the trees.  I may have even seen a such book!  I&#8217;ve certainly <em>tried</em> to learn biochemistry.  It&#8217;s a perfectly fascinating subject.  But it&#8217;s only recently that I&#8217;ve gotten serious about chemical reaction networks and nonequilibrium thermodynamics.  this may help guide my studies now.</p>
<p>Anyway, let me start with the &#8216;glycolytic pathway&#8217;.  <a href="https://en.wikipedia.org/wiki/Glycolysis">Glycolysis</a> is the process of breaking down a sugar called <a href="https://en.wikipedia.org/wiki/Glucose">glucose</a>, thereby powering the formation of <a href="https://en.wikipedia.org/wiki/Adenosine_triphosphate">ATP</a>, which holds energy in a form that the cell can easily use to do many things.</p>
<p>Glycolysis looks pretty complicated, at least if you&#8217;re a mathematician:</p>
<div align="center"><a href="http://math.ucr.edu/home/baez/chemical/glycolysis.jpg"><img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/chemical/glycolysis.jpg" /><br />
</a></div>
<p>But when you&#8217;re trying to understand the activities of a complicated criminal network, a good slogan is &#8216;follow the money&#8217;.  And for a chemical reaction network, you can &#8216;follow the conserved quantities&#8217;.  We&#8217;ve got various kinds of atoms&#8212;hydrogen, carbon, nitrogen, oxygen, phosphorus&#8212;and the number of each kind is conserved.  That should help us follow what&#8217;s going on.</p>
<p>Energy is also conserved, and that&#8217;s incredibly important in thermodynamics.  <a href="https://en.wikipedia.org/wiki/Thermodynamic_free_energy">Free energy</a>&mdash;energy in forms that are actually <i>useful</i>&mdash;is not conserved.  But it&#8217;s still very good to follow it, since while it can go away, turning into heat, it essentially never appears out of nowhere.</p>
<p>The usual definition of free energy is something like</p>
<p><img src="https://s0.wp.com/latex.php?latex=F+%3D+E+-+TS+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="F = E - TS " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E" class="latex" /> is energy, <img src="https://s0.wp.com/latex.php?latex=T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T" class="latex" /> is temperature and <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> is entropy.  You can think of this roughly &#8220;energy minus energy in the form of heat&#8221;.  There&#8217;s a lot more to say here, but I just want to add that free energy can also be interpreted as &#8216;relative information&#8217;, a purely information-theoretic concept.   For an explanation, see Section 4 of this paper:</p>
<p>&bull; John Baez and Blake Pollard, <a href="http://arxiv.org/abs/1512.02742">Relative entropy in biological systems</a>.  (Blog article <a href="https://johncarlosbaez.wordpress.com/2015/11/27/relative-entropy-in-biological-systems/">here</a>.)</p>
<p>Since I like abstract generalities, this information-theoretic way of understanding free energy appeals to me.</p>
<p>And of course free energy is <i>useful</i>, so an organism should care about it&#8212;and we should be able to track what an organism actually does with it.  This is one of my main goals: understanding better what it means for a system to &#8216;do something with free energy&#8217;.</p>
<p>In glycolysis, some of the free energy of glucose gets transferred to ATP.  ATP is a bit like &#8216;money&#8217;: it carries free energy in a way that the cell can easily &#8216;spend&#8217; to do interesting things.  So, at some point I want to look at an example of how the cell actually spends this money.  But for now I want to think about glycolysis&#8212;which may be more like &#8216;cashing a check and getting money&#8217;.</p>
<p>First, let&#8217;s see what we get if we &#8216;black-box&#8217; glycolysis.  I&#8217;ve written about <a href="https://johncarlosbaez.wordpress.com/2015/09/04/a-compositional-framework-for-markov-processes/">black-boxing electrical circuits and Markov processes</a>: it&#8217;s a way to ignore their inner workings and focus on the relation between inputs and outputs.</p>
<p>Blake Pollard and I are starting to study the black-boxing of chemical reaction networks.   If we black-box glycolysis, we get this:</p>
<div align="center">
glucose + 2 NAD<sup>+</sup> + 2 ADP + 2 phosphate &rarr;<br />
2 pyruvate + 2 NADH + 2 H<sup>+</sup> + 2 ATP + 2 H<sub>2</sub>O
</div>
<p>I&#8217;ll talk about NAD<sup>+</sup> and NADH later; let&#8217;s temporarily ignore those.</p>
<p>A molecule of glucose has <em>more free energy</em> than 2 pyruvate molecules plus 2 water molecules.   On the other hand, ADP + phosphate has <em>less</em> free energy than ATP.  So, glycolysis is taking free energy from glucose and putting some of it into the handy form of ATP molecules.  And a natural question is: how efficient is this reaction?  How much free energy gets wasted?</p>
<p>Here&#8217;s an interesting paper that touches indirectly on this question:</p>
<p>&bull; Daniel A. Beard, Eric Babson, Edward Curtis and Hong Qian, <a href="http://projects.csail.mit.edu/wiki/pub/Evodesign/MetabolicNetworks/Beard-etal-2004-j-theo-biology.pdf">Thermodynamic constraints for biochemical networks</a>, <em>Journal of Theoretical Biology</em> <strong>228</strong> (2004), 327&#8211;333.</p>
<p>They develop a bunch of machinery for studying chemical reaction networks, which I hope to explain someday.  (Mathematicians will be delighted to hear that they use <a href="https://en.wikipedia.org/wiki/Matroid_representation">matroids</a>, a general framework for studying linear dependence.  Biochemists may be less delighted.)   Then they apply this machinery to glycolysis, using computers to do some calculations, and they conclude:</p>
<blockquote><p>
  Returning to the original problem of ATP production in energy metabolism, and searching for the flux vector that maximizes ATP production while satisfying the<br />
  mass balance constraint and the thermodynamic constraint, we find that at most 20.5 ATP are produced for each glucose molecule consumed.
</p></blockquote>
<p>So, they&#8217;re getting some upper bound on how good glycolysis could actually be!</p>
<p><b>Puzzle 1.</b> What upper bounds can you get simply from free energy considerations?</p>
<p>For example, ignore NADH and NAD<sup>+</sup> for a second, and ask how much ATP you could make from turning a molecule of glucose into pyruvate and water if free energy were the only consideration.  To answer this, you could take the free energy of a mole glucose minus the free energy of the corresponding amount of pyruvate and water, and divide it by the free energy of a mole of ATP minus the free energy of the corresponding amount of ADP and phosphate.  What do you get?</p>
<p><b>Puzzle 2.</b> How do NADH and NAD<sup>+</sup> fit into the story?  In the last paragraph I ignored those.  We shouldn&#8217;t really do that!  NAD<sup>+</sup> is an oxidized form of <a href="https://en.wikipedia.org/wiki/Nicotinamide_adenine_dinucleotide">nicotinamide adenine dinucleotide</a>.  NADH is the the reduced form of the same chemical.  In our cells, NADH has more free energy than NAD<sup>+</sup>.  So, besides producing &#8216;free energy money&#8217; in the form of ATP, glycolysis is producing it in the form of NADH!    This should improve our upper bound on how much ATP could be produced by glycolysis.</p>
<p>However, the cell uses NADH for more than just &#8216;money&#8217;.  It uses NADH to oxidize other chemicals and NAD<sup>+</sup> to reduce them.  Reduction and oxidation are really important in chemistry, including biochemistry.  I need to understand this whole <a href="https://en.wikipedia.org/wiki/Redox">redox</a> business better.  Right now my guess is that it&#8217;s connected to yet another conserved quantity, which I haven&#8217;t mentioned so far.</p>
<p><b>Puzzle 3.</b>  What conserved quantity is that?</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2016/01/08/glycolysis/#comments">36 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/biology/" rel="category tag">biology</a>, <a href="https://johncarlosbaez.wordpress.com/category/chemistry/" rel="category tag">chemistry</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2016/01/08/glycolysis/" rel="bookmark" title="Permanent Link to Glycolysis (Part 1)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-19921 post type-post status-publish format-standard hentry category-biology category-chemistry category-mathematics category-networks" id="post-19921">
				<h2><a href="https://johncarlosbaez.wordpress.com/2015/07/01/trends-in-reaction-network-theory-part-2/" rel="bookmark">Trends in Reaction Network Theory (Part&nbsp;2)</a></h2>
				<small>1 July, 2015</small><br />


				<div class="entry">
					<p>Here in Copenhagen we&#8217;ll soon be having a bunch of interesting talks on chemical reaction networks:</p>
<p>&bull; <a href="http://www.math.ku.dk/~efeliu/trendsrnt/index.html">Workshop on Mathematical Trends in Reaction Network Theory</a>, 1-3 July 2015, Department of Mathematical Sciences, University of Copenhagen.  Organized by <a href="http://www.math.ku.dk/~efeliu/">Elisenda Feliu</a> and <a href="http://www.math.ku.dk/~pbx512/">Carsten Wiuf</a>.</p>
<p>Looking through the <a href="http://www.math.ku.dk/~efeliu/trendsrnt/abstracts.html">abstracts</a>, here are a couple that strike me.</p>
<p>First of all, Gheorghe Craciun claims to have proved the biggest open conjecture in this field: the Global Attractor Conjecture!</p>
<p>&bull; Gheorge Craciun, <a href="http://arxiv.org/abs/1501.02860">Toric differential inclusions and a proof of the global attractor conjecture</a>.</p>
<p>This famous old conjecture says that for a certain class of chemical reactions, the ones coming from &#8216;complex balanced reaction networks&#8217;, the chemicals will approach equilibrium no matter what their initial concentrations are.  Here&#8217;s what Craciun says:</p>
<blockquote><p>
  <strong>Abstract.</strong> In a groundbreaking 1972 paper Fritz Horn and Roy Jackson showed that a complex balanced mass-action system must have a unique locally stable equilibrium within any compatibility class. In 1974 Horn conjectured that this equilibrium is a global attractor, i.e., all solutions in the same compatibility class must converge to this equilibrium. Later, this claim was called the Global Attractor Conjecture, and it was shown that it has remarkable implications for the dynamics of large classes of polynomial and power-law dynamical systems, even if they are not derived from mass-action kinetics. Several special cases of this conjecture have been proved during the last decade. We describe a proof of the conjecture in full generality. In particular, it will follow that all detailed balanced mass action systems and all deficiency zero mass-action systems have the global attractor property. We will also discuss some implications for biochemical mechanisms that implement noise filtering and cellular homeostasis.
</p></blockquote>
<p>Manoj Gopalkrishnan wrote a <a href="https://johncarlosbaez.wordpress.com/2014/01/07/lyapunov-functions-for-complex-balanced-systems/">great post</a> explaining the concept of complex balanced reaction network here on Azimuth, so if you want to understand the conjecture you could start there.</p>
<p>Even better, Manoj is talking here about a way to do statistical inference with chemistry!  His talk is called &#8216;Statistical inference with a chemical soup&#8217;:</p>
<blockquote><p>
  <b>Abstract.</b> The goal is to design an “intelligent chemical soup” that can do statistical inference. This may have niche technological applications in medicine and biological research, as well as provide fundamental insight into the workings of biochemical reaction pathways. As a first step towards our goal, we describe a scheme that exploits the remarkable mathematical similarity between log-linear models in statistics and chemical reaction networks. We present a simple scheme that encodes the information in a log-linear model as a chemical reaction network. Observed data is encoded as initial concentrations, and the equilibria of the corresponding mass-action system yield the maximum likelihood estimators. The simplicity of our scheme suggests that molecular environments, especially within cells, may be particularly well suited to performing statistical computations.
</p></blockquote>
<p>It&#8217;s based on this paper:</p>
<p>&bull; Manoj Gopalkrishnan, <a href="http://arxiv.org/abs/1506.03172">A scheme for molecular computation of maximum likelihood estimators for log-linear models</a>.</p>
<p>I&#8217;m not sure, but this idea may exploit existing analogies between the approach to equilibrium in chemistry, the approach to equilibrium in evolutionary game theory, and statistical inference.  You may have read <a href="https://johncarlosbaez.wordpress.com/2014/01/22/relative-entropy-in-evolutionary-dynamics/">Marc Harper&#8217;s post</a> about that stuff!</p>
<p>David Doty is giving a broader review of &#8216;Computation by (not about) chemistry&#8217;:</p>
<blockquote><p>
<b>Abstract.</b> The model of chemical reaction networks (CRNs) is extensively used throughout the natural sciences as a descriptive language for existing chemicals. If we instead think of CRNs as a programming language for describing artificially engineered chemicals, what sorts of computations are possible for these chemicals to achieve? The answer depends crucially on several formal choices:</p>
<p>1) Do we treat matter as infinitely divisible (real-valued concentrations) or atomic (integer-valued counts)?</p>
<p>2) How do we represent the input and output of the computation (e.g., Boolean presence or absence of species, positive numbers directly represented by counts/concentrations, positive and negative numbers represented indirectly by the difference between counts/concentrations of a pair of species)?</p>
<p>3) Do we assume mass-action rate laws (reaction rates proportional to reactant counts/concentrations) or do we insist the system works correctly under a broader class of rate laws? </p>
<p>The talk will survey several recent results and techniques. A primary goal of the talk is to convey the &#8220;programming perspective&#8221;: rather than asking &#8220;What does chemistry do?&#8221;, we want to understand &#8220;What could chemistry do?&#8221; as well as &#8220;What can chemistry provably not do?&#8221;
</p></blockquote>
<p>I&#8217;m really interested in chemical reaction networks that appear in biological systems, and there will be lots of talks about that.  For example, Ovidiu Radulescu will talk about &#8216;Taming the complexity of biochemical networks through model reduction and tropical geometry&#8217;.  Model reduction is the process of simplifying complicated models while preserving at least some of their good features.  <a href="https://en.wikipedia.org/wiki/Tropical_geometry">Tropical geometry</a> is a cool version of algebraic geometry that uses the real numbers with <em>minimization</em> as addition and <em>addition</em> as multiplication.  This number system underlies the principle of least action, or the principle of maximum energy.  Here is Radulescu&#8217;s abstract:</p>
<blockquote><p>
<b>Abstract.</b> Biochemical networks are used as models of cellular physiology with diverse applications in biology and medicine. In the absence of objective criteria to detect essential features and prune secondary details, networks generated from data are too big and therefore out of the applicability of many mathematical tools for studying their dynamics and behavior under perturbations. However, under circumstances that we can generically denote by multi-scaleness, large biochemical networks can be approximated by smaller and simpler networks. Model reduction is a way to find these simpler models that can be more easily analyzed. We discuss several model reduction methods for biochemical networks with polynomial or rational rate functions and propose as their common denominator the notion of tropical equilibration, meaning finite intersection of tropical varieties in algebraic geometry. Using tropical methods, one can strongly reduce the number of variables and parameters of biochemical network. For multi-scale networks, these reductions are computed symbolically on orders of magnitude of parameters and variables, and are valid in wide domains of parameter and phase spaces.
</p></blockquote>
<p>I&#8217;m talking about the analogy between probabilities and quantum amplitudes, and how this makes chemistry analogous to particle physics.  You can see two versions of my talk here, but I&#8217;ll be giving the &#8216;more advanced&#8217; version, which is new:</p>
<p>&bull; <a href="http://math.ucr.edu/home/baez/prob/">Probabilities versus amplitudes</a>.</p>
<blockquote><p>
  <strong>Abstract.</strong> Some ideas from quantum theory are just beginning to percolate back to classical probability theory. For example, the master equation for a chemical reaction network describes the interactions of molecules in a stochastic rather than quantum way. If we look at it from the perspective of quantum theory, this formalism turns out to involve creation and annihilation operators, coherent states and other well-known ideas&#8212;but with a few big differences.
</p></blockquote>
<p>Anyway, there are a lot more talks, but if I don&#8217;t have breakfast and walk over to the math department, I&#8217;ll miss those talks!</p>
<p>You can learn more about individual talks in the comments here (see below) and also in Matteo Polettini&#8217;s blog:</p>
<p>&bull; Matteo Polettini, <a href="https://tomate.wordpress.com/2015/07/01/mathematical-trends-in-reaction-network-theory-in-copenhagen-1/">Mathematical trends in reaction network theory: part 1</a> and <a href="https://tomate.wordpress.com/2015/07/02/mathematical-trends-in-reaction-network-theory-in-copenhagen-2/">part 2</a>, <i>Out of Equilibrium</i>, 1 July 2015.</p>
<div align="center">
<img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/networks/pictures/feynman_diagram_hydrogen.png" />
</div>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2015/07/01/trends-in-reaction-network-theory-part-2/#comments">43 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/biology/" rel="category tag">biology</a>, <a href="https://johncarlosbaez.wordpress.com/category/chemistry/" rel="category tag">chemistry</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/networks/" rel="category tag">networks</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2015/07/01/trends-in-reaction-network-theory-part-2/" rel="bookmark" title="Permanent Link to Trends in Reaction Network Theory (Part&nbsp;2)">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-19631 post type-post status-publish format-standard hentry category-mathematics category-networks category-physics" id="post-19631">
				<h2><a href="https://johncarlosbaez.wordpress.com/2015/04/28/a-compositional-framework-for-passive-linear-networks/" rel="bookmark">A Compositional Framework for Passive Linear&nbsp;Networks</a></h2>
				<small>28 April, 2015</small><br />


				<div class="entry">
					<p>Here&#8217;s a new paper on network theory:</p>
<p>• John Baez and Brendan Fong, <a href="http://arxiv.org/abs/1504.05625">A compositional framework for passive linear networks</a>, <i><a href="http://www.tac.mta.ca/tac/volumes/33/38/33-38abs.html">Theory and Applications of Categories</a></i> <b>33</b> (2018), 1158–1222.</p>
<p>While <a href="https://johncarlosbaez.wordpress.com/2015/04/23/categories-in-control-2/"> my paper with Jason Erbele</a> studies <i>signal flow diagrams</i>, this one focuses on <i>circuit diagrams</i>.  The two are different, but closely related.</p>
<p>I&#8217;ll explain their relation at the <a href="https://johncarlosbaez.wordpress.com/2015/04/04/categorical-foundations-of-network-theory/">Turin workshop</a> in May.  For now, let me just talk about this paper with Brendan.  There&#8217;s a lot in here, but let me just try to explain the main result.  It&#8217;s all about &#8216;black boxing&#8217;: hiding the details of a circuit and only remembering its behavior as seen from outside.</p>
<h3> The idea</h3>
<p>In late 1940s, just as Feynman was developing his diagrams for processes in particle physics, Eilenberg and Mac Lane initiated their work on category theory.  Over the subsequent decades, and especially in the work of Joyal and Street in the 1980s, it became clear that these developments were profoundly linked: monoidal categories have a precise graphical representation in terms of string diagrams, and conversely monoidal categories provide an algebraic foundation for the intuitions behind Feynman diagrams.  The key insight is the use of categories where morphisms describe physical processes, rather than structure-preserving maps between mathematical objects.</p>
<p>In work on fundamental physics, the cutting edge has moved from categories to higher categories.  But the same techniques have filtered into more immediate applications, particularly in computation and quantum computation.   Our paper is part of a new program of applying string diagrams to engineering, with the aim of giving diverse diagram languages a unified foundation based on category theory.</p>
<p>Indeed, even before physicists began using Feynman diagrams, various branches of engineering were using diagrams that in retrospect are closely related.   Foremost among these are the ubiquitous electrical circuit diagrams. Although less well-known, similar diagrams are used to describe networks consisting of mechanical, hydraulic, thermodynamic and chemical systems.   Further work, pioneered in particular by <a href="http://en.wikipedia.org/wiki/Jay_Wright_Forrester">Forrester</a> and <a href="http://en.wikipedia.org/wiki/Howard_T._Odum">Odum</a>, applies similar diagrammatic methods to biology, ecology, and economics.</p>
<p>As discussed in detail by <a href="https://archive.org/details/DynamicalAnalogies">Olsen</a>, <a href="http://en.wikipedia.org/wiki/Henry_Paynter">Paynter</a> and others, there are mathematically precise analogies between these different systems.  In each case, the system&#8217;s state is described by variables that come in pairs, with one variable in each pair playing the role of  &#8216;displacement&#8217; and the other playing the role of &#8216;momentum&#8217;.  In engineering, the time derivatives of these variables are sometimes called &#8216;flow&#8217; and &#8216;effort&#8217;.</p>
<table border="1" align="center">
<tbody>
<tr>
<td></td>
<td><b>displacement</b>: &nbsp;&nbsp; <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /></td>
<td><b>flow</b>: &nbsp; &nbsp;&nbsp; <img src="https://s0.wp.com/latex.php?latex=%5Cdot+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;dot q" class="latex" /></td>
<td><b>momentum</b>: &nbsp;&nbsp;&nbsp;&nbsp; <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /></td>
<td><b>effort</b>: &nbsp; &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; <img src="https://s0.wp.com/latex.php?latex=%5Cdot+p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;dot p" class="latex" /></td>
</tr>
<tr>
<td><b>Mechanics: translation</b></td>
<td> position</td>
<td> velocity</td>
<td> momentum</td>
<td> force</td>
</tr>
<tr>
<td><b>Mechanics: rotation</b></td>
<td> angle</td>
<td> angular velocity</td>
<td> angular momentum</td>
<td> torque</td>
</tr>
<tr>
<td><b>Electronics</b></td>
<td> charge</td>
<td> current</td>
<td> flux linkage</td>
<td> voltage</td>
</tr>
<tr>
<td><b>Hydraulics</b></td>
<td> volume</td>
<td> flow</td>
<td> pressure momentum</td>
<td> pressure</td>
</tr>
<tr>
<td><b>Thermal Physics</b></td>
<td> entropy</td>
<td> entropy flow</td>
<td> temperature momentum</td>
<td> temperature</td>
</tr>
<tr>
<td><b>Chemistry</b></td>
<td> moles</td>
<td> molar flow</td>
<td> chemical momentum</td>
<td> chemical potential</td>
</tr>
</tbody>
</table>
<p>In classical mechanics, this pairing of variables is well understood using <a href="http://en.wikipedia.org/wiki/Symplectic_geometry">symplectic geometry</a>.  Thus, any mathematical formulation of the diagrams used to describe networks in engineering needs to take symplectic geometry as well as category theory into account.</p>
<p>While diagrams of networks have been independently introduced in many disciplines, we do not expect formalizing these diagrams to immediately help the practitioners of these disciplines.  At first the flow of information will mainly go in the other direction: by translating ideas from these disciplines into the language of modern mathematics, we can provide mathematicians with food for thought and interesting new problems to solve.  We hope that in the long run mathematicians can return the favor by bringing new insights to the table.</p>
<p>Although we keep the broad applicability of network diagrams in the back of our minds, our paper talks in terms of electrical circuits, for the sake of familiarity.  We also consider a somewhat limited class of circuits.  We only study circuits built from &#8216;passive&#8217; components: that is, those that do not produce energy.  Thus, we exclude batteries and current sources.  We only consider components that respond linearly to an applied voltage.   Thus, we exclude components such as nonlinear resistors or diodes.  Finally, we only consider components with one input and one output, so that a circuit can be described as a graph with edges labeled by components.  Thus, we also exclude transformers.  The most familiar components our framework covers are linear resistors, capacitors and inductors.</p>
<p>While we want to expand our scope in future work, the class of circuits made from these components has appealing mathematical properties, and is worthy of deep study.  Indeed, these circuits has been studied intensively for many decades by electrical engineers.  Even circuits made exclusively of resistors have inspired work by mathematicians of the caliber of <a href="http://math.ucr.edu/home/baez/weyl1923.pdf">Weyl</a> and <a href="https://projecteuclid.org/euclid.jdg/1214430827">Smale</a>!</p>
<p>Our work relies on this research.  All we are adding is an emphasis on symplectic geometry and an explicitly &#8216;compositional&#8217; framework, which clarifies the way a larger circuit can be built from smaller pieces.  This is where monoidal categories become important: the main operations for building circuits from pieces are composition and tensoring.</p>
<p>Our strategy is most easily illustrated for circuits made of linear resistors.  Such a resistor dissipates power, turning useful energy into heat at a rate determined by the voltage across the resistor.  However, a remarkable fact is that a circuit made of these resistors always acts to <i>minimize</i> the power dissipated this way.  This &#8216;principle of minimum power&#8217; can be seen as the reason symplectic geometry becomes important in understanding circuits made of resistors, just as the principle of least action leads to the role of symplectic geometry in classical mechanics.</p>
<p>Here is a circuit made of linear resistors:</p>
<div align="center">
<img src="https://i2.wp.com/math.ucr.edu/home/baez/networks/circuits/circuit.jpg" width="450" /></div>
<p>The wiggly lines are resistors, and their resistances are written beside them: for example, <img src="https://s0.wp.com/latex.php?latex=3%5COmega&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="3&#92;Omega" class="latex" /> means 3 ohms, an &#8216;ohm&#8217; being a unit of resistance.  To formalize this, define a circuit of linear resistors to consist of:</p>
<p>• a set <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> of <b>nodes</b>,<br />
• a set <img src="https://s0.wp.com/latex.php?latex=E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E" class="latex" /> of <b>edges</b>,<br />
• maps <img src="https://s0.wp.com/latex.php?latex=s%2Ct+%3A+E+%5Cto+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s,t : E &#92;to N" class="latex" /> sending each edge to its <b>source</b> and <b>target</b> node,<br />
• a map <img src="https://s0.wp.com/latex.php?latex=r%3A+E+%5Cto+%280%2C%5Cinfty%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r: E &#92;to (0,&#92;infty)" class="latex" /> specifying the <b>resistance</b> of the resistor<br />
labelling each edge,<br />
• maps <img src="https://s0.wp.com/latex.php?latex=i+%3A+X+%5Cto+N%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i : X &#92;to N," class="latex" /> <img src="https://s0.wp.com/latex.php?latex=o+%3A+Y+%5Cto+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="o : Y &#92;to N" class="latex" /> specifying the <b>inputs</b> and outputs of the circuit.</p>
<p>When we run electric current through such a circuit, each node <img src="https://s0.wp.com/latex.php?latex=n+%5Cin+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n &#92;in N" class="latex" /> gets a <b>potential</b> <img src="https://s0.wp.com/latex.php?latex=%5Cphi%28n%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi(n)." class="latex" />  The <b>voltage</b> across an edge <img src="https://s0.wp.com/latex.php?latex=e+%5Cin+E&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="e &#92;in E" class="latex" /> is defined as the change in potential as we move from to the source of <img src="https://s0.wp.com/latex.php?latex=e&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="e" class="latex" /> to its target, <img src="https://s0.wp.com/latex.php?latex=%5Cphi%28t%28e%29%29+-+%5Cphi%28s%28e%29%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi(t(e)) - &#92;phi(s(e))." class="latex" />  The <b>power</b> dissipated by the resistor on this edge is then</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7B1%7D%7Br%28e%29%7D%5Cbig%28%5Cphi%28t%28e%29%29-%5Cphi%28s%28e%29%29%5Cbig%29%5E2+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{1}{r(e)}&#92;big(&#92;phi(t(e))-&#92;phi(s(e))&#92;big)^2 }" class="latex" /></p>
<p>The total power dissipated by the circuit is therefore twice</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28%5Cphi%29+%3D+%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Be+%5Cin+E%7D+%5Cfrac%7B1%7D%7Br%28e%29%7D%5Cbig%28%5Cphi%28t%28e%29%29-%5Cphi%28s%28e%29%29%5Cbig%29%5E2+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(&#92;phi) = &#92;frac{1}{2}&#92;sum_{e &#92;in E} &#92;frac{1}{r(e)}&#92;big(&#92;phi(t(e))-&#92;phi(s(e))&#92;big)^2 }" class="latex" /></p>
<p>The factor of <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B2%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;frac{1}{2}" class="latex" /> is convenient in some later calculations.</p>
<p>Note that <img src="https://s0.wp.com/latex.php?latex=P&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P" class="latex" /> is a nonnegative quadratic form on the vector space <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5EN.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}^N." class="latex" />  However, not every nonnegative definite quadratic form on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5EN&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}^N" class="latex" /> arises in this way from some circuit of linear resistors with <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> as its set of nodes.  The quadratic forms that do arise are called <b>Dirichlet forms</b>.  They have been extensively investigated, and they play a major role in our work.</p>
<p>We write</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpartial+N+%3D+i%28X%29+%5Ccup+o%28Y%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial N = i(X) &#92;cup o(Y)" class="latex" /></p>
<p>for the set of <b>terminals</b>: that is, nodes corresponding to inputs or outputs.  The principle of minimum power says that if we fix the potential at the terminals, the circuit will choose the potential at other nodes to minimize the total power dissipated.    An element <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> of the vector space <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E%7B%5Cpartial+N%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}^{&#92;partial N}" class="latex" /> assigns a potential to each terminal.   Thus, if we fix <img src="https://s0.wp.com/latex.php?latex=%5Cpsi%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi," class="latex" /> the total power dissipated will be twice</p>
<p><img src="https://s0.wp.com/latex.php?latex=Q%28%5Cpsi%29+%3D+%5Cmin_%7B%5Csubstack%7B+%5Cphi+%5Cin+%5Cmathbb%7BR%7D%5EN+%5C%5C+%5Cphi%5Cvert_%7B%5Cpartial+N%7D+%3D+%5Cpsi%7D%7D+%5C%3B+P%28%5Cphi%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q(&#92;psi) = &#92;min_{&#92;substack{ &#92;phi &#92;in &#92;mathbb{R}^N &#92;&#92; &#92;phi&#92;vert_{&#92;partial N} = &#92;psi}} &#92;; P(&#92;phi)" class="latex" /></p>
<p>The function <img src="https://s0.wp.com/latex.php?latex=Q+%3A+%5Cmathbb%7BR%7D%5E%7B%5Cpartial+N%7D+%5Cto+%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q : &#92;mathbb{R}^{&#92;partial N} &#92;to &#92;mathbb{R}" class="latex" /> is again a Dirichlet form.  We call it the <b>power functional</b> of the circuit.</p>
<p>Now, suppose we are unable to see the internal workings of a circuit, and can only observe its &#8216;external behavior&#8217;: that is, the potentials at its terminals and the currents flowing into or out of these terminals.   Remarkably, this behavior is completely determined by the power functional <img src="https://s0.wp.com/latex.php?latex=Q.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q." class="latex" />  The reason is that the current at any terminal can be obtained by differentiating <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> with respect to the potential at this terminal, and relations of this form are <i>all</i> the relations that hold between potentials and currents at the terminals.</p>
<p>The Laplace transform allows us to generalize this immediately to circuits that can also contain linear inductors and capacitors, simply by changing the field we work over, replacing <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}" class="latex" /> by the field <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%28s%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}(s)" class="latex" /> of rational functions of a single real variable, and talking of <b>impedance</b> where we previously talked of resistance.  We obtain a category <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BCirc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{Circ}" class="latex" /> where an object is a finite set, a morphism <img src="https://s0.wp.com/latex.php?latex=f+%3A+X+%5Cto+Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f : X &#92;to Y" class="latex" /> is a circuit with input set <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> and output set <img src="https://s0.wp.com/latex.php?latex=Y%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y," class="latex" /> and composition is given by identifying the outputs of one circuit with the inputs of the next, and taking the resulting union of labelled graphs.  Each such circuit gives rise to a Dirichlet form, now defined over <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%28s%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{R}(s)," class="latex" /> and this Dirichlet form completely describes the externally observable behavior of the circuit.</p>
<p>We can take equivalence classes of circuits, where two circuits count as the same if they have the same Dirichlet form.  We wish for these equivalence classes of circuits to form a category. Although there is a notion of composition for Dirichlet forms, we find that it lacks identity morphisms or, equivalently, it lacks morphisms representing ideal wires of zero impedance. To address this we turn to <a href="http://en.wikipedia.org/wiki/Symplectic_vector_space#Subspaces">Lagrangian subspaces</a> of <a href="http://en.wikipedia.org/wiki/Symplectic_vector_space">symplectic vector spaces</a>.  These generalize quadratic forms via the map</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CBig%28Q%3A+%5Cmathbb%7BF%7D%5E%7B%5Cpartial+N%7D+%5Cto+%5Cmathbb%7BF%7D%5CBig%29+%5Clongmapsto+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Big(Q: &#92;mathbb{F}^{&#92;partial N} &#92;to &#92;mathbb{F}&#92;Big) &#92;longmapsto " class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BGraph%7D%28dQ%29+%3D++%5C%7B%28%5Cpsi%2C+dQ_%5Cpsi%29+%5Cmid+%5Cpsi+%5Cin+%5Cmathbb%7BF%7D%5E%7B%5Cpartial+N%7D+%5C%7D+%5C%3B+%5Csubseteq+%5C%3B+%5Cmathbb%7BF%7D%5E%7B%5Cpartial+N%7D+%5Coplus+%28%5Cmathbb%7BF%7D%5E%7B%5Cpartial+N%7D%29%5E%5Cast+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{Graph}(dQ) =  &#92;{(&#92;psi, dQ_&#92;psi) &#92;mid &#92;psi &#92;in &#92;mathbb{F}^{&#92;partial N} &#92;} &#92;; &#92;subseteq &#92;; &#92;mathbb{F}^{&#92;partial N} &#92;oplus (&#92;mathbb{F}^{&#92;partial N})^&#92;ast " class="latex" /></p>
<p>taking a quadratic form <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> on the vector space <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D%5E%7B%5Cpartial+N%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{F}^{&#92;partial N}" class="latex" /> over the field <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{F}" class="latex" /> to the graph of its differential <img src="https://s0.wp.com/latex.php?latex=dQ.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="dQ." class="latex" /> Here we think of the symplectic vector space <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D%5E%7B%5Cpartial+N%7D+%5Coplus+%28%5Cmathbb%7BF%7D%5E%7B%5Cpartial+N%7D%29%5E%5Cast&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{F}^{&#92;partial N} &#92;oplus (&#92;mathbb{F}^{&#92;partial N})^&#92;ast" class="latex" /> as the state space of the circuit, and the subspace <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BGraph%7D%28dQ%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{Graph}(dQ)" class="latex" /> as the subspace of attainable states, with <img src="https://s0.wp.com/latex.php?latex=%5Cpsi+%5Cin+%5Cmathbb%7BF%7D%5E%7B%5Cpartial+N%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi &#92;in &#92;mathbb{F}^{&#92;partial N}" class="latex" /> describing the potentials at the terminals, and <img src="https://s0.wp.com/latex.php?latex=dQ_%5Cpsi+%5Cin+%28%5Cmathbb%7BF%7D%5E%7B%5Cpartial+N%7D%29%5E%5Cast&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="dQ_&#92;psi &#92;in (&#92;mathbb{F}^{&#92;partial N})^&#92;ast" class="latex" /> the currents.</p>
<p>This construction is well-known in classical mechanics, where the principle of least action plays a role analogous to that of the principle of minimum power here.   The set of Lagrangian subspaces is actually an algebraic variety, the <b><a href="http://en.wikipedia.org/wiki/Lagrangian_Grassmannian">Lagrangian Grassmannian</a></b>, which serves as a compactification of the space of quadratic forms.  The Lagrangian Grassmannian has already played a role in <a href="http://arxiv.org/abs/math-ph/0304015">Sabot&#8217;s work</a> on circuits made of resistors. For us, its importance it that we can find identity morphisms for the composition of Dirichlet forms by taking circuits made of parallel resistors and letting their resistances tend to zero: the limit is not a Dirichlet form, but it exists in the Lagrangian Grassmannian.</p>
<p>Indeed, there exists a category <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BLagrRel%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{LagrRel}" class="latex" /> with finite dimensional symplectic vector spaces as objects and <b>Lagrangian relations</b> as morphisms: that is, linear relations from <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=W&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="W" class="latex" /> that are given by Lagrangian subspaces of <img src="https://s0.wp.com/latex.php?latex=%5Coverline%7BV%7D+%5Coplus+W%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;overline{V} &#92;oplus W," class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%5Coverline%7BV%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;overline{V}" class="latex" /> is the symplectic vector space <b>conjugate</b> to <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V" class="latex" />&#8212;that is, with the sign of the symplectic structure switched.</p>
<p>To move from the Lagrangian subspace defined by the graph of the differential of the power functional to a morphism in the category <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BLagrRel%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{LagrRel}" class="latex" />&#8212;that is, to a Lagrangian relation&#8212; we must treat seriously the input and output functions of the circuit. These express the circuit as built upon a <a href="http://ncatlab.org/nlab/show/cospan">cospan</a>:</p>
<div align="center">
<img src="https://i1.wp.com/math.ucr.edu/home/baez/networks/circuits/cospan.jpg" /></div>
<p>Applicable far more broadly than this present formalization of circuits, cospans model systems with two &#8216;ends&#8217;, an input and output end, albeit without any connotation of directionality: we might just as well exchange the role of the inputs and outputs by taking the mirror image of the above diagram. The role of the input and output functions, as we have discussed, is to mark the terminals we may glue onto the terminals of another circuit, and the pushout of cospans gives formal precision to this gluing construction.</p>
<p>One upshot of this cospan framework is that we may consider circuits with elements of <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> that are both inputs and outputs, such as this one:</p>
<div align="center">
<img src="https://i2.wp.com/math.ucr.edu/home/baez/networks/circuits/identity_circuit.jpg" /></div>
<p>This corresponds to the identity morphism on the finite set with two elements. Another is that some points may be considered an input or output multiple times, like here:</p>
<div align="center">
<img src="https://i1.wp.com/math.ucr.edu/home/baez/networks/circuits/degenerate_circuit.jpg" /></div>
<p>This lets to connect two distinct outputs to the above double input.</p>
<p>Given a set <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> of inputs or outputs, we understand the electrical behavior on this set  by considering the symplectic vector space <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D%5EX+%5Coplus+%7B%28%5Cmathbb%7BF%7D%5EX%29%7D%5E%5Cast%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{F}^X &#92;oplus {(&#92;mathbb{F}^X)}^&#92;ast," class="latex" /> the direct sum of the space <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D%5EX&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{F}^X" class="latex" /> of potentials and the space <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cmathbb%7BF%7D%5EX%29%7D%5E%5Cast&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="{(&#92;mathbb{F}^X)}^&#92;ast" class="latex" /> of currents at these points. A Lagrangian relation specifies which states of the output space <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D%5EY+%5Coplus+%7B%28%5Cmathbb%7BF%7D%5EY%29%7D%5E%5Cast&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{F}^Y &#92;oplus {(&#92;mathbb{F}^Y)}^&#92;ast" class="latex" /> are allowed for each state of the input space <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D%5EX+%5Coplus+%7B%28%5Cmathbb%7BF%7D%5EX%29%7D%5E%5Cast.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{F}^X &#92;oplus {(&#92;mathbb{F}^X)}^&#92;ast." class="latex" /> Turning the Lagrangian subspace <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BGraph%7D%28dQ%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{Graph}(dQ)" class="latex" /> of a circuit into this information requires that we understand the &#8216;symplectification&#8217;</p>
<p><img src="https://s0.wp.com/latex.php?latex=Sf%3A+%5Cmathbb%7BF%7D%5EB+%5Coplus+%7B%28%5Cmathbb%7BF%7D%5EB%29%7D%5E%5Cast+%5Cto+%5Cmathbb%7BF%7D%5EA+%5Coplus+%7B%28%5Cmathbb%7BF%7D%5EA%29%7D%5E%5Cast&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Sf: &#92;mathbb{F}^B &#92;oplus {(&#92;mathbb{F}^B)}^&#92;ast &#92;to &#92;mathbb{F}^A &#92;oplus {(&#92;mathbb{F}^A)}^&#92;ast" class="latex" /></p>
<p>and &#8216;twisted symplectification&#8217;</p>
<p><img src="https://s0.wp.com/latex.php?latex=S%5Etf%3A+%5Cmathbb%7BF%7D%5EB+%5Coplus+%7B%28%5Cmathbb%7BF%7D%5EB%29%7D%5E%5Cast+%5Cto+%5Coverline%7B%5Cmathbb%7BF%7D%5EA+%5Coplus+%7B%28%5Cmathbb%7BF%7D%5EA%29%7D%5E%5Cast%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S^tf: &#92;mathbb{F}^B &#92;oplus {(&#92;mathbb{F}^B)}^&#92;ast &#92;to &#92;overline{&#92;mathbb{F}^A &#92;oplus {(&#92;mathbb{F}^A)}^&#92;ast}" class="latex" /></p>
<p>of a function <img src="https://s0.wp.com/latex.php?latex=f%3A+A+%5Cto+B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f: A &#92;to B" class="latex" /> between finite sets. In particular we need to understand how these apply to the input and output functions with codomain restricted to <img src="https://s0.wp.com/latex.php?latex=%5Cpartial+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial N" class="latex" />; abusing notation, we also write these <img src="https://s0.wp.com/latex.php?latex=i%3A+X+%5Cto+%5Cpartial+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i: X &#92;to &#92;partial N" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=o%3A+Y+%5Cto+%5Cpartial+N.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="o: Y &#92;to &#92;partial N." class="latex" /></p>
<p>The <b>symplectification</b> <img src="https://s0.wp.com/latex.php?latex=Sf&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Sf" class="latex" /> is a Lagrangian relation, and the catch phrase is that it &#8216;copies voltages&#8217; and &#8216;splits currents&#8217;. More precisely, for any given potential-current pair <img src="https://s0.wp.com/latex.php?latex=%28%5Cpsi%2C%5Ciota%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;psi,&#92;iota)" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D%5EB+%5Coplus+%7B%28%5Cmathbb%7BF%7D%5EB%29%7D%5E%5Cast%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{F}^B &#92;oplus {(&#92;mathbb{F}^B)}^&#92;ast," class="latex" /> its image under <img src="https://s0.wp.com/latex.php?latex=Sf&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Sf" class="latex" /> consists of all elements of <img src="https://s0.wp.com/latex.php?latex=%28%5Cpsi%27%2C+%5Ciota%27%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(&#92;psi&#039;, &#92;iota&#039;)" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D%5EA+%5Coplus+%7B%28%5Cmathbb%7BF%7D%5EA%29%7D%5E%5Cast&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{F}^A &#92;oplus {(&#92;mathbb{F}^A)}^&#92;ast" class="latex" />  such that the potential at <img src="https://s0.wp.com/latex.php?latex=a+%5Cin+A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a &#92;in A" class="latex" /> is equal to the potential at <img src="https://s0.wp.com/latex.php?latex=f%28a%29+%5Cin+B%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(a) &#92;in B," class="latex" /> and such that, for each fixed <img src="https://s0.wp.com/latex.php?latex=b+%5Cin+B%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="b &#92;in B," class="latex" /> collectively the currents at the <img src="https://s0.wp.com/latex.php?latex=a+%5Cin+f%5E%7B-1%7D%28b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a &#92;in f^{-1}(b)" class="latex" /> sum to the current at <img src="https://s0.wp.com/latex.php?latex=b.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="b." class="latex" />  We use the symplectification <img src="https://s0.wp.com/latex.php?latex=So&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="So" class="latex" /> of the output function to relate the state on <img src="https://s0.wp.com/latex.php?latex=%5Cpartial+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial N" class="latex" /> to that on the outputs <img src="https://s0.wp.com/latex.php?latex=Y.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y." class="latex" /></p>
<p>As our current framework is set up to report the current <i>out</i> of each node, to describe input currents we define the <b>twisted symplectification</b>:</p>
<p><img src="https://s0.wp.com/latex.php?latex=S%5Etf%3A+%5Cmathbb%7BF%7D%5EB+%5Coplus+%7B%28%5Cmathbb%7BF%7D%5EB%29%7D%5E%5Cast+%5Cto+%5Coverline%7B%5Cmathbb%7BF%7D%5EA+%5Coplus+%7B%28%5Cmathbb%7BF%7D%5EA%29%7D%5E%5Cast%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S^tf: &#92;mathbb{F}^B &#92;oplus {(&#92;mathbb{F}^B)}^&#92;ast &#92;to &#92;overline{&#92;mathbb{F}^A &#92;oplus {(&#92;mathbb{F}^A)}^&#92;ast}" class="latex" /></p>
<p>almost identically to the above, except that we flip the sign of the currents <img src="https://s0.wp.com/latex.php?latex=%5Ciota%27+%5Cin+%28%5Cmathbb%7BF%7D%5EA%29%5E%5Cast.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;iota&#039; &#92;in (&#92;mathbb{F}^A)^&#92;ast." class="latex" />  This again gives a Lagrangian relation. We use the twisted symplectification <img src="https://s0.wp.com/latex.php?latex=S%5Eti&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S^ti" class="latex" /> of the input function to relate the state on <img src="https://s0.wp.com/latex.php?latex=%5Cpartial+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;partial N" class="latex" /> to that on the inputs.</p>
<p>The Lagrangian relation corresponding to a circuit then comprises exactly a list of the potential-current pairs that are possible electrical states of the inputs and outputs of the circuit. In doing so, it identifies distinct circuits.  A simple example of this is the identification of a single 2-ohm resistor:</p>
<div align="center">
<img src="https://i2.wp.com/math.ucr.edu/home/baez/networks/circuits/one-resistor_circuit.jpg" width="350" /></div>
<p>with two 1-ohm resistors in series:</p>
<div align="center">
<img src="https://i2.wp.com/math.ucr.edu/home/baez/networks/circuits/two-resistor_circuit.jpg" width="450" /></div>
<p>Our inability to access the internal workings of a circuit in this representation inspires us to call this process <b>black boxing</b>: you should imagine encasing the circuit in an opaque black box, leaving only the terminals accessible. Fortunately, this information is enough to completely characterize the external behavior of a circuit, including how it interacts when connected with other circuits!</p>
<p>Put more precisely, the black boxing process is <i>functorial</i>: we can  compute the black-boxed version of a circuit made of parts by computing the black-boxed versions of the parts and then composing them.   In fact we shall  prove that <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BCirc%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{Circ}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BLagrRel%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{LagrRel}" class="latex" /> are dagger compact categories, and the black box functor preserves all this extra structure:</p>
<p><b>Theorem.</b> There exists a symmetric monoidal dagger functor, the <b>black box functor</b></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cblacksquare%3A+%5Cmathrm%7BCirc%7D+%5Cto+%5Cmathrm%7BLagrRel%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;blacksquare: &#92;mathrm{Circ} &#92;to &#92;mathrm{LagrRel}" class="latex" /></p>
<p>mapping a finite set <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" /> to the symplectic vector space <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D%5EX+%5Coplus+%28%5Cmathbb%7BF%7D%5EX%29%5E%5Cast&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathbb{F}^X &#92;oplus (&#92;mathbb{F}^X)^&#92;ast" class="latex" /> it generates, and a circuit <img src="https://s0.wp.com/latex.php?latex=%5Cbig%28%28N%2CE%2Cs%2Ct%2Cr%29%2Ci%2Co%5Cbig%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;big((N,E,s,t,r),i,o&#92;big)" class="latex" /> to the Lagrangian relation</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbigcup_%7Bv+%5Cin+%5Cmathrm%7BGraph%7D%28dQ%29%7D+S%5Eti%28v%29+%5Ctimes+So%28v%29++%5Csubseteq+%5Coverline%7B%5Cmathbb%7BF%7D%5EX+%5Coplus+%28%5Cmathbb%7BF%7D%5EX%29%5E%5Cast%7D+%5Coplus+%5Cmathbb%7BF%7D%5EY+%5Coplus+%28%5Cmathbb%7BF%7D%5EY%29%5E%5Cast&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;bigcup_{v &#92;in &#92;mathrm{Graph}(dQ)} S^ti(v) &#92;times So(v)  &#92;subseteq &#92;overline{&#92;mathbb{F}^X &#92;oplus (&#92;mathbb{F}^X)^&#92;ast} &#92;oplus &#92;mathbb{F}^Y &#92;oplus (&#92;mathbb{F}^Y)^&#92;ast" class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=Q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Q" class="latex" /> is the circuit&#8217;s power functional.</p>
<p>The goal of this paper is to prove and explain this result.  The proof is more tricky than one might first expect, but our approach involves concepts that should be useful throughout the study of networks, such as &#8216;decorated cospans&#8217; and &#8216;corelations&#8217;.</p>
<p>Give it a read, and let us know if you have questions or find mistakes!</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2015/04/28/a-compositional-framework-for-passive-linear-networks/#comments">48 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/networks/" rel="category tag">networks</a>, <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2015/04/28/a-compositional-framework-for-passive-linear-networks/" rel="bookmark" title="Permanent Link to A Compositional Framework for Passive Linear&nbsp;Networks">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-19443 post type-post status-publish format-standard hentry category-biology category-mathematics" id="post-19443">
				<h2><a href="https://johncarlosbaez.wordpress.com/2015/03/24/stationary-stability-in-finite-populations/" rel="bookmark">Stationary Stability in Finite&nbsp;Populations</a></h2>
				<small>24 March, 2015</small><br />


				<div class="entry">
					<p><i>guest post by <b><a href="http://www.marcharper.net/">Marc Harper</a></b></i></p>
<p>A while back, in the article <a href="https://johncarlosbaez.wordpress.com/2014/01/22/relative-entropy-in-evolutionary-dynamics/">Relative entropy minimization in evolutionary dynamics</a>, we looked at extensions of the information geometry / evolutionary game theory story to more general time-scales, incentives, and geometries. Today we&#8217;ll see how to make this all work in finite populations!</p>
<p>Let&#8217;s recall the basic idea from last time, which John also described in his <a href="https://johncarlosbaez.wordpress.com/2012/06/07/information-geometry-part-11/">information geometry</a> series. The main theorem is this: when there&#8217;s an evolutionarily stable state for a given fitness landscape, the relative entropy between the stable state and the population distribution decreases along the population trajectories as they converge to the stable state.  In short, relative entropy is a <a href="http://en.wikipedia.org/wiki/Lyapunov_function">Lyapunov function</a>.  This is a nice way to look at the action of a population under natural selection, and it has interesting analogies to Bayesian inference.</p>
<p>The replicator equation is a nice model from an intuitive viewpoint, and it&#8217;s mathematically elegant.  But it has some drawbacks when it comes to modeling real populations. One major issue is that the replicator equation implicitly assumes that the population proportions of each type are differentiable functions of time, obeying a differential equation.  This only makes sense in the limit of large populations.  Other closely related models, such as the <a href="https://en.wikipedia.org/wiki/Lotka-Volterra_equation">Lotka-Volterra</a> model, focus on the number of individuals of each type (e.g. predators and prey) instead of the proportion. But they often assume that the number of individuals is a differentiable function of time, and a population of 3.5 isn&#8217;t very realistic either.</p>
<p>Real populations of replicating entities are not infinitely large; in fact they are often relatively small and of course have whole numbers of each type, at least for large biological replicators (like animals). They take up space and only so many can interact meaningfully. There are quite a few models of evolution that handle finite populations and some predate the replicator equation. Models with more realistic assumptions typically have to leave the realm of derivatives and differential equations behind, which means that the analysis of such models is more difficult, but the behaviors of the models are often much more interesting. Hopefully by the end of this post, you&#8217;ll see how all of these diagrams fit together:</p>
<div align="center">
<p><img src="https://i1.wp.com/www.azimuthproject.org/azimuth/files/ga_phase.png" width="250" /><br />
<br />
<img src="https://i0.wp.com/www.azimuthproject.org/azimuth/files/ga_stationary.png" width="350" /><br />
<br />
<img src="https://i1.wp.com/www.azimuthproject.org/azimuth/files/ga_d_0.png" width="350" /><br />
<br />
<img src="https://i1.wp.com/www.azimuthproject.org/azimuth/files/ga_d_1.png" width="350" /><br />

</div>
<p>One of the best-known finite population models is the <a href="http://en.wikipedia.org/wiki/Moran_process">Moran process</a>, which is a <a href="https://en.wikipedia.org/wiki/Markov_chain">Markov chain</a> on a finite population.  This is the quintessential birth-death process. For a moment consider a population of just two types <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B." class="latex" /> The state of the population is given by a pair of nonnegative integers <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(a,b)" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=a%2Bb%3DN%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a+b=N," class="latex" /> the total number of replicators in the population, and <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="b" class="latex" /> the number of individuals of type <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B" class="latex" /> respectively. Though it may artificial to fix the population size <img src="https://s0.wp.com/latex.php?latex=N%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N," class="latex" /> this often turns out not to be that big of a deal, and you can assume the population is at its carrying capacity to make the assumption realistic. (Lots of people study populations that can change size and that have replicators spatially distributed say on a graph, but we&#8217;ll assume they can all interact with each whenever they want for now).</p>
<p>A Markov model works by transitioning from state to state in each round of the process, so we need to define the transitions probabilities to complete the model. Let&#8217;s put a fitness landscape on the population, given by two functions <img src="https://s0.wp.com/latex.php?latex=f_A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=f_B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_B" class="latex" /> of the population state <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(a,b)." class="latex" /> Now we choose an individual to reproduce proportionally to fitness, e.g. we choose an <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> individual to reproduce with probability</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Ba+f_A%7D%7Ba+f_A+%2B+b+f_B%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{a f_A}{a f_A + b f_B} }" class="latex" /></p>
<p>since there are <img src="https://s0.wp.com/latex.php?latex=a&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a" class="latex" /> individuals of type <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> and they each have fitness <img src="https://s0.wp.com/latex.php?latex=f_A.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_A." class="latex" /> This is analogous to the ratio of fitness to mean fitness from the discrete replicator equation, since</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Ba+f_A%7D%7Ba+f_A+%2B+b+f_B%7D+%3D++%5Cfrac%7B%5Cfrac%7Ba%7D%7BN%7D+f_A%7D%7B%5Cfrac%7Ba%7D%7BN%7D+f_A+%2B+%5Cfrac%7Bb%7D%7BN%7D+f_B%7D+%5Cto+%5Cfrac%7Bx_i+f_i%28x%29%7D%7B%5Coverline%7Bf%28x%29%7D%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{a f_A}{a f_A + b f_B} =  &#92;frac{&#92;frac{a}{N} f_A}{&#92;frac{a}{N} f_A + &#92;frac{b}{N} f_B} &#92;to &#92;frac{x_i f_i(x)}{&#92;overline{f(x)}} }" class="latex" /></p>
<p>and the discrete replicator equation is typically similar to the continuous replicator equation (this can be made precise), so the Moran process captures the idea of natural selection in a similar way. Actually there is a way to recover the replicator equation from the Moran process in large populations&#8212;details at the end!</p>
<p>We&#8217;ll assume that the fitnesses are nonnegative and that the total fitness (the denominator) is never zero; if that seems artificial, some people prefer to transform the fitness landscape by <img src="https://s0.wp.com/latex.php?latex=e%5E%7B%5Cbeta+f%28x%29%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="e^{&#92;beta f(x)}," class="latex" /> which gives a ratio reminiscent of the Boltzmann or Fermi  distribution from statistical physics, with the parameter <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> playing the role of <b>intensity of selection</b> rather than inverse temperature. This is sometimes called <b>Fermi selection</b>.</p>
<p>That takes care of the birth part. The death part is easier: we just choose an individual at random (uniformly) to be replaced. Now we can form the transition probabilities of moving between population states.  For instance the probability of moving from state <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(a,b)" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%28a%2B1%2C+b-1%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(a+1, b-1)" class="latex" /> is given by the product of the birth and death probabilities, since they are independent:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+T_a%5E%7Ba%2B1%7D+%3D+%5Cfrac%7Ba+f_A%7D%7Ba+f_A+%2B+b+f_B%7D+%5Cfrac%7Bb%7D%7BN%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ T_a^{a+1} = &#92;frac{a f_A}{a f_A + b f_B} &#92;frac{b}{N} } " class="latex" /></p>
<p>since we have to chose a replicator of type <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> to reproduce and one of type <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B" class="latex" /> to be replaced. Similarly for <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(a,b)" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%28a-1%2C+b%2B1%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(a-1, b+1)" class="latex" /> (switch all the a&#8217;s and b&#8217;s), and we can write the probability of staying in the state <img src="https://s0.wp.com/latex.php?latex=%28a%2C+N-a%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(a, N-a)" class="latex" /> as</p>
<p><img src="https://s0.wp.com/latex.php?latex=T_a%5E%7Ba%7D+%3D+1+-+T_%7Ba%7D%5E%7Ba%2B1%7D+-+T_%7Ba%7D%5E%7Ba-1%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T_a^{a} = 1 - T_{a}^{a+1} - T_{a}^{a-1} " class="latex" /></p>
<p>Since we only replace one individual at a time, this covers all the possible transitions, and keeps the population constant.</p>
<p>We&#8217;d like to analyze this model and many people have come up with clever ways to do so, computing quantities like <b>fixation probabilities</b> (also known as <b>absorption probabilities</b>), indicating the chance that the population will end up with one type completely dominating, i.e. in state <img src="https://s0.wp.com/latex.php?latex=%280%2C+N%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(0, N)" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=%28N%2C0%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(N,0)." class="latex" /> If we assume that the fitness of type <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> is constant and simply equal to 1, and the fitness of type <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=r+%5Cneq+1%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r &#92;neq 1," class="latex" /> we can calculate the probability that a single mutant of type <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B" class="latex" /> will take over a population of type <img src="https://s0.wp.com/latex.php?latex=A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A" class="latex" /> using standard Markov chain methods:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5Crho+%3D+%5Cfrac%7B1+-+r%5E%7B-1%7D%7D%7B1+-+r%5E%7B-N%7D%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;rho = &#92;frac{1 - r^{-1}}{1 - r^{-N}} }" class="latex" /></p>
<p>For neutral relative fitness (<img src="https://s0.wp.com/latex.php?latex=r%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r=1" class="latex" />), <img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D+1%2FN%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho = 1/N," class="latex" /> which is the probability a neutral mutant invades by drift alone since selection is neutral. Since the two boundary states <img src="https://s0.wp.com/latex.php?latex=%280%2C+N%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(0, N)" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=%28N%2C0%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(N,0)" class="latex" /> are absorbing (no transitions out), in the long run <i>every</i> population ends up in one of these two states, i.e. the population is homogeneous. (This is the formulation referred to by Matteo Smerlak in <a href="https://johncarlosbaez.wordpress.com/2012/10/08/the-mathematical-origin-of-irreversibility/">The mathematical origins of irreversibility</a>.)</p>
<p>That&#8217;s a bit different flavor of result than what we discussed previously, since we had stable states where both types were present, and now that&#8217;s impossible, and a bit disappointing. We need to make the population model a bit more complex to have more interesting behaviors, and we can do this in a very nice way by adding the effects of mutation. At the time of reproduction, we&#8217;ll allow either type to mutate into the other with probability <img src="https://s0.wp.com/latex.php?latex=%5Cmu.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mu." class="latex" /> This changes the transition probabilities to something like</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+T_a%5E%7Ba%2B1%7D+%3D+%5Cfrac%7Ba+%281-%5Cmu%29+f_A+%2B+b+%5Cmu+f_B%7D%7Ba+f_A+%2B+b+f_B%7D+%5Cfrac%7Bb%7D%7BN%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ T_a^{a+1} = &#92;frac{a (1-&#92;mu) f_A + b &#92;mu f_B}{a f_A + b f_B} &#92;frac{b}{N} } " class="latex" /></p>
<p>Now the process never stops wiggling around, but it does have something known as a <b>stationary distribution</b>, which gives the probability that the population is in any given state <i>in the long run</i>.</p>
<p>For populations with more than two types the basic ideas are the same, but there are more neighboring states that the population could move to, and many more states in the Markov process. One can also use more complicated mutation matrices, but this setup is good enough to typically guarantee that no one species completely takes over. For interesting behaviors, typically <img src="https://s0.wp.com/latex.php?latex=%5Cmu+%3D+1%2FN&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mu = 1/N" class="latex" /> is a good choice (there&#8217;s some biological evidence that mutation rates are typically inversely proportional to genome size).</p>
<p>Without mutation, once the population reached <img src="https://s0.wp.com/latex.php?latex=%280%2CN%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(0,N)" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=%28N%2C0%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(N,0)," class="latex" /> it stayed there. Now the population bounces between states, either because of drift, selection, or mutation. Based on our stability theorems for evolutionarily stable states, it&#8217;s reasonable to hope that for small mutation rates and larger populations (less drift), the population should spend most of its time near the evolutionarily stable state. This can be measured by the stationary distribution which gives the long run probabilities of a process being in a given state.</p>
<p>Previous work by Claussen and Traulsen:</p>
<p>&bull; Jens Christian Claussen and Arne Traulsen, <a href="http://arxiv.org/abs/cond-mat/0409656">Non-Gaussian fluctuations arising from finite populations: exact results for the evolutionary Moran process</a>, <i><a href="http://journals.aps.org/pre/abstract/10.1103/PhysRevE.71.025101">Physical Review E</a></i> <b>71</b> (2005), 025101.</p>
<p>suggested that the stationary distribution is at least sometimes maximal around evolutionarily stable states. Specifically, they showed that for a very similar model with fitness landscape given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%28%5Cbegin%7Barray%7D%7Bc%7D+f_A+%5C%5C+f_B+%5Cend%7Barray%7D%5Cright%29++%3D+%5Cleft%28%5Cbegin%7Barray%7D%7Bcc%7D+1+%26+2%5C%5C+2%261+%5Cend%7Barray%7D%5Cright%29++%5Cleft%28%5Cbegin%7Barray%7D%7Bc%7D+a%5C%5C+b+%5Cend%7Barray%7D%5Cright%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;left(&#92;begin{array}{c} f_A &#92;&#92; f_B &#92;end{array}&#92;right)  = &#92;left(&#92;begin{array}{cc} 1 &amp; 2&#92;&#92; 2&amp;1 &#92;end{array}&#92;right)  &#92;left(&#92;begin{array}{c} a&#92;&#92; b &#92;end{array}&#92;right) " class="latex" /></p>
<p>the stationary state is essentially a binomial distribution centered at <img src="https://s0.wp.com/latex.php?latex=%28N%2F2%2C+N%2F2%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(N/2, N/2)." class="latex" /></p>
<p>Unfortunately, the stationary distribution can be very difficult to compute for an arbitrary Markov chain. While it can be computed for the Markov process described above without mutation, and in the case studied by Claussen and Traulsen, there&#8217;s no general analytic formula for the process with mutation, nor for more than two types, because the processes are not <i>reversible</i>. Since we can&#8217;t compute the stationary distribution analytically, we&#8217;ll have to find another way to show that the local maxima of the stationary distribution are &#8220;evolutionarily stable&#8221;. We can approximate the stationary distribution fairly easily with a computer, so it&#8217;s easy to plot the results for just about any landscape and reasonable population size (e.g. <img src="https://s0.wp.com/latex.php?latex=N+%5Capprox+100&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N &#92;approx 100" class="latex" />).</p>
<p>It turns out that we can use a relative entropy minimization approach, just like for the continuous replicator equation! But how? We lack some essential ingredients such as deterministic and differentiable trajectories. Here&#8217;s what we do:</p>
<p>&bull; We show that the local maxima and minima of the stationary distribution satisfy a <i>complex balance</i> criterion.</p>
<p>&bull; We then show that these states minimize an <i>expected</i> relative entropy.</p>
<p>&bull; This will mean that the current state and the <i>expected next state</i> are &#8216;close&#8217;.</p>
<p>&bull; Lastly, we show that these states satisfy an analogous definition of evolutionary stability (now incorporating mutation).</p>
<p>The relative entropy allows us to measure how close the current state is to the expected next state, which captures the idea of stability in another way.  This ports the relative minimization Lyapunov result to some more realistic Markov chain models. The only downside is that we&#8217;ll assume the populations are &#8220;sufficiently large&#8221;, but in practice for populations of three types, <img src="https://s0.wp.com/latex.php?latex=N%3D20&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N=20" class="latex" /> is typically enough for common fitness landscapes (there are lots of examples <a href="http://people.mbi.ucla.edu/marcharper/stationary_stable/3x3/incentive.html">here</a> for <img src="https://s0.wp.com/latex.php?latex=N%3D80%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N=80," class="latex" /> which are prettier than the smaller populations). The reason for this is that the population state <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(a,b)" class="latex" /> needs enough &#8220;resolution&#8221; <img src="https://s0.wp.com/latex.php?latex=%28a%2FN%2C+b%2FN%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(a/N, b/N)" class="latex" /> to get sufficiently close to the stable state, which is not necessarily a ratio of integers. If you allow some wiggle room, smaller populations are still typically pretty close.</p>
<p>Evolutionarily stable states are closely related to Nash equilibria, which have a nice intuitive description in traditional game theory as &#8220;states that no player has an incentive to deviate from&#8221;. But in evolutionary game theory, we don&#8217;t use a game matrix to compute e.g. maximum payoff strategies, rather the game matrix defines a fitness landscape which then determines how natural selection unfolds.</p>
<p>We&#8217;re going to see this idea again in a moment, and to help get there let&#8217;s introduce an function called an <b>incentive</b> that encodes how a fitness landscape is used for selection. One way is to simply replace the quantities <img src="https://s0.wp.com/latex.php?latex=a+f_A%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="a f_A(a,b)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=b+f_B%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="b f_B(a,b)" class="latex" /> in the fitness-proportionate selection ratio above, which now becomes (for two population types):</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7B%5Cvarphi_A%28a%2Cb%29%7D%7B%5Cvarphi_A%28a%2Cb%29+%2B+%5Cvarphi_B%28a%2Cb%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{&#92;varphi_A(a,b)}{&#92;varphi_A(a,b) + &#92;varphi_B(a,b)} }" class="latex" /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi_A%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;varphi_A(a,b)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cvarphi_B%28a%2Cb%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;varphi_B(a,b)" class="latex" /> are the incentive function components that determine how the fitness landscape is used for natural selection (if at all). We have seen two examples above:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cvarphi_A%28a%2Cb%29+%3D+a+f_A%28a%2C+b%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;varphi_A(a,b) = a f_A(a, b)" class="latex" /></p>
<p>for the Moran process and fitness-proportionate selection, and</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cvarphi_A%28a%2Cb%29+%3D+a+e%5E%7B%5Cbeta+f_A%28a%2C+b%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;varphi_A(a,b) = a e^{&#92;beta f_A(a, b)}" class="latex" /></p>
<p>for an alternative that incorporates a strength of selection term <img src="https://s0.wp.com/latex.php?latex=%5Cbeta%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta," class="latex" /> preventing division by zero for fitness landscapes defined by zero-sum game matrices, such as a rock-paper-scissors game. Using an incentive function also simplifies the transition probabilities and results as we move to populations of more than two types. Introducing mutation, we can describe the ratio for incentive-proportion selection with mutation for the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th population type when the population is in state <img src="https://s0.wp.com/latex.php?latex=x%3D%28a%2Cb%2C%5Cldots%29+%2F+N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x=(a,b,&#92;ldots) / N" class="latex" /> as</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_i%28x%29+%3D+%5Cfrac%7B%5Csum_%7Bk%3D1%7D%5E%7Bn%7D%7B%5Cvarphi_k%28x%29+M_%7Bi+k%7D+%7D%7D%7B%5Csum_%7Bk%3D1%7D%5E%7Bn%7D%7B%5Cvarphi_k%28x%29%7D%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_i(x) = &#92;frac{&#92;sum_{k=1}^{n}{&#92;varphi_k(x) M_{i k} }}{&#92;sum_{k=1}^{n}{&#92;varphi_k(x)}} }" class="latex" /></p>
<p>for some matrix of mutation probabilities <img src="https://s0.wp.com/latex.php?latex=M.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M." class="latex" /> This is just the probability that we get a new individual of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th type (by birth and/or mutation). A common choice for the mutation matrix is to use a single mutation probability <img src="https://s0.wp.com/latex.php?latex=%5Cmu&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mu" class="latex" /> and spread it out over all the types, such as letting</p>
<p><img src="https://s0.wp.com/latex.php?latex=M_%7Bij%7D+%3D+%5Cmu+%2F+%28n-1%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M_{ij} = &#92;mu / (n-1)" class="latex" /></p>
<p>and</p>
<p><img src="https://s0.wp.com/latex.php?latex=M_%7Bii%7D+%3D+1+-+%5Cmu&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M_{ii} = 1 - &#92;mu" class="latex" /></p>
<p>Now we are ready to define the <b>expected next state</b> for the population and see how it captures a notion of stability. For a given state population <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> in a multitype population, using <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x" class="latex" /> to indicate the normalized population state <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%2C%5Cldots%29+%2F+N%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="(a,b,&#92;ldots) / N," class="latex" /> consider all the neighboring states <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y" class="latex" /> that the population could move to in one step of the process (one birth-death cycle). These neighboring states are the result of increasing a population type by one (birth) and decreasing another by one (death, possibly the same type), of course excluding cases on the boundary where the number of individuals of any type drops below zero or rises above <img src="https://s0.wp.com/latex.php?latex=N.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N." class="latex" /> Now we can define the expected next state as the sum of neighboring states weighted by the transition probabilities</p>
<p><img src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+%5Csum_%7By%7D%7By+T_x%5E%7By%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E(x) = &#92;sum_{y}{y T_x^{y}}" class="latex" /></p>
<p>with transition probabilities given by</p>
<p><img src="https://s0.wp.com/latex.php?latex=T_%7Bx%7D%5E%7By%7D+%3D+p_%7Bi%7D%28x%29+x_%7Bj%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T_{x}^{y} = p_{i}(x) x_{j}" class="latex" /></p>
<p>for states <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y" class="latex" /> that differ in <img src="https://s0.wp.com/latex.php?latex=1%2FN&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/N" class="latex" /> at the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th coordinate and <img src="https://s0.wp.com/latex.php?latex=-1%2FN&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="-1/N" class="latex" /> at <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j" class="latex" />th coordinate from <img src="https://s0.wp.com/latex.php?latex=x.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x." class="latex" /> Here <img src="https://s0.wp.com/latex.php?latex=x_j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_j" class="latex" /> is just the probability of the random death of an individual of the <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j" class="latex" />th type, so the transition probabilities are still just birth (with mutation) and death as for the Moran process we started with.</p>
<p>Skipping some straightforward algebraic manipulations, we can show that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+E%28x%29+%3D+%5Csum_%7By%7D%7By+T_x%5E%7By%7D%7D+%3D+%5Cfrac%7BN-1%7D%7BN%7Dx+%2B+%5Cfrac%7B1%7D%7BN%7Dp%28x%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ E(x) = &#92;sum_{y}{y T_x^{y}} = &#92;frac{N-1}{N}x + &#92;frac{1}{N}p(x)} " class="latex" /></p>
<p>Then it&#8217;s easy to see that <img src="https://s0.wp.com/latex.php?latex=E%28x%29+%3D+x&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E(x) = x" class="latex" /> if and only if <img src="https://s0.wp.com/latex.php?latex=x+%3D+p%28x%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x = p(x)," class="latex" /> and that <img src="https://s0.wp.com/latex.php?latex=x+%3D+p%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x = p(x)" class="latex" /> if and only if <img src="https://s0.wp.com/latex.php?latex=x_i+%3D+%5Cvarphi_i%28x%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x_i = &#92;varphi_i(x)." class="latex" /> So we have a nice description of &#8216;stability&#8217; in terms of fixed points of the expected next state function and the incentive function</p>
<p><img src="https://s0.wp.com/latex.php?latex=x+%3D+E%28x%29+%3D+p%28x%29+%3D+%5Cvarphi%28x%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x = E(x) = p(x) = &#92;varphi(x)," class="latex" /></p>
<p>and we&#8217;ve gotten back to &#8220;no one has an incentive to deviate&#8221;. More precisely, for the Moran process</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cvarphi_i%28x%29+%3D+x_i+f_i%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;varphi_i(x) = x_i f_i(x)" class="latex" /></p>
<p>and we get back <img src="https://s0.wp.com/latex.php?latex=f_i%28x%29+%3D+f_j%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f_i(x) = f_j(x)" class="latex" /> for every type. So we take <img src="https://s0.wp.com/latex.php?latex=x+%3D+%5Cvarphi%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x = &#92;varphi(x)" class="latex" /> as our analogous condition to an evolutionarily stable state, though it&#8217;s just the &#8216;no motion&#8217; part and not also the &#8216;stable&#8217; part. That&#8217;s what we need the stationary distribution for!</p>
<p>To turn this into a useful number that measures stability, we use the relative entropy of the expected next state and the current state, in analogy with the Lyapunov theorem for the replicator equation. The <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">relative entropy</a></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+D%28x%2C+y%29+%3D+%5Csum_i+x_i+%5Cln%28x_i%29+-+y_i+%5Cln%28x_i%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ D(x, y) = &#92;sum_i x_i &#92;ln(x_i) - y_i &#92;ln(x_i) }" class="latex" /></p>
<p>has the really nice property that <img src="https://s0.wp.com/latex.php?latex=D%28x%2Cy%29+%3D+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D(x,y) = 0" class="latex" /> if and only if <img src="https://s0.wp.com/latex.php?latex=x+%3D+y%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="x = y," class="latex" /> so we can use the relative entropy <img src="https://s0.wp.com/latex.php?latex=D%28E%28x%29%2C+x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="D(E(x), x)" class="latex" /> as a measure of <i>how close to stable</i> any particular state is!  Here the expected next state takes the place of the &#8216;evolutionarily stable state&#8217; in the result described last time for the replicator equation.</p>
<p>Finally, we need to show that the maxima (and minima) of of the stationary distribution are these fixed points by showing that these states minimize the expected relative entropy.</p>
<p>Seeing that local maxima and minima of the stationary distribution minimize the expected relative entropy is a more involved, so let&#8217;s just sketch the details. In general, these Markov processes are not reversible, so they don&#8217;t satisfy the <a href="https://johncarlosbaez.wordpress.com/2012/10/08/the-mathematical-origin-of-irreversibility/">detailed-balance condition</a>, but the stationary probabilities do satisfy something called the global balance condition, which says that for the stationary distribution <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> we have that</p>
<p><img src="https://s0.wp.com/latex.php?latex=s_x+%5Csum_%7Bx%7D%7BT_x%5E%7By%7D%7D+%3D+%5Csum_%7By%7D%7Bs_y+T_y%5E%7Bx%7D%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_x &#92;sum_{x}{T_x^{y}} = &#92;sum_{y}{s_y T_y^{x}}" class="latex" /></p>
<p>When the stationary distribution is at a local maximum (or minimum), we can show essentially that this implies (up to an <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;epsilon," class="latex" /> for a large enough population) that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B%5Csum_%7Bx%7D%7BT_x%5E%7By%7D%7D+%3D+%5Csum_%7By%7D%7BT_y%5E%7Bx%7D%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{&#92;sum_{x}{T_x^{y}} = &#92;sum_{y}{T_y^{x}} }" class="latex" /></p>
<p>a sort of probability inflow-outflow equation, which is very similar to the condition of complex balanced equilibrium described by Manoj Gopalkrishnan in this <a href="https://johncarlosbaez.wordpress.com/2014/01/07/lyapunov-functions-for-complex-balanced-systems/">Azimuth post</a>. With some algebraic manipulation, we can show that these states have <img src="https://s0.wp.com/latex.php?latex=E%28x%29%3Dx.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E(x)=x." class="latex" /></p>
<p>Now let&#8217;s look again at the figures from the start.   The first shows the vector field of the replicator equation:</p>
<div align="center">
<img src="https://i1.wp.com/www.azimuthproject.org/azimuth/files/ga_phase.png" width="250" />
</div>
<p>You can see rest points at the center, on the center of each boundary edge, and on the corner points. The center point is evolutionarily stable, the center points of the boundary are semi-stable (but stable when the population is restricted to a boundary simplex), and the corner points are unstable.</p>
<p>This one shows the stationary distribution for a finite population model with a Fermi incentive on the same landscape, for a population of size 80:</p>
<div align="center">
<img src="https://i0.wp.com/www.azimuthproject.org/azimuth/files/ga_stationary.png" width="350" />
</div>
<p>A fixed population size gives a partitioning of the simplex, and each triangle of the partition is colored by the value of the stationary distribution. So you can see that there are local maxima in the center and on the centers of the triangle boundary edges. In this case, the size of the mutation probability determines how much of the stationary distribution is concentrated on the center of the simplex.</p>
<p>This shows one-half of the Euclidean distance squared between the current state and the expected next state:</p>
<div align="center">
<img src="https://i1.wp.com/www.azimuthproject.org/azimuth/files/ga_d_0.png" width="350" />
</div>
<p>And finally, this shows the same thing but with the relative entropy as the &#8216;distance function&#8217;:</p>
<div align="center">
<img src="https://i1.wp.com/www.azimuthproject.org/azimuth/files/ga_d_1.png" width="350" />
</div>
<p>As you can see, the Euclidean distance is locally minimal at each of the local maxima and minima of the stationary distribution (including the corners); the relative entropy is only guaranteed so on the interior states (because the relative entropy doesn&#8217;t play nicely with the boundary, and unlike the replicator equation, the Markov process can jump on and off the boundary). It turns out that the relative R&eacute;nyi entropies for <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> between 0 and 1 also work just fine, but for the large population limit (the replicator dynamic), the relative entropy is the somehow the right choice for the replicator equation (has the derivative that easily gives Lyapunov stability), which is due to the connections between relative entropy and Fisher information in the information geometry of the simplex. The Euclidean distance is the <img src="https://s0.wp.com/latex.php?latex=q%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q=0" class="latex" /> case and the ordinary relative entropy is <img src="https://s0.wp.com/latex.php?latex=q%3D1.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q=1." class="latex" /></p>
<p>As it turns out, something very similar holds for another popular finite population model, the Wright&ndash;Fisher process! This model is more complicated, so if you are interested in the details, check out our <a href="http://arxiv.org/abs/1311.0941">paper</a>, which has many nice examples and figures. We also define a process that bridges the gap between the atomic nature of the Moran process and the generational nature of the Wright&ndash;Fisher process, and prove the general result for that model.</p>
<p>Finally, let&#8217;s see how the Moran process relates back to the replicator equation (see also the appendix in this <a href="http://www.ped.fas.harvard.edu/people/faculty/publications_nowak/JTB_06.pdf">paper</a>), and how we recover the stability theory of the replicator equation. We can use the transition probabilities of the Moran process to define a stochastic differential equation (called a Langevin equation) with drift and diffusion terms that are essentially (for populations with two types:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BDrift%7D%28x%29+%3D+T%5E%7B%2B%7D%28x%29+-+T%5E%7B-%7D%28x%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{Drift}(x) = T^{+}(x) - T^{-}(x) " class="latex" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cmathrm%7BDiffusion%7D%28x%29+%3D+%5Csqrt%7B%5Cfrac%7BT%5E%7B%2B%7D%28x%29+%2B+T%5E%7B-%7D%28x%29%7D%7BN%7D%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;mathrm{Diffusion}(x) = &#92;sqrt{&#92;frac{T^{+}(x) + T^{-}(x)}{N}} }" class="latex" /></p>
<p>As the population size gets larger, the diffusion term drops out, and the stochastic differential equation becomes essentially the replicator equation. For the stationary distribution, the variance (e.g. for the binomial example above) also has an inverse dependence on <img src="https://s0.wp.com/latex.php?latex=N%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N," class="latex" /> so the distribution limits to a delta-function that is zero except for at the evolutionarily stable state!</p>
<p>What about the relative entropy? Loosely speaking, as the population size gets larger, the iteration of the expected next state also becomes deterministic. Then the evolutionarily stable states is a fixed point of the expected next state function, and the expected relative entropy is essentially the same as the ordinary relative entropy, at least in a neighborhood of the evolutionarily stable state.  This is good enough to establish local stability.</p>
<p>Earlier I said both the local maxima and minima minimize the expected relative entropy. Dash and I haven&#8217;t proven that the local maxima always correspond to evolutionarily stable states (and the minima to unstable states). That&#8217;s because the generalization of evolutionarily stable state we use is really just a &#8216;no motion&#8217; condition, and isn&#8217;t strong enough to imply stability in a neighborhood for the deterministic replicator equation. So for now we are calling the local maxima <b>stationary stable</b> states.</p>
<p>We&#8217;ve also tried a similar approach to populations evolving on networks, which is a popular topic in evolutionary graph theory, and the results are encouraging! But there are many more &#8216;states&#8217; in such a process, since the configuration of the network has to be taken into account, and whether the population is clustered together or not. See the end of our <a href="http://arxiv.org/abs/1311.0941">paper</a> for an interesting example of a population on a cycle.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2015/03/24/stationary-stability-in-finite-populations/#comments">5 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/biology/" rel="category tag">biology</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2015/03/24/stationary-stability-in-finite-populations/" rel="bookmark" title="Permanent Link to Stationary Stability in Finite&nbsp;Populations">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-19297 post type-post status-publish format-standard hentry category-physics" id="post-19297">
				<h2><a href="https://johncarlosbaez.wordpress.com/2015/03/13/quantum-superposition/" rel="bookmark">Quantum Superposition</a></h2>
				<small>13 March, 2015</small><br />


				<div class="entry">
					<p><i>guest post by <b><a href="http://www.azimuthproject.org/azimuth/show/Piotr+Migdal">Piotr Migdał</a></b></i></p>
<p>In this blog post I will introduce some basics of quantum mechanics, with the emphasis on why a particle being in a few places at once behaves measurably differently from a particle whose position we just don&#8217;t know.  It&#8217;s a kind of continuation of the &#8220;Quantum Network Theory&#8221; series (<a href="https://johncarlosbaez.wordpress.com/2013/08/05/quantum-network-theory-part-1/">Part 1</a>, <a href="https://johncarlosbaez.wordpress.com/2013/08/13/quantum-network-theory-part-2/">Part 2</a>) by <a href="http://www.azimuthproject.org/azimuth/show/Tomi+Johnson">Tomi Johnson</a> about our work in Jake Biamonte&#8217;s group at the <a href="http://www.isi.it/">ISI Foundation</a> in Turin.  My goal is to explain quantum community detection.  Before that, I need to introduce the relevant basics of quantum mechanics, and of the classical <a href="http://en.wikipedia.org/wiki/Community_structure">community detection</a>.</p>
<p>But before I start, let me introduce myself, as it&#8217;s my first post to Azimuth.</p>
<p>I just finished my quantum optics theory Ph.D in Maciej Lewenstein&#8217;s group at <a href="http://www.icfo.eu/">The Institute of Photonic Sciences</a> in Castelldefels, a beach near Barcelona.  My scientific interests range from quantum physics, through complex networks, to data-driven approach&#8230;. to pretty much anything&mdash;and now I work as a data science freelancer. I enjoy doing data visualizations (for example of <a href="http://stared.github.io/tagoverflow/?site=math&amp;size=32">relations between topics in mathematics</a>), I am a big fan of <a href="http://mathoverflow.net/questions/150053/gini-coefficient-and-renyi-entropy/">R&eacute;nyi entropy</a> (largely thanks to Azimuth), and I&#8217;m a <a href="http://offtopicarium.wikidot.com/v1:open-science-2-0">believer in open science</a>. If you think that there are too many <a href="http://offtopicarium.wikidot.com/">off-topic</a> <a href="http://crastina.se/theres-no-projects-like-side-projects/">side projects</a> here, you are absolutely right!</p>
<p>In my opinion, quantum mechanics is easy. Based on my <a href="http://warsztatywww.wikidot.com/en:indie-camp-for-hs-geeks">gifted education experience</a> it takes roughly 9 intense hours to introduce entanglement to students having only a very basic linear algebra background. Even more, I believe that it is possible to get familiar with quantum mechanics by just playing with it&mdash;so I am developing a <a href="http://quantumgame.io/">Quantum Game</a>!</p>
<h3> Quantum weirdness </h3>
<p>In quantum mechanics a particle can be in a few places at once. It sounds strange. So strange, that some pioneers of quantum mechanics (including, famously, Albert Einstein) didn&#8217;t want to believe in it: not because of any disagreement with experiment, not because of any lack of mathematical beauty, just because it didn&#8217;t fit their philosophical view of physics.</p>
<p>It went further: in the Soviet Union the idea that electron can be in many places (<a href="http://en.wikipedia.org/wiki/Resonance_%28chemistry%29">resonance bonds</a>) was <a href="http://paulingblog.wordpress.com/2009/03/26/paulings-theory-of-resonance-a-soviet-controversy/">considered to oppose materialism</a>.  Later, in California, <a href="http://www.hippiessavedphysics.com/">hippies investigated quantum mechanics as a basis for parapsychology</a>&mdash;which, arguably, gave birth to the field of quantum information.</p>
<p>As Griffiths put it in his <em><a href="https://archive.org/details/IntroductionToQuantumMechanics_718">Introduction to Quantum Mechanics</a></em> (Chapter 4.4.1):</p>
<blockquote><p>
  To the layman, the philosopher, or the classical physicist, a statement of the form &#8220;this particle doesn&#8217;t have a well-defined position&#8221; <code>[...]</code> sounds vague, incompetent, or (worst of all) profound. It is none of these.
</p></blockquote>
<p>In this guest blog post I will try to show that not only can a particle be in many places at once, but also that if it were not in many places at once then it would cause problems. That is, as fundamental phenomena as atoms forming chemical bonds, or particle moving in the vacuum, require it.</p>
<p>As in many other cases, the simplest non-trivial case is perfect for explaining idea, as it covers the most important phenomena, while being easy to analyze, visualize and comprehend. Quantum mechanics is not an exception&mdash;let us start with a system of two states.</p>
<h3>A two state system</h3>
<p>Let us study a simplified model of the <a href="https://en.wikipedia.org/wiki/Dihydrogen_cation">hydrogen molecular ion</a> <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BH%7D_2%5E%2B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{H}_2^+" class="latex" />, that is, a system of two protons and one electron (see <a href="http://www.feynmanlectures.caltech.edu/III_10.html#Ch10-S1">Feynman Lectures on Physics</a>, Vol. III, Chapter 10.1).  Since the protons are heavy and slow, we treat them as fixed.  We focus on the electron moving in the electric field created by protons.</p>
<p>In quantum mechanics we describe the state of a system using a complex vector.  In simple terms, this is a list of <a href="http://en.wikipedia.org/wiki/Complex_number">complex numbers</a> called &#8216;probability amplitudes&#8217;.  For an electron that can be near one proton or another, we use a list of two numbers:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+%3D++++++%5Cbegin%7Bbmatrix%7D++++++++++%5Calpha+%5C%5C+%5Cbeta++++++%5Cend%7Bbmatrix%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi&#92;rangle =      &#92;begin{bmatrix}          &#92;alpha &#92;&#92; &#92;beta      &#92;end{bmatrix}  " class="latex" /></p>
<p>In this state the electron is near the first proton with probability <img src="https://s0.wp.com/latex.php?latex=%7C%5Calpha%7C%5E2%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;alpha|^2," class="latex" /> and near the second one with probability <img src="https://s0.wp.com/latex.php?latex=%7C%5Cbeta%7C%5E2.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;beta|^2." class="latex" /></p>
<p>Note that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi+%5Crangle+%3D+%5Calpha+%5Cbegin%7Bbmatrix%7D++++++++++1+%5C%5C+0++++++%5Cend%7Bbmatrix%7D+%2B+%5Cbeta+%5Cbegin%7Bbmatrix%7D++++++++++0+%5C%5C+1++++++%5Cend%7Bbmatrix%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi &#92;rangle = &#92;alpha &#92;begin{bmatrix}          1 &#92;&#92; 0      &#92;end{bmatrix} + &#92;beta &#92;begin{bmatrix}          0 &#92;&#92; 1      &#92;end{bmatrix} " class="latex" /></p>
<p>So, we say the electron is in a &#8216;linear combination&#8217; or &#8216;superposition&#8217; of the two states</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle+%3D++++++%5Cbegin%7Bbmatrix%7D++++++++++1+%5C%5C+0++++++%5Cend%7Bbmatrix%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|1&#92;rangle =      &#92;begin{bmatrix}          1 &#92;&#92; 0      &#92;end{bmatrix}  " class="latex" /></p>
<p>(where it&#8217;s near the first proton) and the state</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C2%5Crangle+%3D++++++%5Cbegin%7Bbmatrix%7D++++++++++0+%5C%5C+1++++++%5Cend%7Bbmatrix%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|2&#92;rangle =      &#92;begin{bmatrix}          0 &#92;&#92; 1      &#92;end{bmatrix}  " class="latex" /></p>
<p>(where it&#8217;s near the second proton).</p>
<blockquote><p>
  Why do we denote unit vectors in strange brackets looking like</p>
<p>  <img src="https://s0.wp.com/latex.php?latex=%7C+%5Cmathrm%7Bsomething%7D+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;mathrm{something} &#92;rangle" class="latex" /> ?</p>
<p>  Well, this is called <a href="https://en.wikipedia.org/wiki/Bra%E2%80%93ket_notation">Dirac notation (or bra-ket notation)</a> and it is immensely useful in quantum mechanics.   We won&#8217;t go into it in detail here; merely note that <img src="https://s0.wp.com/latex.php?latex=%7C+%5Ccdot+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;cdot &#92;rangle" class="latex" /> stands for a column vector and <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Ccdot+%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;cdot |" class="latex" /> stands for a row vector, while <img src="https://s0.wp.com/latex.php?latex=%5Cpsi&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi" class="latex" /> is a traditional symbol for a quantum state.).
</p></blockquote>
<p>Amplitudes can be thought as &#8216;square roots&#8217; of probabilities. We can force an electron to localize by performing a classical measurement, for example by moving protons away and measuring which of them has neutral charge (for being coupled with the electron).  Then, we get probability <img src="https://s0.wp.com/latex.php?latex=%7C+%5Calpha%7C%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;alpha|^2" class="latex" /> of finding it near the first proton and <img src="https://s0.wp.com/latex.php?latex=%7C%5Cbeta%7C%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;beta|^2" class="latex" /> of finding it near the second.  So, we require that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Calpha%7C%5E2+%2B+%7C%5Cbeta%7C%5E2+%3D+1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;alpha|^2 + |&#92;beta|^2 = 1" class="latex" /></p>
<p>Note that as amplitudes are complex, for a given probability there are many possible amplitudes. For example</p>
<p><img src="https://s0.wp.com/latex.php?latex=1+%3D+%7C1%7C%5E2+%3D+%7C-1%7C%5E2+%3D+%7Ci%7C%5E2+%3D+%5Cleft%7C+%5Ctfrac%7B1%2Bi%7D%7B%5Csqrt%7B2%7D%7D+%5Cright%7C%5E2+%3D+%5Ccdots+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1 = |1|^2 = |-1|^2 = |i|^2 = &#92;left| &#92;tfrac{1+i}{&#92;sqrt{2}} &#92;right|^2 = &#92;cdots " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> is the imaginary unit, with <img src="https://s0.wp.com/latex.php?latex=i%5E2+%3D+-1.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i^2 = -1." class="latex" /></p>
<p>We will now show that the electron &#8216;wants&#8217; to be spread out.  Electrons don&#8217;t really have desires, so this is physics slang for saying that the electron will have less energy if its probability of being near the first proton is equal to its probability of being near the second proton: namely, 50%.</p>
<p>In quantum mechanics, a <a href="http://en.wikipedia.org/wiki/Hamiltonian_%28quantum_mechanics%29">Hamiltonian</a> is a matrix that describes the relation between the energy and evolution (i.e. how the state changes in time).  The expected value of the energy of any state <img src="https://s0.wp.com/latex.php?latex=%7C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;psi &#92;rangle" class="latex" /> is</p>
<p><img src="https://s0.wp.com/latex.php?latex=E+%3D+%5Clangle+%5Cpsi+%7C+H+%7C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E = &#92;langle &#92;psi | H | &#92;psi &#92;rangle" class="latex" /></p>
<p>Here the row vector <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;psi |" class="latex" /> is the column vector <img src="https://s0.wp.com/latex.php?latex=%7C+%5Cpsi%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;psi&#92;rangle" class="latex" /> after <a href="http://en.wikipedia.org/wiki/Conjugate_transpose">transposition and complex conjugation</a> (i.e. changing  <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=-i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="-i" class="latex" />), and</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%7C+H+%7C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;psi | H | &#92;psi &#92;rangle" class="latex" /></p>
<p>means we are doing matrix multiplication on <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%7C%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;psi |," class="latex" /> <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;psi &#92;rangle" class="latex" /> to get a number.</p>
<p>For the electron in the <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BH%7D_2%5E%2B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{H}_2^+" class="latex" /> molecule the Hamiltonian can be written as the following <img src="https://s0.wp.com/latex.php?latex=2+%5Ctimes+2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="2 &#92;times 2" class="latex" /> matrix with real, positive entries:</p>
<p><img src="https://s0.wp.com/latex.php?latex=H+%3D++++++%5Cbegin%7Bbmatrix%7D++++++++++E_0+%26+%5CDelta+%5C%5C++++++++++%5CDelta+%26+E_0++++++%5Cend%7Bbmatrix%7D%2C++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H =      &#92;begin{bmatrix}          E_0 &amp; &#92;Delta &#92;&#92;          &#92;Delta &amp; E_0      &#92;end{bmatrix},  " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=E_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E_0" class="latex" /> is the energy of the electron being either in state <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|1&#92;rangle" class="latex" /> or state <img src="https://s0.wp.com/latex.php?latex=%7C2%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|2&#92;rangle" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta" class="latex" /> is the &#8216;tunneling amplitude&#8217;, which describes how easy it is for the electron to move from neighborhood of one proton to that of the other.</p>
<p>The expected value&#8212;physicists call it the &#8216;expectation value&#8217;&#8212;of the energy of a given state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi&#92;rangle" class="latex" /> is:</p>
<p><img src="https://s0.wp.com/latex.php?latex=E+%3D+%5Clangle+%5Cpsi+%7C+H+%7C+%5Cpsi+%5Crangle+%5Cequiv++++++%5Cbegin%7Bbmatrix%7D++++++++++%5Calpha%5E%2A+%26+%5Cbeta%5E%2A++++++%5Cend%7Bbmatrix%7D++++++%5Cbegin%7Bbmatrix%7D++++++++++E_0+%26+%5CDelta+%5C%5C++++++++++%5CDelta+%26+E_0++++++%5Cend%7Bbmatrix%7D++++++%5Cbegin%7Bbmatrix%7D++++++++++%5Calpha+%5C%5C+%5Cbeta++++++%5Cend%7Bbmatrix%7D.++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E = &#92;langle &#92;psi | H | &#92;psi &#92;rangle &#92;equiv      &#92;begin{bmatrix}          &#92;alpha^* &amp; &#92;beta^*      &#92;end{bmatrix}      &#92;begin{bmatrix}          E_0 &amp; &#92;Delta &#92;&#92;          &#92;Delta &amp; E_0      &#92;end{bmatrix}      &#92;begin{bmatrix}          &#92;alpha &#92;&#92; &#92;beta      &#92;end{bmatrix}.  " class="latex" /></p>
<blockquote><p>
  The star symbol denotes the complex conjugation. If you are unfamiliar with complex numbers, just work with real numbers on which this operation does nothing.
</p></blockquote>
<p><b>Exercise 1.</b> Find <img src="https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;beta" class="latex" /> with</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Calpha%7C%5E2+%2B+%7C%5Cbeta%7C%5E2+%3D+1+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;alpha|^2 + |&#92;beta|^2 = 1 " class="latex" /></p>
<p>that minimize or maximize the expectation value of energy <img src="https://s0.wp.com/latex.php?latex=%5Clangle+%5Cpsi+%7C+H+%7C+%5Cpsi+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;langle &#92;psi | H | &#92;psi &#92;rangle" class="latex" /> for</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+%3D++++++%5Cbegin%7Bbmatrix%7D++++++++++%5Calpha+%5C%5C+%5Cbeta++++++%5Cend%7Bbmatrix%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi&#92;rangle =      &#92;begin{bmatrix}          &#92;alpha &#92;&#92; &#92;beta      &#92;end{bmatrix}  " class="latex" /></p>
<p><b>Exercise 2.</b> What&#8217;s the expectation value value of the energy for the states <img src="https://s0.wp.com/latex.php?latex=%7C+1+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| 1 &#92;rangle" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7C+2+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| 2 &#92;rangle" class="latex" />?</p>
<p>Or if you are lazy, just read the answer!   It is straightforward to check that</p>
<p><img src="https://s0.wp.com/latex.php?latex=E+%3D+%28%5Calpha%5E%2A+%5Calpha+%2B+%5Cbeta%5E%2A+%5Cbeta%29+E_0+%2B+%28%5Calpha%5E%2A+%5Cbeta+%2B+%5Cbeta%5E%2A+%5Calpha%29+%5CDelta++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E = (&#92;alpha^* &#92;alpha + &#92;beta^* &#92;beta) E_0 + (&#92;alpha^* &#92;beta + &#92;beta^* &#92;alpha) &#92;Delta  " class="latex" /></p>
<p>The coefficient of <img src="https://s0.wp.com/latex.php?latex=E_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E_0" class="latex" /> is 1, so the minimal energy is <img src="https://s0.wp.com/latex.php?latex=E_0+-+%5CDelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E_0 - &#92;Delta" class="latex" /> and the maximal energy is <img src="https://s0.wp.com/latex.php?latex=E_0+%2B+%5CDelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E_0 + &#92;Delta" class="latex" />.  The states achieving these energies are spread out:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C+%5Cpsi_-+%5Crangle+%3D++++++%5Cbegin%7Bbmatrix%7D++++++++++1%2F%5Csqrt%7B2%7D+%5C%5C+-1%2F%5Csqrt%7B2%7D++++++%5Cend%7Bbmatrix%7D%2C++++++%5Cquad+%5Ctext%7Bwith%7D+%5Cquad++++++%5Cquad+E+%3D+E_0+-+%5CDelta++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;psi_- &#92;rangle =      &#92;begin{bmatrix}          1/&#92;sqrt{2} &#92;&#92; -1/&#92;sqrt{2}      &#92;end{bmatrix},      &#92;quad &#92;text{with} &#92;quad      &#92;quad E = E_0 - &#92;Delta  " class="latex" /></p>
<p>and</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C+%5Cpsi_%2B+%5Crangle+%3D++++++%5Cbegin%7Bbmatrix%7D++++++++++1%2F%5Csqrt%7B2%7D+%5C%5C+1%2F%5Csqrt%7B2%7D++++++%5Cend%7Bbmatrix%7D%2C++++++%5Cquad+%5Ctext%7Bwith%7D+%5Cquad++++++%5Cquad+E+%3D+E_0+%2B+%5CDelta++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;psi_+ &#92;rangle =      &#92;begin{bmatrix}          1/&#92;sqrt{2} &#92;&#92; 1/&#92;sqrt{2}      &#92;end{bmatrix},      &#92;quad &#92;text{with} &#92;quad      &#92;quad E = E_0 + &#92;Delta  " class="latex" /></p>
<p>The energies of these states are below and above the energy <img src="https://s0.wp.com/latex.php?latex=E_0%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E_0," class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5CDelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta" class="latex" /> says how much.</p>
<p>So, the electron is &#8216;happier&#8217; (electrons don&#8217;t have moods either) to be in the state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_-%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi_-&#92;rangle" class="latex" /> than to be localized near only one of the protons.  In other words&mdash;and this is Chemistry 101&mdash;atoms like to share electrons and it bonds them.  Also, they like to share electrons in a particular and symmetric way.</p>
<p>For reference, <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_%2B+%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi_+ &#92;rangle" class="latex" /> is called &#8216;antibonding state&#8217;. If the electron is in this state, the atoms will get repelled from each other&mdash;and so much for the molecule!</p>
<h3> How to classically add quantum things </h3>
<p>How can we tell a difference between an electron being in a superposition between two states, and just not knowing its &#8216;real&#8217; position?  Well, first we need to devise a way to describe probabilistic mixtures.</p>
<p>It looks simple&mdash;if we have an electron in the state <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|1&#92;rangle" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=%7C2%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|2&#92;rangle" class="latex" /> with probabilities <img src="https://s0.wp.com/latex.php?latex=1%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/2" class="latex" />, we may be tempted to write</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle+%3D+%5Ctfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%7C1%5Crangle+%2B+%5Ctfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%7C2%5Crangle++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi&#92;rangle = &#92;tfrac{1}{&#92;sqrt{2}} |1&#92;rangle + &#92;tfrac{1}{&#92;sqrt{2}} |2&#92;rangle  " class="latex" /></p>
<p>We&#8217;re getting the right probabilities, so it looks legit.  But there is something strange about the energy. We have obtained the state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_%2B%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi_+&#92;rangle" class="latex" /> with energy <img src="https://s0.wp.com/latex.php?latex=E_0%2B%5CDelta&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E_0+&#92;Delta" class="latex" /> by mixing two states with the energy <img src="https://s0.wp.com/latex.php?latex=E_0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E_0" class="latex" />!</p>
<p>Moreover, we could have used different amplitudes such that <img src="https://s0.wp.com/latex.php?latex=%7C%5Calpha%7C%5E2%3D%7C%5Cbeta%7C%5E2%3D1%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;alpha|^2=|&#92;beta|^2=1/2" class="latex" /> and gotten different energies.  So, we need to devise a way to avoid guessing amplitudes. All in all, we used quotation marks for &#8216;square roots&#8217; for a reason!</p>
<p>It turns out that to describe statistical mixtures we can use <a href="http://en.wikipedia.org/wiki/Density_matrix">density matrices</a>.</p>
<p>The states we&#8217;d been looking at before are described by vectors like this:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%7C+%5Cpsi+%5Crangle+%3D++++++%5Cbegin%7Bbmatrix%7D++++++++++%5Calpha+%5C%5C+%5Cbeta++++++%5Cend%7Bbmatrix%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="| &#92;psi &#92;rangle =      &#92;begin{bmatrix}          &#92;alpha &#92;&#92; &#92;beta      &#92;end{bmatrix}  " class="latex" /></p>
<p>These are called &#8216;pure states&#8217;.  For a pure state, here is how we create a density matrix:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D+%7C+%5Cpsi+%5Crangle+%5Clangle+%5Cpsi+%7C++++++%5Cequiv++++++%5Cbegin%7Bbmatrix%7D++++++++++%5Calpha+%5Calpha%5E%2A+%26+%5Calpha+%5Cbeta%5E%2A%5C%5C++++++++++%5Cbeta+%5Calpha%5E%2A+%26+%5Cbeta+%5Cbeta%5E%2A+++++++%5Cend%7Bbmatrix%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho = | &#92;psi &#92;rangle &#92;langle &#92;psi |      &#92;equiv      &#92;begin{bmatrix}          &#92;alpha &#92;alpha^* &amp; &#92;alpha &#92;beta^*&#92;&#92;          &#92;beta &#92;alpha^* &amp; &#92;beta &#92;beta^*       &#92;end{bmatrix}  " class="latex" /></p>
<p>On the diagonal we get probabilities (<img src="https://s0.wp.com/latex.php?latex=%7C%5Calpha%7C%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;alpha|^2" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5Cbeta%7C%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;beta|^2" class="latex" />), whereas the off-diagonal terms (<img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5Cbeta%5E%2A&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;alpha &#92;beta^*" class="latex" /> and its complex conjugate) are related to the presence of quantum effects.  For example, for <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_-%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi_-&#92;rangle" class="latex" /> we get</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D++++++%5Cbegin%7Bbmatrix%7D++++++++++1%2F2+%26+-1%2F2%5C%5C++++++++++-1%2F2+%26+1%2F2+++++++%5Cend%7Bbmatrix%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho =      &#92;begin{bmatrix}          1/2 &amp; -1/2&#92;&#92;          -1/2 &amp; 1/2       &#92;end{bmatrix}  " class="latex" /></p>
<p>For an electron in the state <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|1&#92;rangle" class="latex" /> we get</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D++++++%5Cbegin%7Bbmatrix%7D++++++++++1+%26+0%5C%5C++++++++++0+%26+0+++++++%5Cend%7Bbmatrix%7D.++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho =      &#92;begin{bmatrix}          1 &amp; 0&#92;&#92;          0 &amp; 0       &#92;end{bmatrix}.  " class="latex" /></p>
<p>To calculate the energy, the recipe is the following:</p>
<p><img src="https://s0.wp.com/latex.php?latex=E+%3D+%5Cmathrm%7Btr%7D%5BH+%5Crho%5D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E = &#92;mathrm{tr}[H &#92;rho]  " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Btr%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{tr}" class="latex" /> is the &#8216;<a href="https://en.wikipedia.org/wiki/Trace_%28linear_algebra%29">trace</a>&#8216;: the sum of the diagonal entries.   For a <img src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n &#92;times n" class="latex" /> square matrix with entries <img src="https://s0.wp.com/latex.php?latex=A_%7Bij%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="A_{ij}" class="latex" /> its trace is</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Btr%7D%28A%29+%3D+A_%7B11%7D+%2B+A_%7B22%7D+%2B+%5Cldots+%2B+A_%7Bnn%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{tr}(A) = A_{11} + A_{22} + &#92;ldots + A_{nn}" class="latex" /></p>
<p><b>Exercise 3.</b>   Show that this formula for energy, and the previous one, give the same result on pure states.</p>
<p>I advertised that density matrices allow us to mix quantum states.  How do they do that? Very simple: just by adding density matrices, multiplied by the respective probabilities:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D+p_1+%5Crho_1+%2B+p_2+%5Crho_2+%2B+%5Ccdots+%2B+p_n+%5Crho_n+++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho = p_1 &#92;rho_1 + p_2 &#92;rho_2 + &#92;cdots + p_n &#92;rho_n   " class="latex" /></p>
<p>It is exactly how we would mix probability vectors.  Indeed, the diagonals are probability vectors!</p>
<p>So, let&#8217;s say that our co-worker was drunk and we are not sure if (s)he said that the state is <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_-%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi_-&#92;rangle" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|1&#92;rangle" class="latex" />. However, we think that the probabilities are <img src="https://s0.wp.com/latex.php?latex=1%2F3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1/3" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=2%2F3.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="2/3." class="latex" />  We get the density matrix:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D++++++%5Cbegin%7Bbmatrix%7D++++++++++5%2F6+%26+-1%2F6%5C%5C++++++++++-1%2F6+%26+1%2F6+++++++%5Cend%7Bbmatrix%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho =      &#92;begin{bmatrix}          5/6 &amp; -1/6&#92;&#92;          -1/6 &amp; 1/6       &#92;end{bmatrix}  " class="latex" /></p>
<p>So, how about its energy?</p>
<p><b>Exercise 4.</b>  Show that calculating energy using density matrix gives the same result as averaging energy over component pure states.</p>
<p>I may have given the impression that density matrix is an artificial thing, at best&mdash;a practical trick, and what we &#8216;really&#8217; have are pure states (vectors), each with a given probability. If so, the next exercise is for you:</p>
<p><b>Exercise 5.</b> Show that a 50%-50% mixture of <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|1&#92;rangle" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7C2%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|2&#92;rangle" class="latex" /> is the same as a 50%-50% mixture of <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_%2B%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi_+&#92;rangle" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_-%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|&#92;psi_-&#92;rangle" class="latex" />.</p>
<p>This is different than statistical mechanics, or statistics, where we can always think about probability distributions as uniquely defined statistical mixtures of possible states.  Here, as we see, it can be a bit more tricky.</p>
<p>As we said, for the diagonals things work as for classical probabilities. But there is more&mdash;at the same time as adding probabilities we also add the off-diagonal terms, which can add up to cancel, depending on their signs. It&#8217;s why it&#8217;s mixing quantum states may make them losing their quantum properties.</p>
<p>The value of the off-diagonal term is related to so-called &#8216;coherence&#8217; between the states <img src="https://s0.wp.com/latex.php?latex=%7C1%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|1&#92;rangle" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7C2%5Crangle&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|2&#92;rangle" class="latex" />. Its value is bounded by the respective probabilities:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C+%5Crho_%7B12%7D+%5Cright%7C+%5Cleq+%5Csqrt%7B%5Crho_%7B11%7D%5Crho_%7B22%7D%7D+%3D+%5Csqrt%7Bp_1+p_2%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;left| &#92;rho_{12} &#92;right| &#92;leq &#92;sqrt{&#92;rho_{11}&#92;rho_{22}} = &#92;sqrt{p_1 p_2}  " class="latex" /></p>
<p>where for pure states we get equality.</p>
<p>If the value is zero, there are no quantum effects between two positions: this means that the electron is sure to be at one place or the other, though we might be uncertain at which place. This is fundamentally different from a superposition (non-zero <img src="https://s0.wp.com/latex.php?latex=%5Crho_%7B12%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho_{12}" class="latex" />), where we are uncertain at which site a particle is, but it can no longer be thought to be at one site <em>or</em> the other: it must be in some way associated with both simultaneously.</p>
<p><b>Exercise 6.</b>  For each <img src="https://s0.wp.com/latex.php?latex=c+%5Cin+%5B-1%2C1%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c &#92;in [-1,1]" class="latex" /> propose how to obtain a mixed state described by density matrix</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D+++++++%5Cbegin%7Bbmatrix%7D++++++++++1%2F2+%26+c%2F2%5C%5C++++++++++c%2F2+%26+1%2F2+++++++%5Cend%7Bbmatrix%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho =       &#92;begin{bmatrix}          1/2 &amp; c/2&#92;&#92;          c/2 &amp; 1/2       &#92;end{bmatrix}  " class="latex" /></p>
<p>by mixing pure states of your choice.</p>
<h3> A spatial wavefunction </h3>
<p>A similar thing works for position. Instead of a two-level system let&#8217;s take a particle in one dimension. The analogue of a state vector is a wavefunction, a complex-valued function on a line:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cpsi%28x%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;psi(x) " class="latex" /></p>
<p>In this continuous variant, <img src="https://s0.wp.com/latex.php?latex=p%28x%29+%3D+%7C%5Cpsi%28x%29%7C%5E2&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(x) = |&#92;psi(x)|^2" class="latex" /> is the probability density of finding particle in one place.</p>
<p>We construct the density matrix (or rather: &#8216;density operator&#8217;) in an way that is analogous to what we did for the two-level system:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho%28x%2C+x%27%29+%3D+%5Cpsi%28x%29+%5Cpsi%5E%2A%28x%27%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho(x, x&#039;) = &#92;psi(x) &#92;psi^*(x&#039;) " class="latex" /></p>
<p>Instead of a 2&times;2 matrix matrix, it is a complex function of two real variables.  The probability density can be described by its diagonal values, i.e.</p>
<p><img src="https://s0.wp.com/latex.php?latex=p%28x%29+%3D+%5Crho%28x%2Cx%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(x) = &#92;rho(x,x)" class="latex" /></p>
<p>Again, we may wonder if the particle energetically favors being in many places at once.  Well, it does.</p>
<blockquote><p>
  Density matrices for a classical and quantum state. They yield the same probability distributions (for positions). However, their off-diagonal values (i.e. $x\neq x&#8217;$) are different. The classical state is just a probabilistic mixture of a particle being in a particular place.
</p></blockquote>
<div align="center"><a href="http://math.ucr.edu/home/baez/physical/migdal_superposition/mixture_vs_superposition.png"><img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/physical/migdal_superposition/mixture_vs_superposition.png" /></a></div>
<p>What would happen if we had a mixture of perfectly localized particles?  Due to <a href="https://en.wikipedia.org/wiki/Uncertainty_principle">Heisenberg&#8217;s uncertainly principle</a> we have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CDelta+x+%5CDelta+p+%5Cgeq+%5Cfrac%7B%5Chbar%7D%7B2%7D%2C+++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;Delta x &#92;Delta p &#92;geq &#92;frac{&#92;hbar}{2},   " class="latex" /></p>
<p>that is, that the product of <a href="https://en.wikipedia.org/wiki/Standard_deviation">standard deviations</a> of position and momentum is at least some value.</p>
<p>If we exactly know the position, then the uncertainty of momentum goes to infinity.  (The same thing holds if we don&#8217;t know position, but it can be known, even in principle. Quantum mechanics couldn&#8217;t care less if the particle&#8217;s position is known by us, by our friend, by our detector or by a dust particle.)</p>
<p>The Hamiltonian represents energy, the energy of <a href="http://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation">a free particle in continuous system</a> is</p>
<p><img src="https://s0.wp.com/latex.php?latex=H%3Dp%5E2%2F%282m%29++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H=p^2/(2m)  " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m" class="latex" /> is its mass, and <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> is its momentum: that is, mass times velocity.  So, if the particle is completely localized:</p>
<p>&bull; its energy is infinite,<br />
&bull; its velocity are infinite, so in no time its wavefunction will spread everywhere.</p>
<p>Infinite energies sometimes happen if physics. But if we get infinite velocities we see that there is something wrong. So a particle needs to be spread out, or &#8216;delocalized&#8217;, to some degree, to have finite energy.</p>
<blockquote><p>
  As a side note, to consider high energies we would need to employ special relativity. In fact, one cannot localize a massive particle that much, as it will create a soup of particles and antiparticles, once its energy related to momentum uncertainty is as much as the energy related to its mass; see <a href="https://en.wikipedia.org/wiki/Fine_structure">the Darwin term in the fine structure</a>.
</p></blockquote>
<p>Moreover, depending on the degree of its delocalization its behavior is different. For example, a statistical mixture of highly localized particles would spread a lot faster than the same $p(x)$ but derived from a single wavefunction.  The density matrix of the former would be in between of that of pure state (a &#8216;circular&#8217; Gaussian function) and the classical state (a &#8216;linear&#8217; Gaussian). That is, it would be an &#8216;oval&#8217; Gaussian, with off-diagonal values being smaller than for the pure state.</p>
<p>Let us look at two <a href="http://en.wikipedia.org/wiki/Gaussian_function">Gaussian wavefunctions</a>, with varying level of coherent superposition between them. That is, each Gaussian is already a superposition, but when we combine two we let ourselves use a superposition, or a mixture, or something in between.  For a perfect superposition of Gaussian, we would have the density matrix</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho%28x%2Cx%27%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%5Cphi%28x%2B%5Ctfrac%7Bd%7D%7B2%7D%29+%2B+%5Cphi%28x-%5Ctfrac%7Bd%7D%7B2%7D%29+%5Cright%29+%5Cleft%28+%5Cphi%28x%27%2B%5Ctfrac%7Bd%7D%7B2%7D%29+%2B+%5Cphi%28x%27-%5Ctfrac%7Bd%7D%7B2%7D%29+%5Cright%29++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho(x,x&#039;) = &#92;frac{1}{2} &#92;left( &#92;phi(x+&#92;tfrac{d}{2}) + &#92;phi(x-&#92;tfrac{d}{2}) &#92;right) &#92;left( &#92;phi(x&#039;+&#92;tfrac{d}{2}) + &#92;phi(x&#039;-&#92;tfrac{d}{2}) &#92;right)  " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Cphi%28x%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;phi(x)" class="latex" /> is a normalized Gaussian function.  For a statistical mixture between these Gaussians split by a distance of <img src="https://s0.wp.com/latex.php?latex=d%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="d," class="latex" /> we would have:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Crho%28x%2Cx%27%29+%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cphi%28x%2B%5Ctfrac%7Bd%7D%7B2%7D%29+%5Cphi%28x%27%2B%5Ctfrac%7Bd%7D%7B2%7D%29++%2B++%5Cfrac%7B1%7D%7B2%7D+%5Cphi%28x-%5Ctfrac%7Bd%7D%7B2%7D%29+%5Cphi%28x%27-%5Ctfrac%7Bd%7D%7B2%7D%29++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;rho(x,x&#039;) = &#92;frac{1}{2} &#92;phi(x+&#92;tfrac{d}{2}) &#92;phi(x&#039;+&#92;tfrac{d}{2})  +  &#92;frac{1}{2} &#92;phi(x-&#92;tfrac{d}{2}) &#92;phi(x&#039;-&#92;tfrac{d}{2})  " class="latex" /></p>
<p>And in general,</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Barray%7D%7Bccl%7D++%5Crho%28x%2Cx%27%29+%26%3D%26+%5Cfrac%7B1%7D%7B2%7D+%5Cleft%28+%5Cphi%28x%2B%5Ctfrac%7Bd%7D%7B2%7D%29+%5Cphi%28x%27%2B%5Ctfrac%7Bd%7D%7B2%7D%29++%2B++%5Cphi%28x-%5Ctfrac%7Bd%7D%7B2%7D%29+%5Cphi%28x%27-%5Ctfrac%7Bd%7D%7B2%7D%29%5Cright%29+%2B+%5C%5C+%5C%5C++%26%26+%5Cfrac%7Bc%7D%7B2%7D+%5Cleft%28+%5Cphi%28x%2B%5Ctfrac%7Bd%7D%7B2%7D%29+%5Cphi%28x%27-%5Ctfrac%7Bd%7D%7B2%7D%29++%2B+%5Cphi%28x-%5Ctfrac%7Bd%7D%7B2%7D%29+%5Cphi%28x%27%2B%5Ctfrac%7Bd%7D%7B2%7D%29+%5Cright%29++%5Cend%7Barray%7D++&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;begin{array}{ccl}  &#92;rho(x,x&#039;) &amp;=&amp; &#92;frac{1}{2} &#92;left( &#92;phi(x+&#92;tfrac{d}{2}) &#92;phi(x&#039;+&#92;tfrac{d}{2})  +  &#92;phi(x-&#92;tfrac{d}{2}) &#92;phi(x&#039;-&#92;tfrac{d}{2})&#92;right) + &#92;&#92; &#92;&#92;  &amp;&amp; &#92;frac{c}{2} &#92;left( &#92;phi(x+&#92;tfrac{d}{2}) &#92;phi(x&#039;-&#92;tfrac{d}{2})  + &#92;phi(x-&#92;tfrac{d}{2}) &#92;phi(x&#039;+&#92;tfrac{d}{2}) &#92;right)  &#92;end{array}  " class="latex" /></p>
<p>for some <img src="https://s0.wp.com/latex.php?latex=%7Cc%7C+%5Cleq+1.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="|c| &#92;leq 1." class="latex" /></p>
<blockquote><p>
  PICTURE: Two Gaussian wavefunctions (centered at -2 and +2) in a coherent superposition with each other (the first and the last plot) and a statistical mixture (the middle plot); the 2nd and 4th plot show intermediary states. Superposition can be with different phase, much like the hydrogen example.  <a href="http://nbviewer.ipython.org/github/empet/Math/blob/master/DomainColoring.ipynb">Color represents absolute value and hue phase</a>; here red is for positive numbers and teal is for negative.
</p></blockquote>
<div align="center"><a href="http://math.ucr.edu/home/baez/physical/migdal_superposition/mixture_gaussians_dm.png"><img width="450" src="https://i0.wp.com/math.ucr.edu/home/baez/physical/migdal_superposition/mixture_gaussians_dm.png" /></a></div>
<p>(Click to enlarge.)</p>
<h3> Conclusion </h3>
<p>We have seen learnt the difference between the quantum superposition and the statistical mixture of states. In particular, while both of these descriptions may give the same probabilities, their predictions on the physical properties of states differ. For example, we need an electron to be delocalized in a specific way to describe chemical bonds; and we need delocalization of any particle to predict its movement.</p>
<p>We used density matrices to express both quantum superposition and (classical) lack of knowledge on the same ground. We have identified its off-diagonal terms as ones related to the quantum coherence.</p>
<p>But what if there were not only two states, but many? So, instead of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BH%7D_2%5E%2B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{H}_2^+" class="latex" /> (we were not even considering the full hydrogen atom, but only its ionized version), how about electric excitation on something bigger? Not even <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BC%7D_2%5Cmathrm%7BH%7D_5%5Cmathrm%7BOH%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{C}_2&#92;mathrm{H}_5&#92;mathrm{OH}" class="latex" /> or some sugar, but a protein complex!</p>
<p>So, this will be your homework (cf. <a href="http://backreaction.blogspot.com.es/2014/07/youre-not-donut-and-not-mug-either.html">this homework on topology</a>). Just joking, there will be another blog post.</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2015/03/13/quantum-superposition/#comments">26 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2015/03/13/quantum-superposition/" rel="bookmark" title="Permanent Link to Quantum Superposition">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-19011 post type-post status-publish format-standard hentry category-information-and-entropy category-mathematics category-physics" id="post-19011">
				<h2><a href="https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/" rel="bookmark">A Second Law for Open Markov&nbsp;Processes</a></h2>
				<small>15 November, 2014</small><br />


				<div class="entry">
					<p><i>guest post by <b><a href="http://www.azimuthproject.org/azimuth/show/Blake+Pollard">Blake Pollard</a></b></i></p>
<p>What comes to mind when you hear the term &#8216;random process&#8217;? Do you think of Brownian motion? Do you think of particles hopping around? Do you think of a drunkard staggering home?</p>
<p>Today I’m going to tell you about a version of the drunkard’s walk with a few modifications. Firstly, we don’t have just one drunkard: we can have any positive real number of drunkards. Secondly, our drunkards have no memory; where they go next doesn’t depend on where they’ve been. Thirdly, there are special places, such as entrances to bars, where drunkards magically appear and disappear.</p>
<p>The second condition says that our drunkards satisfy the Markov property, making their random walk into a <b>Markov process</b>. The third condition is really what I want to tell you about, because it makes our Markov process into a more general ‘open Markov process’.</p>
<p>There are a collection of places the drunkards can be, for example:</p>
<p><img src="https://s0.wp.com/latex.php?latex=V%3D+%5C%7B+%5Ctext%7Bbar%7D%2C%5Ctext%7Bsidewalk%7D%2C+%5Ctext%7Bstreet%7D%2C+%5Ctext%7Btaco+truck%7D%2C+%5Ctext%7Bhome%7D+%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V= &#92;{ &#92;text{bar},&#92;text{sidewalk}, &#92;text{street}, &#92;text{taco truck}, &#92;text{home} &#92;} " class="latex" /></p>
<p>We call this set <img src="https://s0.wp.com/latex.php?latex=V&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V" class="latex" /> the set of <b>states</b>. There are certain probabilities associated with traveling between these places. We call these <b>transition rates</b>. For example it is more likely for a drunkard to go from the bar to the taco truck than to go from the bar to home so the transition rate between the bar and the taco truck should be greater than the transition rate from the bar to home. Sometimes you can’t get from one place to another without passing through intermediate places. In reality the drunkard can’t go directly from the bar to the taco truck: he or she has to go from the bar to sidewalk to the taco truck.</p>
<p>This information can all be summarized by drawing a directed graph where the positive numbers labelling the edges are the transition rates:</p>
<div align="center"><a href="http://math.ucr.edu/home/baez/mathematical/pollard_markov/drunkwalk.png"><img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/pollard_markov/drunkwalk.png" /></a></div>
<p>For simplicity we draw only three states: home, bar, taco truck. Drunkards go from home to the bar and back, but they never go straight from home to the taco truck.</p>
<p>We can keep track of where all of our drunkards are using a vector with 3 entries:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p%28t%29+%3D+%5Cleft%28+%5Cbegin%7Barray%7D%7Bc%7D+p_h%28t%29+%5C%5C+p_b%28t%29+%5C%5C+p_%7Btt%7D%28t%29+%5Cend%7Barray%7D+%5Cright%29+%5Cin+%5Cmathbb%7BR%7D%5E3+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p(t) = &#92;left( &#92;begin{array}{c} p_h(t) &#92;&#92; p_b(t) &#92;&#92; p_{tt}(t) &#92;end{array} &#92;right) &#92;in &#92;mathbb{R}^3 } " class="latex" /></p>
<p>We call this our <b>population distribution</b>. The first entry <img src="https://s0.wp.com/latex.php?latex=p_h&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_h" class="latex" /> is the number of drunkards that are at home, the second <img src="https://s0.wp.com/latex.php?latex=p_b&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_b" class="latex" /> is how many are at the bar, and the third <img src="https://s0.wp.com/latex.php?latex=p_%7Btt%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_{tt}" class="latex" /> is how many are at the taco truck.</p>
<p>There is a set of coupled, linear, first-order differential equations we can write down using the information in our graph that tells us how the number of drunkards in each place change with time.  This is called the <b>master equation</b>:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bd+p%7D%7Bd+t%7D+%3D+H+p+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{d p}{d t} = H p } " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=H&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H" class="latex" /> is a 3&times;3 matrix which we call the <b>Hamiltonian</b>. The off-diagonal entries are nonnegative:</p>
<p><img src="https://s0.wp.com/latex.php?latex=H_%7Bij%7D+%5Cgeq+0%2C+i+%5Cneq+j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H_{ij} &#92;geq 0, i &#92;neq j" class="latex" /></p>
<p>and the columns sum to zero:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Csum_i+H_%7Bij%7D%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sum_i H_{ij}=0" class="latex" /></p>
<p>We call a matrix satisfying these conditions <b>infinitesimal stochastic</b>. <b>Stochastic</b> matrices have columns that sum to one. If we take the exponential of an infinitesimal stochastic matrix we get one whose columns sum to one, hence the label &#8216;infinitesimal&#8217;.</p>
<p>The Hamiltonian for the graph above is</p>
<p><img src="https://s0.wp.com/latex.php?latex=H+%3D+%5Cleft%28+%5Cbegin%7Barray%7D%7Bccc%7D+-2+%26+5+%26+10+%5C%5C+2+%26+-12+%26+0+%5C%5C+0+%26+7+%26+-10+%5Cend%7Barray%7D+%5Cright%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="H = &#92;left( &#92;begin{array}{ccc} -2 &amp; 5 &amp; 10 &#92;&#92; 2 &amp; -12 &amp; 0 &#92;&#92; 0 &amp; 7 &amp; -10 &#92;end{array} &#92;right) " class="latex" /></p>
<p>John has written a lot about Markov processes and infinitesimal stochastic Hamiltonians in previous posts.</p>
<p>Given two vectors <img src="https://s0.wp.com/latex.php?latex=p%2Cq+%5Cin+%5Cmathbb%7BR%7D%5E3&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p,q &#92;in &#92;mathbb{R}^3" class="latex" /> describing the populations of drunkards which obey the same master equation, we can calculate the <b>relative entropy</b> of <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> relative to <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" />:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+S%28p%2Cq%29+%3D+%5Csum_%7B+i+%5Cin+V%7D+p_i+%5Cln+%5Cleft%28+%5Cfrac%7Bp_i%7D%7Bq_i%7D+%5Cright%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ S(p,q) = &#92;sum_{ i &#92;in V} p_i &#92;ln &#92;left( &#92;frac{p_i}{q_i} &#92;right) } " class="latex" /></p>
<p>This is an example of a &#8216;divergence&#8217;.  In statistics, a <a href="https://en.wikipedia.org/wiki/Divergence_%28statistics%29">divergence</a> a way of measuring the distance between probability distributions, which may not be symmetrical and may even not obey the triangle inequality.</p>
<p>The relative entropy is important because it decreases monotonically with time, making it a <a href="https://en.wikipedia.org/wiki/Lyapunov_function">Lyapunov function</a> for Markov processes. Indeed, it is a well known fact that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7BdS%28p%28t%29%2Cq%28t%29+%29+%7D+%7Bdt%7D+%5Cleq+0+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{dS(p(t),q(t) ) } {dt} &#92;leq 0 }" class="latex" /></p>
<p>This is true for any two population distributions which evolve according to the same master equation, though you have to allow infinity as a possible value for the relative entropy and negative infinity for its time derivative.</p>
<p>Why is entropy <i>decreasing?</i>  Doesn&#8217;t the Second Law of Thermodynamics say entropy <i>increases?</i></p>
<p>Don&#8217;t worry: the reason is that I have not put a minus sign in my definition of relative entropy.  Put one in if you like, and then it will increase.  Sometimes without the minus sign it&#8217;s called the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback&#8211;Leibler divergence</a>.  This <i>decreases</i> with the passage of time, saying that any two population distributions <img src="https://s0.wp.com/latex.php?latex=p%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q(t)" class="latex" /> get &#8216;closer together&#8217; as they get randomized with the passage of time.</p>
<p>That itself is a nice result, but I want to tell you what happens when you allow drunkards to appear and disappear at certain states. Drunkards appear at the bar once they’ve had enough to drink and once they are home for long enough they can disappear. The set of places where drunkards can appear or disappear <img src="https://s0.wp.com/latex.php?latex=B&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B" class="latex" /> is called the set of <b>boundary states</b>.  So for the above process</p>
<p><img src="https://s0.wp.com/latex.php?latex=B+%3D+%5C%7B+%5Ctext%7Bhome%7D%2C%5Ctext%7Bbar%7D+%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B = &#92;{ &#92;text{home},&#92;text{bar} &#92;}" class="latex" /></p>
<p>is the set of boundary states. This changes the way in which the population of drunkards changes with time!</p>
<p>The drunkards at the taco truck obey the master equation. For them,</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7Bdp_%7Btt%7D%7D%7Bdt%7D+%3D+7p_b+-10+p_%7Btt%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{dp_{tt}}{dt} = 7p_b -10 p_{tt} } " class="latex" /></p>
<p>still holds.  But because the populations can appear or disappear at the boundary states the master equation no longer holds at those states! Instead it is useful to define the flow of drunkards into the <img src="https://s0.wp.com/latex.php?latex=i%5E%7Bth%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i^{th}" class="latex" /> state by</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7BDp_i%7D%7BDt%7D+%3D+%5Cfrac%7Bdp_i%7D%7Bdt%7D-%5Csum_j+H_%7Bij%7D+p_j%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{Dp_i}{Dt} = &#92;frac{dp_i}{dt}-&#92;sum_j H_{ij} p_j} " class="latex" /></p>
<p>This quantity describes by how much the rate of change of the populations at the boundary states differ from that given by the master equation.</p>
<p>The reason why we are interested in open Markov processes is because you can take two open Markov processes and glue them together along some subset of their boundary states to get a new open Markov process! This allows us to build up or break down complicated Markov processes using open Markov processes as the building blocks.</p>
<p>For example we can draw the graph corresponding to the drunkards’ walk again, only now we will distinguish boundary states from internal states by coloring internal states blue and having boundary states be white:</p>
<div align="center"><a href="http://math.ucr.edu/home/baez/mathematical/pollard_markov/drunkopen.png"><img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/pollard_markov/drunkopen.png" /></a></div>
<p>Consider another open Markov process with states</p>
<p><img src="https://s0.wp.com/latex.php?latex=V%3D%5C%7B+%5Ctext%7Bhome%7D%2C%5Ctext%7Bwork%7D%2C%5Ctext%7Bbar%7D+%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="V=&#92;{ &#92;text{home},&#92;text{work},&#92;text{bar} &#92;}" class="latex" /></p>
<p>where</p>
<p><img src="https://s0.wp.com/latex.php?latex=B%3D%5C%7B+%5Ctext%7Bhome%7D%2C+%5Ctext%7Bbar%7D%5C%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B=&#92;{ &#92;text{home}, &#92;text{bar}&#92;} " class="latex" /></p>
<p>are the boundary states, leaving</p>
<p><img src="https://s0.wp.com/latex.php?latex=I%3D%5C%7B%5Ctext%7Bwork%7D%5C%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="I=&#92;{&#92;text{work}&#92;}" class="latex" /></p>
<p>as an internal state:</p>
<div align="center"><a href="http://math.ucr.edu/home/baez/mathematical/pollard_markov/drunkopen2.png"><img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/pollard_markov/drunkopen2.png" /></a></div>
<p>Since the boundary states of this process overlap with the boundary states of the first process we can compose the two to form a new Markov process:</p>
<div align="center"><a href="http://math.ucr.edu/home/baez/mathematical/pollard_markov/drunkcomposite.png"><img width="450" src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/pollard_markov/drunkcomposite.png" /></a></div>
<p>Notice the boundary states are now internal states. I hope any Markov process that could approximately model your behavior has more interesting nodes! There is a nice way to figure out the Hamiltonian of the composite from the Hamiltonians of the pieces, but we will leave that for another time.</p>
<p>We can ask ourselves, how does relative entropy change with time in open Markov processes?  You can read my paper for the details, but here is the punchline:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7BdS%28p%28t%29%2Cq%28t%29+%29+%7D%7Bdt%7D+%5Cleq+%5Csum_%7Bi+%5Cin+B%7D+%5Cfrac%7BDp_i%7D%7BDt%7D%5Cfrac%7B%5Cpartial+S%7D%7B%5Cpartial+p_i%7D+%2B+%5Cfrac%7BDq_i%7D%7BDt%7D%5Cfrac%7B%5Cpartial+S%7D%7B%5Cpartial+q_i%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{dS(p(t),q(t) ) }{dt} &#92;leq &#92;sum_{i &#92;in B} &#92;frac{Dp_i}{Dt}&#92;frac{&#92;partial S}{&#92;partial p_i} + &#92;frac{Dq_i}{Dt}&#92;frac{&#92;partial S}{&#92;partial q_i} } " class="latex" /></p>
<p>This is a version of the Second Law of Thermodynamics for open Markov processes.</p>
<p>It is important to notice that the sum is only over the boundary states! This inequality tells us that relative entropy still decreases inside our process, but depending on the flow of populations through the boundary states the relative entropy of the whole process could either increase or decrease! This inequality will be important when we study how the relative entropy changes in different parts of a bigger more complicated process.</p>
<p>That is all for now, but I leave it as an exercise for you to imagine a Markov process that describes your life. How many states does it have? What are the relative transition rates? Are there states you would like to spend more or less time in? Are there states somewhere you would like to visit?</p>
<p>Here is my paper, which proves the above inequality:</p>
<p>&bull; Blake Pollard, <a href="http://arxiv.org/abs/1410.6531">A Second Law for open Markov processes</a>, <i>Open Systems and Information Dynamics</i> <b>23</b> (2016), 1650006.</p>
<p>If you have comments or corrections, let me know!</p>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comments">29 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/" rel="category tag">information and entropy</a>, <a href="https://johncarlosbaez.wordpress.com/category/mathematics/" rel="category tag">mathematics</a>, <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/" rel="bookmark" title="Permanent Link to A Second Law for Open Markov&nbsp;Processes">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
			<div class="post-17954 post type-post status-publish format-standard hentry category-conferences category-networks category-physics category-quantum-technologies" id="post-17954">
				<h2><a href="https://johncarlosbaez.wordpress.com/2014/05/06/quantum-frontiers-in-network-science/" rel="bookmark">Quantum Frontiers in Network&nbsp;Science</a></h2>
				<small>6 May, 2014</small><br />


				<div class="entry">
					<p><i>guest post by <b><a href="http://www.azimuthproject.org/azimuth/show/Jacob+Biamonte">Jacob Biamonte</a></b></i></p>
<p>There&#8217;s going to be a workshop on <i>quantum network theory</i> in Berkeley this June.  The event is being organized by some of my collaborators and will be a satellite of the biggest annual network science conference, <a href="http://www.netsci2014.net/">NetSci</a>.  </p>
<p>A theme of the <a href="http://math.ucr.edu/home/baez/networks/">Network Theory</a> series here on Azimuth has been to merge ideas appearing in quantum theory with other disciplines. Remember the <a href="http://math.ucr.edu/home/baez/networks/networks_1.html">first post</a> by John which outlined the goal of a general theory of networks?  Well, everyone&#8217;s been chipping away at this stuff for a few years now and I think you&#8217;ll agree that this workshop seems like an excellent way to push these topics even further, particularly as they apply to complex networks.  </p>
<p>The event is being organized by <a href="http://www.azimuthproject.org/azimuth/show/Mauro+Faccin">Mauro Faccin</a>, <a href="http://filrad.homelinux.org/">Filippo Radicchi</a> and <a href="http://www.azimuthproject.org/azimuth/show/Zolt%C3%A1n+Zimbor%C3%A1s">Zoltán Zimborás</a>.  You might recall when <a href="http://www.azimuthproject.org/azimuth/show/Tomi+Johnson">Tomi Johnson</a> first explained to us some ideas connecting quantum physics with the concepts of  complex networks (see <a href="https://johncarlosbaez.wordpress.com/2013/08/05/quantum-network-theory-part-1/">Quantum Network Theory Part 1</a> and <a href="https://johncarlosbaez.wordpress.com/2013/08/13/quantum-network-theory-part-2/">Part 2</a>).  Tomi&#8217;s going to be speaking at this event.  I understand there is even still a little bit of space left to contribute talks and/or to attend.  I suspect that those interested can sort this out by emailing the organizers or just <a href="http://www.thequantumnetwork.org/quantum-frontiers-netsci2014/call-for-abstracts/">follow the instructions to submit an abstract</a>.  </p>
<p>They have named their event <i>Quantum Frontiers in Network Science</i> or QNET for short.  Here&#8217;s their call.      </p>
<div style="background:#fff1f1;border:solid black;border-width:2px 1px;padding:0 1em;margin:0 1em;overflow:auto;">
<p><b>Quantum Frontiers in Network Science</b></p>
<p>This year the biggest annual network science conference, NetSci will take place in Berkeley California on 2-6 June. We are organizing a one-day Satellite Workshop on Quantum Frontiers in Network Science (QNET).</p>
<div align="center">
<img src="https://i0.wp.com/www.netsci2014.net/images/cropped_banner_2014_blueRed_view.jpg" width="400" alt="quantum netsci2014" />
</div>
<p>A grand challenge in contemporary complex network science is to reconcile the staple “statistical mechanics based approach” with a theory based on quantum physics. When considering networks where quantum coherence effects play a non-trivial role, the predictive power of complex network science has been shown to break down. A new theory is now being developed which is based on quantum theory, from first principles. Network theory is a diverse subject which developed independently in several disciplines to rely on graphs with additional structure to model complex systems. Network science has of course played a significant role in quantum theory, for example in topics such as tensor network states, chiral quantum walks on complex networks, categorical tensor networks, and categorical models of quantum circuits, to name only a few. However, the ideas of complex network science are only now starting to be united with modern quantum theory. From this respect, one aim of the workshop is to put in contact two big and generally not very well connected scientific communities: statistical and quantum physicists.</p>
<p>The topic of network science underwent a revolution when it was realized that systems such as social or transport networks could be interrelated through common network properties, but what are the relevant properties to consider when facing quantum systems? This question is particularly timely as there has been a recent push towards studying increasingly larger quantum mechanical systems, where the analysis is only beginning to undergo a shift towards embracing the concepts of complex networks.</p>
<div align="center">
<img src="https://i2.wp.com/www.thequantumnetwork.org/wp-content/uploads/2014/01/tensor-network-invariants-a.png" width="300" alt="brain network" />
</div>
<p>For example, theoretical and experimental attention has turned to explaining transport in photosynthetic complexes comprising tens to hundreds of molecules and thousands of atoms using quantum mechanics. Likewise, in condensed matter physics using the language of “chiral quantum walks”, the topological structure of the interconnections comprising complex materials strongly affects their transport properties.</p>
<p>An ultimate goal is a mathematical theory and formal description which pinpoints the similarities and differences between the use of networks throughout the quantum sciences. This would give rise to a theory of networks augmenting the current statistical mechanics approach to complex network structure, evolution, and process with a new theory based on quantum mechanics.</p>
<p><b>Topics of special interest to the satellite include</b></p>
<p>&bull; Quantum transport and chiral quantum walks on complex networks <br />
&bull; Detecting community structure in quantum systems<br />
&bull; Tensor algebra and multiplex networks<br />
&bull; Quantum information measures (such as entropy) applied to complex networks<br />
&bull; Quantum critical phenomena in complex networks<br />
&bull; Quantum models of network growth<br />
&bull; Quantum techniques for reaction networks<br />
&bull; Quantum algorithms for problems in complex network science<br />
&bull; Foundations of quantum theory in relation to complex networks and processes thereon<br />
&bull; Quantum inspired mathematics as a foundation for network science</p>
<p><b>Info</b></p>
<p>QNET will be held at the NetSci Conference venue at the Clark Kerr Campus of the University of California, on June 2nd in the morning (8am-1pm).</p>
<p><b>Links</b></p>
<p>&bull; Main conference page: <a href="http://www.netsci2014.net/">NetSci2014</a><br />
&bull; <a href="http://www.thequantumnetwork.org/quantum-frontiers-for-network-science-satellite-netsci2014/">Call for abstracts and the program</a></p>
</div>
<p>It sounds interesting!  You&#8217;ll notice that the list of topics seems reminiscent of some of the things we&#8217;ve been talking about right here on Azimuth!  A general theme of the <a href="http://math.ucr.edu/home/baez/networks/">Network Theory Series</a> has been geared towards developing frameworks to describe networked systems through a <i>common language</i> and then to map the use of tools and results across disciplines.  It seems like a great place to talk about these ideas.  Oh, and here&#8217;s a current list of the speakers:</p>
<p>&bull; <a href="http://iris.ucl.ac.uk/iris/browse/profile?upi=LBANC26">Leonardo Banchi</a> (UCL, London)<br />
&bull; <a href="http://www.maths.qmul.ac.uk/~gbianconi/">Ginestra Bianconi</a> (London)<br />
&bull; <a href="https://plus.google.com/104764835065704561257/posts">Silvano Garnerone</a> (IQC, Waterloo)<br />
&bull; <a href="http://www.lps.ens.fr/~laetitia/">Laetitia Gauvin</a> (ISI Foundation)<br />
&bull; <a href="https://sites.google.com/site/marcojavarone/">Marco Javarone</a> (Sassari)<br />
&bull; <a href="http://www.azimuthproject.org/azimuth/show/Tomi+Johnson">Tomi Johnson</a> (Oxford)</p>
<p>and again, the organizers are </p>
<p>&bull; <a href="http://www.azimuthproject.org/azimuth/show/Mauro+Faccin">Mauro Faccin</a> (ISI Foundation)<br />
&bull; <a href="http://filrad.homelinux.org/">Filippo Radicchi</a> (Indiana University)<br />
&bull; <a href="http://www.azimuthproject.org/azimuth/show/Zolt%C3%A1n+Zimbor%C3%A1s">Zoltán Zimborás</a> (UCL)</p>
<p>From the call, we can notice that a central discussion topic at QNET will be about contrasting stochastic and quantum mechanics.  Here on Azimuth we like this stuff.  You might remember that <i>stochastic mechanics</i> was formulated in the network theory series to mathematically resemble quantum theory (see e.g. <a href="http://math.ucr.edu/home/baez/networks/networks_12.html">Part 12</a>).  This formalism was then employed to produce several results, including a stochastic version of Noether&#8217;s theorem by John and Brendan in <a href="http://math.ucr.edu/home/baez/networks/networks_11.html">Parts 11</a> and <a href="http://math.ucr.edu/home/baez/networks/networks_13.html">13</a>&#8212;recently Ville has also written <a href="https://johncarlosbaez.wordpress.com/2014/05/03/noethers-theorem-quantum-vs-stochastic/">Noether’s Theorem: Quantum vs Stochastic</a>.  Several other results were produced by relating quantum field theory to Petri nets from population biology and to chemical reaction networks in chemistry (see the <a href="http://math.ucr.edu/home/baez/networks">Network Theory</a> homepage).  It seems to me that people attending QNET will be interested in these sorts of things, as well as other related topics.  </p>
<p>One of the features of complex network science is that it is often numerically based and geared directly towards interesting real-world applications.  I suspect some interesting results should stem from the discussions that will take place at this workshop.  </p>
<p>By the way, here&#8217;s a view of downtown San Francisco at dusk from Berkeley Hills California from the <a href="http://www.netsci2014.net/">NetSci homepage</a>: </p>
<div align="center">
<img src="https://i0.wp.com/www.netsci2014.net/images/downtown.jpg" width="450" alt="San Francisco" />
</div>
									</div>

				<p class="postmetadata">
				<img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/speech_bubble.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2014/05/06/quantum-frontiers-in-network-science/#comments">4 Comments</a>				| <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/documents.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/category/conferences/" rel="category tag">conferences</a>, <a href="https://johncarlosbaez.wordpress.com/category/networks/" rel="category tag">networks</a>, <a href="https://johncarlosbaez.wordpress.com/category/physics/" rel="category tag">physics</a>, <a href="https://johncarlosbaez.wordpress.com/category/quantum-technologies/" rel="category tag">quantum technologies</a>								 | <img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/permalink.gif" alt="" /> <a href="https://johncarlosbaez.wordpress.com/2014/05/06/quantum-frontiers-in-network-science/" rel="bookmark" title="Permanent Link to Quantum Frontiers in Network&nbsp;Science">Permalink</a>
<br /><img src="https://s2.wp.com/wp-content/themes/pub/contempt/images/blog/figure_ver1.gif" alt="" /> Posted by John Baez				</p>
			</div>
			<hr />
		
		<div class="navigation">
			<div class="alignleft"><a href="https://johncarlosbaez.wordpress.com/page/8/?s=information+and+entropy" >&laquo; Previous Entries</a></div>
			<div class="alignright"><a href="https://johncarlosbaez.wordpress.com/page/6/?s=information+and+entropy" >Next Entries &raquo;</a></div>
		</div>

	
	</div>

	<div id="sidebar">
				<ul>

		 <li>

				<p>You have searched the <a href="https://johncarlosbaez.wordpress.com/">Azimuth</a> blog archives for <strong>&#8216;information and entropy&#8217;</strong>. If you are unable to find anything in these search results, you can try one of these links.</p>

					</li> 
		<li id="recent-posts-3" class="widget widget_recent_entries">
		<h2 class="widgettitle">latest posts:</h2>

		<ul>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/26/classical-mechanics-versus-thermodynamics-part-4/">Classical Mechanics versus Thermodynamics (Part&nbsp;4)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/">Classical Mechanics versus Thermodynamics (Part&nbsp;3)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/22/maxwells-relations-part-3/">Maxwell&#8217;s Relations (Part&nbsp;3)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/18/maxwells-relations-part-two/">Maxwell&#8217;s Relations (Part&nbsp;2)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/17/maxwells-relations-part-1/">Maxwell&#8217;s Relations (Part&nbsp;1)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/09/13/the-cyclic-identity-for-partial-derivatives/">The Cyclic Identity for Partial&nbsp;Derivatives</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/17/information-geometry-part-21/">Information Geometry (Part&nbsp;21)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/14/information-geometry-part-20/">Information Geometry (Part&nbsp;20)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/08/information-geometry-part-19/">Information Geometry (Part&nbsp;19)</a>
									</li>
											<li>
					<a href="https://johncarlosbaez.wordpress.com/2021/08/05/information-geometry-part-18/">Information Geometry (Part&nbsp;18)</a>
									</li>
					</ul>

		</li>
<li id="recent-comments-2" class="widget widget_recent_comments"><h2 class="widgettitle">latest comments:</h2>
				<table class="recentcommentsavatar" cellspacing="0" cellpadding="0" border="0">
					<tr><td title="Toby Bartels" class="recentcommentsavatartop" style="height:32px; width:32px;"><a href="http://tobybartels.name/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/68c7b083965f5073c50bf7c8d2aac358?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstexttop" style=""><a href="http://tobybartels.name/" rel="nofollow">Toby Bartels</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172598">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="David Corfield" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">David Corfield on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172597">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="Toby Bartels" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://tobybartels.name/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/68c7b083965f5073c50bf7c8d2aac358?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://tobybartels.name/" rel="nofollow">Toby Bartels</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/26/classical-mechanics-versus-thermodynamics-part-4/#comment-172596">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="David Corfield" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://lh3.googleusercontent.com/a/AATXAJxXcoKzwm_cY3LJp3qldhAQvZVoBimQd4xe5tDl=s96-c' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">David Corfield on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172590">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="amarashiki" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://gravatar.com/amarashiki" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/62b2df0762257e75433ad6f161488c3a?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://gravatar.com/amarashiki" rel="nofollow">amarashiki</a> on <a href="https://johncarlosbaez.wordpress.com/2012/01/23/classical-mechanics-versus-thermodynamics-part-2/#comment-172566">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="John Baez" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://math.ucr.edu/home/baez/" rel="nofollow"><img alt='' src='https://0.gravatar.com/avatar/34784534843022b3541c8ddd693718cb?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></a></td><td class="recentcommentstextend" style=""><a href="http://math.ucr.edu/home/baez/" rel="nofollow">John Baez</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172560">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="domenico" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://2.gravatar.com/avatar/ba06491deb8346d20356ac2ae05893ee?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">domenico on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172559">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="domenico" class="recentcommentsavatarend" style="height:32px; width:32px;"><img alt='' src='https://2.gravatar.com/avatar/ba06491deb8346d20356ac2ae05893ee?s=32&#038;d=identicon&#038;r=G' class='avatar avatar-32' height='32' width='32' /></td><td class="recentcommentstextend" style="">domenico on <a href="https://johncarlosbaez.wordpress.com/2021/09/23/classical-mechanics-versus-thermodynamics-part-3/#comment-172558">Classical Mechanics versus The&hellip;</a></td></tr><tr><td title="Maxwell Relations | Equivalent eXchange" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow"></a></td><td class="recentcommentstextend" style=""><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow">Maxwell Relations |&hellip;</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/22/maxwells-relations-part-3/#comment-172557">Maxwell&#8217;s Relations (Par&hellip;</a></td></tr><tr><td title="Maxwell Relations | Equivalent eXchange" class="recentcommentsavatarend" style="height:32px; width:32px;"><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow"></a></td><td class="recentcommentstextend" style=""><a href="http://equivalentexchange.blog/2021/09/25/maxwell-relations/" rel="nofollow">Maxwell Relations |&hellip;</a> on <a href="https://johncarlosbaez.wordpress.com/2021/09/18/maxwells-relations-part-two/#comment-172556">Maxwell&#8217;s Relations (Par&hellip;</a></td></tr>				</table>
				</li>
<li id="text-3" class="widget widget_text"><h2 class="widgettitle">How To Write Math Here:</h2>
			<div class="textwidget"><p>You can <a href="http://en.wikibooks.org/wiki/LaTeX/Mathematics">include math in your comments using LaTeX</a>,  but you need to do it this way:</p>
<p>&#036;latex  E = mc^2&#036;</p>
<p>You need the word 'latex' right after the first dollar sign, and it needs a space after it.  Double dollar signs don't work, and other limitations apply, some described <a href="http://en.support.wordpress.com/latex/">here</a>.  You can't preview comments here, but I'm happy to fix errors.</p>
</div>
		</li>
<li id="categories-2" class="widget widget_categories"><h2 class="widgettitle">Read Posts On:</h2>

			<ul>
					<li class="cat-item cat-item-177"><a href="https://johncarlosbaez.wordpress.com/category/art/">art</a> (3)
</li>
	<li class="cat-item cat-item-4003"><a href="https://johncarlosbaez.wordpress.com/category/astronomy/">astronomy</a> (29)
</li>
	<li class="cat-item cat-item-8262191"><a href="https://johncarlosbaez.wordpress.com/category/azimuth/">azimuth</a> (60)
</li>
	<li class="cat-item cat-item-86856"><a href="https://johncarlosbaez.wordpress.com/category/biodiversity/">biodiversity</a> (38)
</li>
	<li class="cat-item cat-item-4936"><a href="https://johncarlosbaez.wordpress.com/category/biology/">biology</a> (107)
</li>
	<li class="cat-item cat-item-355244"><a href="https://johncarlosbaez.wordpress.com/category/carbon-emissions/">carbon emissions</a> (78)
</li>
	<li class="cat-item cat-item-5936"><a href="https://johncarlosbaez.wordpress.com/category/chemistry/">chemistry</a> (74)
</li>
	<li class="cat-item cat-item-6108"><a href="https://johncarlosbaez.wordpress.com/category/climate/">climate</a> (155)
</li>
	<li class="cat-item cat-item-5043"><a href="https://johncarlosbaez.wordpress.com/category/computer-science/">computer science</a> (57)
</li>
	<li class="cat-item cat-item-9204"><a href="https://johncarlosbaez.wordpress.com/category/conferences/">conferences</a> (81)
</li>
	<li class="cat-item cat-item-1098"><a href="https://johncarlosbaez.wordpress.com/category/culture/">culture</a> (4)
</li>
	<li class="cat-item cat-item-657"><a href="https://johncarlosbaez.wordpress.com/category/economics/">economics</a> (32)
</li>
	<li class="cat-item cat-item-1212"><a href="https://johncarlosbaez.wordpress.com/category/energy/">energy</a> (50)
</li>
	<li class="cat-item cat-item-25393"><a href="https://johncarlosbaez.wordpress.com/category/engineering/">engineering</a> (11)
</li>
	<li class="cat-item cat-item-14852"><a href="https://johncarlosbaez.wordpress.com/category/mathematics/game-theory/">game theory</a> (29)
</li>
	<li class="cat-item cat-item-1215"><a href="https://johncarlosbaez.wordpress.com/category/geography/">geography</a> (4)
</li>
	<li class="cat-item cat-item-337"><a href="https://johncarlosbaez.wordpress.com/category/health/">health</a> (4)
</li>
	<li class="cat-item cat-item-678"><a href="https://johncarlosbaez.wordpress.com/category/history/">history</a> (2)
</li>
	<li class="cat-item cat-item-23375499"><a href="https://johncarlosbaez.wordpress.com/category/information-and-entropy/">information and entropy</a> (92)
</li>
	<li class="cat-item cat-item-3558"><a href="https://johncarlosbaez.wordpress.com/category/jobs/">jobs</a> (11)
</li>
	<li class="cat-item cat-item-5465"><a href="https://johncarlosbaez.wordpress.com/category/journals/">journals</a> (5)
</li>
	<li class="cat-item cat-item-3582"><a href="https://johncarlosbaez.wordpress.com/category/mathematics/">mathematics</a> (479)
</li>
	<li class="cat-item cat-item-18"><a href="https://johncarlosbaez.wordpress.com/category/music/">music</a> (3)
</li>
	<li class="cat-item cat-item-3968"><a href="https://johncarlosbaez.wordpress.com/category/networks/">networks</a> (185)
</li>
	<li class="cat-item cat-item-154934"><a href="https://johncarlosbaez.wordpress.com/category/oceans/">oceans</a> (13)
</li>
	<li class="cat-item cat-item-1211"><a href="https://johncarlosbaez.wordpress.com/category/physics/">physics</a> (205)
</li>
	<li class="cat-item cat-item-10451"><a href="https://johncarlosbaez.wordpress.com/category/probability/">probability</a> (92)
</li>
	<li class="cat-item cat-item-4909"><a href="https://johncarlosbaez.wordpress.com/category/psychology/">psychology</a> (6)
</li>
	<li class="cat-item cat-item-3330"><a href="https://johncarlosbaez.wordpress.com/category/publishing/">publishing</a> (19)
</li>
	<li class="cat-item cat-item-46615"><a href="https://johncarlosbaez.wordpress.com/category/puzzles/">puzzles</a> (14)
</li>
	<li class="cat-item cat-item-4140243"><a href="https://johncarlosbaez.wordpress.com/category/quantum-technologies/">quantum technologies</a> (28)
</li>
	<li class="cat-item cat-item-562"><a href="https://johncarlosbaez.wordpress.com/category/questions/">questions</a> (3)
</li>
	<li class="cat-item cat-item-93974"><a href="https://johncarlosbaez.wordpress.com/category/risks/">risks</a> (48)
</li>
	<li class="cat-item cat-item-37893"><a href="https://johncarlosbaez.wordpress.com/category/seminars/">seminars</a> (21)
</li>
	<li class="cat-item cat-item-581"><a href="https://johncarlosbaez.wordpress.com/category/software/">software</a> (19)
</li>
	<li class="cat-item cat-item-39438"><a href="https://johncarlosbaez.wordpress.com/category/strategies/">strategies</a> (36)
</li>
	<li class="cat-item cat-item-6877"><a href="https://johncarlosbaez.wordpress.com/category/sustainability/">sustainability</a> (71)
</li>
	<li class="cat-item cat-item-66608272"><a href="https://johncarlosbaez.wordpress.com/category/the-practice-of-science/">the practice of science</a> (27)
</li>
	<li class="cat-item cat-item-61590"><a href="https://johncarlosbaez.wordpress.com/category/this-weeks-finds/">this week&#039;s finds</a> (18)
</li>
			</ul>

			</li>
<li id="linkcat-20924250" class="widget widget_links"><h2 class="widgettitle">also visit these:</h2>

	<ul class='xoxo blogroll'>
<li><a href="http://www.azimuthproject.org/azimuth/show/Azimuth+Blog" title="Go here to see what’s on this blog, organized by topic or author!">Azimuth Blog Overview</a></li>
<li><a href="http://www.azimuthproject.org/azimuth/show/HomePage" title="for scientists and engineers who want to save the planet">Azimuth Project</a></li>
<li><a href="http://bittooth.blogspot.com/" title="David Summers on energy: oil, gas and more">Bit Tooth Energy</a></li>
<li><a href="http://bravenewclimate.com/" title="Barry Brooks on climate and energy policy">Brave New Climate</a></li>
<li><a href="http://physics.ucsd.edu/do-the-math/" title="UC San Diego prof uses physics and estimation to assess energy, growth, options">Do the Math</a></li>
<li><a href="http://dotearth.blogs.nytimes.com/" title="Andrew Revkin’s environmental blog on the New York Times">Dot Earth</a></li>
<li><a href="http://e360.yale.edu/" title="News from the Yale School of Forestry &amp; Environmental Studies">Environment 360</a></li>
<li><a href="http://planet3.org/" title="A metablog on sustainability">Planet3.0</a></li>
<li><a href="http://www.realclimate.org/" title="climate science from climate scientists">RealClimate</a></li>
<li><a href="http://www.easterbrook.ca/steve/" title="Steve Easterbrook&#8217;s blog on software engineering and climate modeling">Serendipity</a></li>
<li><a href="http://scienceofdoom.com/" title="climate science in perspective">The Science of Doom</a></li>
<li><a href="http://e360.yale.edu/" title="opinion, analysis, reporting and debate on environmental issues">Yale Environment 360</a></li>

	</ul>
</li>

<li id="rss_links-3" class="widget widget_rss_links"><h2 class="widgettitle">RSS feeds:</h2>
<p class="size-small"><a class="feed-image-link" href="https://johncarlosbaez.wordpress.com/feed/" title="Subscribe to Posts"><img src="https://johncarlosbaez.wordpress.com/i/rss/red-small.png?m=1391188133h" alt="RSS Feed" /></a>&nbsp;<a href="https://johncarlosbaez.wordpress.com/feed/" title="Subscribe to Posts">RSS - Posts</a></p><p class="size-small"><a class="feed-image-link" href="https://johncarlosbaez.wordpress.com/comments/feed/" title="Subscribe to Comments"><img src="https://johncarlosbaez.wordpress.com/i/rss/red-small.png?m=1391188133h" alt="RSS Feed" /></a>&nbsp;<a href="https://johncarlosbaez.wordpress.com/comments/feed/" title="Subscribe to Comments">RSS - Comments</a></p>
</li>
<li id="blog_subscription-3" class="widget widget_blog_subscription jetpack_subscription_widget"><h2 class="widgettitle"><label for="subscribe-field">Email Subscription:</label></h2>

			<form
				action="https://subscribe.wordpress.com"
				method="post"
				accept-charset="utf-8"
				id=""
			>
				<p>Enter your email address to subscribe to this blog and receive notifications of new posts by email.</p>
					<div class="jetpack-subscribe-count">
						<p>
						Join 5,228 other followers						</p>
					</div>
									<p id="subscribe-email">
					<label
						id="subscribe-field-label"
						for="subscribe-field"
						class="screen-reader-text"
					>
						Email Address:					</label>

					<input
							type="email"
							name="email"
							
							style="width: 95%; padding: 1px 10px"
							placeholder="Enter your email address"
							value=""
							id="subscribe-field"
						/>				</p>

				<p id="subscribe-submit"
									>
                    <input type="hidden" name="action" value="subscribe"/>
                    <input type="hidden" name="blog_id" value="12777403"/>
                    <input type="hidden" name="source" value="https://johncarlosbaez.wordpress.com/page/7/?s=information+and+entropy"/>
                    <input type="hidden" name="sub-type" value="widget"/>
                    <input type="hidden" name="redirect_fragment" value="blog_subscription-3"/>
					<input type="hidden" id="_wpnonce" name="_wpnonce" value="ffcb185558" />                    <button type="submit"
	                    	                        class="wp-block-button__link"
	                    		                	                >
	                    Sign me up!                    </button>
                </p>
            </form>
			
</li>
<li id="search-3" class="widget widget_search"><h2 class="widgettitle">SEARCH:</h2>
<form method="get" id="searchform" action="https://johncarlosbaez.wordpress.com/">
<div><label for="s" class="search-label">Search</label><input type="text" value="information and entropy" name="s" id="s" />
<input type="submit" id="searchsubmit" value="Search" />
</div>
</form></li>
<li id="blog-stats-2" class="widget widget_blog-stats"><h2 class="widgettitle">Blog Stats:</h2>
		<ul>
			<li>4,177,577 hits</li>
		</ul>
		</li>
		</ul>
	</div>



<div id="footer">
	<p>
	<br />
	<a href="https://wordpress.com/?ref=footer_blog" rel="nofollow">Blog at WordPress.com.</a>
	</p>
</div>

</div>

		<!--  -->
<script src='//0.gravatar.com/js/gprofiles.js?ver=202138y' id='grofiles-cards-js'></script>
<script id='wpgroho-js-extra'>
var WPGroHo = {"my_hash":""};
</script>
<script crossorigin='anonymous' type='text/javascript' src='https://s1.wp.com/wp-content/mu-plugins/gravatar-hovercards/wpgroho.js?m=1610363240h'></script>

	<script>
		// Initialize and attach hovercards to all gravatars
		( function() {
			function init() {
				if ( typeof Gravatar === 'undefined' ) {
					return;
				}

				if ( typeof Gravatar.init !== 'function' ) {
					return;
				}

				Gravatar.profile_cb = function ( hash, id ) {
					WPGroHo.syncProfileData( hash, id );
				};

				Gravatar.my_hash = WPGroHo.my_hash;
				Gravatar.init( 'body', '#wp-admin-bar-my-account' );
			}

			if ( document.readyState !== 'loading' ) {
				init();
			} else {
				document.addEventListener( 'DOMContentLoaded', init );
			}
		} )();
	</script>

		<div style="display:none">
	<div class="grofile-hash-map-68c7b083965f5073c50bf7c8d2aac358">
	</div>
	<div class="grofile-hash-map-34784534843022b3541c8ddd693718cb">
	</div>
	<div class="grofile-hash-map-7d52fbe20c8ac05886a296e9ee2159b1">
	</div>
	<div class="grofile-hash-map-62b2df0762257e75433ad6f161488c3a">
	</div>
	<div class="grofile-hash-map-ba06491deb8346d20356ac2ae05893ee">
	</div>
	</div>

<script>
window.addEventListener( "load", function( event ) {
	var link = document.createElement( "link" );
	link.href = "https://s0.wp.com/wp-content/mu-plugins/actionbar/actionbar.css?v=20210915";
	link.type = "text/css";
	link.rel = "stylesheet";
	document.head.appendChild( link );

	var script = document.createElement( "script" );
	script.src = "https://s0.wp.com/wp-content/mu-plugins/actionbar/actionbar.js?v=20210920";
	script.defer = true;
	document.body.appendChild( script );
} );
</script>

	<script crossorigin='anonymous' type='text/javascript' src='https://s2.wp.com/_static/??-eJx9jksOwjAMRC9EarWLSl0gzpImVuXQfLAd2t6eVAIJsWA1nrGePbAV43JSTApBwOOTHJa9C3KBr1Wspqx1oSRgfaRkZssQrShym4yydXf5hdq98KjIx1u6rbgcTeG8H4axZaIfhpJbq0c5oWYxzui79uhPkY38giogdRbHVJRyOjvc4rUfh2nqh2Hswwtq4FN0'></script>
<script type="text/javascript">
// <![CDATA[
(function() {
try{
  if ( window.external &&'msIsSiteMode' in window.external) {
    if (window.external.msIsSiteMode()) {
      var jl = document.createElement('script');
      jl.type='text/javascript';
      jl.async=true;
      jl.src='/wp-content/plugins/ie-sitemode/custom-jumplist.php';
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(jl, s);
    }
  }
}catch(e){}
})();
// ]]>
</script><script src="//stats.wp.com/w.js?62" defer></script> <script type="text/javascript">
_tkq = window._tkq || [];
_stq = window._stq || [];
_tkq.push(['storeContext', {'blog_id':'12777403','blog_tz':'0','user_lang':'en','blog_lang':'en','user_id':'0'}]);
_stq.push(['view', {'blog':'12777403','v':'wpcom','tz':'0','user_id':'0','subd':'johncarlosbaez'}]);
_stq.push(['extra', {'crypt':'UE40eW5QN0p8M2Y/RE1TaVhzUzFMbjdWNHpwZGhTayxPSUFCMGNrd29+Smw0TDhnZmRTK0hlRi9QSGh6bi9GXVhBJWIlZlR5U1JMLU8/MkNtblkvY1d6eVImTEouL2UleTBRZmlNdkp0aWJaNFJhPS0uTVpHa1hIc25EbVJyQmw/SkZ+Q3lLcjU/NDBvQTZnVzVKW2VqN2ZlfC5WbGQ/MTY9dmIxVytZNy5qYUxVXWRxMml5PURScmNEN1BzfnFKV1FEVEpPS2JwRU1GVj9ELFM9JXNjM24tais1N1MlejRVRHl2X3lkN3RJZEolU24/LHZnSHB4YUdPTlMzZ1pwMFddR1prVWU2MnJQLW18cF1JSGxTTF1kWUtsNmZrOXM9N1A9NVg/LyxxWmRSak1QLmdQTElIeTM3VDJLU1hUSlhyPXVILHUuLksuR01UUzliLEwu'}]);
_stq.push([ 'clickTrackerInit', '12777403', '0' ]);
	</script>
<noscript><img src="https://pixel.wp.com/b.gif?v=noscript" style="height:1px;width:1px;overflow:hidden;position:absolute;bottom:1px;" alt="" /></noscript>
<script>
if ( 'object' === typeof wpcom_mobile_user_agent_info ) {

	wpcom_mobile_user_agent_info.init();
	var mobileStatsQueryString = "";
	
	if( false !== wpcom_mobile_user_agent_info.matchedPlatformName )
		mobileStatsQueryString += "&x_" + 'mobile_platforms' + '=' + wpcom_mobile_user_agent_info.matchedPlatformName;
	
	if( false !== wpcom_mobile_user_agent_info.matchedUserAgentName )
		mobileStatsQueryString += "&x_" + 'mobile_devices' + '=' + wpcom_mobile_user_agent_info.matchedUserAgentName;
	
	if( wpcom_mobile_user_agent_info.isIPad() )
		mobileStatsQueryString += "&x_" + 'ipad_views' + '=' + 'views';

	if( "" != mobileStatsQueryString ) {
		new Image().src = document.location.protocol + '//pixel.wp.com/g.gif?v=wpcom-no-pv' + mobileStatsQueryString + '&baba=' + Math.random();
	}
	
}
</script>
</body>
</html>
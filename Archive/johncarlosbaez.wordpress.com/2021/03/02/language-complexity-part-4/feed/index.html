<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Language Complexity (Part 4)	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/</link>
	<description></description>
	<lastBuildDate>Sat, 06 Mar 2021 19:08:05 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169708</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sat, 06 Mar 2021 19:08:05 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29971#comment-169708</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169707&quot;&gt;domenico&lt;/a&gt;.

There are many measures of complexity for strings besides Kolmogorov complexity (which is theoretically nice, but unfortunately uncomputable in general).   I&#039;m fond of Levin&#039;s &lt;a href=&quot;http://www.scholarpedia.org/article/Universal_search#Levin_complexity&quot; rel=&quot;nofollow ugc&quot;&gt;time-bounded complexity&lt;/a&gt;, which penalizes programs that take a long time to run.   This is computable.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169707">domenico</a>.</p>
<p>There are many measures of complexity for strings besides Kolmogorov complexity (which is theoretically nice, but unfortunately uncomputable in general).   I&#8217;m fond of Levin&#8217;s <a href="http://www.scholarpedia.org/article/Universal_search#Levin_complexity" rel="nofollow ugc">time-bounded complexity</a>, which penalizes programs that take a long time to run.   This is computable.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: domenico		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169707</link>

		<dc:creator><![CDATA[domenico]]></dc:creator>
		<pubDate>Sat, 06 Mar 2021 18:01:25 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29971#comment-169707</guid>

					<description><![CDATA[I am thinking that the a simple program can give a complex output with a simple input (for example the Maldelbrot set), so that the complexity of the output string is not a measure of the complexity of the program; I am thinking that the Kolmogorov complexity is not a clear measure of the complexity of the program, is only the measure of the program length (is it right for a Turing machine?); but the minimum cyclomatic complexity of a program that generates a given string, or the cyclomatic complexity of a compiled translation of the high level program, could be a correct measure: it is a topological measure of the polyhedron number of faces representing the control flow graph.]]></description>
			<content:encoded><![CDATA[<p>I am thinking that the a simple program can give a complex output with a simple input (for example the Maldelbrot set), so that the complexity of the output string is not a measure of the complexity of the program; I am thinking that the Kolmogorov complexity is not a clear measure of the complexity of the program, is only the measure of the program length (is it right for a Turing machine?); but the minimum cyclomatic complexity of a program that generates a given string, or the cyclomatic complexity of a compiled translation of the high level program, could be a correct measure: it is a topological measure of the polyhedron number of faces representing the control flow graph.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: David A. Tanzer		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169651</link>

		<dc:creator><![CDATA[David A. Tanzer]]></dc:creator>
		<pubDate>Wed, 03 Mar 2021 09:05:48 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29971#comment-169651</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169644&quot;&gt;Peter Morgan&lt;/a&gt;.

So, whenever we can put a bound on the amortized running time of statements, then Python time complexity = Turing time complexity.  A more complicated picture, clearly.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169644">Peter Morgan</a>.</p>
<p>So, whenever we can put a bound on the amortized running time of statements, then Python time complexity = Turing time complexity.  A more complicated picture, clearly.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: David A. Tanzer		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169650</link>

		<dc:creator><![CDATA[David A. Tanzer]]></dc:creator>
		<pubDate>Wed, 03 Mar 2021 08:54:58 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29971#comment-169650</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169644&quot;&gt;Peter Morgan&lt;/a&gt;.

Despite the fact that there is no bound on the size of the integers, the whole program could be implemented with linear time complexity.  For example, if j += 3 were implemented as three increments of 1 - since with regular bit operations, incrementing by 1 has an amortized cost that is constant.  (50 percent of the time only one bit needs to be updated, 25 percent of the time two bits get updated, etc.)]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169644">Peter Morgan</a>.</p>
<p>Despite the fact that there is no bound on the size of the integers, the whole program could be implemented with linear time complexity.  For example, if j += 3 were implemented as three increments of 1 &#8211; since with regular bit operations, incrementing by 1 has an amortized cost that is constant.  (50 percent of the time only one bit needs to be updated, 25 percent of the time two bits get updated, etc.)</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: David A. Tanzer		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169649</link>

		<dc:creator><![CDATA[David A. Tanzer]]></dc:creator>
		<pubDate>Wed, 03 Mar 2021 08:36:08 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29971#comment-169649</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169644&quot;&gt;Peter Morgan&lt;/a&gt;.

Consider a silly implementation of the tripling function:

def triple(n):
   j = 0
   for i in range(n):  j += 3
   return j]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169644">Peter Morgan</a>.</p>
<p>Consider a silly implementation of the tripling function:</p>
<p>def triple(n):<br />
   j = 0<br />
   for i in range(n):  j += 3<br />
   return j</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: David A. Tanzer		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169648</link>

		<dc:creator><![CDATA[David A. Tanzer]]></dc:creator>
		<pubDate>Wed, 03 Mar 2021 08:23:26 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29971#comment-169648</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169644&quot;&gt;Peter Morgan&lt;/a&gt;.

True. Your point can be generalized, in connection with many data types.  E.g. since strings have unbounded length, there is no bound on the running time for the single statement string.upper().]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169644">Peter Morgan</a>.</p>
<p>True. Your point can be generalized, in connection with many data types.  E.g. since strings have unbounded length, there is no bound on the running time for the single statement string.upper().</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Peter Morgan		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/03/02/language-complexity-part-4/#comment-169644</link>

		<dc:creator><![CDATA[Peter Morgan]]></dc:creator>
		<pubDate>Tue, 02 Mar 2021 13:24:16 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29971#comment-169644</guid>

					<description><![CDATA[Python Integers are unlimited precision, so there is no &quot;absolute bound on the amount of clock time needed for the processor to complete one step&quot; for any Integer operations. So we can define a Python-complexity that is different from Turing-complexity in this specific respect (and perhaps in other respects, insofar as such different definitions can be useful).]]></description>
			<content:encoded><![CDATA[<p>Python Integers are unlimited precision, so there is no &#8220;absolute bound on the amount of clock time needed for the processor to complete one step&#8221; for any Integer operations. So we can define a Python-complexity that is different from Turing-complexity in this specific respect (and perhaps in other respects, insofar as such different definitions can be useful).</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Language Complexity (Part 1)	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/</link>
	<description></description>
	<lastBuildDate>Sat, 06 Mar 2021 20:22:42 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: sansdomino		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169713</link>

		<dc:creator><![CDATA[sansdomino]]></dc:creator>
		<pubDate>Sat, 06 Mar 2021 20:22:42 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29948#comment-169713</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169606&quot;&gt;John Baez&lt;/a&gt;.

I&#039;m aware. What this argument establishes that Chomskyite grammarians do not study natural languages like English, they study abstract mathematical objects that do not exist in nature. In real life only finitely many strings formed e.g. by repeating conjunctions or modifier can be parsed by any human even in theory, already since words take time to be spoken and humans have finite lifespans.

Studying languages as they actually exist in real life is indeed hard, but then we have many methods for actually doing this. I welcome you to sometimes engage with people who do this. Or not, if you wish… but if so, please stop pretending that whatever it is you are doing amounts to studying &quot;the English language&quot;.

More empirically grounded modelling that would allow you to keep around most concepts of theoretical linguistics would not even be hard! E.g. one model of language immediately superior to a set of sentences floating in a vacuum would be a set of agents running grammar-parsing algorithms on finite memory, allowing us to still maintain notions such as unrealized but grammatical sentences that could be parsed by some of these speakers. — &lt;em&gt;Any&lt;/em&gt; ontological grounding like this, though, no matter how simple, will necessarily require abandoning at minimum the notion of infinitely large languages.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169606">John Baez</a>.</p>
<p>I&#8217;m aware. What this argument establishes that Chomskyite grammarians do not study natural languages like English, they study abstract mathematical objects that do not exist in nature. In real life only finitely many strings formed e.g. by repeating conjunctions or modifier can be parsed by any human even in theory, already since words take time to be spoken and humans have finite lifespans.</p>
<p>Studying languages as they actually exist in real life is indeed hard, but then we have many methods for actually doing this. I welcome you to sometimes engage with people who do this. Or not, if you wish… but if so, please stop pretending that whatever it is you are doing amounts to studying &#8220;the English language&#8221;.</p>
<p>More empirically grounded modelling that would allow you to keep around most concepts of theoretical linguistics would not even be hard! E.g. one model of language immediately superior to a set of sentences floating in a vacuum would be a set of agents running grammar-parsing algorithms on finite memory, allowing us to still maintain notions such as unrealized but grammatical sentences that could be parsed by some of these speakers. — <em>Any</em> ontological grounding like this, though, no matter how simple, will necessarily require abandoning at minimum the notion of infinitely large languages.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169606</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sun, 28 Feb 2021 03:39:26 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29948#comment-169606</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169605&quot;&gt;sansdomino&lt;/a&gt;.

Grammarians don&#039;t usually study the collection of &quot;actually spoken, actually written or actually thought sentences&quot; since this is collection is very hard to describe in detail, or study.  It is easier to describe the infinite collection of all grammatical sentence.  Chomsky has written about this fact and argued that it&#039;s important.

For example, there is a set of infinitely many sentences of this form:

A cat is asleep.
A cat and another cat is asleep.
A cat and another cat and another cat is asleep.
A cat and another cat and another and another cat is asleep.
etc.

and while only finitely many of these have ever been actually spoken, actually written or actually thought, all of them are considered grammatical in most theories of grammar.

I suspect fewer than 7 of them have been actually spoken, actually written or actually thought, unless someone deliberately decided to have fun with them.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169605">sansdomino</a>.</p>
<p>Grammarians don&#8217;t usually study the collection of &#8220;actually spoken, actually written or actually thought sentences&#8221; since this is collection is very hard to describe in detail, or study.  It is easier to describe the infinite collection of all grammatical sentence.  Chomsky has written about this fact and argued that it&#8217;s important.</p>
<p>For example, there is a set of infinitely many sentences of this form:</p>
<p>A cat is asleep.<br />
A cat and another cat is asleep.<br />
A cat and another cat and another cat is asleep.<br />
A cat and another cat and another and another cat is asleep.<br />
etc.</p>
<p>and while only finitely many of these have ever been actually spoken, actually written or actually thought, all of them are considered grammatical in most theories of grammar.</p>
<p>I suspect fewer than 7 of them have been actually spoken, actually written or actually thought, unless someone deliberately decided to have fun with them.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: sansdomino		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169605</link>

		<dc:creator><![CDATA[sansdomino]]></dc:creator>
		<pubDate>Sun, 28 Feb 2021 02:44:55 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29948#comment-169605</guid>

					<description><![CDATA[Insofar as English, or any other natural language, only has existed (and will exist) for a finite time among a finite speaker population with a finite rate of thought, I would argue that its extension — its real, physical extent of actually spoken, actually written or even just actually thought sentences — is obviously likewise finite.]]></description>
			<content:encoded><![CDATA[<p>Insofar as English, or any other natural language, only has existed (and will exist) for a finite time among a finite speaker population with a finite rate of thought, I would argue that its extension — its real, physical extent of actually spoken, actually written or even just actually thought sentences — is obviously likewise finite.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: fredkintanar		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169525</link>

		<dc:creator><![CDATA[fredkintanar]]></dc:creator>
		<pubDate>Mon, 22 Feb 2021 01:17:04 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29948#comment-169525</guid>

					<description><![CDATA[It might be difficult to distinguish simpler from different. For example, the point about: Uncomplicated clausal structure (e.g., no subordinate clauses). Perhaps speakers of a pidgin can achieve just as much complexity of semantics just using discourse connectives between main clauses, eliminating the need for embedding clauses. So complexity in the discourse-level of grammatical relations compensates for simplification at the sentence level. 
    Or maybe pidgins shouldn&#039;t be compared to the codified speech of entire language communities, but are much narrower. A mother talks differently when interacting with her own child, since she knows what vocabulary and grammar the child already has used (some of this inferred from the mother&#039;s knowledge of the child&#039;s exposure and previous performance). Something like a pair-idiolect that evolves rapidly from day to day. Similarly, a pidgin speaker may adjust the register of their speech planning to what they know and learn about what the listener picks up on. If they simplify with one listener, that doesn&#039;t mean more complex resources of grammar and phonology aren&#039;t available when speaking with a more sophisticated or familiar listener.]]></description>
			<content:encoded><![CDATA[<p>It might be difficult to distinguish simpler from different. For example, the point about: Uncomplicated clausal structure (e.g., no subordinate clauses). Perhaps speakers of a pidgin can achieve just as much complexity of semantics just using discourse connectives between main clauses, eliminating the need for embedding clauses. So complexity in the discourse-level of grammatical relations compensates for simplification at the sentence level.<br />
    Or maybe pidgins shouldn&#8217;t be compared to the codified speech of entire language communities, but are much narrower. A mother talks differently when interacting with her own child, since she knows what vocabulary and grammar the child already has used (some of this inferred from the mother&#8217;s knowledge of the child&#8217;s exposure and previous performance). Something like a pair-idiolect that evolves rapidly from day to day. Similarly, a pidgin speaker may adjust the register of their speech planning to what they know and learn about what the listener picks up on. If they simplify with one listener, that doesn&#8217;t mean more complex resources of grammar and phonology aren&#8217;t available when speaking with a more sophisticated or familiar listener.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: particlelinguist		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169471</link>

		<dc:creator><![CDATA[particlelinguist]]></dc:creator>
		<pubDate>Thu, 18 Feb 2021 12:28:31 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29948#comment-169471</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169380&quot;&gt;David A. Tanzer&lt;/a&gt;.

Well, no need to reinvent an already existing field :) (Parts of) computational linguistics is devoted to describing the complexity classes of the different modules of grammar. Jeff Heinz at Stony Brook is probably the most well-known researcher regarding the (sub)regular complexity of phonology. Thomas Graf, another comp.linguist at Stony brook has a blog &#039;outdex&#039; where he talks about these complexity classes sometimes.

Probably the best known result regarding the complexity of syntax is from the 80s by Shieber, establishing non-context-freeness using Swiss German. Lots of work by Aravind Joshi and students is relevant here, too. I&#039;m not aware of much work on morphology (i.e. for example inflection) but I think that all morphological phenomena are by and large regular (in the technical sense).]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169380">David A. Tanzer</a>.</p>
<p>Well, no need to reinvent an already existing field :) (Parts of) computational linguistics is devoted to describing the complexity classes of the different modules of grammar. Jeff Heinz at Stony Brook is probably the most well-known researcher regarding the (sub)regular complexity of phonology. Thomas Graf, another comp.linguist at Stony brook has a blog &#8216;outdex&#8217; where he talks about these complexity classes sometimes.</p>
<p>Probably the best known result regarding the complexity of syntax is from the 80s by Shieber, establishing non-context-freeness using Swiss German. Lots of work by Aravind Joshi and students is relevant here, too. I&#8217;m not aware of much work on morphology (i.e. for example inflection) but I think that all morphological phenomena are by and large regular (in the technical sense).</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Giampiero Campa		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169403</link>

		<dc:creator><![CDATA[Giampiero Campa]]></dc:creator>
		<pubDate>Sun, 14 Feb 2021 13:59:36 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29948#comment-169403</guid>

					<description><![CDATA[Interesting. It reminds me of this talk in which the author uses Shannon&#039;s and Zipf&#039;s laws as a guidance to categorize animal communication (including bees and flowers at some point) and to make inferences about possible extraterrestrial communication:

https://longnow.org/seminars/02020/apr/29/interspecies-communication-and-search-extraterrestrial-intelligence/]]></description>
			<content:encoded><![CDATA[<p>Interesting. It reminds me of this talk in which the author uses Shannon&#8217;s and Zipf&#8217;s laws as a guidance to categorize animal communication (including bees and flowers at some point) and to make inferences about possible extraterrestrial communication:</p>
<p><a href="https://longnow.org/seminars/02020/apr/29/interspecies-communication-and-search-extraterrestrial-intelligence/" rel="nofollow ugc">https://longnow.org/seminars/02020/apr/29/interspecies-communication-and-search-extraterrestrial-intelligence/</a></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169385</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sat, 13 Feb 2021 21:31:52 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29948#comment-169385</guid>

					<description><![CDATA[Here are some ways in which pidgins are simpler, &lt;a href=&quot;https://en.wikipedia.org/wiki/Pidgin#Common_traits&quot; rel=&quot;nofollow ugc&quot;&gt;adapted from Wikipedia&lt;/a&gt;.  Some are grammatical; some concern pronunciation:

&#8226; Typologically most closely resemble isolating languages
&#8226; Uncomplicated clausal structure (e.g., no subordinate clauses)
&#8226; Reduction or elimination of syllable codas
&#8226; Reduction of consonant clusters 
&#8226; Elimination of aspiration or sound changes
&#8226; Lack of tones
&#8226; Lack of grammatical tense; use of separate words to indicate tense, usually preceding the verb
&#8226; Lack of conjugation or declension
&#8226; Lack of grammatical gender or grammatical number, supplanted by reduplication to represent plurals and superlatives, and other parts of speech that represent the concept being increased and clear indication of the gender or animated objects.
&#8226; Lack of clear parts of speech or word categorization; common use and derivation of new vocabulary through conversion, e.g. nominalization, verbification, adjectivization etc.]]></description>
			<content:encoded><![CDATA[<p>Here are some ways in which pidgins are simpler, <a href="https://en.wikipedia.org/wiki/Pidgin#Common_traits" rel="nofollow ugc">adapted from Wikipedia</a>.  Some are grammatical; some concern pronunciation:</p>
<p>&bull; Typologically most closely resemble isolating languages<br />
&bull; Uncomplicated clausal structure (e.g., no subordinate clauses)<br />
&bull; Reduction or elimination of syllable codas<br />
&bull; Reduction of consonant clusters<br />
&bull; Elimination of aspiration or sound changes<br />
&bull; Lack of tones<br />
&bull; Lack of grammatical tense; use of separate words to indicate tense, usually preceding the verb<br />
&bull; Lack of conjugation or declension<br />
&bull; Lack of grammatical gender or grammatical number, supplanted by reduplication to represent plurals and superlatives, and other parts of speech that represent the concept being increased and clear indication of the gender or animated objects.<br />
&bull; Lack of clear parts of speech or word categorization; common use and derivation of new vocabulary through conversion, e.g. nominalization, verbification, adjectivization etc.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: David A. Tanzer		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169380</link>

		<dc:creator><![CDATA[David A. Tanzer]]></dc:creator>
		<pubDate>Sat, 13 Feb 2021 21:06:02 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29948#comment-169380</guid>

					<description><![CDATA[Interesting comments. I&#039;m wondering to what extent these dimensions of language complexity can still be captured in terms of computational complexity.  If the formal grammar for a pidgin is a comparatively simpler set of rules, then its parsing algorithm might have lower time complexity.]]></description>
			<content:encoded><![CDATA[<p>Interesting comments. I&#8217;m wondering to what extent these dimensions of language complexity can still be captured in terms of computational complexity.  If the formal grammar for a pidgin is a comparatively simpler set of rules, then its parsing algorithm might have lower time complexity.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Len		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169375</link>

		<dc:creator><![CDATA[Len]]></dc:creator>
		<pubDate>Sat, 13 Feb 2021 18:17:44 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29948#comment-169375</guid>

					<description><![CDATA[It&#039;s not just pidgins versus creoles, my understanding is that older languages (such as those found in very isolated communities like a single river valley in New Guinea) are generally more complex then newer languages (which were creoles or pidgins more recently).  If I were to guess, this is the result of generations upon generations of children bringing something to a language.]]></description>
			<content:encoded><![CDATA[<p>It&#8217;s not just pidgins versus creoles, my understanding is that older languages (such as those found in very isolated communities like a single river valley in New Guinea) are generally more complex then newer languages (which were creoles or pidgins more recently).  If I were to guess, this is the result of generations upon generations of children bringing something to a language.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Roger Witte		</title>
		<link>https://johncarlosbaez.wordpress.com/2021/02/12/language-complexity-part-1/#comment-169371</link>

		<dc:creator><![CDATA[Roger Witte]]></dc:creator>
		<pubDate>Sat, 13 Feb 2021 14:12:13 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=29948#comment-169371</guid>

					<description><![CDATA[I think there is something rather special about the complexities of  natural languages.  It is easy to observe, because Pidgins don&#039;t have it and Creoles do.  So it is something that children bring to their native language, and they synthesise it if it is absent. On the other hand synthetic formal languages generally don&#039;t have it. It is clearly something grammatical but not purely semantic or syntactic.]]></description>
			<content:encoded><![CDATA[<p>I think there is something rather special about the complexities of  natural languages.  It is easy to observe, because Pidgins don&#8217;t have it and Creoles do.  So it is something that children bring to their native language, and they synthesise it if it is absent. On the other hand synthetic formal languages generally don&#8217;t have it. It is clearly something grammatical but not purely semantic or syntactic.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

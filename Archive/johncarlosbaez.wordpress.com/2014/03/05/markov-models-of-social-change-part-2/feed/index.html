<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Markov Models of Social Change (Part 2)	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/</link>
	<description></description>
	<lastBuildDate>Tue, 18 Mar 2014 12:18:57 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: domenico		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38800</link>

		<dc:creator><![CDATA[domenico]]></dc:creator>
		<pubDate>Tue, 18 Mar 2014 12:18:57 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17639#comment-38800</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38741&quot;&gt;domenico&lt;/a&gt;.

I think that each dynamic can be seen in the game theory, and it is possible to reduce the time intervals of each dynamic to obtain discrete equation.
I try to formalize the cross-impact balance to give the expert the possibility to control the dynamic (for good purpose like here); but it is fun if the cross-impact balance have a dynamic, and the Markov chain have a dynamic, that it is an approximation of an autonomous system.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38741">domenico</a>.</p>
<p>I think that each dynamic can be seen in the game theory, and it is possible to reduce the time intervals of each dynamic to obtain discrete equation.<br />
I try to formalize the cross-impact balance to give the expert the possibility to control the dynamic (for good purpose like here); but it is fun if the cross-impact balance have a dynamic, and the Markov chain have a dynamic, that it is an approximation of an autonomous system.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: lee bloomquist		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38752</link>

		<dc:creator><![CDATA[lee bloomquist]]></dc:creator>
		<pubDate>Tue, 18 Mar 2014 00:18:37 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17639#comment-38752</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38741&quot;&gt;domenico&lt;/a&gt;.

Domenico, &quot;if an expert give a connection between values of the factors in the cross-impact balance, then the expert give a probability that the two values are connected by a graph, an arrow that connect the two factors, so that the cross-impact balance have a graph representation&quot;

Yes, and from the graph in that google drive pdf, there is a &quot;local logic&quot; to it all. The percent of time that the token spends in a place, is by some sort of pattern, associative-- 

Imagine yourself as one of the states in a Markov chain, while other players in the game represent other unique states. But in this game, you only have one ball between you, and you pass it to each other.

Those passes of the ball are the links of the Markov chain.

The logic of these chains is that they link every player to every other player.

Say that after all is said in the round-up of the game by expert commentators,

that you, as one of the states in the Markov chain, had control of the ball X PERCENT of the total time the ball had been in play during the game.

What happens during the game is that the ball is tricky to hold onto. The average of unique possession by a player is like the quantum of the game. After that quantum of time, usually a different player wins the ball away from you.

There is an equation about it.

say the probability that you have control of the ball in the game is P.

Then the probability that you&#039;ll hold onto it for two quanta of time in the game =

PP

where P is your rate of ball control in the game,

In the Petri net if the Markov chain in that diagram I posted on google drive, above, has the instances of these equations as &#039;arrow to self&#039; in the diagram.

Domenico maybe this be one way to see Markov chains in game theory]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38741">domenico</a>.</p>
<p>Domenico, &#8220;if an expert give a connection between values of the factors in the cross-impact balance, then the expert give a probability that the two values are connected by a graph, an arrow that connect the two factors, so that the cross-impact balance have a graph representation&#8221;</p>
<p>Yes, and from the graph in that google drive pdf, there is a &#8220;local logic&#8221; to it all. The percent of time that the token spends in a place, is by some sort of pattern, associative&#8211; </p>
<p>Imagine yourself as one of the states in a Markov chain, while other players in the game represent other unique states. But in this game, you only have one ball between you, and you pass it to each other.</p>
<p>Those passes of the ball are the links of the Markov chain.</p>
<p>The logic of these chains is that they link every player to every other player.</p>
<p>Say that after all is said in the round-up of the game by expert commentators,</p>
<p>that you, as one of the states in the Markov chain, had control of the ball X PERCENT of the total time the ball had been in play during the game.</p>
<p>What happens during the game is that the ball is tricky to hold onto. The average of unique possession by a player is like the quantum of the game. After that quantum of time, usually a different player wins the ball away from you.</p>
<p>There is an equation about it.</p>
<p>say the probability that you have control of the ball in the game is P.</p>
<p>Then the probability that you&#8217;ll hold onto it for two quanta of time in the game =</p>
<p>PP</p>
<p>where P is your rate of ball control in the game,</p>
<p>In the Petri net if the Markov chain in that diagram I posted on google drive, above, has the instances of these equations as &#8216;arrow to self&#8217; in the diagram.</p>
<p>Domenico maybe this be one way to see Markov chains in game theory</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: domenico		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38741</link>

		<dc:creator><![CDATA[domenico]]></dc:creator>
		<pubDate>Mon, 17 Mar 2014 19:23:44 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17639#comment-38741</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-37969&quot;&gt;Vanessa Schweizer&lt;/a&gt;.

I am thinking to the cross-impact balance like a real transition matrix for a Markov chain.
If an expert give a connection between values of the factors in the cross-impact balance, then the expert give a probability that the two values are connected by a graph, an arrow that connect the two factors, so that the cross-impact balance have a graph representation with value for each arrow (like Markov chain).
Here there is not a probability constraint on the factors, that can assume each value, so that the constraint on the transition values are not more true (it is not a probability).
The values are coarse, so that the value is not a true mathematical measure, it is like an interval (a measure with human error).
I don&#039;t think that the matrix is constant in the time, because the cross-impact balance is a measure of a dynamical system.
It seem a differential equation, or a discrete equation, where the function is
$latex y_s(n+1)-y_s(n) = \sum_k A_{sk} y_k(n) $
and the parameter values are positive, or negative, values of experts: it can be a simple linear approximation of a slow dynamical system.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-37969">Vanessa Schweizer</a>.</p>
<p>I am thinking to the cross-impact balance like a real transition matrix for a Markov chain.<br />
If an expert give a connection between values of the factors in the cross-impact balance, then the expert give a probability that the two values are connected by a graph, an arrow that connect the two factors, so that the cross-impact balance have a graph representation with value for each arrow (like Markov chain).<br />
Here there is not a probability constraint on the factors, that can assume each value, so that the constraint on the transition values are not more true (it is not a probability).<br />
The values are coarse, so that the value is not a true mathematical measure, it is like an interval (a measure with human error).<br />
I don&#8217;t think that the matrix is constant in the time, because the cross-impact balance is a measure of a dynamical system.<br />
It seem a differential equation, or a discrete equation, where the function is<br />
<img src="https://s0.wp.com/latex.php?latex=y_s%28n%2B1%29-y_s%28n%29+%3D+%5Csum_k+A_%7Bsk%7D+y_k%28n%29+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y_s(n+1)-y_s(n) = &#92;sum_k A_{sk} y_k(n) " class="latex" /><br />
and the parameter values are positive, or negative, values of experts: it can be a simple linear approximation of a slow dynamical system.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: lee bloomquist		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38728</link>

		<dc:creator><![CDATA[lee bloomquist]]></dc:creator>
		<pubDate>Mon, 17 Mar 2014 14:33:19 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17639#comment-38728</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38674&quot;&gt;John Baez&lt;/a&gt;.

It&#039;s an experiment I know about. The diagram is &quot;Petri nets of the Markov chains in probability learning for n=3.&quot;

In it I use the equation about which you posed and emphasized a question in your previous comment.

Does this example of the equation address the question you had in mind?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38674">John Baez</a>.</p>
<p>It&#8217;s an experiment I know about. The diagram is &#8220;Petri nets of the Markov chains in probability learning for n=3.&#8221;</p>
<p>In it I use the equation about which you posed and emphasized a question in your previous comment.</p>
<p>Does this example of the equation address the question you had in mind?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38724</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Mon, 17 Mar 2014 13:42:49 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17639#comment-38724</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38691&quot;&gt;lee bloomquist&lt;/a&gt;.

I really don&#039;t understand why you bring up &quot;probability learning&quot; in response to almost everything I talk about here.  It doesn&#039;t seem relevant here, and you&#039;re not explaining the relevance.  In any case, I can&#039;t access the link you provided.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38691">lee bloomquist</a>.</p>
<p>I really don&#8217;t understand why you bring up &#8220;probability learning&#8221; in response to almost everything I talk about here.  It doesn&#8217;t seem relevant here, and you&#8217;re not explaining the relevance.  In any case, I can&#8217;t access the link you provided.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: lee bloomquist		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38691</link>

		<dc:creator><![CDATA[lee bloomquist]]></dc:creator>
		<pubDate>Mon, 17 Mar 2014 00:22:39 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17639#comment-38691</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38674&quot;&gt;John Baez&lt;/a&gt;.

John wrote, &quot;My questions are what does this Markov chain really mean?&quot;

If the attached diagram of (a) the equation in question to (b) the laboratory animal experiments called probability learning, is in fact a correct application of the equation, then one could perhaps compare this application in the lab experiment when studying the same questions in this very interesting social psychology experiment with experts.

https://docs.google.com/file/d/0B9LMgeIAqlIETWZOdmJxLTRoRmc/edit?usp=docslist_api]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38674">John Baez</a>.</p>
<p>John wrote, &#8220;My questions are what does this Markov chain really mean?&#8221;</p>
<p>If the attached diagram of (a) the equation in question to (b) the laboratory animal experiments called probability learning, is in fact a correct application of the equation, then one could perhaps compare this application in the lab experiment when studying the same questions in this very interesting social psychology experiment with experts.</p>
<p><a href="https://docs.google.com/file/d/0B9LMgeIAqlIETWZOdmJxLTRoRmc/edit?usp=docslist_api" rel="nofollow ugc">https://docs.google.com/file/d/0B9LMgeIAqlIETWZOdmJxLTRoRmc/edit?usp=docslist_api</a></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Giampiero Campa		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38680</link>

		<dc:creator><![CDATA[Giampiero Campa]]></dc:creator>
		<pubDate>Sun, 16 Mar 2014 18:27:35 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17639#comment-38680</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38671&quot;&gt;John Baez&lt;/a&gt;.

&lt;blockquote&gt;Even if it’s oversimplified in various ways (which seems inevitable), it could be quite interesting!&lt;/blockquote&gt;

As the saying goes, all models are wrong, some are useful :-)

The equations are explained very well in the paper, yes I for one would love to see a few blog posts about this model.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38671">John Baez</a>.</p>
<blockquote><p>Even if it’s oversimplified in various ways (which seems inevitable), it could be quite interesting!</p></blockquote>
<p>As the saying goes, all models are wrong, some are useful :-)</p>
<p>The equations are explained very well in the paper, yes I for one would love to see a few blog posts about this model.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38674</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sun, 16 Mar 2014 16:24:08 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17639#comment-38674</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-37969&quot;&gt;Vanessa Schweizer&lt;/a&gt;.

John wrote:

&lt;blockquote&gt;
Still, I’m hoping that we can make up some story using probability theory such that finding the equilibrium of a Markov chain obtained from the stochastic cross-impact balance method can be explained as finding the ‘unique probability distribution such that…’ where the ‘…’ is something both mathematically precise and conceptually interesting. 
&lt;/blockquote&gt;

So far the best story I can get is this.  

We elicit information from experts that lets us define a discrete-time Markov chain on some finite set of scenarios.  (Jamie&#039;s blog post uses a continuous-time Markov chain, but this gives rise to a discrete-time Markov chain with the same equilibria, which I&#039;ll find easier to work with here.)

If $latex p_i(n)$ is the probability of the $latex i$th scenario at the $latex n$th time step, this Markov chain looks like

$latex \displaystyle{ p_i(n+1) = \sum_j T_{i j} p_j(n) } $ 

where $latex T_{i j}$ is a matrix of transition probabilities---necessarily a &lt;b&gt;stochastic&lt;/b&gt; matrix, meaning

$latex T_{i j} \ge 0$

for all $latex i, j$ and 

$latex \displaystyle{  \sum_i T_{i j} = 1}$

for all $latex j.$

So, a probability distribution $latex p_i$ is an equilibrium for this Markov chain if

$latex \displaystyle{ p_i = \sum_j T_{i j} p_j } $ 

My questions are &lt;b&gt;what does this Markov chain really mean?&lt;/b&gt; and &lt;b&gt;what do these matrix elements $latex T_{i j}$ really mean?&lt;/b&gt;  In particular, the time steps in this Markov chain are most likely &lt;i&gt;not&lt;/i&gt; about actual time in the real world.

In a rough sense $latex T_{i j}$ measures how much being in the $latex j$th scenario increases the chance that we are in the $latex i$th scenario.  The equilibrium condition 

$latex \displaystyle{ p_i = \sum_j T_{i j} p_j } $ 

is a kind of self-consistency condition, as hinted in the name &#039;cross-impact balance&#039;.   The Markov chain may be just a method of finding choices of $latex p_i$ that obey this condition: we take any choice of $latex p_i(0)$, we keep on evolving it via

$latex \displaystyle{ p_i(n+1) = \sum_j T_{i j} p_j(n) } $ 

and we get closer and closer to an equilibrium.  In this way of thinking, the time steps don&#039;t have any significance of their own.

But my initial attempts to be more precise about the meaning of the coefficients $latex T_{i j}$ as &#039;correlations&#039;---see above---didn&#039;t quite make sense.  

I&#039;m hoping that the condition

$latex \displaystyle{ p_i = \sum_j T_{i j} p_j } $ 

is an example of &lt;a href=&quot;https://en.wikipedia.org/wiki/Structural_equation_modeling&quot; rel=&quot;nofollow&quot;&gt;structural equation modelling&lt;/a&gt;, but I haven&#039;t seen people do this modelling where the quantities involved are probabilities and they all influence each other!]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-37969">Vanessa Schweizer</a>.</p>
<p>John wrote:</p>
<blockquote><p>
Still, I’m hoping that we can make up some story using probability theory such that finding the equilibrium of a Markov chain obtained from the stochastic cross-impact balance method can be explained as finding the ‘unique probability distribution such that…’ where the ‘…’ is something both mathematically precise and conceptually interesting.
</p></blockquote>
<p>So far the best story I can get is this.  </p>
<p>We elicit information from experts that lets us define a discrete-time Markov chain on some finite set of scenarios.  (Jamie&#8217;s blog post uses a continuous-time Markov chain, but this gives rise to a discrete-time Markov chain with the same equilibria, which I&#8217;ll find easier to work with here.)</p>
<p>If <img src="https://s0.wp.com/latex.php?latex=p_i%28n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i(n)" class="latex" /> is the probability of the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th scenario at the <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" />th time step, this Markov chain looks like</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_i%28n%2B1%29+%3D+%5Csum_j+T_%7Bi+j%7D+p_j%28n%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_i(n+1) = &#92;sum_j T_{i j} p_j(n) } " class="latex" /> </p>
<p>where <img src="https://s0.wp.com/latex.php?latex=T_%7Bi+j%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T_{i j}" class="latex" /> is a matrix of transition probabilities&#8212;necessarily a <b>stochastic</b> matrix, meaning</p>
<p><img src="https://s0.wp.com/latex.php?latex=T_%7Bi+j%7D+%5Cge+0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T_{i j} &#92;ge 0" class="latex" /></p>
<p>for all <img src="https://s0.wp.com/latex.php?latex=i%2C+j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i, j" class="latex" /> and </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B++%5Csum_i+T_%7Bi+j%7D+%3D+1%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{  &#92;sum_i T_{i j} = 1}" class="latex" /></p>
<p>for all <img src="https://s0.wp.com/latex.php?latex=j.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j." class="latex" /></p>
<p>So, a probability distribution <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> is an equilibrium for this Markov chain if</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_i+%3D+%5Csum_j+T_%7Bi+j%7D+p_j+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_i = &#92;sum_j T_{i j} p_j } " class="latex" /> </p>
<p>My questions are <b>what does this Markov chain really mean?</b> and <b>what do these matrix elements <img src="https://s0.wp.com/latex.php?latex=T_%7Bi+j%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T_{i j}" class="latex" /> really mean?</b>  In particular, the time steps in this Markov chain are most likely <i>not</i> about actual time in the real world.</p>
<p>In a rough sense <img src="https://s0.wp.com/latex.php?latex=T_%7Bi+j%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T_{i j}" class="latex" /> measures how much being in the <img src="https://s0.wp.com/latex.php?latex=j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="j" class="latex" />th scenario increases the chance that we are in the <img src="https://s0.wp.com/latex.php?latex=i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i" class="latex" />th scenario.  The equilibrium condition </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_i+%3D+%5Csum_j+T_%7Bi+j%7D+p_j+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_i = &#92;sum_j T_{i j} p_j } " class="latex" /> </p>
<p>is a kind of self-consistency condition, as hinted in the name &#8216;cross-impact balance&#8217;.   The Markov chain may be just a method of finding choices of <img src="https://s0.wp.com/latex.php?latex=p_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i" class="latex" /> that obey this condition: we take any choice of <img src="https://s0.wp.com/latex.php?latex=p_i%280%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i(0)" class="latex" />, we keep on evolving it via</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_i%28n%2B1%29+%3D+%5Csum_j+T_%7Bi+j%7D+p_j%28n%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_i(n+1) = &#92;sum_j T_{i j} p_j(n) } " class="latex" /> </p>
<p>and we get closer and closer to an equilibrium.  In this way of thinking, the time steps don&#8217;t have any significance of their own.</p>
<p>But my initial attempts to be more precise about the meaning of the coefficients <img src="https://s0.wp.com/latex.php?latex=T_%7Bi+j%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="T_{i j}" class="latex" /> as &#8216;correlations&#8217;&#8212;see above&#8212;didn&#8217;t quite make sense.  </p>
<p>I&#8217;m hoping that the condition</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p_i+%3D+%5Csum_j+T_%7Bi+j%7D+p_j+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p_i = &#92;sum_j T_{i j} p_j } " class="latex" /> </p>
<p>is an example of <a href="https://en.wikipedia.org/wiki/Structural_equation_modeling" rel="nofollow">structural equation modelling</a>, but I haven&#8217;t seen people do this modelling where the quantities involved are probabilities and they all influence each other!</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38671</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sun, 16 Mar 2014 16:00:36 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17639#comment-38671</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38625&quot;&gt;Giampiero Campa&lt;/a&gt;.

I noticed that article too!  It says:

&lt;blockquote&gt;
The research project is based on a new cross-disciplinary &#039;Human And Nature DYnamical&#039; (HANDY) model, led by applied mathematician Safa Motesharri of the US National Science Foundation-supported National Socio-Environmental Synthesis Center, in association with a team of natural and social scientists. The study based on the HANDY model has been accepted for publication in the peer-reviewed Elsevier journal, Ecological Economics.
&lt;/blockquote&gt;

I looked for papers by &lt;a href=&quot;http://www.sesync.org/users/smotesharrei&quot; rel=&quot;nofollow&quot;&gt;Safa Motesharri&lt;/a&gt; and found only this:

&#8226; Safa Motesharri, Jorge Rivas and Eugenia Kalnay, &lt;a href=&quot;http://www.atmos.umd.edu/~ekalnay/pubs/handy-paper-for-submission-2.pdf&quot; rel=&quot;nofollow&quot;&gt;A minimal model for human and nature interaction&lt;/a&gt;, 13 November 2012.

This describes the HANDY model, which turns out to be a set of 4 coupled ordinary differential equations.  I&#039;d like to blog about this, or get one of those authors to do so.  Even if it&#039;s oversimplified in various ways (which seems inevitable), it could be quite interesting!]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38625">Giampiero Campa</a>.</p>
<p>I noticed that article too!  It says:</p>
<blockquote><p>
The research project is based on a new cross-disciplinary &#8216;Human And Nature DYnamical&#8217; (HANDY) model, led by applied mathematician Safa Motesharri of the US National Science Foundation-supported National Socio-Environmental Synthesis Center, in association with a team of natural and social scientists. The study based on the HANDY model has been accepted for publication in the peer-reviewed Elsevier journal, Ecological Economics.
</p></blockquote>
<p>I looked for papers by <a href="http://www.sesync.org/users/smotesharrei" rel="nofollow">Safa Motesharri</a> and found only this:</p>
<p>&bull; Safa Motesharri, Jorge Rivas and Eugenia Kalnay, <a href="http://www.atmos.umd.edu/~ekalnay/pubs/handy-paper-for-submission-2.pdf" rel="nofollow">A minimal model for human and nature interaction</a>, 13 November 2012.</p>
<p>This describes the HANDY model, which turns out to be a set of 4 coupled ordinary differential equations.  I&#8217;d like to blog about this, or get one of those authors to do so.  Even if it&#8217;s oversimplified in various ways (which seems inevitable), it could be quite interesting!</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Giampiero Campa		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/03/05/markov-models-of-social-change-part-2/#comment-38625</link>

		<dc:creator><![CDATA[Giampiero Campa]]></dc:creator>
		<pubDate>Sat, 15 Mar 2014 20:28:37 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17639#comment-38625</guid>

					<description><![CDATA[Seemingly interesting study here on &lt;a href=&quot;http://www.theguardian.com/environment/earth-insight/2014/mar/14/nasa-civilisation-irreversible-collapse-study-scientists&quot; rel=&quot;nofollow&quot;&gt;collapse of civilizations&lt;/a&gt; (whatever &quot;collapse&quot; might mean). I wonder what kind of model he used.]]></description>
			<content:encoded><![CDATA[<p>Seemingly interesting study here on <a href="http://www.theguardian.com/environment/earth-insight/2014/mar/14/nasa-civilisation-irreversible-collapse-study-scientists" rel="nofollow">collapse of civilizations</a> (whatever &#8220;collapse&#8221; might mean). I wonder what kind of model he used.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

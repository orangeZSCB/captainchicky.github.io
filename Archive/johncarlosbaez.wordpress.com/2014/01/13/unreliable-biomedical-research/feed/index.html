<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Unreliable Biomedical Research	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/</link>
	<description></description>
	<lastBuildDate>Thu, 23 Jan 2014 19:57:57 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: Hank Roberts		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35539</link>

		<dc:creator><![CDATA[Hank Roberts]]></dc:creator>
		<pubDate>Thu, 23 Jan 2014 19:57:57 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17356#comment-35539</guid>

					<description><![CDATA[I followed that plowing link through to &lt;a href=&quot;http://onpasture.com/2013/06/24/keyline-plowing-gets-you-522720-worms-for-280/#comments&quot; rel=&quot;nofollow&quot;&gt;where the guy who did the plow work commented&lt;/a&gt;
:
&lt;blockquote&gt;... I was under the impression that the study would unfortunately not be ‘publishable’ in academic journals due to an insufficient number of test plots at each site. My understanding was that an insufficient number of soil samples at each site and high variability between samples brought about results with low statistical reliability. Although the study results did indicate keyline plowing had no effect on soils (save for those lovely (but hungry) earthworms), it was not possible to determine if it was the result of the tool or under-sampling.&lt;/blockquote&gt;]]></description>
			<content:encoded><![CDATA[<p>I followed that plowing link through to <a href="http://onpasture.com/2013/06/24/keyline-plowing-gets-you-522720-worms-for-280/#comments" rel="nofollow">where the guy who did the plow work commented</a><br />
:</p>
<blockquote><p>&#8230; I was under the impression that the study would unfortunately not be ‘publishable’ in academic journals due to an insufficient number of test plots at each site. My understanding was that an insufficient number of soil samples at each site and high variability between samples brought about results with low statistical reliability. Although the study results did indicate keyline plowing had no effect on soils (save for those lovely (but hungry) earthworms), it was not possible to determine if it was the result of the tool or under-sampling.</p></blockquote>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: David Lyon		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35453</link>

		<dc:creator><![CDATA[David Lyon]]></dc:creator>
		<pubDate>Mon, 20 Jan 2014 20:39:39 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17356#comment-35453</guid>

					<description><![CDATA[The 21st century model for collaborative problem solving contains concepts such as open source code, peer to peer data distribution and crowd-sourced funding. The core idea is to build secure, persistent systems by removing single points of failure. The current tragedy of the untrustworthiness of scientific publishing can not be blamed on scientists, but on the failure-prone 20th century system that they feel trapped within. If the single funding source is corrupt, data analysis is twisted or data is lost. If the single steward of the data depends too much on publishing a certain result at a certain time, the research is spoiled. If the editors of the top handful of journals are corrupt or under outside control, research is guided in directions that they choose and other avenues are left unexplored.

As a physics graduate student, I&#039;ve completely lost faith in the way science is currently done and my PhD thesis date has therefore receded towards the end of time. However, I&#039;m excited about the promise of 21st century science 2.0 that uses public data, a decentralized anonymous scientific reputation system, free peer-to-peer publishing with no middlemen, etc. Something much like the Selected Papers Network advocated by this community will be a vital component of science 2.0, but even more reform is needed throughout the entire supply chain of science.]]></description>
			<content:encoded><![CDATA[<p>The 21st century model for collaborative problem solving contains concepts such as open source code, peer to peer data distribution and crowd-sourced funding. The core idea is to build secure, persistent systems by removing single points of failure. The current tragedy of the untrustworthiness of scientific publishing can not be blamed on scientists, but on the failure-prone 20th century system that they feel trapped within. If the single funding source is corrupt, data analysis is twisted or data is lost. If the single steward of the data depends too much on publishing a certain result at a certain time, the research is spoiled. If the editors of the top handful of journals are corrupt or under outside control, research is guided in directions that they choose and other avenues are left unexplored.</p>
<p>As a physics graduate student, I&#8217;ve completely lost faith in the way science is currently done and my PhD thesis date has therefore receded towards the end of time. However, I&#8217;m excited about the promise of 21st century science 2.0 that uses public data, a decentralized anonymous scientific reputation system, free peer-to-peer publishing with no middlemen, etc. Something much like the Selected Papers Network advocated by this community will be a vital component of science 2.0, but even more reform is needed throughout the entire supply chain of science.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Anonymous		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35356</link>

		<dc:creator><![CDATA[Anonymous]]></dc:creator>
		<pubDate>Fri, 17 Jan 2014 10:09:42 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17356#comment-35356</guid>

					<description><![CDATA[If the researchers were more interested in what the actual truth is, maybe they would make better experiments (by taking larger sample sizes, ruling out possible errors in the experiment more rigorously, etc.).  However, the current funding system of the academia does not give much incentive to valiantly search the truth. Instead, it rewards quantity over quality and flashy (but wrong) results over solid, but boring work. Even worse, the system actually penalizes rigour and solid, long term work but kicking out people who are not able to (or do not want to) churn out publications - no matter what their quality is - at high speed.

I&#039;m an advanced graduate student and I even consider myself relatively good at what I do. I also love physics, but the academic world and perverse financial incentives and high pressure to perform are things that make me constantly worry about my future and make me think that maybe I should go work in some other field instead and keep physics as just a hobby.]]></description>
			<content:encoded><![CDATA[<p>If the researchers were more interested in what the actual truth is, maybe they would make better experiments (by taking larger sample sizes, ruling out possible errors in the experiment more rigorously, etc.).  However, the current funding system of the academia does not give much incentive to valiantly search the truth. Instead, it rewards quantity over quality and flashy (but wrong) results over solid, but boring work. Even worse, the system actually penalizes rigour and solid, long term work but kicking out people who are not able to (or do not want to) churn out publications &#8211; no matter what their quality is &#8211; at high speed.</p>
<p>I&#8217;m an advanced graduate student and I even consider myself relatively good at what I do. I also love physics, but the academic world and perverse financial incentives and high pressure to perform are things that make me constantly worry about my future and make me think that maybe I should go work in some other field instead and keep physics as just a hobby.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Linas Vepstas		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35339</link>

		<dc:creator><![CDATA[Linas Vepstas]]></dc:creator>
		<pubDate>Thu, 16 Jan 2014 20:20:55 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17356#comment-35339</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35330&quot;&gt;John Baez&lt;/a&gt;.

Yes, I think that is what it is. Now, as I think about it, I believe you can dig up many more examples of this, e.g. in searches for gravitational waves or dark matter or neutrino mass (or older Higgs boson searches) or Pioneer anomaly....  I&#039;d occasionally see graphs with ridiculously tiny error bars on them, and some pertinent phenomenon far, far outside those error bars, and I&#039;d wonder: is that a misprint? Am I mis-understanding the graph? Were the people who made those error bars just plain wrong?  How could measurement/prediction X have possibly been so confidently wrong?

If the criterion for correctness in physics is that &quot;the true answer must lie within a few lengths of error bars&quot;, then I humbly suggest that a lot of what is published in physics is also wrong and/or unreproducible.  Again, the explanation for this is so is surely subtle. 

(Sorry I have no specific examples at my fingertips, but I think that, with some attention, they can be found)]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35330">John Baez</a>.</p>
<p>Yes, I think that is what it is. Now, as I think about it, I believe you can dig up many more examples of this, e.g. in searches for gravitational waves or dark matter or neutrino mass (or older Higgs boson searches) or Pioneer anomaly&#8230;.  I&#8217;d occasionally see graphs with ridiculously tiny error bars on them, and some pertinent phenomenon far, far outside those error bars, and I&#8217;d wonder: is that a misprint? Am I mis-understanding the graph? Were the people who made those error bars just plain wrong?  How could measurement/prediction X have possibly been so confidently wrong?</p>
<p>If the criterion for correctness in physics is that &#8220;the true answer must lie within a few lengths of error bars&#8221;, then I humbly suggest that a lot of what is published in physics is also wrong and/or unreproducible.  Again, the explanation for this is so is surely subtle. </p>
<p>(Sorry I have no specific examples at my fingertips, but I think that, with some attention, they can be found)</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Chris Aldrich		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35338</link>

		<dc:creator><![CDATA[Chris Aldrich]]></dc:creator>
		<pubDate>Thu, 16 Jan 2014 19:53:15 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17356#comment-35338</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35331&quot;&gt;John Baez&lt;/a&gt;.

This also sounds similar to the concept of the &quot;Proteus Phenomenon&quot; which is the &quot;tendency for early findings in a new area of research to alternate between opposite conclusions&quot;,  which I ran across recently via &lt;a href=&quot;http://wordspy.com/words/Proteusphenomenon.asp&quot; rel=&quot;nofollow&quot;&gt;WordSpy&lt;/a&gt;]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35331">John Baez</a>.</p>
<p>This also sounds similar to the concept of the &#8220;Proteus Phenomenon&#8221; which is the &#8220;tendency for early findings in a new area of research to alternate between opposite conclusions&#8221;,  which I ran across recently via <a href="http://wordspy.com/words/Proteusphenomenon.asp" rel="nofollow">WordSpy</a></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35331</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Thu, 16 Jan 2014 15:03:25 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17356#comment-35331</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35317&quot;&gt;Linas Vepstas&lt;/a&gt;.

I wrote a blog article here about Jonah Lehrer&#039;s article:

&#8226; &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2011/10/18/the-decline-effect/&quot; rel=&quot;nofollow&quot;&gt;The decline effect&lt;/a&gt;, &lt;i&gt;Azimuth&lt;/i&gt;, 18 October 2011.

I dug up some good discussions of the &#039;decline effect&#039; he discusses---the effect where initially an experiment is confirmed and later, slowly, it becomes harder to confirm.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35317">Linas Vepstas</a>.</p>
<p>I wrote a blog article here about Jonah Lehrer&#8217;s article:</p>
<p>&bull; <a href="https://johncarlosbaez.wordpress.com/2011/10/18/the-decline-effect/" rel="nofollow">The decline effect</a>, <i>Azimuth</i>, 18 October 2011.</p>
<p>I dug up some good discussions of the &#8216;decline effect&#8217; he discusses&#8212;the effect where initially an experiment is confirmed and later, slowly, it becomes harder to confirm.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35330</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Thu, 16 Jan 2014 14:57:13 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17356#comment-35330</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35318&quot;&gt;Linas Vepstas&lt;/a&gt;.

John Beattie wrote:

&lt;blockquote&gt;
Does the sentence say that there has been a reduction in the measured value and the reduction equals ten times the estimate of the error, i.e. the error estimate made for the first measurement? 
&lt;/blockquote&gt;

Yes, that&#039;s how I read the sentence.

I doubt they&#039;re claiming the weak interaction constant has &lt;i&gt;actually decreased&lt;/i&gt; that much from 1969 to 2001, though one could read the sentence that way if one didn&#039;t know physicists don&#039;t believe constants of nature change so rapidly.  (Some believe they change, but much more slowly.)]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35318">Linas Vepstas</a>.</p>
<p>John Beattie wrote:</p>
<blockquote><p>
Does the sentence say that there has been a reduction in the measured value and the reduction equals ten times the estimate of the error, i.e. the error estimate made for the first measurement?
</p></blockquote>
<p>Yes, that&#8217;s how I read the sentence.</p>
<p>I doubt they&#8217;re claiming the weak interaction constant has <i>actually decreased</i> that much from 1969 to 2001, though one could read the sentence that way if one didn&#8217;t know physicists don&#8217;t believe constants of nature change so rapidly.  (Some believe they change, but much more slowly.)</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Beattie		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35327</link>

		<dc:creator><![CDATA[John Beattie]]></dc:creator>
		<pubDate>Thu, 16 Jan 2014 14:08:22 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17356#comment-35327</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35318&quot;&gt;Linas Vepstas&lt;/a&gt;.

That is an interesting article.  Does anyone know what this sentence means?

&quot;...the weak coupling ratio exhibited by decaying neutrons, which appears to have fallen by more than ten standard deviations between 1969 and 2001.&quot; [second-last paragraph of the article]

&quot;...fallen by ten standard deviations...&quot; is what is giving me most difficulty. 

Does the sentence say that there has been a reduction in the measured value and the reduction equals ten times the estimate of the error, i.e. the error estimate made for the first measurement? 

I very much doubt if that is what it is saying but I feel I ought to give a guess at what it might be saying, in order to help show what my difficulty is.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35318">Linas Vepstas</a>.</p>
<p>That is an interesting article.  Does anyone know what this sentence means?</p>
<p>&#8220;&#8230;the weak coupling ratio exhibited by decaying neutrons, which appears to have fallen by more than ten standard deviations between 1969 and 2001.&#8221; [second-last paragraph of the article]</p>
<p>&#8220;&#8230;fallen by ten standard deviations&#8230;&#8221; is what is giving me most difficulty. </p>
<p>Does the sentence say that there has been a reduction in the measured value and the reduction equals ten times the estimate of the error, i.e. the error estimate made for the first measurement? </p>
<p>I very much doubt if that is what it is saying but I feel I ought to give a guess at what it might be saying, in order to help show what my difficulty is.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Linas Vepstas		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35318</link>

		<dc:creator><![CDATA[Linas Vepstas]]></dc:creator>
		<pubDate>Thu, 16 Jan 2014 05:19:04 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17356#comment-35318</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35317&quot;&gt;Linas Vepstas&lt;/a&gt;.

The New Yorker article I just posted above quotes only one physics effect, at the very end: &quot;the weak coupling ratio exhibited by decaying neutrons, which appears to have fallen by more than ten standard deviations between 1969 and 2001.&quot;  I can remember one more from my student days: the fine structure constant seems to have changed by more than six sigma (?) since the 1940&#039;s. Presumably this is all &quot;experimental error&quot;, but these are measurements made by world-class, top-notch, name-brand physicists ... not exactly error-prone ding-dongs. So the explanation, whatever it is, is subtle. The typical publication-bias effect seems insufficient.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35317">Linas Vepstas</a>.</p>
<p>The New Yorker article I just posted above quotes only one physics effect, at the very end: &#8220;the weak coupling ratio exhibited by decaying neutrons, which appears to have fallen by more than ten standard deviations between 1969 and 2001.&#8221;  I can remember one more from my student days: the fine structure constant seems to have changed by more than six sigma (?) since the 1940&#8217;s. Presumably this is all &#8220;experimental error&#8221;, but these are measurements made by world-class, top-notch, name-brand physicists &#8230; not exactly error-prone ding-dongs. So the explanation, whatever it is, is subtle. The typical publication-bias effect seems insufficient.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Linas Vepstas		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/01/13/unreliable-biomedical-research/#comment-35317</link>

		<dc:creator><![CDATA[Linas Vepstas]]></dc:creator>
		<pubDate>Thu, 16 Jan 2014 04:58:35 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=17356#comment-35317</guid>

					<description><![CDATA[&#8226; Jonah Lehrer, &lt;a href=&quot;http://www.newyorker.com/reporting/2010/12/13/101213fa_fact_lehrer?currentPage=all&quot; rel=&quot;nofollow&quot;&gt;The Truth Wears Off:  Is there something wrong with the scientific method?&lt;/a&gt;, &lt;i&gt;New Yorker&lt;/i&gt;, 13 December, 2010.

It&#039;s not just biomedical, its far far more widespread.]]></description>
			<content:encoded><![CDATA[<p>&bull; Jonah Lehrer, <a href="http://www.newyorker.com/reporting/2010/12/13/101213fa_fact_lehrer?currentPage=all" rel="nofollow">The Truth Wears Off:  Is there something wrong with the scientific method?</a>, <i>New Yorker</i>, 13 December, 2010.</p>
<p>It&#8217;s not just biomedical, its far far more widespread.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

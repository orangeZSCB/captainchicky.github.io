<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: A Second Law for Open Markov Processes	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/</link>
	<description></description>
	<lastBuildDate>Mon, 18 Apr 2016 04:50:21 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: Information Geometry (Part 16) &#124; Azimuth		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-76229</link>

		<dc:creator><![CDATA[Information Geometry (Part 16) &#124; Azimuth]]></dc:creator>
		<pubDate>Thu, 14 Jan 2016 07:04:36 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=19011#comment-76229</guid>

					<description><![CDATA[Lately we&#039;ve been thinking about open Markov processes.  These are random processes where something can hop randomly from one state to another (that&#039;s the &#039;Markov process&#039; part) but also enter or leave the system (that&#039;s the &#039;open&#039; part).

The ultimate goal is to understand the nonequilibrium thermodynamics of open systems---systems where energy and maybe matter flows in and out.  If we could understand this well enough, we could understand in detail how &lt;i&gt;life&lt;/i&gt; works.  That&#039;s a difficult job!  But one has to start somewhere, and this is one place to start.

We have a few papers on this subject:

&#8226; Blake Pollard, &lt;a href=&quot;http://arxiv.org/abs/1410.6531&quot; rel=&quot;nofollow&quot;&gt;A Second Law for open Markov processes&lt;/a&gt;.  (Blog article &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.)

&#8226; John Baez, Brendan Fong and Blake Pollard, &lt;a href=&quot;http://arxiv.org/abs/1504.05625&quot; rel=&quot;nofollow&quot;&gt;A compositional framework for Markov processes&lt;/a&gt;.  (Blog article &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2015/09/04/a-compositional-framework-for-markov-processes/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.)

&#8226; Blake Pollard, &lt;a href=&quot;http://arxiv.org/abs/1601.00711&quot; rel=&quot;nofollow&quot;&gt;Open Markov processes: A compositional perspective on non-equilibrium steady states in biology&lt;/a&gt;.  (Blog article &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2016/01/11/information-geometry-part-15/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;.)]]></description>
			<content:encoded><![CDATA[<p>Lately we&#8217;ve been thinking about open Markov processes.  These are random processes where something can hop randomly from one state to another (that&#8217;s the &#8216;Markov process&#8217; part) but also enter or leave the system (that&#8217;s the &#8216;open&#8217; part).</p>
<p>The ultimate goal is to understand the nonequilibrium thermodynamics of open systems&#8212;systems where energy and maybe matter flows in and out.  If we could understand this well enough, we could understand in detail how <i>life</i> works.  That&#8217;s a difficult job!  But one has to start somewhere, and this is one place to start.</p>
<p>We have a few papers on this subject:</p>
<p>&bull; Blake Pollard, <a href="http://arxiv.org/abs/1410.6531" rel="nofollow">A Second Law for open Markov processes</a>.  (Blog article <a href="https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/" rel="nofollow">here</a>.)</p>
<p>&bull; John Baez, Brendan Fong and Blake Pollard, <a href="http://arxiv.org/abs/1504.05625" rel="nofollow">A compositional framework for Markov processes</a>.  (Blog article <a href="https://johncarlosbaez.wordpress.com/2015/09/04/a-compositional-framework-for-markov-processes/" rel="nofollow">here</a>.)</p>
<p>&bull; Blake Pollard, <a href="http://arxiv.org/abs/1601.00711" rel="nofollow">Open Markov processes: A compositional perspective on non-equilibrium steady states in biology</a>.  (Blog article <a href="https://johncarlosbaez.wordpress.com/2016/01/11/information-geometry-part-15/" rel="nofollow">here</a>.)</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: zhangwfjh		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-65345</link>

		<dc:creator><![CDATA[zhangwfjh]]></dc:creator>
		<pubDate>Sat, 28 Mar 2015 05:59:29 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=19011#comment-65345</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-65314&quot;&gt;John Baez&lt;/a&gt;.

Got it. Thank you very much.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-65314">John Baez</a>.</p>
<p>Got it. Thank you very much.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-65314</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Fri, 27 Mar 2015 16:06:14 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=19011#comment-65314</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-65297&quot;&gt;zhangwfjh&lt;/a&gt;.

Entropy is maximized by the &quot;flat&quot; or &quot;constant&quot; probability distribution: the one with

$latex p_i = p_j$

for all $latex i, j.$  So, it&#039;s not surprising that entropy increases for any Markov process for which the flat probability distribution is an equilibrium state.  This happens if and only if time evolution is given by  &lt;a href=&quot;https://en.wikipedia.org/wiki/Doubly_stochastic_matrix&quot; rel=&quot;nofollow&quot;&gt;doubly stochastic&lt;/a&gt; matrices: matrices of nonnegative numbers where the entries in any column &lt;em&gt;and in any row&lt;/em&gt; sum to 1.

But for most Markov processes, time evolution is &lt;em&gt;not&lt;/em&gt; doubly stochastic.  For most Markov processes, the flat probability distribution is &lt;em&gt;not&lt;/em&gt; an equilibrium.

So, for most Markov processes we need to use relative entropy.  If we evolve a probability distribution according to a Markov process, its entropy &lt;em&gt;relative to any equilibrium distribution&lt;/em&gt; will increase.  (Blake says it decreases, but that&#039;s just because he&#039;s leaving the minus sign out of the definition of relative entropy.  It&#039;s just a different convention.)

This is the best way to generalize the 2nd law from doubly stochastic Markov processes to general Markov processes.  I have argued that &lt;a href=&quot;http://math.ucr.edu/home/baez/information/information_geometry_6.html&quot; rel=&quot;nofollow&quot;&gt;relative entropy is more fundamental than entropy&lt;/a&gt;, because how much information you gain when you learn something depends on what you already knew.   Note that the ordinary entropy is --- up to a constant factor and additive constant --- the same as entropy relative to the flat probability distribution.  So even ordinary entropy is relative entropy in disguise.

But the really nice thing is that when we use relative entropy, we don&#039;t need to worry about the equilibrium state!  If $latex p(t)$ and $latex q(t)$ are two probability distributions evolving in time according to a Markov process, the relative entropy $latex S(p(t), q(t))$ always increases!   The case where $latex q(t)$ is an equilibrium solution &#8212; constant in time &#8212; is just a special case.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-65297">zhangwfjh</a>.</p>
<p>Entropy is maximized by the &#8220;flat&#8221; or &#8220;constant&#8221; probability distribution: the one with</p>
<p><img src="https://s0.wp.com/latex.php?latex=p_i+%3D+p_j&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p_i = p_j" class="latex" /></p>
<p>for all <img src="https://s0.wp.com/latex.php?latex=i%2C+j.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="i, j." class="latex" />  So, it&#8217;s not surprising that entropy increases for any Markov process for which the flat probability distribution is an equilibrium state.  This happens if and only if time evolution is given by  <a href="https://en.wikipedia.org/wiki/Doubly_stochastic_matrix" rel="nofollow">doubly stochastic</a> matrices: matrices of nonnegative numbers where the entries in any column <em>and in any row</em> sum to 1.</p>
<p>But for most Markov processes, time evolution is <em>not</em> doubly stochastic.  For most Markov processes, the flat probability distribution is <em>not</em> an equilibrium.</p>
<p>So, for most Markov processes we need to use relative entropy.  If we evolve a probability distribution according to a Markov process, its entropy <em>relative to any equilibrium distribution</em> will increase.  (Blake says it decreases, but that&#8217;s just because he&#8217;s leaving the minus sign out of the definition of relative entropy.  It&#8217;s just a different convention.)</p>
<p>This is the best way to generalize the 2nd law from doubly stochastic Markov processes to general Markov processes.  I have argued that <a href="http://math.ucr.edu/home/baez/information/information_geometry_6.html" rel="nofollow">relative entropy is more fundamental than entropy</a>, because how much information you gain when you learn something depends on what you already knew.   Note that the ordinary entropy is &#8212; up to a constant factor and additive constant &#8212; the same as entropy relative to the flat probability distribution.  So even ordinary entropy is relative entropy in disguise.</p>
<p>But the really nice thing is that when we use relative entropy, we don&#8217;t need to worry about the equilibrium state!  If <img src="https://s0.wp.com/latex.php?latex=p%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q(t)" class="latex" /> are two probability distributions evolving in time according to a Markov process, the relative entropy <img src="https://s0.wp.com/latex.php?latex=S%28p%28t%29%2C+q%28t%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S(p(t), q(t))" class="latex" /> always increases!   The case where <img src="https://s0.wp.com/latex.php?latex=q%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q(t)" class="latex" /> is an equilibrium solution &mdash; constant in time &mdash; is just a special case.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: zhangwfjh		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-65297</link>

		<dc:creator><![CDATA[zhangwfjh]]></dc:creator>
		<pubDate>Fri, 27 Mar 2015 08:07:43 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=19011#comment-65297</guid>

					<description><![CDATA[Very interesting post. I have a question. Why do we consider relative entropy for Markov processes rather than entropy? As far as I know, the entropy doesn&#039;t always increase along the time evolution of Markov process, instead relative entropy does. How to explain the differences?]]></description>
			<content:encoded><![CDATA[<p>Very interesting post. I have a question. Why do we consider relative entropy for Markov processes rather than entropy? As far as I know, the entropy doesn&#8217;t always increase along the time evolution of Markov process, instead relative entropy does. How to explain the differences?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: francesco		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-61104</link>

		<dc:creator><![CDATA[francesco]]></dc:creator>
		<pubDate>Mon, 15 Dec 2014 07:50:20 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=19011#comment-61104</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-61088&quot;&gt;John Baez&lt;/a&gt;.

Sorry, that&#039;s meant to be a fact. :)
(The question mark was left behind after reformulating my comment.)]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-61088">John Baez</a>.</p>
<p>Sorry, that&#8217;s meant to be a fact. :)<br />
(The question mark was left behind after reformulating my comment.)</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-61088</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Mon, 15 Dec 2014 04:10:05 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=19011#comment-61088</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-61082&quot;&gt;francesco&lt;/a&gt;.

Francesco wrote:

&lt;blockquote&gt;
I would like to point out that a sort of information-theoretic “second-law–like” converse also hold, i.e., that any process that makes any ensemble of initial distributions less and less distinguishable over time is necessarily Markovian?
&lt;/blockquote&gt;

The question mark at the end confuses me.  Are you pointing out a fact, or asking a question?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-61082">francesco</a>.</p>
<p>Francesco wrote:</p>
<blockquote><p>
I would like to point out that a sort of information-theoretic “second-law–like” converse also hold, i.e., that any process that makes any ensemble of initial distributions less and less distinguishable over time is necessarily Markovian?
</p></blockquote>
<p>The question mark at the end confuses me.  Are you pointing out a fact, or asking a question?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: francesco		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-61082</link>

		<dc:creator><![CDATA[francesco]]></dc:creator>
		<pubDate>Mon, 15 Dec 2014 02:57:46 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=19011#comment-61082</guid>

					<description><![CDATA[Very nice post! Landed here after googling &quot;markov second law.&quot; Not sure whether I am going to contravene any blogosphere etiquette now (in which case, I apologise in advance), but I would like to point out that a sort of information-theoretic &quot;second-law--like&quot; converse also hold, i.e., that any process that makes any ensemble of initial distributions less and less distinguishable over time is necessarily Markovian? I would be happy to discuss this further, in case you are interested.]]></description>
			<content:encoded><![CDATA[<p>Very nice post! Landed here after googling &#8220;markov second law.&#8221; Not sure whether I am going to contravene any blogosphere etiquette now (in which case, I apologise in advance), but I would like to point out that a sort of information-theoretic &#8220;second-law&#8211;like&#8221; converse also hold, i.e., that any process that makes any ensemble of initial distributions less and less distinguishable over time is necessarily Markovian? I would be happy to discuss this further, in case you are interested.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Curious		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-60110</link>

		<dc:creator><![CDATA[Curious]]></dc:creator>
		<pubDate>Sat, 22 Nov 2014 05:59:27 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=19011#comment-60110</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-60090&quot;&gt;John Baez&lt;/a&gt;.

Call me convinced.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-60090">John Baez</a>.</p>
<p>Call me convinced.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-60090</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Fri, 21 Nov 2014 19:26:12 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=19011#comment-60090</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-60076&quot;&gt;Curious&lt;/a&gt;.

Up to some minor fudge factors, the entropy of a probability distribution $latex p$ is the Kullback-Leibler divergence of $latex p$ relative to the uniform distribution.  Every Markov process with a finite set of states has at least one equilibium distribution.   For Markov processes where the equilibrium distribution is the uniform distribution, entropy increases.  This is the simplest version of the Second Law.  Equivalently, the Kullback-Leibler divergence of $latex p(t)$ relative to the uniform distribution decreases.  

For Markov processes where the equilibrium distribution is some other distribution $latex q,$ the Kullback-Leibler divergence of $latex p(t)$ relative to $latex q$ decreases.  This is the simplest version of the Second Law that applies to all Markov processes with a finite set of states.

But in fact there&#039;s a more powerful generalization, which is what Blake uses.  For any Markov process, if we take two probability distributions $latex p$ and $latex q$ and evolve them forward in time, the Kullback-Leibler divergence of $latex p(t)$ relative to $latex q(t)$ decreases!

This subsumes all the results I mentioned previously.  It has the great advantage that we don&#039;t need to know an equilibrium distribution to apply it.  This, I claim, is the right way to think about the Second Law for Markov processes.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-60076">Curious</a>.</p>
<p>Up to some minor fudge factors, the entropy of a probability distribution <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> is the Kullback-Leibler divergence of <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> relative to the uniform distribution.  Every Markov process with a finite set of states has at least one equilibium distribution.   For Markov processes where the equilibrium distribution is the uniform distribution, entropy increases.  This is the simplest version of the Second Law.  Equivalently, the Kullback-Leibler divergence of <img src="https://s0.wp.com/latex.php?latex=p%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t)" class="latex" /> relative to the uniform distribution decreases.  </p>
<p>For Markov processes where the equilibrium distribution is some other distribution <img src="https://s0.wp.com/latex.php?latex=q%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q," class="latex" /> the Kullback-Leibler divergence of <img src="https://s0.wp.com/latex.php?latex=p%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t)" class="latex" /> relative to <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> decreases.  This is the simplest version of the Second Law that applies to all Markov processes with a finite set of states.</p>
<p>But in fact there&#8217;s a more powerful generalization, which is what Blake uses.  For any Markov process, if we take two probability distributions <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> and evolve them forward in time, the Kullback-Leibler divergence of <img src="https://s0.wp.com/latex.php?latex=p%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(t)" class="latex" /> relative to <img src="https://s0.wp.com/latex.php?latex=q%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q(t)" class="latex" /> decreases!</p>
<p>This subsumes all the results I mentioned previously.  It has the great advantage that we don&#8217;t need to know an equilibrium distribution to apply it.  This, I claim, is the right way to think about the Second Law for Markov processes.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Curious		</title>
		<link>https://johncarlosbaez.wordpress.com/2014/11/15/a-second-law-for-open-markov-processes/#comment-60076</link>

		<dc:creator><![CDATA[Curious]]></dc:creator>
		<pubDate>Fri, 21 Nov 2014 06:24:00 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=19011#comment-60076</guid>

					<description><![CDATA[Can you motivate why it is okay to think of the KL divergence as being relevant for a 2nd law analogy? It seems like the more natural comparison would have been with the entropy, and in that case, the entropy of the stationary distribution need not be greater than the original entropy.]]></description>
			<content:encoded><![CDATA[<p>Can you motivate why it is okay to think of the KL divergence as being relevant for a 2nd law analogy? It seems like the more natural comparison would have been with the entropy, and in that case, the entropy of the stationary distribution need not be greater than the original entropy.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

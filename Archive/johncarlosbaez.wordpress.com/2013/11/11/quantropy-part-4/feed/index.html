<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Quantropy (Part 4)	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/</link>
	<description></description>
	<lastBuildDate>Tue, 11 Feb 2020 16:42:29 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: Herb		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-158719</link>

		<dc:creator><![CDATA[Herb]]></dc:creator>
		<pubDate>Tue, 11 Feb 2020 16:42:29 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16858#comment-158719</guid>

					<description><![CDATA[Roger Balian tried to mix equilibrium statistical mechanics with quantum states in his work &quot;Justification of the Maximum Entropy Criterion in Quantum Mechanics&quot;. https://link.springer.com/chapter/10.1007/978-94-015-7860-8_9]]></description>
			<content:encoded><![CDATA[<p>Roger Balian tried to mix equilibrium statistical mechanics with quantum states in his work &#8220;Justification of the Maximum Entropy Criterion in Quantum Mechanics&#8221;. <a href="https://link.springer.com/chapter/10.1007/978-94-015-7860-8_9" rel="nofollow ugc">https://link.springer.com/chapter/10.1007/978-94-015-7860-8_9</a></p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Alek		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-100842</link>

		<dc:creator><![CDATA[Alek]]></dc:creator>
		<pubDate>Fri, 24 Nov 2017 13:56:29 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16858#comment-100842</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-33972&quot;&gt;John Baez&lt;/a&gt;.

The problem with the units of Z comes from dimensionally invalid formula for differential entropy used in obtaining Gibbs-Boltzmann distribution. instead of integrating p(q)log(q) one should calculate p(q)log(p(q)/m(q)) - where m(q) is a &quot;base measure&quot; i.e dq^n - thus dimensionful. After solving the optimization problem the base measure will appear in the numerator...]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-33972">John Baez</a>.</p>
<p>The problem with the units of Z comes from dimensionally invalid formula for differential entropy used in obtaining Gibbs-Boltzmann distribution. instead of integrating p(q)log(q) one should calculate p(q)log(p(q)/m(q)) &#8211; where m(q) is a &#8220;base measure&#8221; i.e dq^n &#8211; thus dimensionful. After solving the optimization problem the base measure will appear in the numerator&#8230;</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Uwe Stroinski		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-77421</link>

		<dc:creator><![CDATA[Uwe Stroinski]]></dc:creator>
		<pubDate>Wed, 17 Feb 2016 09:55:57 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16858#comment-77421</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-77376&quot;&gt;Simon Burton&lt;/a&gt;.

Back then I did some calculations on the harmonic oscillator. If I remember correctly they ran out of hand pretty quickly and got filed away with the comment &quot;hard work or idea needed&quot;.

I would also like to see some progression here.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-77376">Simon Burton</a>.</p>
<p>Back then I did some calculations on the harmonic oscillator. If I remember correctly they ran out of hand pretty quickly and got filed away with the comment &#8220;hard work or idea needed&#8221;.</p>
<p>I would also like to see some progression here.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-77387</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Mon, 15 Feb 2016 19:34:42 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16858#comment-77387</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-77376&quot;&gt;Simon Burton&lt;/a&gt;.

All the Hilbert spaces used in physics are countable dimensional.  But anyway, I agree that after the free particle, the harmonic oscillator is the next example to study!

My student Blake Pollard was once planning to write a paper on the quantropy of the harmonic oscillator.  He did a bunch of calculations, but he got distracted by other things (like trying to write a thesis).  I doubt he&#039;ll come back to that project.   So, anyone who wants should give it a try and report back.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-77376">Simon Burton</a>.</p>
<p>All the Hilbert spaces used in physics are countable dimensional.  But anyway, I agree that after the free particle, the harmonic oscillator is the next example to study!</p>
<p>My student Blake Pollard was once planning to write a paper on the quantropy of the harmonic oscillator.  He did a bunch of calculations, but he got distracted by other things (like trying to write a thesis).  I doubt he&#8217;ll come back to that project.   So, anyone who wants should give it a try and report back.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Simon Burton		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-77376</link>

		<dc:creator><![CDATA[Simon Burton]]></dc:creator>
		<pubDate>Mon, 15 Feb 2016 08:29:47 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16858#comment-77376</guid>

					<description><![CDATA[I would quite like to see some of these quantropy calculations in the context of the harmonic oscillator. I feel I have some chance of understanding a calculation done in a &lt;em&gt;countable&lt;/em&gt; dimensional vector space.

Or is this left as an exercise for the reader?]]></description>
			<content:encoded><![CDATA[<p>I would quite like to see some of these quantropy calculations in the context of the harmonic oscillator. I feel I have some chance of understanding a calculation done in a <em>countable</em> dimensional vector space.</p>
<p>Or is this left as an exercise for the reader?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Garrett Lisi		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-65423</link>

		<dc:creator><![CDATA[Garrett Lisi]]></dc:creator>
		<pubDate>Mon, 30 Mar 2015 20:45:38 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16858#comment-65423</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-65421&quot;&gt;John Baez&lt;/a&gt;.

The relation of fundamental physics to information is certainly a tightly woven web. I also was interested by what Frank had to say in that article about Gravi-GUT unification:

&quot;Although general relativity is based on broadly the same principle of local symmetry that guides us to the other interactions, its implementation of that principle is significantly different. The near-equality of unified coupling strengths, as we just discussed, powerfully suggests that there should be a unified theory including all four forces, but that fact in itself does not tell us how to achieve it.
String theory may offer a framework in which such four-force unification can be achieved. This is not the event, and I am not the person, to review the vast amount of work that has been done in that direction, so far with inconclusive results. It would be disappointing if string theory does not, in future years, make more direct contact with empirical reality. There are many possibilities, including some hint of additional spatial dimensions (i.e., a useful larger broken symmetry SO(1, N) → SO(1, 3))...&quot;

If he continues that line, he&#039;ll see that he needs to use at least spin(11,3) to include gravity and the gauge fields acting on a fermion generation, or spin(12,4) if he wishes to have de Sitter spacetime, at which point he&#039;ll be looking at e8(-24). I&#039;ll have to ask him about that at some point. I do hope Frank will reconsider his strong favorable stance on supersymmetry once he has to pay up on a bet on it in a few months.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-65421">John Baez</a>.</p>
<p>The relation of fundamental physics to information is certainly a tightly woven web. I also was interested by what Frank had to say in that article about Gravi-GUT unification:</p>
<p>&#8220;Although general relativity is based on broadly the same principle of local symmetry that guides us to the other interactions, its implementation of that principle is significantly different. The near-equality of unified coupling strengths, as we just discussed, powerfully suggests that there should be a unified theory including all four forces, but that fact in itself does not tell us how to achieve it.<br />
String theory may offer a framework in which such four-force unification can be achieved. This is not the event, and I am not the person, to review the vast amount of work that has been done in that direction, so far with inconclusive results. It would be disappointing if string theory does not, in future years, make more direct contact with empirical reality. There are many possibilities, including some hint of additional spatial dimensions (i.e., a useful larger broken symmetry SO(1, N) → SO(1, 3))&#8230;&#8221;</p>
<p>If he continues that line, he&#8217;ll see that he needs to use at least spin(11,3) to include gravity and the gauge fields acting on a fermion generation, or spin(12,4) if he wishes to have de Sitter spacetime, at which point he&#8217;ll be looking at e8(-24). I&#8217;ll have to ask him about that at some point. I do hope Frank will reconsider his strong favorable stance on supersymmetry once he has to pay up on a bet on it in a few months.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-65421</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Mon, 30 Mar 2015 18:21:15 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16858#comment-65421</guid>

					<description><![CDATA[This Nobel prize winner has a fun piece on the future of physics:

&#8226; Frank Wilczek, &lt;a href=&quot;http://arxiv.org/abs/1503.07735&quot; rel=&quot;nofollow&quot;&gt;Physics in 100 years&lt;/a&gt;.

The first part is about SO(1O) grand unification, etc.---&lt;a href=&quot;http://math.ucr.edu/home/baez/guts.pdf&quot; rel=&quot;nofollow&quot;&gt;good stuff to know&lt;/a&gt;, but not new.  Then he says something that reminds me of my paper with Blake on quantropy, and my claim that all minimum principles may boil down to some sort of generalization of Occam&#039;s razor (minimizing algorithmic complexity for hypotheses):

&lt;blockquote&gt;
  The &quot;higher&quot;, integrated forms of dynamics are more constrained than the lower, derived forms. Thus force fields derived from energy principles  must be conservative, and dynamical equations that follow from action principles must be capable of being written in canonical, Hamiltonian form. Two of the Maxwell equations (the magnetic Gauss law and Faraday&#039;s law of induction) become identities when we introduce potentials. Is it possible to go further in this direction?
  
  Leaving that interesting question open, let us consider more closely the foundational quantity in present-day physics: action. Our fundamental laws are most powerfully expressed using Feynman path integrals. Within that framework action appears directly and prominently, supplying the measure.  And it is at the level of action that our local symmetry principles take a simple form, as statements of invariance.
  
  Given Planck&#039;s constant as a unit, action becomes a purely numerical (dimensionless) quantity. The world-action is therefore a specific numerical quantity that governs the basic operation of the physical world. One would like for such a basic quantity to have profound independent meaning.
  
  Information is another dimensionless quantity that plays a large and increasing role in our description of the world. Many of the terms that arise naturally in discussions of information have a distinctly physical character. For example we commonly speak of density of information and flow of information. Going deeper, we find far-reaching analogies between information and (negative) entropy, as noted already in Shannon&#039;s original work. Nowadays many discussions of the microphysical origin of entropy, and of foundations of statistical mechanics in general, start from discussions of information and ignorance. I think it is fair to say that there has been a unification fusing the physical quantity (negative) entropy and the conceptual quantity information.
  
  A strong formal connection between entropy and action arises through the Euclidean, imaginary-time path integral formulation of partition functions. Indeed, in that framework the expectation value of the Euclideanized action essentially is the entropy. The identication of entropy with Euclideanized action has been used, among other things, to motivate an algebraically simple (but deeply mysterious) &quot;derivation&quot; of black hole entropy.
  
  If one could motivate the imaginary-time path integral directly and insightfully, rather than indirectly through the apparatus of energy eigenvalues, Boltzmann factors, and so forth, then one would have progressed toward this general prediction of unification:
  
  &lt;em&gt;Fundamental action principles, and thus the laws of physics, will be reinterpreted as statements about information and its transformations.&lt;/em&gt;
&lt;/blockquote&gt;]]></description>
			<content:encoded><![CDATA[<p>This Nobel prize winner has a fun piece on the future of physics:</p>
<p>&bull; Frank Wilczek, <a href="http://arxiv.org/abs/1503.07735" rel="nofollow">Physics in 100 years</a>.</p>
<p>The first part is about SO(1O) grand unification, etc.&#8212;<a href="http://math.ucr.edu/home/baez/guts.pdf" rel="nofollow">good stuff to know</a>, but not new.  Then he says something that reminds me of my paper with Blake on quantropy, and my claim that all minimum principles may boil down to some sort of generalization of Occam&#8217;s razor (minimizing algorithmic complexity for hypotheses):</p>
<blockquote><p>
  The &#8220;higher&#8221;, integrated forms of dynamics are more constrained than the lower, derived forms. Thus force fields derived from energy principles  must be conservative, and dynamical equations that follow from action principles must be capable of being written in canonical, Hamiltonian form. Two of the Maxwell equations (the magnetic Gauss law and Faraday&#8217;s law of induction) become identities when we introduce potentials. Is it possible to go further in this direction?</p>
<p>  Leaving that interesting question open, let us consider more closely the foundational quantity in present-day physics: action. Our fundamental laws are most powerfully expressed using Feynman path integrals. Within that framework action appears directly and prominently, supplying the measure.  And it is at the level of action that our local symmetry principles take a simple form, as statements of invariance.</p>
<p>  Given Planck&#8217;s constant as a unit, action becomes a purely numerical (dimensionless) quantity. The world-action is therefore a specific numerical quantity that governs the basic operation of the physical world. One would like for such a basic quantity to have profound independent meaning.</p>
<p>  Information is another dimensionless quantity that plays a large and increasing role in our description of the world. Many of the terms that arise naturally in discussions of information have a distinctly physical character. For example we commonly speak of density of information and flow of information. Going deeper, we find far-reaching analogies between information and (negative) entropy, as noted already in Shannon&#8217;s original work. Nowadays many discussions of the microphysical origin of entropy, and of foundations of statistical mechanics in general, start from discussions of information and ignorance. I think it is fair to say that there has been a unification fusing the physical quantity (negative) entropy and the conceptual quantity information.</p>
<p>  A strong formal connection between entropy and action arises through the Euclidean, imaginary-time path integral formulation of partition functions. Indeed, in that framework the expectation value of the Euclideanized action essentially is the entropy. The identication of entropy with Euclideanized action has been used, among other things, to motivate an algebraically simple (but deeply mysterious) &#8220;derivation&#8221; of black hole entropy.</p>
<p>  If one could motivate the imaginary-time path integral directly and insightfully, rather than indirectly through the apparatus of energy eigenvalues, Boltzmann factors, and so forth, then one would have progressed toward this general prediction of unification:</p>
<p>  <em>Fundamental action principles, and thus the laws of physics, will be reinterpreted as statements about information and its transformations.</em>
</p></blockquote>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-60206</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Mon, 24 Nov 2014 19:44:31 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16858#comment-60206</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-33991&quot;&gt;John Baez&lt;/a&gt;.

Bruce wrote:

&lt;blockquote&gt;
That is, sticking to classical ideas, I don’t see why that “quantity with dimensions of action” can’t have an arbitrary value.
&lt;/blockquote&gt;

Yes, it can have any value you want.  But its value affects the free energy you compute for the classical ideal gas.   If you want to get the &quot;right answer&quot;---the answer we now believe to be close to the answer for an actual gas---you need to pick this quantity with dimensions of action to be Planck&#039;s constant.

But suppose we didn&#039;t have quantum mechanics!   Would we be in serious trouble?   

Probably not. Since only energy &lt;i&gt;differences&lt;/i&gt; are measurable, one can argue---as Tobias did &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-33987&quot; rel=&quot;nofollow&quot;&gt;earlier in this long conversation&lt;/a&gt;, that an additive constant ambiguity in our definition of free energy doesn&#039;t affect any physical predictions.  That sounds correct to me.

But there&#039;s more.  The ambiguity also affects the &lt;i&gt;entropy&lt;/i&gt; you compute for the classical ideal gas!   This is more surprising, because---at least nowadays---we&#039;re less likely to think of entropy as being defined only up to an additive constant.  

But in fact, if you try to measure the entropy of a substance (as opposed to computing it), you&#039;ll see that we typically fix this constant using the Third Law of Thermodynamics: 


The entropy of a perfect crystal at absolute zero is exactly equal to zero. 


So, we measure the entropy of a gas at a given temperature by first chilling it down to absolute zero, or close, and then keeping careful track of how much heat energy it takes to warm it up to the given temperature.  If we can&#039;t afford to do this experiment, entropy is defined only up to a constant.
(And indeed, we can never afford to get all the way down to absolute zero: we have to hope that close is good enough.)

But a classical ideal gas never freezes and forms a crystal!  I believe its entropy just keeps dropping more and more as we go closer and closer to absolute zero!  More precisely, it goes to $latex -\infty$: at low temperatures it goes roughly like $latex \log(T)$, up to some fudge factors.

In short, the free energy and energy of a classical ideal gas are ambiguous up to additive constants, and the latter behaves in a rather annoying way.  If there were no quantum mechanics we could learn to live with this, but in fact physicists were irritated by this problem until quantum mechanics came along.  

I found this article quite helpful:

&#8226; S. M. Tan, &lt;i&gt;Statistical Physics&lt;/i&gt;, &lt;a href=&quot;http://home.comcast.net/~szemengtan/StatisticalMechanics/IdealGas.pdf&quot; rel=&quot;nofollow&quot;&gt;Chapter 4: the Classical Ideal Gas&lt;/a&gt;.

though they should have come out and said what I just said.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-33991">John Baez</a>.</p>
<p>Bruce wrote:</p>
<blockquote><p>
That is, sticking to classical ideas, I don’t see why that “quantity with dimensions of action” can’t have an arbitrary value.
</p></blockquote>
<p>Yes, it can have any value you want.  But its value affects the free energy you compute for the classical ideal gas.   If you want to get the &#8220;right answer&#8221;&#8212;the answer we now believe to be close to the answer for an actual gas&#8212;you need to pick this quantity with dimensions of action to be Planck&#8217;s constant.</p>
<p>But suppose we didn&#8217;t have quantum mechanics!   Would we be in serious trouble?   </p>
<p>Probably not. Since only energy <i>differences</i> are measurable, one can argue&#8212;as Tobias did <a href="https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-33987" rel="nofollow">earlier in this long conversation</a>, that an additive constant ambiguity in our definition of free energy doesn&#8217;t affect any physical predictions.  That sounds correct to me.</p>
<p>But there&#8217;s more.  The ambiguity also affects the <i>entropy</i> you compute for the classical ideal gas!   This is more surprising, because&#8212;at least nowadays&#8212;we&#8217;re less likely to think of entropy as being defined only up to an additive constant.  </p>
<p>But in fact, if you try to measure the entropy of a substance (as opposed to computing it), you&#8217;ll see that we typically fix this constant using the Third Law of Thermodynamics: </p>
<p>The entropy of a perfect crystal at absolute zero is exactly equal to zero. </p>
<p>So, we measure the entropy of a gas at a given temperature by first chilling it down to absolute zero, or close, and then keeping careful track of how much heat energy it takes to warm it up to the given temperature.  If we can&#8217;t afford to do this experiment, entropy is defined only up to a constant.<br />
(And indeed, we can never afford to get all the way down to absolute zero: we have to hope that close is good enough.)</p>
<p>But a classical ideal gas never freezes and forms a crystal!  I believe its entropy just keeps dropping more and more as we go closer and closer to absolute zero!  More precisely, it goes to <img src="https://s0.wp.com/latex.php?latex=-%5Cinfty&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="-&#92;infty" class="latex" />: at low temperatures it goes roughly like <img src="https://s0.wp.com/latex.php?latex=%5Clog%28T%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;log(T)" class="latex" />, up to some fudge factors.</p>
<p>In short, the free energy and energy of a classical ideal gas are ambiguous up to additive constants, and the latter behaves in a rather annoying way.  If there were no quantum mechanics we could learn to live with this, but in fact physicists were irritated by this problem until quantum mechanics came along.  </p>
<p>I found this article quite helpful:</p>
<p>&bull; S. M. Tan, <i>Statistical Physics</i>, <a href="http://home.comcast.net/~szemengtan/StatisticalMechanics/IdealGas.pdf" rel="nofollow">Chapter 4: the Classical Ideal Gas</a>.</p>
<p>though they should have come out and said what I just said.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Bruce Smith		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-60176</link>

		<dc:creator><![CDATA[Bruce Smith]]></dc:creator>
		<pubDate>Sun, 23 Nov 2014 23:41:39 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16858#comment-60176</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-33991&quot;&gt;John Baez&lt;/a&gt;.

Right -- I understand this part:

&lt;blockquote&gt;
to compute the free energy of a classical ideal gas ‘on the nose’, not just up to a constant, we’re forced to introduce a quantity with dimensions of action. 
&lt;/blockquote&gt;

But in the absence of any desire to go beyond the classical situation, I don&#039;t get this part:

&lt;blockquote&gt;
This quantity later turns out to equal Planck’s constant.
&lt;/blockquote&gt;

That is, sticking to classical ideas, I don&#039;t see why that &quot;quantity with dimensions of action&quot; can&#039;t have an arbitrary value.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-33991">John Baez</a>.</p>
<p>Right &#8212; I understand this part:</p>
<blockquote><p>
to compute the free energy of a classical ideal gas ‘on the nose’, not just up to a constant, we’re forced to introduce a quantity with dimensions of action.
</p></blockquote>
<p>But in the absence of any desire to go beyond the classical situation, I don&#8217;t get this part:</p>
<blockquote><p>
This quantity later turns out to equal Planck’s constant.
</p></blockquote>
<p>That is, sticking to classical ideas, I don&#8217;t see why that &#8220;quantity with dimensions of action&#8221; can&#8217;t have an arbitrary value.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-60139</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sat, 22 Nov 2014 22:33:07 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16858#comment-60139</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-33991&quot;&gt;John Baez&lt;/a&gt;.

John wrote:

&lt;blockquote&gt;    This has the effect … of introducing a fundamental length scale, which allows us to make the partition function dimensionless and also choose a specific value for it. 
&lt;/blockquote&gt;

Bruce wrote:

&lt;blockquote&gt;
By “it” I think you mean the length scale.
&lt;/blockquote&gt;

No, I meant the partition function.  

It might be helpful to recall the more familiar but completely analogous situation in statistical mechanics, where we need to choose a quantity with dimensions of action to make the partition function $latex Z$ dimensionless, and also give the partition function a specific value. 

This is important, for example, when we try to compute the free energy of a classical ideal gas, which is 

$latex -k T \ln Z$  

If we only know the partition function up to a constant multiple, we only know the free energy up to an additive constant.  And if a quantity isn&#039;t dimensionless, it&#039;s usually considered bad to take its logarithm (though Tobias has argued above that it can be okay).

Earlier I wrote:

&lt;blockquote&gt;
When people compute the free energy of a classical ideal gas. they actually want to know the answer ‘on the nose’, not just up to a constant. The reason, perhaps, is that in this subject everyone assumes that the free energy of a box full of vacuum is zero. So a zero of energy has already been fixed.

You can see one version here:

&#8226; S. M. Tan, &lt;i&gt;Statistical Physics&lt;/i&gt;, &lt;a href=&quot;http://home.comcast.net/~szemengtan/StatisticalMechanics/IdealGas.pdf&quot; rel=&quot;nofollow&quot;&gt;Chapter 4: the Classical Ideal Gas&lt;/a&gt;.

where the final answer is in equation (4.31).  One strange thing about this particular version of the calculation is that it starts as a quantum calculation and then takes the classical limit. You will see that the volume of the box divided by the &#039;thermal DeBroglie wavelength&#039; of the gas molecules shows up in the answer---see eq. (4.36) for an explanation of what I mean.  

Thus, &lt;i&gt;the answer involves Planck&#039;s constant, even in the classical limit!&lt;/i&gt; 

You can also try to compute the free energy of the classical ideal gas purely using classical mechanics.  People must have tried this before quantum mechanics was invented.  This is closer to what we&#039;re talking about here.  In this you naively start by computing

$latex Z = \displaystyle{\int_{\mathbb{R}^{3n} \times B^{n}} e^{-E(p)/kT} \; d^{3n} p \, d^{3n} q }$

where $latex p \in \mathbb{R}^{3n}$ describes the momentum  of $latex n$ particles in a 3-dimensional box $latex B \subseteq \mathbb{R}^3,$  $latex q \in B^n$ describes the position of those particles, and $latex E(p)$ is the kinetic energy of those particles, a quadratic function of $latex p$.

However, this formula for $latex Z$ is &#039;wrong&#039;, because $latex Z$ is not dimensionless!  It has units of momentum times position to the &lt;i&gt;n&lt;/i&gt;th power: that is, action to the &lt;i&gt;n&lt;/i&gt;th power.  To make it dimensionless we need to divide the measure

$latex d^{3n} p \, d^{3n} q$

by something with units of action to the &lt;i&gt;n&lt;/i&gt;th power... and this is where Planck&#039;s constant, or more precisely $latex \hbar^n,$ shows up!  In this approach, it enters in a somewhat ad hoc way.   

In other words, we&#039;re seeing that to compute the free energy of a classical ideal gas &#039;on the nose&#039;, not just up to a constant, we&#039;re &lt;i&gt;forced&lt;/i&gt; to introduce a quantity with dimensions of action.  This quantity later turns out to equal Planck&#039;s constant.  

So, we&#039;re seeing a way that quantum mechanics pushes its nose under the door even when you didn&#039;t invite it, like a camel that you wish would stay outside your tent.
&lt;/blockquote&gt;]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/11/11/quantropy-part-4/#comment-33991">John Baez</a>.</p>
<p>John wrote:</p>
<blockquote><p>    This has the effect … of introducing a fundamental length scale, which allows us to make the partition function dimensionless and also choose a specific value for it.
</p></blockquote>
<p>Bruce wrote:</p>
<blockquote><p>
By “it” I think you mean the length scale.
</p></blockquote>
<p>No, I meant the partition function.  </p>
<p>It might be helpful to recall the more familiar but completely analogous situation in statistical mechanics, where we need to choose a quantity with dimensions of action to make the partition function <img src="https://s0.wp.com/latex.php?latex=Z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Z" class="latex" /> dimensionless, and also give the partition function a specific value. </p>
<p>This is important, for example, when we try to compute the free energy of a classical ideal gas, which is </p>
<p><img src="https://s0.wp.com/latex.php?latex=-k+T+%5Cln+Z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="-k T &#92;ln Z" class="latex" />  </p>
<p>If we only know the partition function up to a constant multiple, we only know the free energy up to an additive constant.  And if a quantity isn&#8217;t dimensionless, it&#8217;s usually considered bad to take its logarithm (though Tobias has argued above that it can be okay).</p>
<p>Earlier I wrote:</p>
<blockquote><p>
When people compute the free energy of a classical ideal gas. they actually want to know the answer ‘on the nose’, not just up to a constant. The reason, perhaps, is that in this subject everyone assumes that the free energy of a box full of vacuum is zero. So a zero of energy has already been fixed.</p>
<p>You can see one version here:</p>
<p>&bull; S. M. Tan, <i>Statistical Physics</i>, <a href="http://home.comcast.net/~szemengtan/StatisticalMechanics/IdealGas.pdf" rel="nofollow">Chapter 4: the Classical Ideal Gas</a>.</p>
<p>where the final answer is in equation (4.31).  One strange thing about this particular version of the calculation is that it starts as a quantum calculation and then takes the classical limit. You will see that the volume of the box divided by the &#8216;thermal DeBroglie wavelength&#8217; of the gas molecules shows up in the answer&#8212;see eq. (4.36) for an explanation of what I mean.  </p>
<p>Thus, <i>the answer involves Planck&#8217;s constant, even in the classical limit!</i> </p>
<p>You can also try to compute the free energy of the classical ideal gas purely using classical mechanics.  People must have tried this before quantum mechanics was invented.  This is closer to what we&#8217;re talking about here.  In this you naively start by computing</p>
<p><img src="https://s0.wp.com/latex.php?latex=Z+%3D+%5Cdisplaystyle%7B%5Cint_%7B%5Cmathbb%7BR%7D%5E%7B3n%7D+%5Ctimes+B%5E%7Bn%7D%7D+e%5E%7B-E%28p%29%2FkT%7D+%5C%3B+d%5E%7B3n%7D+p+%5C%2C+d%5E%7B3n%7D+q+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Z = &#92;displaystyle{&#92;int_{&#92;mathbb{R}^{3n} &#92;times B^{n}} e^{-E(p)/kT} &#92;; d^{3n} p &#92;, d^{3n} q }" class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=p+%5Cin+%5Cmathbb%7BR%7D%5E%7B3n%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p &#92;in &#92;mathbb{R}^{3n}" class="latex" /> describes the momentum  of <img src="https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="n" class="latex" /> particles in a 3-dimensional box <img src="https://s0.wp.com/latex.php?latex=B+%5Csubseteq+%5Cmathbb%7BR%7D%5E3%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="B &#92;subseteq &#92;mathbb{R}^3," class="latex" />  <img src="https://s0.wp.com/latex.php?latex=q+%5Cin+B%5En&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q &#92;in B^n" class="latex" /> describes the position of those particles, and <img src="https://s0.wp.com/latex.php?latex=E%28p%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="E(p)" class="latex" /> is the kinetic energy of those particles, a quadratic function of <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" />.</p>
<p>However, this formula for <img src="https://s0.wp.com/latex.php?latex=Z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Z" class="latex" /> is &#8216;wrong&#8217;, because <img src="https://s0.wp.com/latex.php?latex=Z&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Z" class="latex" /> is not dimensionless!  It has units of momentum times position to the <i>n</i>th power: that is, action to the <i>n</i>th power.  To make it dimensionless we need to divide the measure</p>
<p><img src="https://s0.wp.com/latex.php?latex=d%5E%7B3n%7D+p+%5C%2C+d%5E%7B3n%7D+q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="d^{3n} p &#92;, d^{3n} q" class="latex" /></p>
<p>by something with units of action to the <i>n</i>th power&#8230; and this is where Planck&#8217;s constant, or more precisely <img src="https://s0.wp.com/latex.php?latex=%5Chbar%5En%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar^n," class="latex" /> shows up!  In this approach, it enters in a somewhat ad hoc way.   </p>
<p>In other words, we&#8217;re seeing that to compute the free energy of a classical ideal gas &#8216;on the nose&#8217;, not just up to a constant, we&#8217;re <i>forced</i> to introduce a quantity with dimensions of action.  This quantity later turns out to equal Planck&#8217;s constant.  </p>
<p>So, we&#8217;re seeing a way that quantum mechanics pushes its nose under the door even when you didn&#8217;t invite it, like a camel that you wish would stay outside your tent.
</p></blockquote>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: The Large-Number Limit for Reaction Networks (Part 2)	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/</link>
	<description></description>
	<lastBuildDate>Wed, 08 Oct 2014 23:36:21 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: The Large-Number Limit for Reaction Networks (Part 3) &#124; Azimuth		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-58067</link>

		<dc:creator><![CDATA[The Large-Number Limit for Reaction Networks (Part 3) &#124; Azimuth]]></dc:creator>
		<pubDate>Wed, 08 Oct 2014 23:36:21 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16399#comment-58067</guid>

					<description><![CDATA[Now we have most of the concepts and tools in place, and we can tackle the large-number limit using quantum techniques.  You can review the details here:

• &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/01/the-large-number-limit-for-reaction-networks-part-1/&quot; rel=&quot;nofollow&quot;&gt;The large-number limit for reaction networks (part 1)&lt;/a&gt;.

• &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/&quot; rel=&quot;nofollow&quot;&gt;The large-number limit for reaction networks (part 2) &lt;/a&gt;.
]]></description>
			<content:encoded><![CDATA[<p>Now we have most of the concepts and tools in place, and we can tackle the large-number limit using quantum techniques.  You can review the details here:</p>
<p>• <a href="https://johncarlosbaez.wordpress.com/2013/07/01/the-large-number-limit-for-reaction-networks-part-1/" rel="nofollow">The large-number limit for reaction networks (part 1)</a>.</p>
<p>• <a href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/" rel="nofollow">The large-number limit for reaction networks (part 2) </a>.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Dan		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31613</link>

		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Fri, 12 Jul 2013 19:25:42 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16399#comment-31613</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31541&quot;&gt;John Baez&lt;/a&gt;.

Ah!  I see that I&#039;m chasing down the Generalized Central Limit Theorem....

http://www.stat.purdue.edu/research/technical_reports/pdfs/1-527/tr-406.pdf

Rabbit holes are fun, but not often conducive to productivity.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31541">John Baez</a>.</p>
<p>Ah!  I see that I&#8217;m chasing down the Generalized Central Limit Theorem&#8230;.</p>
<p><object data="http://www.stat.purdue.edu/research/technical_reports/pdfs/1-527/tr-406.pdf" type="application/pdf" width="100%" height="800" style="height: 800px;"><p><a href="http://www.stat.purdue.edu/research/technical_reports/pdfs/1-527/tr-406.pdf">Click to access tr-406.pdf</a></p></object></p>
<p>Rabbit holes are fun, but not often conducive to productivity.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Dan		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31612</link>

		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Fri, 12 Jul 2013 19:04:45 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16399#comment-31612</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31541&quot;&gt;John Baez&lt;/a&gt;.

It looks like maybe there was a word missing in the paper I quoted (I thought maybe they just needed to drop the -ly).  From this paper

http://www.actuaries.org/LIBRARY/ASTIN/vol6no1/42.pdf

it seems that the theorem in Feller says something about all infinitely divisible distributions on the nonnegative integers being compound Poisson, meaning they can be represented as

$latex \sum_{n=1}^{N} X_n$ 

where $latex N$ is Poisson and $latex X_n$ are iid and independent of $latex N$.  And infinitely divisible seems to be a condition on the characteristic function of the distribution.  It looks like it means that all roots of the characteristic function are themselves characteristic functions.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31541">John Baez</a>.</p>
<p>It looks like maybe there was a word missing in the paper I quoted (I thought maybe they just needed to drop the -ly).  From this paper</p>
<p><object data="http://www.actuaries.org/LIBRARY/ASTIN/vol6no1/42.pdf" type="application/pdf" width="100%" height="800" style="height: 800px;"><p><a href="http://www.actuaries.org/LIBRARY/ASTIN/vol6no1/42.pdf">Click to access 42.pdf</a></p></object></p>
<p>it seems that the theorem in Feller says something about all infinitely divisible distributions on the nonnegative integers being compound Poisson, meaning they can be represented as</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bn%3D1%7D%5E%7BN%7D+X_n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;sum_{n=1}^{N} X_n" class="latex" /> </p>
<p>where <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> is Poisson and <img src="https://s0.wp.com/latex.php?latex=X_n&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X_n" class="latex" /> are iid and independent of <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" />.  And infinitely divisible seems to be a condition on the characteristic function of the distribution.  It looks like it means that all roots of the characteristic function are themselves characteristic functions.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Dan		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31608</link>

		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Fri, 12 Jul 2013 15:23:00 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16399#comment-31608</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31541&quot;&gt;John Baez&lt;/a&gt;.

So, your comment got me to thinking about the relationship between falling powers moments (what seem to be referred to as &quot;factorial moments&quot; elsewhere) and cumulants.  And it sent me down a rabbit hole called the Umbral Calculus, which I had never heard of before.  If you haven&#039;t either, then the introduction of this survey is nice:

http://www1.combinatorics.org/Surveys/ds3.pdf

Anyway, I found myself reading this paper by Di Nardo and Senato:

http://www.unibas.it/utenti/dinardo/amm4.pdf

Using the umbral calculus, it details the relationships between moments, factorial moments, central moments, and cumulants of random variables.  The Poisson distribution seems to come up a lot.  There&#039;s a lot of notation and (unfortunately) I don&#039;t really have the time to understand it fully.  But here&#039;s a few tidbits I pulled out that might be relevant to the present discussion:

1. Proposition 7.1 shows that the factorial moment generating function is $latex M[\log(1+t)]$ where $latex M(t)$ is the ordinary moment generating function.  So, for the Poisson with mean $latex \mu$, we&#039;d get $latex e^{t\mu}$ demonstrating the property you used in your proof above, i.e., the the r-th factorial moment of the Poisson is just $latex \mu^r$.

2. Footnote 3 is a quote giving a short history of cumulants, which I found interesting.

3. The first sentence of section 4 says:
&lt;blockquote&gt;
The family of Poisson r.v.&#039;s plays a crucial role in the theory of r.v.&#039;s, especially because the most general infinitely [sic] distribution may be represented as a limit of an appropriate sequence of compound Poisson processes (cf. [4]).
&lt;/blockquote&gt;
Now, [4] is the second volume of Feller&#039;s classic treatise on probability theory.  I&#039;m almost ashamed to admit that I don&#039;t have access to a copy of that text, so I&#039;m not really sure what that statement means, but it sounds like it might be relevant to your classical limit, no?  After all, you understand the limit for Poisson distributions....]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31541">John Baez</a>.</p>
<p>So, your comment got me to thinking about the relationship between falling powers moments (what seem to be referred to as &#8220;factorial moments&#8221; elsewhere) and cumulants.  And it sent me down a rabbit hole called the Umbral Calculus, which I had never heard of before.  If you haven&#8217;t either, then the introduction of this survey is nice:</p>
<p><object data="http://www1.combinatorics.org/Surveys/ds3.pdf" type="application/pdf" width="100%" height="800" style="height: 800px;"><p><a href="http://www1.combinatorics.org/Surveys/ds3.pdf">Click to access ds3.pdf</a></p></object></p>
<p>Anyway, I found myself reading this paper by Di Nardo and Senato:</p>
<p><object data="http://www.unibas.it/utenti/dinardo/amm4.pdf" type="application/pdf" width="100%" height="800" style="height: 800px;"><p><a href="http://www.unibas.it/utenti/dinardo/amm4.pdf">Click to access amm4.pdf</a></p></object></p>
<p>Using the umbral calculus, it details the relationships between moments, factorial moments, central moments, and cumulants of random variables.  The Poisson distribution seems to come up a lot.  There&#8217;s a lot of notation and (unfortunately) I don&#8217;t really have the time to understand it fully.  But here&#8217;s a few tidbits I pulled out that might be relevant to the present discussion:</p>
<p>1. Proposition 7.1 shows that the factorial moment generating function is <img src="https://s0.wp.com/latex.php?latex=M%5B%5Clog%281%2Bt%29%5D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M[&#92;log(1+t)]" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=M%28t%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M(t)" class="latex" /> is the ordinary moment generating function.  So, for the Poisson with mean <img src="https://s0.wp.com/latex.php?latex=%5Cmu&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mu" class="latex" />, we&#8217;d get <img src="https://s0.wp.com/latex.php?latex=e%5E%7Bt%5Cmu%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="e^{t&#92;mu}" class="latex" /> demonstrating the property you used in your proof above, i.e., the the r-th factorial moment of the Poisson is just <img src="https://s0.wp.com/latex.php?latex=%5Cmu%5Er&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mu^r" class="latex" />.</p>
<p>2. Footnote 3 is a quote giving a short history of cumulants, which I found interesting.</p>
<p>3. The first sentence of section 4 says:</p>
<blockquote><p>
The family of Poisson r.v.&#8217;s plays a crucial role in the theory of r.v.&#8217;s, especially because the most general infinitely [sic] distribution may be represented as a limit of an appropriate sequence of compound Poisson processes (cf. [4]).
</p></blockquote>
<p>Now, [4] is the second volume of Feller&#8217;s classic treatise on probability theory.  I&#8217;m almost ashamed to admit that I don&#8217;t have access to a copy of that text, so I&#8217;m not really sure what that statement means, but it sounds like it might be relevant to your classical limit, no?  After all, you understand the limit for Poisson distributions&#8230;.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Dan		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31557</link>

		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Wed, 10 Jul 2013 15:02:25 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16399#comment-31557</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31541&quot;&gt;John Baez&lt;/a&gt;.

I doubt our paths will ever cross, but I do appreciate the offer and certainly wouldn&#039;t turn down a beer.  But, as you noted, this is really just about the fun for me.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31541">John Baez</a>.</p>
<p>I doubt our paths will ever cross, but I do appreciate the offer and certainly wouldn&#8217;t turn down a beer.  But, as you noted, this is really just about the fun for me.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31541</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Wed, 10 Jul 2013 03:20:30 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16399#comment-31541</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31503&quot;&gt;Dan&lt;/a&gt;.

If I ever meet you I will gladly buy you a beer or two---or any beverage of your choice.  That may recompense you for your unpaid work (though I know you did it just for fun).

I like your approach, because it illustrates a little bit of the power and beauty of cumulants.  First, the cumulant generating function of the Poisson distribution is so much simpler than the moment generating function.  Second, it&#039;s nice how all the higher cumulants don&#039;t care when you translate the Poisson distribution to make its mean zero.  (I bet that&#039;s a general property of cumulants but I&#039;m too lazy to think about it now.)

Your approach is also a bit like my final approach, in the following sense.   We avoid working directly with moments and work with other quantities, of which the moments are certain polynomial functions.  For me, I happened to notice that when 

$latex \displaystyle{ p(n) = e^{-\mu} \frac{\mu^n}{n!} } $  

is a Poisson distribution, these quantities

$latex \displaystyle{ \sum_{n = 1}^\infty  n^{\underline{k}} \; p(n) = \sum_{n = 1}^\infty  n(n-1)(n-2) \cdots (n-k+1) \, p(n) }$

are simpler than the moments:

$latex \displaystyle{ \sum_{n = 1}^\infty  n^k \; p(n) }$

They obey

$latex \displaystyle{ \sum_{n = 1}^\infty  n^{\underline{k}} \; p(n) = \left(\sum_{n = 1}^\infty  n p(n)\right)^k}$

Someone who knew more about Poisson distributions would presumably know all sorts of tricks like this, including cumulants, but I&#039;ve never really studied them before.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31503">Dan</a>.</p>
<p>If I ever meet you I will gladly buy you a beer or two&#8212;or any beverage of your choice.  That may recompense you for your unpaid work (though I know you did it just for fun).</p>
<p>I like your approach, because it illustrates a little bit of the power and beauty of cumulants.  First, the cumulant generating function of the Poisson distribution is so much simpler than the moment generating function.  Second, it&#8217;s nice how all the higher cumulants don&#8217;t care when you translate the Poisson distribution to make its mean zero.  (I bet that&#8217;s a general property of cumulants but I&#8217;m too lazy to think about it now.)</p>
<p>Your approach is also a bit like my final approach, in the following sense.   We avoid working directly with moments and work with other quantities, of which the moments are certain polynomial functions.  For me, I happened to notice that when </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+p%28n%29+%3D+e%5E%7B-%5Cmu%7D+%5Cfrac%7B%5Cmu%5En%7D%7Bn%21%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ p(n) = e^{-&#92;mu} &#92;frac{&#92;mu^n}{n!} } " class="latex" />  </p>
<p>is a Poisson distribution, these quantities</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Csum_%7Bn+%3D+1%7D%5E%5Cinfty++n%5E%7B%5Cunderline%7Bk%7D%7D+%5C%3B+p%28n%29+%3D+%5Csum_%7Bn+%3D+1%7D%5E%5Cinfty++n%28n-1%29%28n-2%29+%5Ccdots+%28n-k%2B1%29+%5C%2C+p%28n%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;sum_{n = 1}^&#92;infty  n^{&#92;underline{k}} &#92;; p(n) = &#92;sum_{n = 1}^&#92;infty  n(n-1)(n-2) &#92;cdots (n-k+1) &#92;, p(n) }" class="latex" /></p>
<p>are simpler than the moments:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Csum_%7Bn+%3D+1%7D%5E%5Cinfty++n%5Ek+%5C%3B+p%28n%29+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;sum_{n = 1}^&#92;infty  n^k &#92;; p(n) }" class="latex" /></p>
<p>They obey</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Csum_%7Bn+%3D+1%7D%5E%5Cinfty++n%5E%7B%5Cunderline%7Bk%7D%7D+%5C%3B+p%28n%29+%3D+%5Cleft%28%5Csum_%7Bn+%3D+1%7D%5E%5Cinfty++n+p%28n%29%5Cright%29%5Ek%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;sum_{n = 1}^&#92;infty  n^{&#92;underline{k}} &#92;; p(n) = &#92;left(&#92;sum_{n = 1}^&#92;infty  n p(n)&#92;right)^k}" class="latex" /></p>
<p>Someone who knew more about Poisson distributions would presumably know all sorts of tricks like this, including cumulants, but I&#8217;ve never really studied them before.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31540</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Wed, 10 Jul 2013 03:04:44 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16399#comment-31540</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31518&quot;&gt;RZ&lt;/a&gt;.

If I were smart enough maybe I could do what you&#039;re saying.  Can I use some version of the central limit theorem to prove that all the higher centered moments of a Poisson distribution with mean $latex N$ approach certain functions of $latex N$ as $latex N \to \infty$? 

I would like to know.  But anyway, I got the job done some other way.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31518">RZ</a>.</p>
<p>If I were smart enough maybe I could do what you&#8217;re saying.  Can I use some version of the central limit theorem to prove that all the higher centered moments of a Poisson distribution with mean <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> approach certain functions of <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> as <img src="https://s0.wp.com/latex.php?latex=N+%5Cto+%5Cinfty&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N &#92;to &#92;infty" class="latex" />? </p>
<p>I would like to know.  But anyway, I got the job done some other way.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: RZ		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31518</link>

		<dc:creator><![CDATA[RZ]]></dc:creator>
		<pubDate>Tue, 09 Jul 2013 08:16:53 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16399#comment-31518</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31490&quot;&gt;Dan&lt;/a&gt;.

off the top of my head, can&#039;t you just invoke the central limit theorem and state that for a large number of particles the Poisson distribution looks like a Gaussian with the correct mean and variance up to $latex O(\hbar),$ and then all moments become &quot;classical&quot; (whatever that means here)?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31490">Dan</a>.</p>
<p>off the top of my head, can&#8217;t you just invoke the central limit theorem and state that for a large number of particles the Poisson distribution looks like a Gaussian with the correct mean and variance up to <img src="https://s0.wp.com/latex.php?latex=O%28%5Chbar%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="O(&#92;hbar)," class="latex" /> and then all moments become &#8220;classical&#8221; (whatever that means here)?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Dan		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31503</link>

		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Mon, 08 Jul 2013 18:19:47 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16399#comment-31503</guid>

					<description><![CDATA[Okay, John, you have a perfectly good answer to your puzzle, but here&#039;s an attempt at an abstract nonsense proof based on cumulants (for my own personal edification).  I&#039;ll start with some overly complicated notation (a prerequisite for any abstract nonsense proof).   All of this is in the context of the PMF 

$latex p(n) = e^{-\mu} \frac{\mu^n}{n!}$

where the mean is $latex \mu = c_i/\hbar$.  We have several random variables to worry about.  The ordinary number operator $latex N$ has MGF:

$latex M(t) = \langle e^{tN}\Psi_{c/\hbar}\rangle=\sum_n e^{tn} p(n) = \exp(\mu (e^t-1))$

The rescaled number operator $latex \tilde{N}$ has MGF:

$latex M_\hbar (t) = \langle e^{t\tilde{N}} \Psi_{c_i/\hbar}\rangle = \exp(\mu (e^{t\hbar}-1))$

Finally, we have the $latex c_i$-centered, rescaled number operator $latex \tilde{N}-c_i$ which has MGF:

$latex M_\hbar^{(c_i)} = \exp (\mu e^{t\hbar} -tc_i -\mu)$

Now, the CGF of the $latex c_i$-centered, rescaled number operator is

$latex \log M_\hbar^{(c_i)}=\mu e^{t\hbar}-tc_i -\mu$

So, the first cumulant of $latex \tilde{N}-c_i$ is 

$latex \frac{d}{dt}\log M_\hbar^{(c_i)}(0)=\hbar\mu -c_i=c_i-c_i=0$

where we recall that $latex \mu=c_i/\hbar$.  For higher order cumulants, the extra $latex tc_i$ term gets killed and we get the same answer as for the rescaled number operator, i.e., for $latex r=2,3,\cdots$ we have that

$latex \frac{d^r}{dt^r} \log M_\hbar^{(c_i)} (0) = \frac{d^r}{dt^r} \log M_\hbar(0)=\hbar^r \mu = \hbar^{r-1}c_i$

Thus, all cumulants for the centered, rescaled number operator of order greater than $latex r=1$ are proportional to $latex \hbar$ and the first cumulant is zero.  Furthermore, the moments of the centered, rescaled number operator can be written as polynomials of degree 1 or greater in its cumulants.  Therefore, all of the $latex c_i$-centered moments of the rescaled number operator are either zero or proportional to $latex \hbar$ and hence go to zero in the limit.

I&#039;ve always been partial to direct demonstration proofs, so I like your proof better.  But I&#039;ve already spent so much time on this that I felt I should finish it.... Now I&#039;d better get back to the work I&#039;m being paid for. :)]]></description>
			<content:encoded><![CDATA[<p>Okay, John, you have a perfectly good answer to your puzzle, but here&#8217;s an attempt at an abstract nonsense proof based on cumulants (for my own personal edification).  I&#8217;ll start with some overly complicated notation (a prerequisite for any abstract nonsense proof).   All of this is in the context of the PMF </p>
<p><img src="https://s0.wp.com/latex.php?latex=p%28n%29+%3D+e%5E%7B-%5Cmu%7D+%5Cfrac%7B%5Cmu%5En%7D%7Bn%21%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p(n) = e^{-&#92;mu} &#92;frac{&#92;mu^n}{n!}" class="latex" /></p>
<p>where the mean is <img src="https://s0.wp.com/latex.php?latex=%5Cmu+%3D+c_i%2F%5Chbar&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mu = c_i/&#92;hbar" class="latex" />.  We have several random variables to worry about.  The ordinary number operator <img src="https://s0.wp.com/latex.php?latex=N&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N" class="latex" /> has MGF:</p>
<p><img src="https://s0.wp.com/latex.php?latex=M%28t%29+%3D+%5Clangle+e%5E%7BtN%7D%5CPsi_%7Bc%2F%5Chbar%7D%5Crangle%3D%5Csum_n+e%5E%7Btn%7D+p%28n%29+%3D+%5Cexp%28%5Cmu+%28e%5Et-1%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M(t) = &#92;langle e^{tN}&#92;Psi_{c/&#92;hbar}&#92;rangle=&#92;sum_n e^{tn} p(n) = &#92;exp(&#92;mu (e^t-1))" class="latex" /></p>
<p>The rescaled number operator <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BN%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;tilde{N}" class="latex" /> has MGF:</p>
<p><img src="https://s0.wp.com/latex.php?latex=M_%5Chbar+%28t%29+%3D+%5Clangle+e%5E%7Bt%5Ctilde%7BN%7D%7D+%5CPsi_%7Bc_i%2F%5Chbar%7D%5Crangle+%3D+%5Cexp%28%5Cmu+%28e%5E%7Bt%5Chbar%7D-1%29%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M_&#92;hbar (t) = &#92;langle e^{t&#92;tilde{N}} &#92;Psi_{c_i/&#92;hbar}&#92;rangle = &#92;exp(&#92;mu (e^{t&#92;hbar}-1))" class="latex" /></p>
<p>Finally, we have the <img src="https://s0.wp.com/latex.php?latex=c_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c_i" class="latex" />-centered, rescaled number operator <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BN%7D-c_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;tilde{N}-c_i" class="latex" /> which has MGF:</p>
<p><img src="https://s0.wp.com/latex.php?latex=M_%5Chbar%5E%7B%28c_i%29%7D+%3D+%5Cexp+%28%5Cmu+e%5E%7Bt%5Chbar%7D+-tc_i+-%5Cmu%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M_&#92;hbar^{(c_i)} = &#92;exp (&#92;mu e^{t&#92;hbar} -tc_i -&#92;mu)" class="latex" /></p>
<p>Now, the CGF of the <img src="https://s0.wp.com/latex.php?latex=c_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c_i" class="latex" />-centered, rescaled number operator is</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clog+M_%5Chbar%5E%7B%28c_i%29%7D%3D%5Cmu+e%5E%7Bt%5Chbar%7D-tc_i+-%5Cmu&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;log M_&#92;hbar^{(c_i)}=&#92;mu e^{t&#92;hbar}-tc_i -&#92;mu" class="latex" /></p>
<p>So, the first cumulant of <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BN%7D-c_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;tilde{N}-c_i" class="latex" /> is </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7Bd%7D%7Bdt%7D%5Clog+M_%5Chbar%5E%7B%28c_i%29%7D%280%29%3D%5Chbar%5Cmu+-c_i%3Dc_i-c_i%3D0&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;frac{d}{dt}&#92;log M_&#92;hbar^{(c_i)}(0)=&#92;hbar&#92;mu -c_i=c_i-c_i=0" class="latex" /></p>
<p>where we recall that <img src="https://s0.wp.com/latex.php?latex=%5Cmu%3Dc_i%2F%5Chbar&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mu=c_i/&#92;hbar" class="latex" />.  For higher order cumulants, the extra <img src="https://s0.wp.com/latex.php?latex=tc_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="tc_i" class="latex" /> term gets killed and we get the same answer as for the rescaled number operator, i.e., for <img src="https://s0.wp.com/latex.php?latex=r%3D2%2C3%2C%5Ccdots&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r=2,3,&#92;cdots" class="latex" /> we have that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7Bd%5Er%7D%7Bdt%5Er%7D+%5Clog+M_%5Chbar%5E%7B%28c_i%29%7D+%280%29+%3D+%5Cfrac%7Bd%5Er%7D%7Bdt%5Er%7D+%5Clog+M_%5Chbar%280%29%3D%5Chbar%5Er+%5Cmu+%3D+%5Chbar%5E%7Br-1%7Dc_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;frac{d^r}{dt^r} &#92;log M_&#92;hbar^{(c_i)} (0) = &#92;frac{d^r}{dt^r} &#92;log M_&#92;hbar(0)=&#92;hbar^r &#92;mu = &#92;hbar^{r-1}c_i" class="latex" /></p>
<p>Thus, all cumulants for the centered, rescaled number operator of order greater than <img src="https://s0.wp.com/latex.php?latex=r%3D1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="r=1" class="latex" /> are proportional to <img src="https://s0.wp.com/latex.php?latex=%5Chbar&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar" class="latex" /> and the first cumulant is zero.  Furthermore, the moments of the centered, rescaled number operator can be written as polynomials of degree 1 or greater in its cumulants.  Therefore, all of the <img src="https://s0.wp.com/latex.php?latex=c_i&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="c_i" class="latex" />-centered moments of the rescaled number operator are either zero or proportional to <img src="https://s0.wp.com/latex.php?latex=%5Chbar&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;hbar" class="latex" /> and hence go to zero in the limit.</p>
<p>I&#8217;ve always been partial to direct demonstration proofs, so I like your proof better.  But I&#8217;ve already spent so much time on this that I felt I should finish it&#8230;. Now I&#8217;d better get back to the work I&#8217;m being paid for. :)</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: domenico		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/06/the-large-number-limit-for-reaction-networks-part-2/#comment-31501</link>

		<dc:creator><![CDATA[domenico]]></dc:creator>
		<pubDate>Mon, 08 Jul 2013 17:20:23 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16399#comment-31501</guid>

					<description><![CDATA[I am thinking a simple idea, and monstrous calculations.
If a system have a operator distribution that depend on the temperature, then it is possible to apply the statistical mechanic over the second quantization.
If this happen there is a connection between Feynmann diagram and chemical reaction (from elementary particles interaction to molecule chemical reaction potential).
Can the Feynmann diagram be applied to the molecule reaction using simply an approximation of the reaction potential instead of the potential between elementary particles?]]></description>
			<content:encoded><![CDATA[<p>I am thinking a simple idea, and monstrous calculations.<br />
If a system have a operator distribution that depend on the temperature, then it is possible to apply the statistical mechanic over the second quantization.<br />
If this happen there is a connection between Feynmann diagram and chemical reaction (from elementary particles interaction to molecule chemical reaction potential).<br />
Can the Feynmann diagram be applied to the molecule reaction using simply an approximation of the reaction potential instead of the potential between elementary particles?</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Relative Entropy (Part 2)	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/</link>
	<description></description>
	<lastBuildDate>Thu, 26 May 2016 18:23:31 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-36897</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Sat, 22 Feb 2014 11:08:11 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16333#comment-36897</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-36862&quot;&gt;Steve&lt;/a&gt;.

Yes indeed---I&#039;ll fix that.  Thanks!]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-36862">Steve</a>.</p>
<p>Yes indeed&#8212;I&#8217;ll fix that.  Thanks!</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Steve		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-36862</link>

		<dc:creator><![CDATA[Steve]]></dc:creator>
		<pubDate>Fri, 21 Feb 2014 18:59:15 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16333#comment-36862</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-31333&quot;&gt;John Baez&lt;/a&gt;.

Thanks for the broader overview of those diagrams! As long as we&#039;re correcting small typos, I&#039;m thinking that by &quot;It’s each to check that multiplying two stochastic matrices gives a stochastic matrix,&quot; you meant &quot;It’s easy to check that multiplying two stochastic matrices gives a stochastic matrix.&quot;]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-31333">John Baez</a>.</p>
<p>Thanks for the broader overview of those diagrams! As long as we&#8217;re correcting small typos, I&#8217;m thinking that by &#8220;It’s each to check that multiplying two stochastic matrices gives a stochastic matrix,&#8221; you meant &#8220;It’s easy to check that multiplying two stochastic matrices gives a stochastic matrix.&#8221;</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Relative Entropy (Part 4) &#124; Azimuth		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-36574</link>

		<dc:creator><![CDATA[Relative Entropy (Part 4) &#124; Azimuth]]></dc:creator>
		<pubDate>Sun, 16 Feb 2014 11:19:03 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16333#comment-36574</guid>

					<description><![CDATA[Now Tobias Fritz and I have finally finished our paper on this subject:

&#8226; &lt;a href=&quot;http://arxiv.org/abs/1402.3067&quot; rel=&quot;nofollow&quot;&gt;A Bayesian characterization of relative entropy&lt;/a&gt;.]]></description>
			<content:encoded><![CDATA[<p>Now Tobias Fritz and I have finally finished our paper on this subject:</p>
<p>&bull; <a href="http://arxiv.org/abs/1402.3067" rel="nofollow">A Bayesian characterization of relative entropy</a>.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Categories in Control &#124; Azimuth		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-36003</link>

		<dc:creator><![CDATA[Categories in Control &#124; Azimuth]]></dc:creator>
		<pubDate>Thu, 06 Feb 2014 07:38:27 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16333#comment-36003</guid>

					<description><![CDATA[Tobias Fritz, a postdoc at the Perimeter Institute, is working with me on category-theoretic aspects of information theory. We published a paper on entropy with Tom Leinster, and we&#8217;ve got a followup on relative entropy that&#8217;s almost done. I should be working on it right this instant!  But for now, read the series of posts here on Azimuth: Relative Entropy Part 1, Part 2 and Part 3. [&#8230;]]]></description>
			<content:encoded><![CDATA[<p>Tobias Fritz, a postdoc at the Perimeter Institute, is working with me on category-theoretic aspects of information theory. We published a paper on entropy with Tom Leinster, and we&#8217;ve got a followup on relative entropy that&#8217;s almost done. I should be working on it right this instant!  But for now, read the series of posts here on Azimuth: Relative Entropy Part 1, Part 2 and Part 3. [&#8230;]</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: When does Bayesian inference shatter? &#124; It&#039;s chancy.		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-35018</link>

		<dc:creator><![CDATA[When does Bayesian inference shatter? &#124; It&#039;s chancy.]]></dc:creator>
		<pubDate>Sat, 04 Jan 2014 03:53:18 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16333#comment-35018</guid>

					<description><![CDATA[[&#8230;] but I don’t have the knowledge and training to develop this idea — you’d need someone like John Baez for [&#8230;]]]></description>
			<content:encoded><![CDATA[<p>[&#8230;] but I don’t have the knowledge and training to develop this idea — you’d need someone like John Baez for [&#8230;]</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Relative Entropy (Part 3) &#124; Azimuth		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-34788</link>

		<dc:creator><![CDATA[Relative Entropy (Part 3) &#124; Azimuth]]></dc:creator>
		<pubDate>Wed, 25 Dec 2013 03:22:26 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16333#comment-34788</guid>

					<description><![CDATA[In the last couple days I&#039;ve returned to working on a paper with Tobias Fritz where we give a Bayesian characterization of the concept of &#039;relative entropy&#039;.  This summer I wrote two blog articles about this paper:

&#8226; &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/06/20/relative-entropy-part-1/&quot; rel=&quot;nofollow&quot;&gt;Relative Entropy (Part 1)&lt;/a&gt;: how various structures important in probability theory arise naturally when you do linear algebra using only the nonnegative real numbers. 

&#8226; &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/&quot; rel=&quot;nofollow&quot;&gt;Relative Entropy (Part 2)&lt;/a&gt;: a category related to statistical inference, $latex \mathrm{FinStat},$ and how relative entropy defines a functor on this category.

But then Tobias Fritz noticed a big problem.]]></description>
			<content:encoded><![CDATA[<p>In the last couple days I&#8217;ve returned to working on a paper with Tobias Fritz where we give a Bayesian characterization of the concept of &#8216;relative entropy&#8217;.  This summer I wrote two blog articles about this paper:</p>
<p>&bull; <a href="https://johncarlosbaez.wordpress.com/2013/06/20/relative-entropy-part-1/" rel="nofollow">Relative Entropy (Part 1)</a>: how various structures important in probability theory arise naturally when you do linear algebra using only the nonnegative real numbers. </p>
<p>&bull; <a href="https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/" rel="nofollow">Relative Entropy (Part 2)</a>: a category related to statistical inference, <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BFinStat%7D%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;mathrm{FinStat}," class="latex" /> and how relative entropy defines a functor on this category.</p>
<p>But then Tobias Fritz noticed a big problem.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-31572</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Thu, 11 Jul 2013 06:48:18 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16333#comment-31572</guid>

					<description><![CDATA[I had written:

&lt;blockquote&gt;
This covers the case when $latex y = f(x).$ We also can’t figure out $latex s_{x,y}$ if $latex y$ isn’t in the image of $latex f.$
&lt;/blockquote&gt;

But now I see that second case never comes up!  In this situation

&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;http://math.ucr.edu/home/baez/mathematical/FP_morphism.jpg&quot;/&gt;&lt;/div&gt;

we can show that the function $latex f$ is onto.  The paper I&#039;m writing with Tobias will explain this...]]></description>
			<content:encoded><![CDATA[<p>I had written:</p>
<blockquote><p>
This covers the case when <img src="https://s0.wp.com/latex.php?latex=y+%3D+f%28x%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y = f(x)." class="latex" /> We also can’t figure out <img src="https://s0.wp.com/latex.php?latex=s_%7Bx%2Cy%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s_{x,y}" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y" class="latex" /> isn’t in the image of <img src="https://s0.wp.com/latex.php?latex=f.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f." class="latex" />
</p></blockquote>
<p>But now I see that second case never comes up!  In this situation</p>
<div align="center"><img src="https://i2.wp.com/math.ucr.edu/home/baez/mathematical/FP_morphism.jpg"/></div>
<p>we can show that the function <img src="https://s0.wp.com/latex.php?latex=f&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f" class="latex" /> is onto.  The paper I&#8217;m writing with Tobias will explain this&#8230;</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-31571</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Thu, 11 Jul 2013 06:44:43 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16333#comment-31571</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-31350&quot;&gt;arch1&lt;/a&gt;.

Yes, that&#039;s one of the equations that would hold if the whole diagram above commuted.  There&#039;s also another:

$latex s \circ f = 1_X$

And this is something we really don&#039;t want, usually.  Taken together with 

$latex f \circ s = 1_Y$

that would imply a very strong condition on our function $latex f.$  

Can anyone see what this condition amounts to?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-31350">arch1</a>.</p>
<p>Yes, that&#8217;s one of the equations that would hold if the whole diagram above commuted.  There&#8217;s also another:</p>
<p><img src="https://s0.wp.com/latex.php?latex=s+%5Ccirc+f+%3D+1_X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s &#92;circ f = 1_X" class="latex" /></p>
<p>And this is something we really don&#8217;t want, usually.  Taken together with </p>
<p><img src="https://s0.wp.com/latex.php?latex=f+%5Ccirc+s+%3D+1_Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f &#92;circ s = 1_Y" class="latex" /></p>
<p>that would imply a very strong condition on our function <img src="https://s0.wp.com/latex.php?latex=f.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f." class="latex" />  </p>
<p>Can anyone see what this condition amounts to?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: arch1		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-31350</link>

		<dc:creator><![CDATA[arch1]]></dc:creator>
		<pubDate>Wed, 03 Jul 2013 16:47:36 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16333#comment-31350</guid>

					<description><![CDATA[Thanks John.  (The two arrow types don&#039;t cause me problems if I remind myself that, as you said, functions are special cases of stochastic maps.)

I think that the equation &#039;q then s yields the same distribution on X as p does&#039; answers your exercise (in other words, as you imply above, if its diagram commutes a hypothesis is optimal).]]></description>
			<content:encoded><![CDATA[<p>Thanks John.  (The two arrow types don&#8217;t cause me problems if I remind myself that, as you said, functions are special cases of stochastic maps.)</p>
<p>I think that the equation &#8216;q then s yields the same distribution on X as p does&#8217; answers your exercise (in other words, as you imply above, if its diagram commutes a hypothesis is optimal).</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-31333</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Wed, 03 Jul 2013 03:26:03 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16333#comment-31333</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-31311&quot;&gt;arch1&lt;/a&gt;.

arch1 wrote:

&lt;blockquote&gt;
“unless there are observations that happen with probability zero—that is, unless there are $latex y \in X$”: Do you mean $latex Y$ instead of $latex X$?
&lt;/blockquote&gt;

Yes, thanks---I&#039;ll fix that.  Deliberately calling an element of $latex X$  “$latex y$” would be heinous mathematical crime... here in Singapore I&#039;d probably get caned for it.

I&#039;m really glad you found the exposition clear!  I&#039;m warming up to write a paper about this, so I need to know what works and what doesn&#039;t.  

I&#039;ll tell you what it means for a diagram to commute.  Here&#039;s a simple example:

&lt;div align=&quot;center&quot;&gt;
&lt;img width=&quot;200&quot; src=&quot;http://math.ucr.edu/home/baez/mathematical/measure-preserving_stochastic_map.jpg&quot; /&gt;
&lt;/div&gt;

A diagram commutes whenever, given two ways to get from one object to another by following a chain of arrows, those two ways are equal.  In this case we have two ways to get from $latex 1$ to $latex Y.$  There&#039;s a direct way using just $latex q$ and indirect way using first $latex p$ and then $latex f.$  But they are equal---that&#039;s what the equation below the diagram says.  If I were talking to category theorists, I could skip the equation and just say &#034;the diagram commutes&#034;.

This pays off in situations where we have big complicated diagrams like this:

&lt;a href=&quot;http://en.wikipedia.org/wiki/Zig-zag_lemma&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/6/61/Complex_ses_diagram.png&quot; /&gt;&lt;/a&gt;

(from the proof of the &#039;zig-zag lemma&#039; on Wikipedia) or this:

&lt;a href=&quot;http://whatsonmyblackboard.wordpress.com/2011/06/21/commutative-braid/&quot; rel=&quot;nofollow&quot;&gt;&lt;img width=&quot;450&quot; src=&quot;http://whatsonmyblackboard.files.wordpress.com/2011/06/21june2011.jpg?w=450&quot; /&gt;
&lt;/a&gt;

(a typical sort of thing you see on an algebraic topologist&#039;s whiteboard, drawn by Patrick Orson.)   Instead of writing down dozens of equations, you get a nice visual depiction of what&#039;s going on, and you can learn to reason very quickly with these diagrams.

Unfortunately my post is not a great introduction to commutative diagrams, for two reasons.  

First, I&#039;m heavily using &lt;i&gt;two kinds of arrows&lt;/i&gt;, straight ones and wiggly ones.  This is a bit nonstandard; it means my diagrams involve not just one category but two: the category of finite sets and stochastic maps (wiggly arrows), and a subcategory of that, the category of finite sets and functions (straight arrows).  If you&#039;re just getting started at this game, you&#039;d want to start with one kind of arrow. 

Second, lots of my diagrams &lt;i&gt;don&#039;t&lt;/i&gt; commute!  They don&#039;t completely commute, so I have to say which equations &lt;i&gt;do&lt;/i&gt; hold, by writing them below the diagram, like here:

&lt;div align=&quot;center&quot;&gt;
&lt;img width=&quot;240&quot; src=&quot;http://math.ucr.edu/home/baez/mathematical/FinStat_morphism.jpg&quot; /&gt;
&lt;/div&gt;

As an exercise you can try to guess an equation not listed here that &lt;i&gt;would&lt;/i&gt; hold if the diagram &lt;i&gt;did&lt;/i&gt; commute.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/02/relative-entropy-part-2/#comment-31311">arch1</a>.</p>
<p>arch1 wrote:</p>
<blockquote><p>
“unless there are observations that happen with probability zero—that is, unless there are <img src="https://s0.wp.com/latex.php?latex=y+%5Cin+X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y &#92;in X" class="latex" />”: Do you mean <img src="https://s0.wp.com/latex.php?latex=Y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y" class="latex" /> instead of <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" />?
</p></blockquote>
<p>Yes, thanks&#8212;I&#8217;ll fix that.  Deliberately calling an element of <img src="https://s0.wp.com/latex.php?latex=X&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="X" class="latex" />  “<img src="https://s0.wp.com/latex.php?latex=y&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="y" class="latex" />” would be heinous mathematical crime&#8230; here in Singapore I&#8217;d probably get caned for it.</p>
<p>I&#8217;m really glad you found the exposition clear!  I&#8217;m warming up to write a paper about this, so I need to know what works and what doesn&#8217;t.  </p>
<p>I&#8217;ll tell you what it means for a diagram to commute.  Here&#8217;s a simple example:</p>
<div align="center">
<img width="200" src="https://i1.wp.com/math.ucr.edu/home/baez/mathematical/measure-preserving_stochastic_map.jpg" />
</div>
<p>A diagram commutes whenever, given two ways to get from one object to another by following a chain of arrows, those two ways are equal.  In this case we have two ways to get from <img src="https://s0.wp.com/latex.php?latex=1&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="1" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=Y.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Y." class="latex" />  There&#039;s a direct way using just <img src="https://s0.wp.com/latex.php?latex=q&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="q" class="latex" /> and indirect way using first <img src="https://s0.wp.com/latex.php?latex=p&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="p" class="latex" /> and then <img src="https://s0.wp.com/latex.php?latex=f.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f." class="latex" />  But they are equal&#8212;that&#039;s what the equation below the diagram says.  If I were talking to category theorists, I could skip the equation and just say &quot;the diagram commutes&quot;.</p>
<p>This pays off in situations where we have big complicated diagrams like this:</p>
<p><a href="http://en.wikipedia.org/wiki/Zig-zag_lemma" rel="nofollow"><img src="http://upload.wikimedia.org/wikipedia/commons/6/61/Complex_ses_diagram.png" /></a></p>
<p>(from the proof of the &#8216;zig-zag lemma&#8217; on Wikipedia) or this:</p>
<p><a href="http://whatsonmyblackboard.wordpress.com/2011/06/21/commutative-braid/" rel="nofollow"><img width="450" src="https://whatsonmyblackboard.files.wordpress.com/2011/06/21june2011.jpg?w=450" /><br />
</a></p>
<p>(a typical sort of thing you see on an algebraic topologist&#8217;s whiteboard, drawn by Patrick Orson.)   Instead of writing down dozens of equations, you get a nice visual depiction of what&#8217;s going on, and you can learn to reason very quickly with these diagrams.</p>
<p>Unfortunately my post is not a great introduction to commutative diagrams, for two reasons.  </p>
<p>First, I&#8217;m heavily using <i>two kinds of arrows</i>, straight ones and wiggly ones.  This is a bit nonstandard; it means my diagrams involve not just one category but two: the category of finite sets and stochastic maps (wiggly arrows), and a subcategory of that, the category of finite sets and functions (straight arrows).  If you&#8217;re just getting started at this game, you&#8217;d want to start with one kind of arrow. </p>
<p>Second, lots of my diagrams <i>don&#8217;t</i> commute!  They don&#8217;t completely commute, so I have to say which equations <i>do</i> hold, by writing them below the diagram, like here:</p>
<div align="center">
<img width="240" src="https://i1.wp.com/math.ucr.edu/home/baez/mathematical/FinStat_morphism.jpg" />
</div>
<p>As an exercise you can try to guess an equation not listed here that <i>would</i> hold if the diagram <i>did</i> commute.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

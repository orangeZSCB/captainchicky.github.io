<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	
	>
<channel>
	<title>
	Comments on: Monte Carlo Methods in Climate Science	</title>
	<atom:link href="https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/feed/" rel="self" type="application/rss+xml" />
	<link>https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/</link>
	<description></description>
	<lastBuildDate>Sat, 03 Aug 2013 03:38:49 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
	<item>
		<title>
		By: Nathan Urban		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-32158</link>

		<dc:creator><![CDATA[Nathan Urban]]></dc:creator>
		<pubDate>Sat, 03 Aug 2013 03:38:49 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16530#comment-32158</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31958&quot;&gt;Dan&lt;/a&gt;.

John,

We use bounded uniform priors on all the parameters except climate sensitivity, which uses a truncated Cauchy prior.  The preprint you link to is not the final published version.  Use &lt;a href=&quot;http://public.lanl.gov/nurban/pubs/moc-projections.pdf&quot; rel=&quot;nofollow&quot;&gt;my version&lt;/a&gt;.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31958">Dan</a>.</p>
<p>John,</p>
<p>We use bounded uniform priors on all the parameters except climate sensitivity, which uses a truncated Cauchy prior.  The preprint you link to is not the final published version.  Use <a href="http://public.lanl.gov/nurban/pubs/moc-projections.pdf" rel="nofollow">my version</a>.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: hypergeometric		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-32068</link>

		<dc:creator><![CDATA[hypergeometric]]></dc:creator>
		<pubDate>Tue, 30 Jul 2013 16:00:50 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16530#comment-32068</guid>

					<description><![CDATA[Note, BTW, that $latex P(M = m) = \int P(M = m&#124;S = s) P(S = s)\;\mathrm{d}s$ and that $latex P(M = m)$ is sometimes called [i]evidence[/i] per [K].]]></description>
			<content:encoded><![CDATA[<p>Note, BTW, that <img src="https://s0.wp.com/latex.php?latex=P%28M+%3D+m%29+%3D+%5Cint+P%28M+%3D+m%7CS+%3D+s%29+P%28S+%3D+s%29%5C%3B%5Cmathrm%7Bd%7Ds&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M = m) = &#92;int P(M = m|S = s) P(S = s)&#92;;&#92;mathrm{d}s" class="latex" /> and that <img src="https://s0.wp.com/latex.php?latex=P%28M+%3D+m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M = m)" class="latex" /> is sometimes called [i]evidence[/i] per [K].</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: hypergeometric		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31993</link>

		<dc:creator><![CDATA[hypergeometric]]></dc:creator>
		<pubDate>Fri, 26 Jul 2013 23:19:16 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16530#comment-31993</guid>

					<description><![CDATA[Additional comment on the above Comment discussion including Dan says: 25 July, 2013 at 12:31 pm, while MCMC is used in a Bayesian scheme to find or describe a Posterior, it can be used to do the same for ANY density, irrespective. It&#039;s used in Bayesian work but is just machinery.]]></description>
			<content:encoded><![CDATA[<p>Additional comment on the above Comment discussion including Dan says: 25 July, 2013 at 12:31 pm, while MCMC is used in a Bayesian scheme to find or describe a Posterior, it can be used to do the same for ANY density, irrespective. It&#8217;s used in Bayesian work but is just machinery.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: hypergeometric		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31987</link>

		<dc:creator><![CDATA[hypergeometric]]></dc:creator>
		<pubDate>Fri, 26 Jul 2013 17:23:07 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16530#comment-31987</guid>

					<description><![CDATA[Hi John,

Limited comments now. More later. Great article. Great appetizer.

(1) In the discussion of MCMC suggest putting a reference to [K] since you have him anyway and he does a superb job of introducing Metropolis-Rosenbluth-Hastings to the uninitiated, with problem sets. I would not sweat the details of burn-in or other nuances of Monte Carlo for the introductory.

(2) I&#039;d replace

&quot;Note how there is no clear signal from either the curves or the differences that the green curve is at the correct setting value while the blue one has the wrong one: the noise makes it nontrivial to estimate s.&quot;

with something like

 &quot;Note how it&#039;s difficult to make a compelling argument for why the green curve or the blue curve are more faithful representations of the red and, accordingly, which value of s is better. Their difference is due to the variability of noise.&quot; 

followed by the &quot;This is a baby version ....&quot;

(3) To overcome some of the confusion implicit in the comments above, it may be helpful to use less formal notation for Likelihood vs Posterior and simply say that more than one s value may be a candidate explanation and we want to estimate all of them, with associated probability masses. When I have a real computer, I&#039;ll work up some proposed language for that.

Nice job, all!

  -- Jan]]></description>
			<content:encoded><![CDATA[<p>Hi John,</p>
<p>Limited comments now. More later. Great article. Great appetizer.</p>
<p>(1) In the discussion of MCMC suggest putting a reference to [K] since you have him anyway and he does a superb job of introducing Metropolis-Rosenbluth-Hastings to the uninitiated, with problem sets. I would not sweat the details of burn-in or other nuances of Monte Carlo for the introductory.</p>
<p>(2) I&#8217;d replace</p>
<p>&#8220;Note how there is no clear signal from either the curves or the differences that the green curve is at the correct setting value while the blue one has the wrong one: the noise makes it nontrivial to estimate s.&#8221;</p>
<p>with something like</p>
<p> &#8220;Note how it&#8217;s difficult to make a compelling argument for why the green curve or the blue curve are more faithful representations of the red and, accordingly, which value of s is better. Their difference is due to the variability of noise.&#8221; </p>
<p>followed by the &#8220;This is a baby version &#8230;.&#8221;</p>
<p>(3) To overcome some of the confusion implicit in the comments above, it may be helpful to use less formal notation for Likelihood vs Posterior and simply say that more than one s value may be a candidate explanation and we want to estimate all of them, with associated probability masses. When I have a real computer, I&#8217;ll work up some proposed language for that.</p>
<p>Nice job, all!</p>
<p>  &#8212; Jan</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Dan		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31981</link>

		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Fri, 26 Jul 2013 13:04:35 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16530#comment-31981</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31958&quot;&gt;Dan&lt;/a&gt;.

Okay, that makes more sense now.   Thanks for taking the time to hear me out and explain things.   Now that I understand what you&#039;re doing, I would suggest that you change 
&lt;blockquote&gt;
If the modification is better, so that the ratio is greater than 1, the new state is always accepted. With some additional tricks—such as discarding the very beginning of the walk—this gives a set of samples from which can be used to compute $latex P(M=m &#124; S=s)$. Then we can compute $latex P(S = s &#124; M = m)$ using Bayes’ rule.
&lt;/blockquote&gt;
to something like
&lt;blockquote&gt;
If the modification is better, so that the ratio is greater than 1, the new state is always accepted. With some additional tricks—such as discarding the very beginning of the walk—this gives a set of samples from $latex P(S=s&#124;M=m)$. 
&lt;/blockquote&gt;
That is, leave out the stuff about using Bayes theorem again, because as far as I can tell you don&#039;t use it again.  And just go ahead and call the thing you&#039;ve got samples from the posterior, because that&#039;s what it is and that&#039;s what you say you&#039;re showing in figure 4.  Alternately, you could call it $latex P(M=m&#124;S=s)$ thought of as a function of $latex s$ and normalized to be a probability density.  But I think it is confusing to say that you&#039;re doing all of this MCMC stuff &quot;to compute $latex P(M=m&#124;S=s)$&quot; because you really need to already know how to evaluate $latex P(M=m&#124;S=s)$ in order to do the analysis.  $latex P(M=m&#124;S=s)$ is your stochastic model for how the data are generated given the settings.  You have to pick one of those before you can do anything (and, of course, you did; it is implicitly defined by $latex m_{t+1} = s m_t - m_{t-1} + N_t$ with $latex N_t$ being Gaussian noise).  

But, however you decide to write it up, I guess what I&#039;m saying is that the following sentence and a half
&lt;blockquote&gt;
...this gives a set of samples from which can be used to compute $latex P(M=m &#124; S=s)$. Then we can compute $latex P(S = s &#124; M = m)$ using Bayes’ rule.
&lt;/blockquote&gt;
 were ultimately my source of confusion.  Hope that helps in some small way.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31958">Dan</a>.</p>
<p>Okay, that makes more sense now.   Thanks for taking the time to hear me out and explain things.   Now that I understand what you&#8217;re doing, I would suggest that you change </p>
<blockquote><p>
If the modification is better, so that the ratio is greater than 1, the new state is always accepted. With some additional tricks—such as discarding the very beginning of the walk—this gives a set of samples from which can be used to compute <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm+%7C+S%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m | S=s)" class="latex" />. Then we can compute <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s+%7C+M+%3D+m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s | M = m)" class="latex" /> using Bayes’ rule.
</p></blockquote>
<p>to something like</p>
<blockquote><p>
If the modification is better, so that the ratio is greater than 1, the new state is always accepted. With some additional tricks—such as discarding the very beginning of the walk—this gives a set of samples from <img src="https://s0.wp.com/latex.php?latex=P%28S%3Ds%7CM%3Dm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S=s|M=m)" class="latex" />.
</p></blockquote>
<p>That is, leave out the stuff about using Bayes theorem again, because as far as I can tell you don&#8217;t use it again.  And just go ahead and call the thing you&#8217;ve got samples from the posterior, because that&#8217;s what it is and that&#8217;s what you say you&#8217;re showing in figure 4.  Alternately, you could call it <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm%7CS%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m|S=s)" class="latex" /> thought of as a function of <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> and normalized to be a probability density.  But I think it is confusing to say that you&#8217;re doing all of this MCMC stuff &#8220;to compute <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm%7CS%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m|S=s)" class="latex" />&#8221; because you really need to already know how to evaluate <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm%7CS%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m|S=s)" class="latex" /> in order to do the analysis.  <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm%7CS%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m|S=s)" class="latex" /> is your stochastic model for how the data are generated given the settings.  You have to pick one of those before you can do anything (and, of course, you did; it is implicitly defined by <img src="https://s0.wp.com/latex.php?latex=m_%7Bt%2B1%7D+%3D+s+m_t+-+m_%7Bt-1%7D+%2B+N_t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m_{t+1} = s m_t - m_{t-1} + N_t" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=N_t&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="N_t" class="latex" /> being Gaussian noise).  </p>
<p>But, however you decide to write it up, I guess what I&#8217;m saying is that the following sentence and a half</p>
<blockquote><p>
&#8230;this gives a set of samples from which can be used to compute <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm+%7C+S%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m | S=s)" class="latex" />. Then we can compute <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s+%7C+M+%3D+m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s | M = m)" class="latex" /> using Bayes’ rule.
</p></blockquote>
<p> were ultimately my source of confusion.  Hope that helps in some small way.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31971</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Fri, 26 Jul 2013 00:38:48 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16530#comment-31971</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31958&quot;&gt;Dan&lt;/a&gt;.

Thanks for the detailed description of the potential problem, Dan!  You wrote:

&lt;blockquote&gt;
My understanding is that if you do that, then the stationary distribution of your Markov chain will be

$latex \displaystyle{ f(s&#124;m) \equiv \frac{P(M=m&#124;S=s)}{Z(m)} } $
&lt;/blockquote&gt;

That&#039;s my understanding too.

&lt;blockquote&gt;
 So, that’s what it sounds (to me) like you’re doing. Now, here’s what I think you ought to be doing (and quite possibly are, since I believe the following is standard practice). Make your decisions of whether or not to make a step based on the ratio:

$latex \displaystyle{ \frac{P(M=m &#124; S=s&#039;) P(S=s&#039;)}{ P(M=m &#124; S=s) P(S=s)} }$

Then, the stationary distribution of the resulting Markov chain should be the posterior distribution $latex P(S=s&#124;M=m).$
&lt;/blockquote&gt;

Okay, yes, if we had some non-uniform prior $latex P(S = s)$ in mind for the &#039;settings&#039; of our model, we could do that.  But we&#039;re using a uniform prior, so $latex P(S = s)$ becomes invisible here.  We&#039;re doing this because---as far as I know---Keller and Urban are using a uniform prior on their 18 settings, with each setting uniformly distributed in an interval as shown on &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=A224E3DAC13132A9EFA5CBBE32DA8257?doi=10.1.1.140.9169&#038;rep=rep1&#038;type=pdf&quot; rel=&quot;nofollow&quot;&gt;Table 1 on page 15&lt;/a&gt; of their paper.  From this they get a posterior distribution whose marginals are shown in Figure 2 of page 11.

But I see your point.   Even if we&#039;re using a uniform prior, that&#039;s a &lt;i&gt;decision&lt;/i&gt; on our part: a uniform prior is just a special case of using some prior $latex P(S = s),$ so the conceptually more significant formula is the one you mention.   I&#039;ll have to think about how this should affect our explanation.  At the very least, I think we need to clarify the role that $latex P(S = s)$ plays in the whole calculation.

Thanks for putting in the time needed for me to get your point!

(Of course, it&#039;s possible I&#039;m confused &lt;i&gt;now&lt;/i&gt;, but I know enough smart people that I can make sure this is straightened out by the time we submit the paper.)]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31958">Dan</a>.</p>
<p>Thanks for the detailed description of the potential problem, Dan!  You wrote:</p>
<blockquote><p>
My understanding is that if you do that, then the stationary distribution of your Markov chain will be</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+f%28s%7Cm%29+%5Cequiv+%5Cfrac%7BP%28M%3Dm%7CS%3Ds%29%7D%7BZ%28m%29%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ f(s|m) &#92;equiv &#92;frac{P(M=m|S=s)}{Z(m)} } " class="latex" />
</p></blockquote>
<p>That&#8217;s my understanding too.</p>
<blockquote><p>
 So, that’s what it sounds (to me) like you’re doing. Now, here’s what I think you ought to be doing (and quite possibly are, since I believe the following is standard practice). Make your decisions of whether or not to make a step based on the ratio:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7BP%28M%3Dm+%7C+S%3Ds%27%29+P%28S%3Ds%27%29%7D%7B+P%28M%3Dm+%7C+S%3Ds%29+P%28S%3Ds%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{P(M=m | S=s&#039;) P(S=s&#039;)}{ P(M=m | S=s) P(S=s)} }" class="latex" /></p>
<p>Then, the stationary distribution of the resulting Markov chain should be the posterior distribution <img src="https://s0.wp.com/latex.php?latex=P%28S%3Ds%7CM%3Dm%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S=s|M=m)." class="latex" />
</p></blockquote>
<p>Okay, yes, if we had some non-uniform prior <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s)" class="latex" /> in mind for the &#8216;settings&#8217; of our model, we could do that.  But we&#8217;re using a uniform prior, so <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s)" class="latex" /> becomes invisible here.  We&#8217;re doing this because&#8212;as far as I know&#8212;Keller and Urban are using a uniform prior on their 18 settings, with each setting uniformly distributed in an interval as shown on <a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=A224E3DAC13132A9EFA5CBBE32DA8257?doi=10.1.1.140.9169&amp;rep=rep1&amp;type=pdf" rel="nofollow">Table 1 on page 15</a> of their paper.  From this they get a posterior distribution whose marginals are shown in Figure 2 of page 11.</p>
<p>But I see your point.   Even if we&#8217;re using a uniform prior, that&#8217;s a <i>decision</i> on our part: a uniform prior is just a special case of using some prior <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s%29%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s)," class="latex" /> so the conceptually more significant formula is the one you mention.   I&#8217;ll have to think about how this should affect our explanation.  At the very least, I think we need to clarify the role that <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s)" class="latex" /> plays in the whole calculation.</p>
<p>Thanks for putting in the time needed for me to get your point!</p>
<p>(Of course, it&#8217;s possible I&#8217;m confused <i>now</i>, but I know enough smart people that I can make sure this is straightened out by the time we submit the paper.)</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: arch1		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31968</link>

		<dc:creator><![CDATA[arch1]]></dc:creator>
		<pubDate>Fri, 26 Jul 2013 00:27:54 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16530#comment-31968</guid>

					<description><![CDATA[Thanks for the careful explanation John.  Regarding my 2nd point of confusion, I’m still puzzled.  I’m almost certainly misinterpreting or mis-thinking, but I’ll try to be clearer about what confuses me in case on the chance that it helps clarity of the article.

In the MCMC runs which compute $latex \displaystyle{ P(M = m &#124; S = s )} $ as a function of s, your random-walk approach tends to cluster around s values which make that function big.  In other words, for a given m, $latex \displaystyle{ P(S = s) } $ for your MCMC runs tends to be large for precisely those s values for which $latex \displaystyle{ P(M = m &#124; S = s) } $ is also large.

Are you saying that, having thus computed $latex \displaystyle{ P(M = m &#124; S = s) } $, you then compute $latex \displaystyle{ P(S = s &#124; M = m) } $ by plugging this same value of $latex \displaystyle{ P(S = s )} $ into the RHS of Bayes’ formula, and you then use the resulting $latex \displaystyle{ P(S = s &#124; M = m )} $ values to draw conclusions about actual or potential real world scenarios?

If so, I don’t see how this can work, because it seems to me that in order for the LHS of Bayes’ formula to apply to the real world, the inputs on the RHS have to, also.  But the $latex \displaystyle{ P(S = s) } $ values which characterize your MCMC runs have no relation to the real world; rather, they were chosen solely to improve efficiency in an intermediate phase of the computation.]]></description>
			<content:encoded><![CDATA[<p>Thanks for the careful explanation John.  Regarding my 2nd point of confusion, I’m still puzzled.  I’m almost certainly misinterpreting or mis-thinking, but I’ll try to be clearer about what confuses me in case on the chance that it helps clarity of the article.</p>
<p>In the MCMC runs which compute <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28M+%3D+m+%7C+S+%3D+s+%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(M = m | S = s )} " class="latex" /> as a function of s, your random-walk approach tends to cluster around s values which make that function big.  In other words, for a given m, <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28S+%3D+s%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(S = s) } " class="latex" /> for your MCMC runs tends to be large for precisely those s values for which <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28M+%3D+m+%7C+S+%3D+s%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(M = m | S = s) } " class="latex" /> is also large.</p>
<p>Are you saying that, having thus computed <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28M+%3D+m+%7C+S+%3D+s%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(M = m | S = s) } " class="latex" />, you then compute <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28S+%3D+s+%7C+M+%3D+m%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(S = s | M = m) } " class="latex" /> by plugging this same value of <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28S+%3D+s+%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(S = s )} " class="latex" /> into the RHS of Bayes’ formula, and you then use the resulting <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28S+%3D+s+%7C+M+%3D+m+%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(S = s | M = m )} " class="latex" /> values to draw conclusions about actual or potential real world scenarios?</p>
<p>If so, I don’t see how this can work, because it seems to me that in order for the LHS of Bayes’ formula to apply to the real world, the inputs on the RHS have to, also.  But the <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28S+%3D+s%29+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(S = s) } " class="latex" /> values which characterize your MCMC runs have no relation to the real world; rather, they were chosen solely to improve efficiency in an intermediate phase of the computation.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Dan		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31958</link>

		<dc:creator><![CDATA[Dan]]></dc:creator>
		<pubDate>Thu, 25 Jul 2013 12:31:05 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16530#comment-31958</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31944&quot;&gt;John Baez&lt;/a&gt;.

Well, one of us is pretty mixed up.  It&#039;s probably me.  But let me quote the bit that is confusing me, explain what it seems (to me) to be saying that you&#039;re doing (which I think is far from standard practice, if not downright wrong), and then tell you what I think you ought to be doing (and quite possibly are, though it doesn&#039;t sound like it :)).  Anyway, here&#039;s the quote from the section entitled &quot;Markov Chain Monte Carlo&quot;:

&lt;blockquote&gt;
The key to making this work is that at each step on the walk a proposed modification $latex s&#039;$ to the current settings $latex s$ is generated randomly—but it may be rejected if it does not seem to improve the estimates. The essence of the rule is:
&lt;blockquote&gt;
    The modification $latex s \mapsto s&#039;$ is randomly accepted with a probability equal to the ratio

    $latex \displaystyle{ \frac{P(M=m &#124; S=s&#039;)}{ P(M=m &#124; S=s)} }$

    Otherwise the walk stays at the current position. 
&lt;/blockquote&gt;
If the modification is better, so that the ratio is greater than 1, the new state is always accepted. With some additional tricks—such as discarding the very beginning of the walk—this gives a set of samples from which can be used to compute $latex P(M=m &#124; S=s)$. Then we can compute $latex P(S = s &#124; M = m)$ using Bayes’ rule.
&lt;/blockquote&gt;

Now, to me, it sounds like you&#039;re using the Metropolis algorithm to get your Markov chain.  Within that algorithm, you are deciding to accept or reject a step based on consideration of the ratio

$latex \displaystyle{ \frac{P(M=m &#124; S=s&#039;)}{ P(M=m &#124; S=s)} }$

My understanding is that if you do that, then the stationary distribution of your Markov chain will be

$latex f(s&#124;m) \equiv \frac{P(M=m&#124;S=s)}{Z(m)}$

where $latex Z(m)=\int P(M=m&#124;S=s) ds$ is a normalizing constant making your likelihood into a probability density when thought of as a function of the settings $latex s$.  In other words, I think the stationary distribution will be the posterior under the assumption of a uniform prior.  Now, there isn&#039;t anything wrong with this (although, if $latex S$ is not compactly supported, you may get some numerical instabilities), but it doesn&#039;t seem to be standard practice. But, forgetting that and pressing on, you then say that you run the algorithm and do the necessary tricks to get random samples from $latex f(s&#124;m)$.  That&#039;s fine, if you want the posterior under the assumption of a uniform prior.  But now, you seem to be wanting to think of these samples from $latex f(s&#124;m)$ as samples from $latex P(M=m&#124;S=s)$ and then you&#039;re somehow using these samples to get $latex P(S=s&#124;M=m)$ from Bayes rule?  I&#039;m not sure how you would do that.  I mean, I guess you could construct a density estimator of $latex f(s&#124;m)$ from its samples, multiply by $latex P(s)$, and then do a numerical integration to get the normalization, but that seems kind of convoluted.  You&#039;d basically be canceling out $latex Z(m)$ numerically, which makes me wonder why you&#039;d want to run the MCMC algorithm to begin with.  Why not just numerically integrate $latex P(M=m&#124;S=s)P(S=s)$ to find its normalization?  

So, that&#039;s what it sounds (to me) like you&#039;re doing.  Now, here&#039;s what I think you ought to be doing (and quite possibly are, since I believe the following is standard practice).  Make your decisions of whether or not to make a step based on the ratio:

$latex \frac{P(M=m &#124; S=s&#039;) P(S=s&#039;)}{ P(M=m &#124; S=s) P(S=s)} $

Then, the stationary distribution of the resulting Markov chain should be the posterior distribution $latex P(S=s&#124;M=m)$.  So, you run the algorithm and you get random samples from the posterior.  There is no need to use Bayes theorem again because you already used it (i.e., by Bayes, your step decision rule is basically the ratio of posteriors, but the unknown normalization $latex P(M=m)$ cancels out making it possible to evaluate the ratio).  Now you can use those random samples from the posterior to make a density estimator of the posterior, but more likely you&#039;ll want to use them to calculate posterior expectations by appealing to the Law of Large Numbers for Markov Chains (a.k.a. the Ergodic Theorem):

$latex \lim_{n\rightarrow \infty} \frac{1}{n}\sum_{i=1}^n h(s_i) \rightarrow \int h(s) P(S=s&#124;M=m) ds$

So, that&#039;s all my cards on the table....]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31944">John Baez</a>.</p>
<p>Well, one of us is pretty mixed up.  It&#8217;s probably me.  But let me quote the bit that is confusing me, explain what it seems (to me) to be saying that you&#8217;re doing (which I think is far from standard practice, if not downright wrong), and then tell you what I think you ought to be doing (and quite possibly are, though it doesn&#8217;t sound like it :)).  Anyway, here&#8217;s the quote from the section entitled &#8220;Markov Chain Monte Carlo&#8221;:</p>
<blockquote><p>
The key to making this work is that at each step on the walk a proposed modification <img src="https://s0.wp.com/latex.php?latex=s%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s&#039;" class="latex" /> to the current settings <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> is generated randomly—but it may be rejected if it does not seem to improve the estimates. The essence of the rule is:</p>
<blockquote><p>
    The modification <img src="https://s0.wp.com/latex.php?latex=s+%5Cmapsto+s%27&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s &#92;mapsto s&#039;" class="latex" /> is randomly accepted with a probability equal to the ratio</p>
<p>    <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7BP%28M%3Dm+%7C+S%3Ds%27%29%7D%7B+P%28M%3Dm+%7C+S%3Ds%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{P(M=m | S=s&#039;)}{ P(M=m | S=s)} }" class="latex" /></p>
<p>    Otherwise the walk stays at the current position.
</p></blockquote>
<p>If the modification is better, so that the ratio is greater than 1, the new state is always accepted. With some additional tricks—such as discarding the very beginning of the walk—this gives a set of samples from which can be used to compute <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm+%7C+S%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m | S=s)" class="latex" />. Then we can compute <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s+%7C+M+%3D+m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s | M = m)" class="latex" /> using Bayes’ rule.
</p></blockquote>
<p>Now, to me, it sounds like you&#8217;re using the Metropolis algorithm to get your Markov chain.  Within that algorithm, you are deciding to accept or reject a step based on consideration of the ratio</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+%5Cfrac%7BP%28M%3Dm+%7C+S%3Ds%27%29%7D%7B+P%28M%3Dm+%7C+S%3Ds%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ &#92;frac{P(M=m | S=s&#039;)}{ P(M=m | S=s)} }" class="latex" /></p>
<p>My understanding is that if you do that, then the stationary distribution of your Markov chain will be</p>
<p><img src="https://s0.wp.com/latex.php?latex=f%28s%7Cm%29+%5Cequiv+%5Cfrac%7BP%28M%3Dm%7CS%3Ds%29%7D%7BZ%28m%29%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(s|m) &#92;equiv &#92;frac{P(M=m|S=s)}{Z(m)}" class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=Z%28m%29%3D%5Cint+P%28M%3Dm%7CS%3Ds%29+ds&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Z(m)=&#92;int P(M=m|S=s) ds" class="latex" /> is a normalizing constant making your likelihood into a probability density when thought of as a function of the settings <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" />.  In other words, I think the stationary distribution will be the posterior under the assumption of a uniform prior.  Now, there isn&#8217;t anything wrong with this (although, if <img src="https://s0.wp.com/latex.php?latex=S&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S" class="latex" /> is not compactly supported, you may get some numerical instabilities), but it doesn&#8217;t seem to be standard practice. But, forgetting that and pressing on, you then say that you run the algorithm and do the necessary tricks to get random samples from <img src="https://s0.wp.com/latex.php?latex=f%28s%7Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(s|m)" class="latex" />.  That&#8217;s fine, if you want the posterior under the assumption of a uniform prior.  But now, you seem to be wanting to think of these samples from <img src="https://s0.wp.com/latex.php?latex=f%28s%7Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(s|m)" class="latex" /> as samples from <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm%7CS%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m|S=s)" class="latex" /> and then you&#8217;re somehow using these samples to get <img src="https://s0.wp.com/latex.php?latex=P%28S%3Ds%7CM%3Dm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S=s|M=m)" class="latex" /> from Bayes rule?  I&#8217;m not sure how you would do that.  I mean, I guess you could construct a density estimator of <img src="https://s0.wp.com/latex.php?latex=f%28s%7Cm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="f(s|m)" class="latex" /> from its samples, multiply by <img src="https://s0.wp.com/latex.php?latex=P%28s%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(s)" class="latex" />, and then do a numerical integration to get the normalization, but that seems kind of convoluted.  You&#8217;d basically be canceling out <img src="https://s0.wp.com/latex.php?latex=Z%28m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="Z(m)" class="latex" /> numerically, which makes me wonder why you&#8217;d want to run the MCMC algorithm to begin with.  Why not just numerically integrate <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm%7CS%3Ds%29P%28S%3Ds%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m|S=s)P(S=s)" class="latex" /> to find its normalization?  </p>
<p>So, that&#8217;s what it sounds (to me) like you&#8217;re doing.  Now, here&#8217;s what I think you ought to be doing (and quite possibly are, since I believe the following is standard practice).  Make your decisions of whether or not to make a step based on the ratio:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BP%28M%3Dm+%7C+S%3Ds%27%29+P%28S%3Ds%27%29%7D%7B+P%28M%3Dm+%7C+S%3Ds%29+P%28S%3Ds%29%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;frac{P(M=m | S=s&#039;) P(S=s&#039;)}{ P(M=m | S=s) P(S=s)} " class="latex" /></p>
<p>Then, the stationary distribution of the resulting Markov chain should be the posterior distribution <img src="https://s0.wp.com/latex.php?latex=P%28S%3Ds%7CM%3Dm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S=s|M=m)" class="latex" />.  So, you run the algorithm and you get random samples from the posterior.  There is no need to use Bayes theorem again because you already used it (i.e., by Bayes, your step decision rule is basically the ratio of posteriors, but the unknown normalization <img src="https://s0.wp.com/latex.php?latex=P%28M%3Dm%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M=m)" class="latex" /> cancels out making it possible to evaluate the ratio).  Now you can use those random samples from the posterior to make a density estimator of the posterior, but more likely you&#8217;ll want to use them to calculate posterior expectations by appealing to the Law of Large Numbers for Markov Chains (a.k.a. the Ergodic Theorem):</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clim_%7Bn%5Crightarrow+%5Cinfty%7D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5En+h%28s_i%29+%5Crightarrow+%5Cint+h%28s%29+P%28S%3Ds%7CM%3Dm%29+ds&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;lim_{n&#92;rightarrow &#92;infty} &#92;frac{1}{n}&#92;sum_{i=1}^n h(s_i) &#92;rightarrow &#92;int h(s) P(S=s|M=m) ds" class="latex" /></p>
<p>So, that&#8217;s all my cards on the table&#8230;.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31948</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Thu, 25 Jul 2013 03:38:06 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16530#comment-31948</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31932&quot;&gt;arch1&lt;/a&gt;.

arch1 wrote:

&lt;blockquote&gt;
It deals with a *lot* of concepts in a short article (Bayes’ formula, Monte Carlo, parametrized events, multidimensional parameters, and optimization via Markov Chains) so I think it will challenge people new to most of them.
&lt;/blockquote&gt;

Yes.  In a way it&#039;s hopelessly ambitious to introduce all these ideas in one short article, and I&#039;m afraid our article is more dry and compressed than typical for this magazine.  I&#039;m hoping that adding a few carefully chosen sentences here or there could help... not to explain more information, or address nuances, but simply to make the existing information easier to digest.

Or at the very least, we can try to remove all road bumps, like this:

&lt;blockquote&gt;

&quot;“One thing we can more easily do is repeatedly run our model with randomly chosen settings and see what measurements it predicts. By doing this, we can compute the probability that given setting values $latex S = s$ the model predicts measurements $latex M = m$.”

This was a head-scratcher,
&lt;/blockquote&gt;

Thanks!  Yes, it could be confusing that we introduce &lt;i&gt;randomly chosen settings&lt;/i&gt; here: it adds an extra layer of randomness that the reader won&#039;t be expecting.  A more obvious thing to do would be simply &lt;i&gt;choose&lt;/i&gt; settings $latex S = s,$ repeatedly run the model with these settings, and work out $latex P(M = m&#124; S = s).$   

Of course we want to do this for lots of settings, and in the end we want to choose different settings $latex s$ with different probabilities, or frequencies, $latex P(S = s).$  Then we can use Bayes&#039; rule:  

$latex \displaystyle{ P(S = s &#124; M = m) = P(M = m&#124; S = s) \frac{P(S = s)}{P(M = m)} }$

&lt;blockquote&gt;
I still find this confusing, maybe because I have a misconception. I get how “control over P(S=s)” in your MCMC runs helps compute P(M=m&#124;S=s). But in order to use Bayes’ Rule to determine P(S=s&#124;M=m), don’t you also need to know the value of P(S=s) in the real world? 
&lt;/blockquote&gt;

No: the &#039;real world&#039; doesn&#039;t know anything about our model or the probability that some settings of our model take some value $latex S = s.$   In this stage of the calculation the probability $latex P(S = s)$ is something &lt;i&gt;we&lt;/i&gt; control, and our goal is to do that cleverly to efficiently compute $latex P(S = s &#124; M = m).$

However, I sympathize with your confusion, because we zipped through something very quickly: namely, what we do when we have $latex P(S = s &#124; M = m)$.   This conditional probability tells us the probability that we should use various possible settings for our model as a function of some actual past or imagined future measurements.  So it&#039;s very useful, but it&#039;s not the final answer to any real-world question.

By the way, you once complained about what happens when you cut-and-paste a passage containing equations, like this:

&lt;blockquote&gt;
But here &lt;b&gt;Bayes&#039; rule&lt;/b&gt; comes to the rescue, relating what we want to what we can more easily compute:

$latex \displaystyle{ P(S = s &#124; M = m) = P(M = m&#124; S = s) \frac{P(S = s)}{P(M = m)} } $
&lt;/blockquote&gt;

If you cut-and-paste it, for some stupid reason you get

&lt;blockquote&gt;
But here Bayes&#039; rule comes to the rescue, relating what we want to what we can more easily compute:

\displaystyle{ P(S = s &#124; M = m) = P(M = m&#124; S = s) \frac{P(S = s)}{P(M = m)} } 
&lt;/blockquote&gt;

This looks like a mess, but you just need to put &#036;latex in front of the equation, leaving a space before the other stuff, and &#036; after it, like this:

&lt;blockquote&gt;
But here Bayes&#039; rule comes to the rescue, relating what we want to what we can more easily compute:

&#036;latex \displaystyle{ P(S = s &#124; M = m) = P(M = m&#124; S = s) \frac{P(S = s)}{P(M = m)} } &#036;
&lt;/blockquote&gt;

to get something nice:

&lt;blockquote&gt;
But here Bayes&#039; rule comes to the rescue, relating what we want to what we can more easily compute:

$latex \displaystyle{ P(S = s &#124; M = m) = P(M = m&#124; S = s) \frac{P(S = s)}{P(M = m)} } $
&lt;/blockquote&gt;

(The boldface on &quot;&lt;b&gt;Bayes&#039; rule&lt;/b&gt;&quot; is still gone, but life is short.)


]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31932">arch1</a>.</p>
<p>arch1 wrote:</p>
<blockquote><p>
It deals with a *lot* of concepts in a short article (Bayes’ formula, Monte Carlo, parametrized events, multidimensional parameters, and optimization via Markov Chains) so I think it will challenge people new to most of them.
</p></blockquote>
<p>Yes.  In a way it&#8217;s hopelessly ambitious to introduce all these ideas in one short article, and I&#8217;m afraid our article is more dry and compressed than typical for this magazine.  I&#8217;m hoping that adding a few carefully chosen sentences here or there could help&#8230; not to explain more information, or address nuances, but simply to make the existing information easier to digest.</p>
<p>Or at the very least, we can try to remove all road bumps, like this:</p>
<blockquote>
<p>&#8220;“One thing we can more easily do is repeatedly run our model with randomly chosen settings and see what measurements it predicts. By doing this, we can compute the probability that given setting values <img src="https://s0.wp.com/latex.php?latex=S+%3D+s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = s" class="latex" /> the model predicts measurements <img src="https://s0.wp.com/latex.php?latex=M+%3D+m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="M = m" class="latex" />.”</p>
<p>This was a head-scratcher,
</p></blockquote>
<p>Thanks!  Yes, it could be confusing that we introduce <i>randomly chosen settings</i> here: it adds an extra layer of randomness that the reader won&#8217;t be expecting.  A more obvious thing to do would be simply <i>choose</i> settings <img src="https://s0.wp.com/latex.php?latex=S+%3D+s%2C&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = s," class="latex" /> repeatedly run the model with these settings, and work out <img src="https://s0.wp.com/latex.php?latex=P%28M+%3D+m%7C+S+%3D+s%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(M = m| S = s)." class="latex" />   </p>
<p>Of course we want to do this for lots of settings, and in the end we want to choose different settings <img src="https://s0.wp.com/latex.php?latex=s&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="s" class="latex" /> with different probabilities, or frequencies, <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s)." class="latex" />  Then we can use Bayes&#8217; rule:  </p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28S+%3D+s+%7C+M+%3D+m%29+%3D+P%28M+%3D+m%7C+S+%3D+s%29+%5Cfrac%7BP%28S+%3D+s%29%7D%7BP%28M+%3D+m%29%7D+%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(S = s | M = m) = P(M = m| S = s) &#92;frac{P(S = s)}{P(M = m)} }" class="latex" /></p>
<blockquote><p>
I still find this confusing, maybe because I have a misconception. I get how “control over P(S=s)” in your MCMC runs helps compute P(M=m|S=s). But in order to use Bayes’ Rule to determine P(S=s|M=m), don’t you also need to know the value of P(S=s) in the real world?
</p></blockquote>
<p>No: the &#8216;real world&#8217; doesn&#8217;t know anything about our model or the probability that some settings of our model take some value <img src="https://s0.wp.com/latex.php?latex=S+%3D+s.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="S = s." class="latex" />   In this stage of the calculation the probability <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s)" class="latex" /> is something <i>we</i> control, and our goal is to do that cleverly to efficiently compute <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s+%7C+M+%3D+m%29.&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s | M = m)." class="latex" /></p>
<p>However, I sympathize with your confusion, because we zipped through something very quickly: namely, what we do when we have <img src="https://s0.wp.com/latex.php?latex=P%28S+%3D+s+%7C+M+%3D+m%29&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="P(S = s | M = m)" class="latex" />.   This conditional probability tells us the probability that we should use various possible settings for our model as a function of some actual past or imagined future measurements.  So it&#8217;s very useful, but it&#8217;s not the final answer to any real-world question.</p>
<p>By the way, you once complained about what happens when you cut-and-paste a passage containing equations, like this:</p>
<blockquote><p>
But here <b>Bayes&#8217; rule</b> comes to the rescue, relating what we want to what we can more easily compute:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28S+%3D+s+%7C+M+%3D+m%29+%3D+P%28M+%3D+m%7C+S+%3D+s%29+%5Cfrac%7BP%28S+%3D+s%29%7D%7BP%28M+%3D+m%29%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(S = s | M = m) = P(M = m| S = s) &#92;frac{P(S = s)}{P(M = m)} } " class="latex" />
</p></blockquote>
<p>If you cut-and-paste it, for some stupid reason you get</p>
<blockquote><p>
But here Bayes&#8217; rule comes to the rescue, relating what we want to what we can more easily compute:</p>
<p>\displaystyle{ P(S = s | M = m) = P(M = m| S = s) \frac{P(S = s)}{P(M = m)} }
</p></blockquote>
<p>This looks like a mess, but you just need to put &#036;latex in front of the equation, leaving a space before the other stuff, and &#036; after it, like this:</p>
<blockquote><p>
But here Bayes&#8217; rule comes to the rescue, relating what we want to what we can more easily compute:</p>
<p>&#036;latex \displaystyle{ P(S = s | M = m) = P(M = m| S = s) \frac{P(S = s)}{P(M = m)} } &#036;
</p></blockquote>
<p>to get something nice:</p>
<blockquote><p>
But here Bayes&#8217; rule comes to the rescue, relating what we want to what we can more easily compute:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%7B+P%28S+%3D+s+%7C+M+%3D+m%29+%3D+P%28M+%3D+m%7C+S+%3D+s%29+%5Cfrac%7BP%28S+%3D+s%29%7D%7BP%28M+%3D+m%29%7D+%7D+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="&#92;displaystyle{ P(S = s | M = m) = P(M = m| S = s) &#92;frac{P(S = s)}{P(M = m)} } " class="latex" />
</p></blockquote>
<p>(The boldface on &#8220;<b>Bayes&#8217; rule</b>&#8221; is still gone, but life is short.)</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Baez		</title>
		<link>https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31946</link>

		<dc:creator><![CDATA[John Baez]]></dc:creator>
		<pubDate>Thu, 25 Jul 2013 02:24:27 +0000</pubDate>
		<guid isPermaLink="false">http://johncarlosbaez.wordpress.com/?p=16530#comment-31946</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31930&quot;&gt;nick&lt;/a&gt;.

Nick wrote:

&lt;blockquote&gt;
“containing related strongly related things”

This seems awkwardly phrased. 
&lt;/blockquote&gt;

It was just a typo for &quot;strongly related&quot;, not a deliberate phrasing.  Fixed!

&lt;blockquote&gt;
“red are predicted measurements”

I guess this is slightly ambiguous, depending on whether you’re referring to red as a line or a collection of points, but for consistency with the rest of your figure 2 description, I think it should be something like “red is the predicted measurement”
&lt;/blockquote&gt;

I&#039;ll have to think about that.  Right now we&#039;re calling $latex m$ &lt;b&gt;the measurements&lt;/b&gt;, and in our example it&#039;s a list of numbers $latex m_1, \dots, m_T$, each of which we could call &#039;a measurement&#039;, though actually we just say:

&lt;blockquote&gt;
 Suppose our measurements are real numbers $latex m_0,\dots, m_T$ related by

$latex m_{t+1} = s m_t - m_{t-1} + N_t $
&lt;/blockquote&gt;

So, the red curve shows &quot;the measurements&quot;.

&lt;blockquote&gt;
 “modification s’ to the current settings s’ ”

Do you mean “modification s to the current settings s’ “?
&lt;/blockquote&gt;

No, we mean &quot;the modification s&#039; to the current settings s.  In math, primes are often used for &#039;modified&#039; or &#039;changed&#039; things.  Thanks for catching this mistake, though!  Fixed.

&lt;blockquote&gt;
I feel like the word nonlinear should be included somewhere in this article. 
&lt;/blockquote&gt;

Hmm, personally I&#039;m a bit tired of how people keep emphasizing that real life involves a lot of nonlinear phenomena.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a href="https://johncarlosbaez.wordpress.com/2013/07/23/monte-carlo-methods-in-climate-science/#comment-31930">nick</a>.</p>
<p>Nick wrote:</p>
<blockquote><p>
“containing related strongly related things”</p>
<p>This seems awkwardly phrased.
</p></blockquote>
<p>It was just a typo for &#8220;strongly related&#8221;, not a deliberate phrasing.  Fixed!</p>
<blockquote><p>
“red are predicted measurements”</p>
<p>I guess this is slightly ambiguous, depending on whether you’re referring to red as a line or a collection of points, but for consistency with the rest of your figure 2 description, I think it should be something like “red is the predicted measurement”
</p></blockquote>
<p>I&#8217;ll have to think about that.  Right now we&#8217;re calling <img src="https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m" class="latex" /> <b>the measurements</b>, and in our example it&#8217;s a list of numbers <img src="https://s0.wp.com/latex.php?latex=m_1%2C+%5Cdots%2C+m_T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m_1, &#92;dots, m_T" class="latex" />, each of which we could call &#8216;a measurement&#8217;, though actually we just say:</p>
<blockquote><p>
 Suppose our measurements are real numbers <img src="https://s0.wp.com/latex.php?latex=m_0%2C%5Cdots%2C+m_T&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m_0,&#92;dots, m_T" class="latex" /> related by</p>
<p><img src="https://s0.wp.com/latex.php?latex=m_%7Bt%2B1%7D+%3D+s+m_t+-+m_%7Bt-1%7D+%2B+N_t+&#038;bg=ffffff&#038;fg=333333&#038;s=0&#038;c=20201002" alt="m_{t+1} = s m_t - m_{t-1} + N_t " class="latex" />
</p></blockquote>
<p>So, the red curve shows &#8220;the measurements&#8221;.</p>
<blockquote><p>
 “modification s’ to the current settings s’ ”</p>
<p>Do you mean “modification s to the current settings s’ “?
</p></blockquote>
<p>No, we mean &#8220;the modification s&#8217; to the current settings s.  In math, primes are often used for &#8216;modified&#8217; or &#8216;changed&#8217; things.  Thanks for catching this mistake, though!  Fixed.</p>
<blockquote><p>
I feel like the word nonlinear should be included somewhere in this article.
</p></blockquote>
<p>Hmm, personally I&#8217;m a bit tired of how people keep emphasizing that real life involves a lot of nonlinear phenomena.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>

<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	>

<channel>
	<title>OpenData &#8211; Of Particular Significance</title>
	<atom:link href="https://profmattstrassler.com/tag/opendata/feed/" rel="self" type="application/rss+xml" />
	<link>https://profmattstrassler.com</link>
	<description>Conversations About Science with Theoretical Physicist Matt Strassler</description>
	<lastBuildDate>Thu, 21 Mar 2019 11:52:42 +0000</lastBuildDate>
	<language>en</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
<cloud domain='profmattstrassler.com' port='80' path='/?rsscloud=notify' registerProcedure='' protocol='http-post' />
<image>
		<url>https://secure.gravatar.com/blavatar/9192dd01619d8fdbea0a34ba4b097323?s=96&#038;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</url>
		<title>OpenData &#8211; Of Particular Significance</title>
		<link>https://profmattstrassler.com</link>
	</image>
	<atom:link rel="search" type="application/opensearchdescription+xml" href="https://profmattstrassler.com/osd.xml" title="Of Particular Significance" />
	<atom:link rel='hub' href='https://profmattstrassler.com/?pushpress=hub'/>
	<item>
		<title>The Importance and Challenges of &#8220;Open Data&#8221; at the Large Hadron Collider</title>
		<link>https://profmattstrassler.com/2019/03/19/the-importance-and-challenges-of-open-data-at-the-large-hadron-collider/</link>
					<comments>https://profmattstrassler.com/2019/03/19/the-importance-and-challenges-of-open-data-at-the-large-hadron-collider/#comments</comments>
		
		<dc:creator><![CDATA[Matt Strassler]]></dc:creator>
		<pubDate>Tue, 19 Mar 2019 13:35:25 +0000</pubDate>
				<category><![CDATA[History of Science]]></category>
		<category><![CDATA[LHC Background Info]]></category>
		<category><![CDATA[LHC News]]></category>
		<category><![CDATA[Particle Physics]]></category>
		<category><![CDATA[The Scientific Process]]></category>
		<category><![CDATA[cms]]></category>
		<category><![CDATA[LHC]]></category>
		<category><![CDATA[OpenData]]></category>
		<guid isPermaLink="false">http://profmattstrassler.com/?p=10236</guid>

					<description><![CDATA[A little while back I wrote a short post about some research that some colleagues and I did using &#8220;open data&#8221; from the Large Hadron Collider [LHC]. We used data made public by the CMS experimental collaboration &#8212; about 1% &#8230; <a href="https://profmattstrassler.com/2019/03/19/the-importance-and-challenges-of-open-data-at-the-large-hadron-collider/">Continue reading <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[<p>A little while back I wrote a <a href="https://profmattstrassler.com/2019/02/13/breaking-a-little-new-ground-at-the-large-hadron-collider/">short post</a> about some research that some colleagues and I did using &#8220;open data&#8221; from the <a href="https://profmattstrassler.com/articles-and-posts/largehadroncolliderfaq/">Large Hadron Collider</a> [LHC]. We used data made public by the <a href="https://home.cern/science/experiments/cms">CMS experimental collaboration</a> &#8212; about 1% of their current data &#8212; to search for a new particle, using a couple of twists (as proposed over 10 years ago) on a standard technique.  (CMS is one of the two general-purpose particle detectors at the LHC; the other is called ATLAS.)  We had two motivations: (1) Even if we didn&#8217;t find a new particle, we wanted to prove that our search method was effective; and (2) we wanted to stress-test the CMS Open Data framework, to assure it really does provide all the information needed for a search for something unknown.</p>
<p><a href="https://profmattstrassler.com/2019/02/19/a-broad-search-for-fast-hidden-particles/">Recently I discussed</a> (1), and today I want to address (2): to convey why open data from the LHC is useful but controversial, and why we felt it was important, as theoretical physicists <em>(i.e. people who perform particle physics calculations, but do not build and run the actual experiments)</em>, to do something with it that is usually the purview of experimenters.</p>
<p><strong>The Importance of Archiving Data</strong></p>
<p>In many subfields of physics and astronomy, data from experiments is made public as a matter of routine. Usually this occurs after an substantial delay, to allow the experimenters who collected the data to analyze it first for major discoveries. That&#8217;s as it should be: the experimenters spent years of their lives proposing, building and testing the experiment, and they deserve an uninterrupted opportunity to investigate its data. To force them to release data immediately would create a terrible disincentive for anyone to do all the hard work!</p>
<p>Data from particle physics colliders, however, has not historically been made public. More worrying, it has rarely been archived in a form that is easy for others to use at a later date. I&#8217;m not the right person to tell you the history of this situation, but I can give you a sense for why this still happens today.<span id="more-10236"></span></p>
<p>The fundamental issue is the complexity of data sets from colliders, especially from <a href="https://profmattstrassler.com/articles-and-posts/largehadroncolliderfaq/whats-a-hadron-as-in-large-hadron-collider/">hadron</a> colliders such as the Tevatron and the LHC. (Archiving was partly done for <a href="https://home.cern/science/accelerators/large-electron-positron-collider">LEP</a>, a simpler collider, and was used in later studies including <a href="https://arxiv.org/abs/1003.0705">this search for unusual Higgs decays</a>  and <a href="https://arxiv.org/abs/1610.06536">this controversial observation,</a> also <a href="https://profmattstrassler.com/2016/10/21/hiding-from-a-nightmare/">discussed here</a>.) What &#8220;complexity&#8221; are we talking about? Collisions of <a href="https://profmattstrassler.com/articles-and-posts/largehadroncolliderfaq/whats-a-proton-anyway/">protons</a> and/or anti-protons are intrinsically complicated; particles of all sorts go <a href="https://cds.cern.ch/record/2114779/files/diphoton_v0.png">flying in all directions</a>. The general purpose particle detectors ATLAS and CMS have a complex shape and aren&#8217;t uniform. (Here&#8217;s <a href="https://cms.cern/detector">a cutaway image showing CMS as a set of nested almost-cylinders</a>. Note also that there are inherent weak points: places where cooling tubes have to run, where bundles of wires have to bring signals in and out of the machine, and where segments of the detector join together.) Meanwhile the interactions of the particles with the detector&#8217;s material is messy and often subtle (here&#8217;s <a href="https://cds.cern.ch/record/2270046/files/Figure_001.png">a significantly oversimplified view</a>). Not every particle is detected, and the probability of missing one depends on where it passes through the detector and what type of particle it is.</p>
<p>Even more important, 99.999% percent of ATLAS and CMS data is discarded as it comes in; only data which passes a set of filters, collectively called <a href="https://profmattstrassler.com/articles-and-posts/largehadroncolliderfaq/the-trigger-discarding-all-but-the-gold/">the &#8220;trigger,&#8221;</a> will even be stored. The trigger is adjusted regularly as experimental conditions change. If you don&#8217;t understand these filters in detail, you can&#8217;t understand the data. Meanwhile the strategies for processing the raw data change over time, becoming more sophisticated, and introducing their own issues that must be known and managed.</p>
<p>I could easily go on (did I mention that at the LHC <a href="https://cds.cern.ch/record/1479324/files/198609-56-3565522e.png">dozens of collisions occur simultaneously?</a>) If, when you explore the data, you fail to account for all these issues, you can mistake a glitch for a new physical effect, or fail to observe a new physical effect because a glitch obscured it. Any experimentalist inside the collaborations is aware of most of these subtleties, and is surrounded by other experts who will be quick to complain if he or she forgets to account for one of them. That&#8217;s why it&#8217;s rare for the experimenters to report a result that has this type of error embedded in it.</p>
<p>Now,<strong><em> imagine writing a handbook that would encapsulate all of that combined knowledge, for use by people who will someday analyze the data without having access to that collective human library.</em></strong> This handbook would accompany an enormous data set taken in changing conditions, and would need to contain everything a person could possibly need to know in order to properly analyze data from an LHC experiment without making a technical error.</p>
<p><strong>Not easy!</strong> But this is what the <a href="http://opendata.cern.ch/">Open Data project at CERN</a>, in which CMS is one of the participating experiments, aims to do. Because it&#8217;s extremely difficult, and therefore expensive in personnel and time, its value has to be clear.</p>
<p>I personally do think the value <strong><em>is</em></strong> clear, especially at the LHC. Until the last couple of decades, one could argue that data from an old particle physics experiment would go out of date so quickly, superseded by better experiments, that it really wasn&#8217;t needed. But this argument has broken down as experiments have become more expensive, with new ones less frequent. There is no guarantee, for instance, that any machine superseding the LHC will be built during my lifetime; it is a minimum of 20 and perhaps 40 years away. In all that time, the LHC&#8217;s data will be the state of the art in proton-proton collider physics, so it ought to be stored so that experts can use it 25 years from now. The price for making that possible has to be paid.</p>
<p><em>[This price was not paid for the Tevatron, whose data, which will remain the gold standard for <strong>proton-antiproton</strong> collisions for perhaps a century or more, is not well-archived.]</em></p>
<p><strong>Was Using Open Data Necessary For Our Project?</strong></p>
<p>Even if we all agree that it&#8217;s important to archive LHC data so that it can be used by future experimental physicists, it&#8217;s not obvious that <strong><em>today&#8217;s theorists</em> </strong>should use it. There&#8217;s an alternative: a theorist with a particular idea can temporarily join one of the experimental collaborations, and carry out the research with like-minded experimental colleagues. In principle, this is a much better way to do things; it permits access to the full data set, it allows the expert experimentalists to handle and manage the data instead of amateurs like us, and it should in principle lead to state-of-the-art results.</p>
<p>I haven&#8217;t found this approach to work. I&#8217;ve been recommending the use of our technique <a href="https://profmattstrassler.com/2019/02/19/a-broad-search-for-fast-hidden-particles/"><em>[selecting events where the transverse momentum of the muon and antimuon pair is large, and often dropping isolation requirements]</em></a> for over ten years, along with several related techniques. These remarks appear in <a href="https://arxiv.org/abs/0712.2041">papers</a>; I&#8217;ve mentioned these issues in <a href="https://indico.cern.ch/event/94815/contributions/1282671/">many talks</a>, discussed them in detail with at least two dozen experimentalists at ATLAS and CMS (including many colleagues at Harvard), and even started a preliminary project with an experimenter to study them. But everyone had a reason not to proceed. I was told, over and over again, &#8220;Don&#8217;t worry, we&#8217;ll get to this next year.&#8221; After a decade of this, I came to feel that perhaps it would be best if we carried out the analysis ourselves.</p>
<p>Even then, there was an alternative: we could have just done a study of our method using simulated data, and this would have proved the value of our technique. Why spend the huge amount of time and effort to do a detailed analysis, on a fraction of the real data?</p>
<p>First, I worried that a study on simulated data would be no more effective than all of the talks I gave and all the personal encouraging I did over the previous ten years. I think seeing the study done for real has a lot more impact, because it shows explicitly how effective the technique is and how easily it is implemented. <em>[Gosh, if even theorists can do it&#8230;]</em></p>
<p>Second, one of the things we did in our study is include &#8220;non-isolated muons&#8221; &#8212; muons that have other particles close by &#8212; which are normally not included in theorists&#8217; studies. Dropping the usual isolation criteria may be essential for discoveries of hidden particles, as Kathryn Zurek and I have emphasized since 2006 (and studied in <a href="https://arxiv.org/abs/0712.2041">a paper with Han and Si, in 2007</a>). I felt it was important to show this explicitly in our study. But we needed the real data to do this; simulation of the background sources for non-isolated muons would not have been accurate. <em>[The experimenters rarely use non-isolated muons in the type of analysis we carried out, but notably <a href="https://arxiv.org/abs/1808.01890">have been doing so here</a>; my impression is that they were unaware of our work from 2007 and came to this approach independently.]</em></p>
<p><strong>Stress Testing the Archive</strong></p>
<p>A further benefit to using the real data was that we stress-tested the archiving procedure in the Open Data project, and to do this fully, we had to carry out our analysis to the very end. The success or failure of our analysis was a test of whether the CMS Open Data framework truly provides all the information needed to do a complete search for something unknown.</p>
<p>The test received a passing grade, with qualifications. Not only we did complete the project, we were able to repeat a rather precise measurement of the (well-known) cross-section for Z boson production, which would have failed if the archive and the accompanying information had been unusable. That said, there is room for improvement: small things were missing, including some calibration information and some simulated data. The biggest issue is perhaps the format for the data storage (difficult to use and unpack for a typical user).</p>
<p>It&#8217;s important to recognize that the persons in charge of Open Data at CMS have a huge and difficult job; they have to figure out how to write the nearly impossible handbook I referred to above. It&#8217;s therefore crucial that people like our group of theorists actually use the open data sets <em><strong>now</strong></em>, not just after the LHC is over. <em><strong>Now</strong></em>, when the open data sets are still small, is the time to figure out what information is missing, to determine how to improve the data storage, to fill out the documentation and make sure it has no gaps. We hope we&#8217;ve contributed something to that process.</p>
<p><strong>The Future</strong></p>
<p>Should others follow in our footsteps? Yes, I think, though not lightly. In our case, five experts required two years to do the simplest possible study; we could have done it in one year if we&#8217;d been more efficient, but probably not much less. Do not underestimate what this takes, both in terms of understanding the data and learning how to do statistical analysis that most people rarely undertake.</p>
<p>But there are studies that simply cannot be done without real data, and unless you can convince an experimentalist to work with you, your only choice may be to dive in and do your best. And if you are already somewhat informed, but want to learn more about how real experimental analysis is done, so you can appreciate more fully what is typically hidden from view, you will not find a better self-training ground. If you want to take it on, I suggest, as an initial test, that you try to replicate our measurement of the Z boson cross-section. If you can&#8217;t, you&#8217;re not ready for anything else.</p>
<p>I should emphasize that Open Data is a resource that can be used in other ways, and several groups have already done this. In addition to <a href="https://arxiv.org/abs/1704.05842">detailed studies</a> of <a href="https://profmattstrassler.com/articles-and-posts/particle-physics-basics/the-known-apparently-elementary-particles/jets-the-manifestation-of-quarks-and-gluons/">jets</a> carried out on the <em><strong>real</strong></em> data by my collaborators, led by Professor Jesse Thaler, there have been <a href="https://arxiv.org/abs/1807.11916">studies</a> that have relied solely on the archive of <em><strong>simulated</strong></em> data also provided by the CMS Open Data project. These have value too, in that they offer proving grounds for techniques to be applied later to real data. Since exploratory studies of simulated data don&#8217;t require the extreme care that analysis of real data demands, there may be a lot of potential in this aspect of the Open Data project.</p>
<p>In the end, our research study, like most analyses, is just a drop in the huge bucket of information learned from the LHC. Its details should not obscure the larger question: <em><strong>how shall we, as a community, maintain the LHC data set so that it can continue to provide information across the decades?</strong></em> Maybe the Open Data project is the best approach.  If so, how can we best support it?  And if not, what is the alternative?</p>
]]></content:encoded>
					
					<wfw:commentRss>https://profmattstrassler.com/2019/03/19/the-importance-and-challenges-of-open-data-at-the-large-hadron-collider/feed/</wfw:commentRss>
			<slash:comments>25</slash:comments>
		
		
		
		<media:content url="https://1.gravatar.com/avatar/adeb244d3a56730027286aae9204ecc5?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">profmattstrassler</media:title>
		</media:content>
	</item>
	</channel>
</rss>
